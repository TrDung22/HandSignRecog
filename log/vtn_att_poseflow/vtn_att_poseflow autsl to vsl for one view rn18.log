2024-10-12 09:41:29,689 [INFO] Starting vtn_att_poseflow/vtn_att_poseflow autsl to vsl for one view rn18...


2024-10-12 09:50:46,083 [INFO] Starting vtn_att_poseflow/vtn_att_poseflow autsl to vsl for one view rn18...


2024-10-12 09:54:17,101 [INFO] Starting vtn_att_poseflow/vtn_att_poseflow autsl to vsl for one view rn18...


2024-10-12 09:55:34,506 [INFO] Step[50/938]: training loss : 6.405645112991333 TRAIN  loss dict:  {'classification_loss': 6.405645112991333}
2024-10-12 09:56:09,082 [INFO] Step[100/938]: training loss : 5.23721399307251 TRAIN  loss dict:  {'classification_loss': 5.23721399307251}
2024-10-12 09:56:43,749 [INFO] Step[150/938]: training loss : 4.147128620147705 TRAIN  loss dict:  {'classification_loss': 4.147128620147705}
2024-10-12 09:57:18,389 [INFO] Step[200/938]: training loss : 3.151425018310547 TRAIN  loss dict:  {'classification_loss': 3.151425018310547}
2024-10-12 09:57:53,163 [INFO] Step[250/938]: training loss : 2.3554966473579406 TRAIN  loss dict:  {'classification_loss': 2.3554966473579406}
2024-10-12 09:58:27,882 [INFO] Step[300/938]: training loss : 1.8885463571548462 TRAIN  loss dict:  {'classification_loss': 1.8885463571548462}
2024-10-12 09:59:02,681 [INFO] Step[350/938]: training loss : 1.5283675587177277 TRAIN  loss dict:  {'classification_loss': 1.5283675587177277}
2024-10-12 09:59:37,547 [INFO] Step[400/938]: training loss : 1.3562393748760224 TRAIN  loss dict:  {'classification_loss': 1.3562393748760224}
2024-10-12 10:00:12,779 [INFO] Step[450/938]: training loss : 1.2383452022075654 TRAIN  loss dict:  {'classification_loss': 1.2383452022075654}
2024-10-12 10:00:48,568 [INFO] Step[500/938]: training loss : 1.1205270040035247 TRAIN  loss dict:  {'classification_loss': 1.1205270040035247}
2024-10-12 10:01:34,892 [INFO] Step[550/938]: training loss : 0.9059762907028198 TRAIN  loss dict:  {'classification_loss': 0.9059762907028198}
2024-10-12 10:02:29,950 [INFO] Step[600/938]: training loss : 0.89553113758564 TRAIN  loss dict:  {'classification_loss': 0.89553113758564}
2024-10-12 10:03:24,435 [INFO] Step[650/938]: training loss : 0.800469828248024 TRAIN  loss dict:  {'classification_loss': 0.800469828248024}
2024-10-12 10:04:19,085 [INFO] Step[700/938]: training loss : 0.790835200548172 TRAIN  loss dict:  {'classification_loss': 0.790835200548172}
2024-10-12 10:05:14,050 [INFO] Step[750/938]: training loss : 0.7525590705871582 TRAIN  loss dict:  {'classification_loss': 0.7525590705871582}
2024-10-12 10:06:08,674 [INFO] Step[800/938]: training loss : 0.7196043688058853 TRAIN  loss dict:  {'classification_loss': 0.7196043688058853}
2024-10-12 10:07:03,597 [INFO] Step[850/938]: training loss : 0.7164033722877502 TRAIN  loss dict:  {'classification_loss': 0.7164033722877502}
2024-10-12 10:07:57,822 [INFO] Step[900/938]: training loss : 0.7082286769151688 TRAIN  loss dict:  {'classification_loss': 0.7082286769151688}
2024-10-12 10:11:00,050 [INFO] Label accuracies statistics:
2024-10-12 10:11:00,050 [INFO] {0: 0.9, 1: 0.7894736842105263, 2: 0.85, 3: 1.0, 4: 0.9, 5: 0.75, 6: 0.23076923076923078, 7: 0.9, 8: 0.7, 9: 0.631578947368421, 10: 0.8421052631578947, 11: 0.95, 12: 0.6842105263157895, 13: 0.9, 14: 0.8, 15: 1.0, 16: 0.7, 17: 0.3333333333333333, 18: 0.6470588235294118, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 0.7368421052631579, 22: 0.6, 23: 0.9, 24: 0.5263157894736842, 25: 0.95, 26: 0.8947368421052632, 27: 1.0, 28: 0.85, 29: 1.0, 30: 0.9, 31: 0.9, 32: 0.85, 33: 0.95, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.9, 41: 1.0, 42: 1.0, 43: 0.65, 44: 1.0, 45: 0.8, 46: 0.9, 47: 0.45, 48: 0.35, 49: 0.8947368421052632, 50: 0.8, 51: 0.5555555555555556, 52: 0.7777777777777778, 53: 1.0, 54: 0.8, 55: 0.7368421052631579, 56: 1.0, 57: 0.8, 58: 0.625, 59: 0.5555555555555556, 60: 0.8, 61: 0.7368421052631579, 62: 0.8421052631578947, 63: 1.0, 64: 0.9, 65: 0.6, 66: 1.0, 67: 0.75, 68: 0.7777777777777778, 69: 0.8888888888888888, 70: 0.85, 71: 0.7, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.7, 76: 0.5263157894736842, 77: 1.0, 78: 0.7, 79: 1.0, 80: 1.0, 81: 0.7, 82: 0.75, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.7, 87: 0.8823529411764706, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.85, 92: 0.8, 93: 0.85, 94: 0.8421052631578947, 95: 0.75, 96: 0.7058823529411765, 97: 0.4, 98: 0.631578947368421, 99: 0.95, 100: 1.0, 101: 0.95, 102: 0.8947368421052632, 103: 0.8, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.95, 109: 0.95, 110: 0.9, 111: 0.85, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 0.8, 121: 0.95, 122: 0.2, 123: 0.8, 124: 0.95, 125: 0.65, 126: 0.8, 127: 0.65, 128: 0.9, 129: 0.85, 130: 1.0, 131: 0.875, 132: 0.7368421052631579, 133: 0.85, 134: 0.6, 135: 0.65, 136: 0.9, 137: 0.85, 138: 0.85, 139: 0.85, 140: 0.65, 141: 1.0, 142: 0.8, 143: 1.0, 144: 0.85, 145: 0.631578947368421, 146: 0.9, 147: 0.8, 148: 0.65, 149: 1.0, 150: 0.6, 151: 1.0, 152: 0.65, 153: 0.6, 154: 0.65, 155: 0.9, 156: 0.9473684210526315, 157: 1.0, 158: 0.8235294117647058, 159: 1.0, 160: 0.9, 161: 0.85, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.5, 166: 0.05, 167: 0.9, 168: 0.8, 169: 1.0, 170: 0.9473684210526315, 171: 0.9, 172: 0.3, 173: 0.7, 174: 1.0, 175: 0.6111111111111112, 176: 1.0, 177: 1.0, 178: 0.6, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.6, 183: 0.9, 184: 1.0, 185: 0.85, 186: 0.9, 187: 0.9473684210526315, 188: 0.85, 189: 0.95, 190: 0.7, 191: 1.0, 192: 0.85, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.95, 199: 0.75, 200: 0.9473684210526315, 201: 1.0, 202: 0.7, 203: 0.7, 204: 0.95, 205: 0.85, 206: 0.5, 207: 0.7, 208: 0.9, 209: 0.95, 210: 1.0, 211: 0.85, 212: 0.8235294117647058, 213: 0.85, 214: 0.85, 215: 0.85, 216: 0.85, 217: 0.65, 218: 0.9, 219: 1.0, 220: 0.55, 221: 0.6, 222: 1.0, 223: 0.9, 224: 0.75, 225: 0.9}

2024-10-12 10:11:00,367 [INFO] [1] TRAIN  loss: 1.874931493484135 acc: 0.5646239158253946
2024-10-12 10:11:00,367 [INFO] [1] TRAIN  loss dict: {'classification_loss': 1.874931493484135}
2024-10-12 10:11:00,367 [INFO] [1] VALIDATION loss: 0.5941465875335239 VALIDATION  acc: 0.8327297419646899
2024-10-12 10:11:00,367 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 0.5941465875335239}
2024-10-12 10:11:00,367 [INFO] 
2024-10-12 10:12:29,385 [INFO] Step[50/938]: training loss : 0.5425925430655479 TRAIN  loss dict:  {'classification_loss': 0.5425925430655479}
2024-10-12 10:13:24,010 [INFO] Step[100/938]: training loss : 0.46764096021652224 TRAIN  loss dict:  {'classification_loss': 0.46764096021652224}
2024-10-12 10:14:18,777 [INFO] Step[150/938]: training loss : 0.47552942276000976 TRAIN  loss dict:  {'classification_loss': 0.47552942276000976}
2024-10-12 10:15:13,465 [INFO] Step[200/938]: training loss : 0.4589027336239815 TRAIN  loss dict:  {'classification_loss': 0.4589027336239815}
2024-10-12 10:16:08,140 [INFO] Step[250/938]: training loss : 0.4636331981420517 TRAIN  loss dict:  {'classification_loss': 0.4636331981420517}
2024-10-12 10:17:02,893 [INFO] Step[300/938]: training loss : 0.4454987758398056 TRAIN  loss dict:  {'classification_loss': 0.4454987758398056}
2024-10-12 10:17:57,711 [INFO] Step[350/938]: training loss : 0.49874210596084595 TRAIN  loss dict:  {'classification_loss': 0.49874210596084595}
2024-10-12 10:18:52,541 [INFO] Step[400/938]: training loss : 0.43041056334972383 TRAIN  loss dict:  {'classification_loss': 0.43041056334972383}
2024-10-12 10:19:47,132 [INFO] Step[450/938]: training loss : 0.4207004538178444 TRAIN  loss dict:  {'classification_loss': 0.4207004538178444}
2024-10-12 10:20:42,064 [INFO] Step[500/938]: training loss : 0.4182871960103512 TRAIN  loss dict:  {'classification_loss': 0.4182871960103512}
2024-10-12 10:21:36,747 [INFO] Step[550/938]: training loss : 0.4185797543823719 TRAIN  loss dict:  {'classification_loss': 0.4185797543823719}
2024-10-12 10:22:31,543 [INFO] Step[600/938]: training loss : 0.38126819998025896 TRAIN  loss dict:  {'classification_loss': 0.38126819998025896}
2024-10-12 10:23:26,310 [INFO] Step[650/938]: training loss : 0.399193467348814 TRAIN  loss dict:  {'classification_loss': 0.399193467348814}
2024-10-12 10:24:21,015 [INFO] Step[700/938]: training loss : 0.3637099054455757 TRAIN  loss dict:  {'classification_loss': 0.3637099054455757}
2024-10-12 10:25:15,882 [INFO] Step[750/938]: training loss : 0.3312704787403345 TRAIN  loss dict:  {'classification_loss': 0.3312704787403345}
2024-10-12 10:26:10,656 [INFO] Step[800/938]: training loss : 0.4007953380048275 TRAIN  loss dict:  {'classification_loss': 0.4007953380048275}
2024-10-12 10:27:05,695 [INFO] Step[850/938]: training loss : 0.37238142669200897 TRAIN  loss dict:  {'classification_loss': 0.37238142669200897}
2024-10-12 10:27:59,783 [INFO] Step[900/938]: training loss : 0.3548353846371174 TRAIN  loss dict:  {'classification_loss': 0.3548353846371174}
2024-10-12 10:30:52,004 [INFO] Label accuracies statistics:
2024-10-12 10:30:52,004 [INFO] {0: 0.9, 1: 1.0, 2: 0.85, 3: 1.0, 4: 0.9, 5: 0.7, 6: 0.38461538461538464, 7: 0.95, 8: 0.85, 9: 0.7894736842105263, 10: 0.8421052631578947, 11: 0.95, 12: 0.6842105263157895, 13: 0.9, 14: 1.0, 15: 1.0, 16: 0.7, 17: 0.7222222222222222, 18: 0.9411764705882353, 19: 1.0, 20: 1.0, 21: 0.8947368421052632, 22: 0.8, 23: 0.9, 24: 0.3684210526315789, 25: 0.9, 26: 0.8947368421052632, 27: 0.85, 28: 0.8, 29: 1.0, 30: 0.95, 31: 1.0, 32: 0.75, 33: 0.95, 34: 0.9, 35: 1.0, 36: 0.9473684210526315, 37: 0.75, 38: 0.9, 39: 1.0, 40: 0.85, 41: 1.0, 42: 0.95, 43: 0.95, 44: 0.9473684210526315, 45: 0.75, 46: 0.9, 47: 0.2, 48: 0.45, 49: 0.7368421052631579, 50: 0.9, 51: 0.8333333333333334, 52: 0.5555555555555556, 53: 0.95, 54: 0.8, 55: 0.8947368421052632, 56: 1.0, 57: 0.85, 58: 0.8125, 59: 0.7777777777777778, 60: 0.9, 61: 0.7894736842105263, 62: 0.631578947368421, 63: 0.8947368421052632, 64: 0.9, 65: 0.8, 66: 1.0, 67: 0.9, 68: 0.6666666666666666, 69: 0.9444444444444444, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.85, 76: 1.0, 77: 1.0, 78: 0.6, 79: 1.0, 80: 0.95, 81: 0.75, 82: 0.75, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.65, 92: 1.0, 93: 0.95, 94: 0.9473684210526315, 95: 1.0, 96: 0.47058823529411764, 97: 0.45, 98: 0.7894736842105263, 99: 1.0, 100: 0.95, 101: 0.8, 102: 1.0, 103: 0.8, 104: 0.7, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.8, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 0.9, 121: 1.0, 122: 0.3, 123: 1.0, 124: 1.0, 125: 0.8, 126: 0.7, 127: 0.65, 128: 0.8, 129: 0.45, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 0.95, 135: 1.0, 136: 0.9, 137: 0.85, 138: 0.9, 139: 0.95, 140: 0.55, 141: 1.0, 142: 0.9, 143: 0.9, 144: 0.85, 145: 0.9473684210526315, 146: 0.9, 147: 0.85, 148: 0.95, 149: 0.7894736842105263, 150: 0.65, 151: 1.0, 152: 0.95, 153: 0.7, 154: 0.75, 155: 0.95, 156: 0.8947368421052632, 157: 0.9, 158: 0.8235294117647058, 159: 0.95, 160: 0.95, 161: 0.9, 162: 0.7, 163: 0.65, 164: 0.8947368421052632, 165: 0.65, 166: 0.7, 167: 1.0, 168: 0.95, 169: 1.0, 170: 0.9473684210526315, 171: 1.0, 172: 0.4, 173: 0.9, 174: 1.0, 175: 0.7222222222222222, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.9, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.6, 184: 0.9, 185: 0.9, 186: 0.95, 187: 0.8421052631578947, 188: 0.9, 189: 0.85, 190: 1.0, 191: 1.0, 192: 0.8, 193: 0.8, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.95, 198: 1.0, 199: 0.85, 200: 0.8947368421052632, 201: 1.0, 202: 0.95, 203: 0.65, 204: 0.75, 205: 0.85, 206: 0.5, 207: 0.75, 208: 0.85, 209: 0.95, 210: 0.95, 211: 0.7, 212: 0.7647058823529411, 213: 0.85, 214: 0.85, 215: 0.9, 216: 0.6, 217: 0.85, 218: 0.9, 219: 1.0, 220: 0.6, 221: 0.6, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.8}

2024-10-12 10:30:52,441 [INFO] [2] TRAIN  loss: 0.42190546236995824 acc: 0.8687615526802218
2024-10-12 10:30:52,441 [INFO] [2] TRAIN  loss dict: {'classification_loss': 0.42190546236995824}
2024-10-12 10:30:52,441 [INFO] [2] VALIDATION loss: 0.48263851911886724 VALIDATION  acc: 0.8619284744228157
2024-10-12 10:30:52,441 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 0.48263851911886724}
2024-10-12 10:30:52,441 [INFO] 
2024-10-12 10:32:21,206 [INFO] Step[50/938]: training loss : 0.29953095100820065 TRAIN  loss dict:  {'classification_loss': 0.29953095100820065}
2024-10-12 10:33:15,802 [INFO] Step[100/938]: training loss : 0.3069015258550644 TRAIN  loss dict:  {'classification_loss': 0.3069015258550644}
2024-10-12 10:34:10,699 [INFO] Step[150/938]: training loss : 0.2636971249431372 TRAIN  loss dict:  {'classification_loss': 0.2636971249431372}
2024-10-12 10:35:04,723 [INFO] Step[200/938]: training loss : 0.24964174337685108 TRAIN  loss dict:  {'classification_loss': 0.24964174337685108}
2024-10-12 10:35:59,396 [INFO] Step[250/938]: training loss : 0.27426298007369043 TRAIN  loss dict:  {'classification_loss': 0.27426298007369043}
2024-10-12 10:36:53,998 [INFO] Step[300/938]: training loss : 0.27383080527186393 TRAIN  loss dict:  {'classification_loss': 0.27383080527186393}
2024-10-12 10:37:48,755 [INFO] Step[350/938]: training loss : 0.30950536601245404 TRAIN  loss dict:  {'classification_loss': 0.30950536601245404}
2024-10-12 10:38:43,610 [INFO] Step[400/938]: training loss : 0.2813314621895552 TRAIN  loss dict:  {'classification_loss': 0.2813314621895552}
2024-10-12 10:39:38,143 [INFO] Step[450/938]: training loss : 0.2830413627624512 TRAIN  loss dict:  {'classification_loss': 0.2830413627624512}
2024-10-12 10:40:33,008 [INFO] Step[500/938]: training loss : 0.26997459411621094 TRAIN  loss dict:  {'classification_loss': 0.26997459411621094}
2024-10-12 10:41:27,647 [INFO] Step[550/938]: training loss : 0.2799578133225441 TRAIN  loss dict:  {'classification_loss': 0.2799578133225441}
2024-10-12 10:42:22,372 [INFO] Step[600/938]: training loss : 0.25634220995008944 TRAIN  loss dict:  {'classification_loss': 0.25634220995008944}
2024-10-12 10:43:17,220 [INFO] Step[650/938]: training loss : 0.2469481809437275 TRAIN  loss dict:  {'classification_loss': 0.2469481809437275}
2024-10-12 10:44:11,906 [INFO] Step[700/938]: training loss : 0.2638852822780609 TRAIN  loss dict:  {'classification_loss': 0.2638852822780609}
2024-10-12 10:45:06,773 [INFO] Step[750/938]: training loss : 0.2287543934583664 TRAIN  loss dict:  {'classification_loss': 0.2287543934583664}
2024-10-12 10:46:01,459 [INFO] Step[800/938]: training loss : 0.2761218209564686 TRAIN  loss dict:  {'classification_loss': 0.2761218209564686}
2024-10-12 10:46:56,415 [INFO] Step[850/938]: training loss : 0.2609690874814987 TRAIN  loss dict:  {'classification_loss': 0.2609690874814987}
2024-10-12 10:47:50,530 [INFO] Step[900/938]: training loss : 0.22198425479233264 TRAIN  loss dict:  {'classification_loss': 0.22198425479233264}
2024-10-12 10:50:43,473 [INFO] Label accuracies statistics:
2024-10-12 10:50:43,473 [INFO] {0: 0.85, 1: 1.0, 2: 0.85, 3: 0.9473684210526315, 4: 0.85, 5: 0.75, 6: 0.3076923076923077, 7: 0.85, 8: 0.7, 9: 0.9473684210526315, 10: 0.9473684210526315, 11: 0.85, 12: 0.631578947368421, 13: 0.9, 14: 1.0, 15: 0.9, 16: 0.45, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.7894736842105263, 21: 0.7894736842105263, 22: 0.85, 23: 0.85, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.9, 31: 0.8, 32: 1.0, 33: 0.95, 34: 0.75, 35: 1.0, 36: 0.6842105263157895, 37: 0.55, 38: 0.9, 39: 1.0, 40: 0.95, 41: 0.9, 42: 0.95, 43: 0.95, 44: 0.9473684210526315, 45: 0.9, 46: 0.9, 47: 0.35, 48: 0.5, 49: 0.8947368421052632, 50: 0.9, 51: 0.8888888888888888, 52: 0.5555555555555556, 53: 1.0, 54: 0.95, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.5, 59: 0.6666666666666666, 60: 0.85, 61: 0.6842105263157895, 62: 0.5263157894736842, 63: 0.7894736842105263, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.65, 68: 0.7777777777777778, 69: 0.8333333333333334, 70: 0.8, 71: 0.8, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.65, 76: 0.9473684210526315, 77: 1.0, 78: 0.7, 79: 1.0, 80: 1.0, 81: 0.7, 82: 0.7, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.95, 89: 0.8823529411764706, 90: 0.8, 91: 0.9, 92: 0.95, 93: 1.0, 94: 0.9473684210526315, 95: 0.9166666666666666, 96: 0.4117647058823529, 97: 0.65, 98: 0.7368421052631579, 99: 0.95, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.8, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.8, 112: 1.0, 113: 0.85, 114: 0.9, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.9, 121: 0.9, 122: 0.8, 123: 0.75, 124: 1.0, 125: 0.85, 126: 0.65, 127: 0.75, 128: 0.9, 129: 0.85, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 0.55, 135: 0.95, 136: 0.95, 137: 0.8, 138: 0.85, 139: 0.85, 140: 0.75, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.85, 145: 0.8947368421052632, 146: 0.95, 147: 0.75, 148: 0.75, 149: 0.7894736842105263, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.75, 154: 0.65, 155: 0.95, 156: 1.0, 157: 1.0, 158: 0.7647058823529411, 159: 1.0, 160: 0.95, 161: 0.75, 162: 1.0, 163: 0.95, 164: 0.8421052631578947, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.8, 173: 0.8, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.7, 184: 1.0, 185: 0.95, 186: 0.8, 187: 1.0, 188: 0.9, 189: 1.0, 190: 0.75, 191: 1.0, 192: 0.95, 193: 1.0, 194: 0.95, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.85, 200: 0.9473684210526315, 201: 1.0, 202: 1.0, 203: 0.8, 204: 0.8, 205: 0.45, 206: 0.3888888888888889, 207: 0.75, 208: 0.75, 209: 0.95, 210: 1.0, 211: 0.9, 212: 1.0, 213: 0.85, 214: 0.9, 215: 0.9, 216: 0.75, 217: 0.8, 218: 1.0, 219: 1.0, 220: 0.9, 221: 0.6, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.95}

2024-10-12 10:50:43,973 [INFO] [3] TRAIN  loss: 0.2685896376175667 acc: 0.9154343807763401
2024-10-12 10:50:43,973 [INFO] [3] TRAIN  loss dict: {'classification_loss': 0.2685896376175667}
2024-10-12 10:50:43,973 [INFO] [3] VALIDATION loss: 0.44879417939463984 VALIDATION  acc: 0.8721140787686736
2024-10-12 10:50:43,973 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 0.44879417939463984}
2024-10-12 10:50:43,973 [INFO] 
2024-10-12 10:52:12,892 [INFO] Step[50/938]: training loss : 0.22413086988031863 TRAIN  loss dict:  {'classification_loss': 0.22413086988031863}
2024-10-12 10:53:07,302 [INFO] Step[100/938]: training loss : 0.21401634119451046 TRAIN  loss dict:  {'classification_loss': 0.21401634119451046}
2024-10-12 10:54:01,901 [INFO] Step[150/938]: training loss : 0.187381047680974 TRAIN  loss dict:  {'classification_loss': 0.187381047680974}
2024-10-12 10:54:56,369 [INFO] Step[200/938]: training loss : 0.20197000563144685 TRAIN  loss dict:  {'classification_loss': 0.20197000563144685}
2024-10-12 10:55:51,150 [INFO] Step[250/938]: training loss : 0.1975416900962591 TRAIN  loss dict:  {'classification_loss': 0.1975416900962591}
2024-10-12 10:56:45,621 [INFO] Step[300/938]: training loss : 0.17478776324540377 TRAIN  loss dict:  {'classification_loss': 0.17478776324540377}
2024-10-12 10:57:40,025 [INFO] Step[350/938]: training loss : 0.22773423567414283 TRAIN  loss dict:  {'classification_loss': 0.22773423567414283}
2024-10-12 10:58:34,758 [INFO] Step[400/938]: training loss : 0.18095728516578674 TRAIN  loss dict:  {'classification_loss': 0.18095728516578674}
2024-10-12 10:59:29,235 [INFO] Step[450/938]: training loss : 0.21080261997878552 TRAIN  loss dict:  {'classification_loss': 0.21080261997878552}
2024-10-12 11:00:24,323 [INFO] Step[500/938]: training loss : 0.18001933615654708 TRAIN  loss dict:  {'classification_loss': 0.18001933615654708}
2024-10-12 11:01:18,909 [INFO] Step[550/938]: training loss : 0.18567950770258904 TRAIN  loss dict:  {'classification_loss': 0.18567950770258904}
2024-10-12 11:02:13,485 [INFO] Step[600/938]: training loss : 0.19143879175186157 TRAIN  loss dict:  {'classification_loss': 0.19143879175186157}
2024-10-12 11:03:08,019 [INFO] Step[650/938]: training loss : 0.19062630206346512 TRAIN  loss dict:  {'classification_loss': 0.19062630206346512}
2024-10-12 11:04:02,636 [INFO] Step[700/938]: training loss : 0.18047089625149965 TRAIN  loss dict:  {'classification_loss': 0.18047089625149965}
2024-10-12 11:04:57,198 [INFO] Step[750/938]: training loss : 0.1831180017441511 TRAIN  loss dict:  {'classification_loss': 0.1831180017441511}
2024-10-12 11:05:51,738 [INFO] Step[800/938]: training loss : 0.1904440525919199 TRAIN  loss dict:  {'classification_loss': 0.1904440525919199}
2024-10-12 11:06:46,597 [INFO] Step[850/938]: training loss : 0.18882490266114474 TRAIN  loss dict:  {'classification_loss': 0.18882490266114474}
2024-10-12 11:07:39,866 [INFO] Step[900/938]: training loss : 0.1827451378852129 TRAIN  loss dict:  {'classification_loss': 0.1827451378852129}
2024-10-12 11:10:32,366 [INFO] Label accuracies statistics:
2024-10-12 11:10:32,366 [INFO] {0: 0.7, 1: 1.0, 2: 0.85, 3: 1.0, 4: 0.8, 5: 0.9, 6: 0.5384615384615384, 7: 0.95, 8: 0.85, 9: 0.8421052631578947, 10: 1.0, 11: 0.95, 12: 0.8947368421052632, 13: 0.75, 14: 1.0, 15: 1.0, 16: 0.55, 17: 0.7777777777777778, 18: 0.7647058823529411, 19: 0.6842105263157895, 20: 0.8421052631578947, 21: 1.0, 22: 0.8, 23: 0.9, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 0.7, 29: 0.9, 30: 0.85, 31: 0.9, 32: 0.95, 33: 0.85, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.8, 38: 0.85, 39: 1.0, 40: 0.7, 41: 1.0, 42: 0.85, 43: 0.85, 44: 0.9473684210526315, 45: 0.95, 46: 0.9, 47: 0.2, 48: 0.75, 49: 0.8421052631578947, 50: 0.95, 51: 0.8888888888888888, 52: 0.8333333333333334, 53: 0.85, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.75, 58: 0.75, 59: 0.9444444444444444, 60: 0.9, 61: 0.8421052631578947, 62: 0.47368421052631576, 63: 0.9473684210526315, 64: 0.75, 65: 0.9, 66: 1.0, 67: 0.8, 68: 0.7777777777777778, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.9, 76: 0.9473684210526315, 77: 1.0, 78: 0.8, 79: 1.0, 80: 0.85, 81: 0.9, 82: 0.8, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.85, 92: 1.0, 93: 0.9, 94: 0.8947368421052632, 95: 0.6666666666666666, 96: 0.47058823529411764, 97: 0.7, 98: 0.47368421052631576, 99: 0.95, 100: 0.95, 101: 0.95, 102: 0.9473684210526315, 103: 0.8, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.65, 108: 1.0, 109: 1.0, 110: 0.8, 111: 0.55, 112: 1.0, 113: 0.95, 114: 0.95, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 1.0, 122: 0.5, 123: 0.8, 124: 1.0, 125: 0.7, 126: 0.75, 127: 0.9, 128: 0.9, 129: 0.8, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 0.95, 135: 1.0, 136: 0.95, 137: 0.85, 138: 0.95, 139: 1.0, 140: 0.8, 141: 1.0, 142: 0.95, 143: 1.0, 144: 0.95, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 0.8, 149: 0.8421052631578947, 150: 0.85, 151: 1.0, 152: 0.95, 153: 0.8, 154: 0.75, 155: 0.95, 156: 0.8421052631578947, 157: 0.95, 158: 0.7647058823529411, 159: 1.0, 160: 0.85, 161: 0.75, 162: 0.9, 163: 0.8, 164: 0.8421052631578947, 165: 0.55, 166: 0.4, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.85, 172: 0.85, 173: 0.85, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.85, 184: 0.9, 185: 0.9, 186: 0.65, 187: 0.7368421052631579, 188: 0.75, 189: 0.9, 190: 1.0, 191: 1.0, 192: 0.7, 193: 0.9, 194: 0.85, 195: 0.8888888888888888, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.8, 200: 0.8947368421052632, 201: 0.95, 202: 0.75, 203: 0.85, 204: 0.95, 205: 0.95, 206: 0.2777777777777778, 207: 0.65, 208: 0.9, 209: 0.85, 210: 1.0, 211: 1.0, 212: 0.8235294117647058, 213: 0.9, 214: 0.85, 215: 0.9, 216: 0.9, 217: 0.85, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.8}

2024-10-12 11:10:32,413 [INFO] [4] TRAIN  loss: 0.19360670941407238 acc: 0.9394995023460827
2024-10-12 11:10:32,413 [INFO] [4] TRAIN  loss dict: {'classification_loss': 0.19360670941407238}
2024-10-12 11:10:32,413 [INFO] [4] VALIDATION loss: 0.4569662223393853 VALIDATION  acc: 0.8761883205070168
2024-10-12 11:10:32,413 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 0.4569662223393853}
2024-10-12 11:10:32,413 [INFO] 
2024-10-12 11:11:59,660 [INFO] Step[50/938]: training loss : 0.162446703389287 TRAIN  loss dict:  {'classification_loss': 0.162446703389287}
2024-10-12 11:12:54,058 [INFO] Step[100/938]: training loss : 0.15361388422548772 TRAIN  loss dict:  {'classification_loss': 0.15361388422548772}
2024-10-12 11:13:48,652 [INFO] Step[150/938]: training loss : 0.15775573164224624 TRAIN  loss dict:  {'classification_loss': 0.15775573164224624}
2024-10-12 11:14:43,161 [INFO] Step[200/938]: training loss : 0.17281682725995778 TRAIN  loss dict:  {'classification_loss': 0.17281682725995778}
2024-10-12 11:15:37,789 [INFO] Step[250/938]: training loss : 0.14040667250752448 TRAIN  loss dict:  {'classification_loss': 0.14040667250752448}
2024-10-12 11:16:32,144 [INFO] Step[300/938]: training loss : 0.17322607841342688 TRAIN  loss dict:  {'classification_loss': 0.17322607841342688}
2024-10-12 11:17:26,816 [INFO] Step[350/938]: training loss : 0.1506422132253647 TRAIN  loss dict:  {'classification_loss': 0.1506422132253647}
2024-10-12 11:18:21,355 [INFO] Step[400/938]: training loss : 0.15771924778819085 TRAIN  loss dict:  {'classification_loss': 0.15771924778819085}
2024-10-12 11:19:15,627 [INFO] Step[450/938]: training loss : 0.1353546731173992 TRAIN  loss dict:  {'classification_loss': 0.1353546731173992}
2024-10-12 11:20:10,430 [INFO] Step[500/938]: training loss : 0.1415671655163169 TRAIN  loss dict:  {'classification_loss': 0.1415671655163169}
2024-10-12 11:21:04,946 [INFO] Step[550/938]: training loss : 0.147766791023314 TRAIN  loss dict:  {'classification_loss': 0.147766791023314}
2024-10-12 11:21:59,631 [INFO] Step[600/938]: training loss : 0.13777694918215275 TRAIN  loss dict:  {'classification_loss': 0.13777694918215275}
2024-10-12 11:22:54,391 [INFO] Step[650/938]: training loss : 0.17669904924929142 TRAIN  loss dict:  {'classification_loss': 0.17669904924929142}
2024-10-12 11:23:48,978 [INFO] Step[700/938]: training loss : 0.16958753805607557 TRAIN  loss dict:  {'classification_loss': 0.16958753805607557}
2024-10-12 11:24:43,715 [INFO] Step[750/938]: training loss : 0.13447171919047832 TRAIN  loss dict:  {'classification_loss': 0.13447171919047832}
2024-10-12 11:25:38,344 [INFO] Step[800/938]: training loss : 0.12824662163853645 TRAIN  loss dict:  {'classification_loss': 0.12824662163853645}
2024-10-12 11:26:33,241 [INFO] Step[850/938]: training loss : 0.15480670057237148 TRAIN  loss dict:  {'classification_loss': 0.15480670057237148}
2024-10-12 11:27:27,301 [INFO] Step[900/938]: training loss : 0.16283889271318913 TRAIN  loss dict:  {'classification_loss': 0.16283889271318913}
2024-10-12 11:30:19,457 [INFO] Label accuracies statistics:
2024-10-12 11:30:19,457 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.8, 3: 1.0, 4: 0.9, 5: 0.75, 6: 0.38461538461538464, 7: 0.9, 8: 1.0, 9: 0.8947368421052632, 10: 1.0, 11: 0.95, 12: 0.8421052631578947, 13: 1.0, 14: 1.0, 15: 0.85, 16: 0.5, 17: 0.7222222222222222, 18: 0.7058823529411765, 19: 0.8947368421052632, 20: 0.7894736842105263, 21: 1.0, 22: 0.7, 23: 0.8, 24: 0.5263157894736842, 25: 0.95, 26: 0.8421052631578947, 27: 0.9, 28: 1.0, 29: 0.95, 30: 0.9, 31: 0.85, 32: 1.0, 33: 1.0, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.9, 38: 0.9, 39: 1.0, 40: 0.85, 41: 1.0, 42: 0.85, 43: 0.7, 44: 1.0, 45: 0.8, 46: 0.9, 47: 0.45, 48: 0.7, 49: 0.9473684210526315, 50: 0.9, 51: 0.8333333333333334, 52: 0.8333333333333334, 53: 0.95, 54: 1.0, 55: 0.9473684210526315, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.8333333333333334, 60: 0.9, 61: 0.7368421052631579, 62: 0.47368421052631576, 63: 0.7894736842105263, 64: 0.9, 65: 0.9, 66: 0.95, 67: 0.75, 68: 0.5555555555555556, 69: 1.0, 70: 0.9, 71: 0.9, 72: 1.0, 73: 1.0, 74: 0.5, 75: 0.9, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.85, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.9166666666666666, 96: 0.6470588235294118, 97: 0.5, 98: 0.5789473684210527, 99: 1.0, 100: 0.95, 101: 0.95, 102: 0.9473684210526315, 103: 0.85, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.7, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.7, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 1.0, 122: 0.6, 123: 0.85, 124: 1.0, 125: 0.75, 126: 0.8, 127: 0.85, 128: 0.9, 129: 0.85, 130: 1.0, 131: 0.9375, 132: 0.8421052631578947, 133: 1.0, 134: 0.85, 135: 1.0, 136: 0.95, 137: 0.85, 138: 0.85, 139: 0.9, 140: 0.95, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.95, 145: 0.9473684210526315, 146: 1.0, 147: 0.9, 148: 0.8, 149: 0.8947368421052632, 150: 0.75, 151: 1.0, 152: 0.9, 153: 0.85, 154: 0.8, 155: 0.95, 156: 1.0, 157: 0.95, 158: 0.8235294117647058, 159: 1.0, 160: 0.95, 161: 0.8, 162: 0.8, 163: 0.85, 164: 1.0, 165: 0.4, 166: 1.0, 167: 1.0, 168: 0.95, 169: 0.95, 170: 1.0, 171: 1.0, 172: 0.85, 173: 0.8, 174: 1.0, 175: 0.6666666666666666, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.95, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.95, 184: 1.0, 185: 0.95, 186: 0.95, 187: 0.9473684210526315, 188: 0.8, 189: 1.0, 190: 0.9, 191: 1.0, 192: 0.95, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8947368421052632, 201: 1.0, 202: 0.95, 203: 0.75, 204: 0.9, 205: 0.85, 206: 0.5, 207: 0.8, 208: 1.0, 209: 0.95, 210: 1.0, 211: 0.65, 212: 0.9411764705882353, 213: 0.85, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.8, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.8, 225: 0.9}

2024-10-12 11:30:19,946 [INFO] [5] TRAIN  loss: 0.1533662203107593 acc: 0.9528650646950092
2024-10-12 11:30:19,946 [INFO] [5] TRAIN  loss dict: {'classification_loss': 0.1533662203107593}
2024-10-12 11:30:19,946 [INFO] [5] VALIDATION loss: 0.4057702827267349 VALIDATION  acc: 0.8922589406971481
2024-10-12 11:30:19,946 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 0.4057702827267349}
2024-10-12 11:30:19,946 [INFO] 
2024-10-12 11:31:47,006 [INFO] Step[50/938]: training loss : 0.13271875645965336 TRAIN  loss dict:  {'classification_loss': 0.13271875645965336}
2024-10-12 11:32:41,412 [INFO] Step[100/938]: training loss : 0.12713782612234353 TRAIN  loss dict:  {'classification_loss': 0.12713782612234353}
2024-10-12 11:33:36,031 [INFO] Step[150/938]: training loss : 0.1235071575269103 TRAIN  loss dict:  {'classification_loss': 0.1235071575269103}
2024-10-12 11:34:30,566 [INFO] Step[200/938]: training loss : 0.1338528025150299 TRAIN  loss dict:  {'classification_loss': 0.1338528025150299}
2024-10-12 11:35:25,277 [INFO] Step[250/938]: training loss : 0.1301463570073247 TRAIN  loss dict:  {'classification_loss': 0.1301463570073247}
2024-10-12 11:36:19,626 [INFO] Step[300/938]: training loss : 0.1298504125326872 TRAIN  loss dict:  {'classification_loss': 0.1298504125326872}
2024-10-12 11:37:14,198 [INFO] Step[350/938]: training loss : 0.12600580111145973 TRAIN  loss dict:  {'classification_loss': 0.12600580111145973}
2024-10-12 11:38:08,812 [INFO] Step[400/938]: training loss : 0.1382970729097724 TRAIN  loss dict:  {'classification_loss': 0.1382970729097724}
2024-10-12 11:39:03,336 [INFO] Step[450/938]: training loss : 0.11975712228566408 TRAIN  loss dict:  {'classification_loss': 0.11975712228566408}
2024-10-12 11:39:58,069 [INFO] Step[500/938]: training loss : 0.10972073527052999 TRAIN  loss dict:  {'classification_loss': 0.10972073527052999}
2024-10-12 11:40:51,834 [INFO] Step[550/938]: training loss : 0.10793049629777669 TRAIN  loss dict:  {'classification_loss': 0.10793049629777669}
2024-10-12 11:41:46,437 [INFO] Step[600/938]: training loss : 0.14434889243915677 TRAIN  loss dict:  {'classification_loss': 0.14434889243915677}
2024-10-12 11:42:40,802 [INFO] Step[650/938]: training loss : 0.11689452275633812 TRAIN  loss dict:  {'classification_loss': 0.11689452275633812}
2024-10-12 11:43:35,374 [INFO] Step[700/938]: training loss : 0.11701951207593084 TRAIN  loss dict:  {'classification_loss': 0.11701951207593084}
2024-10-12 11:44:30,007 [INFO] Step[750/938]: training loss : 0.12590003369376063 TRAIN  loss dict:  {'classification_loss': 0.12590003369376063}
2024-10-12 11:45:24,585 [INFO] Step[800/938]: training loss : 0.13807889595627784 TRAIN  loss dict:  {'classification_loss': 0.13807889595627784}
2024-10-12 11:46:19,219 [INFO] Step[850/938]: training loss : 0.12466592520475388 TRAIN  loss dict:  {'classification_loss': 0.12466592520475388}
2024-10-12 11:47:13,160 [INFO] Step[900/938]: training loss : 0.12144748888909816 TRAIN  loss dict:  {'classification_loss': 0.12144748888909816}
2024-10-12 11:50:05,948 [INFO] Label accuracies statistics:
2024-10-12 11:50:05,948 [INFO] {0: 0.9, 1: 1.0, 2: 0.95, 3: 1.0, 4: 0.9, 5: 0.95, 6: 0.46153846153846156, 7: 0.85, 8: 0.8, 9: 0.7368421052631579, 10: 1.0, 11: 0.95, 12: 0.8947368421052632, 13: 0.85, 14: 0.9, 15: 0.9, 16: 0.75, 17: 0.6666666666666666, 18: 0.7647058823529411, 19: 0.8947368421052632, 20: 1.0, 21: 0.7894736842105263, 22: 0.65, 23: 0.65, 24: 0.6842105263157895, 25: 0.95, 26: 0.8947368421052632, 27: 0.95, 28: 0.95, 29: 1.0, 30: 0.95, 31: 0.8, 32: 0.95, 33: 0.85, 34: 0.8, 35: 0.95, 36: 1.0, 37: 1.0, 38: 0.95, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.6, 43: 0.9, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.45, 48: 0.75, 49: 0.8421052631578947, 50: 0.7, 51: 0.8333333333333334, 52: 0.7222222222222222, 53: 0.6, 54: 0.95, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.9375, 59: 0.7777777777777778, 60: 0.9, 61: 0.8947368421052632, 62: 0.7894736842105263, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.85, 68: 0.8888888888888888, 69: 1.0, 70: 0.95, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.7, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.8, 82: 0.75, 83: 1.0, 84: 0.9, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.9, 92: 1.0, 93: 0.9, 94: 0.9473684210526315, 95: 1.0, 96: 0.5294117647058824, 97: 0.55, 98: 0.631578947368421, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.7, 104: 0.8, 105: 0.85, 106: 1.0, 107: 0.8, 108: 1.0, 109: 1.0, 110: 0.9, 111: 0.95, 112: 0.95, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.85, 121: 0.95, 122: 0.6, 123: 0.85, 124: 0.95, 125: 0.85, 126: 0.85, 127: 0.5, 128: 0.65, 129: 0.65, 130: 1.0, 131: 0.875, 132: 0.8947368421052632, 133: 1.0, 134: 0.85, 135: 0.95, 136: 1.0, 137: 0.85, 138: 0.9, 139: 0.95, 140: 0.75, 141: 1.0, 142: 0.95, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 0.85, 149: 1.0, 150: 0.4, 151: 1.0, 152: 0.85, 153: 0.95, 154: 0.65, 155: 0.85, 156: 0.8947368421052632, 157: 0.85, 158: 0.8235294117647058, 159: 0.95, 160: 0.95, 161: 0.9, 162: 1.0, 163: 1.0, 164: 0.8421052631578947, 165: 0.6, 166: 0.75, 167: 0.95, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.7, 173: 0.9, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.9, 184: 1.0, 185: 0.9, 186: 0.9, 187: 0.8947368421052632, 188: 0.85, 189: 1.0, 190: 0.75, 191: 1.0, 192: 0.95, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.9, 200: 0.9473684210526315, 201: 1.0, 202: 0.9, 203: 0.9, 204: 0.9, 205: 0.95, 206: 0.3888888888888889, 207: 0.55, 208: 0.9, 209: 0.95, 210: 1.0, 211: 0.85, 212: 0.9411764705882353, 213: 0.9, 214: 0.85, 215: 0.9, 216: 1.0, 217: 0.8, 218: 0.95, 219: 1.0, 220: 0.9, 221: 0.6, 222: 1.0, 223: 1.0, 224: 0.7, 225: 0.85}

2024-10-12 11:50:05,994 [INFO] [6] TRAIN  loss: 0.12581161183835282 acc: 0.9610408076212142
2024-10-12 11:50:05,994 [INFO] [6] TRAIN  loss dict: {'classification_loss': 0.12581161183835282}
2024-10-12 11:50:05,994 [INFO] [6] VALIDATION loss: 0.4179004163078561 VALIDATION  acc: 0.8870529651425985
2024-10-12 11:50:05,994 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 0.4179004163078561}
2024-10-12 11:50:05,994 [INFO] 
2024-10-12 11:51:33,906 [INFO] Step[50/938]: training loss : 0.10330067182891071 TRAIN  loss dict:  {'classification_loss': 0.10330067182891071}
2024-10-12 11:52:28,310 [INFO] Step[100/938]: training loss : 0.11919981881976127 TRAIN  loss dict:  {'classification_loss': 0.11919981881976127}
2024-10-12 11:53:22,937 [INFO] Step[150/938]: training loss : 0.09370981562882662 TRAIN  loss dict:  {'classification_loss': 0.09370981562882662}
2024-10-12 11:54:17,303 [INFO] Step[200/938]: training loss : 0.1262704492546618 TRAIN  loss dict:  {'classification_loss': 0.1262704492546618}
2024-10-12 11:55:11,906 [INFO] Step[250/938]: training loss : 0.09917732410132885 TRAIN  loss dict:  {'classification_loss': 0.09917732410132885}
2024-10-12 11:56:06,263 [INFO] Step[300/938]: training loss : 0.10584543066099286 TRAIN  loss dict:  {'classification_loss': 0.10584543066099286}
2024-10-12 11:57:00,931 [INFO] Step[350/938]: training loss : 0.10966806050390004 TRAIN  loss dict:  {'classification_loss': 0.10966806050390004}
2024-10-12 11:57:55,477 [INFO] Step[400/938]: training loss : 0.13121202893555164 TRAIN  loss dict:  {'classification_loss': 0.13121202893555164}
2024-10-12 11:58:49,869 [INFO] Step[450/938]: training loss : 0.09976325834169984 TRAIN  loss dict:  {'classification_loss': 0.09976325834169984}
2024-10-12 11:59:44,595 [INFO] Step[500/938]: training loss : 0.11021958300843834 TRAIN  loss dict:  {'classification_loss': 0.11021958300843834}
2024-10-12 12:00:38,944 [INFO] Step[550/938]: training loss : 0.11144657876342536 TRAIN  loss dict:  {'classification_loss': 0.11144657876342536}
2024-10-12 12:01:33,611 [INFO] Step[600/938]: training loss : 0.10401517994701863 TRAIN  loss dict:  {'classification_loss': 0.10401517994701863}
2024-10-12 12:02:28,124 [INFO] Step[650/938]: training loss : 0.1403430133126676 TRAIN  loss dict:  {'classification_loss': 0.1403430133126676}
2024-10-12 12:03:22,747 [INFO] Step[700/938]: training loss : 0.11069639654830098 TRAIN  loss dict:  {'classification_loss': 0.11069639654830098}
2024-10-12 12:04:17,168 [INFO] Step[750/938]: training loss : 0.10773005282506347 TRAIN  loss dict:  {'classification_loss': 0.10773005282506347}
2024-10-12 12:05:11,665 [INFO] Step[800/938]: training loss : 0.11993921073153616 TRAIN  loss dict:  {'classification_loss': 0.11993921073153616}
2024-10-12 12:06:06,283 [INFO] Step[850/938]: training loss : 0.10432697271928192 TRAIN  loss dict:  {'classification_loss': 0.10432697271928192}
2024-10-12 12:07:00,363 [INFO] Step[900/938]: training loss : 0.1484366612881422 TRAIN  loss dict:  {'classification_loss': 0.1484366612881422}
2024-10-12 12:09:52,906 [INFO] Label accuracies statistics:
2024-10-12 12:09:52,906 [INFO] {0: 0.9, 1: 1.0, 2: 0.8, 3: 0.8947368421052632, 4: 1.0, 5: 0.85, 6: 0.46153846153846156, 7: 0.95, 8: 0.9, 9: 0.8421052631578947, 10: 1.0, 11: 0.85, 12: 0.8421052631578947, 13: 0.85, 14: 1.0, 15: 0.85, 16: 0.7, 17: 0.7222222222222222, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 0.8947368421052632, 21: 0.7368421052631579, 22: 0.8, 23: 0.85, 24: 0.5263157894736842, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.9, 29: 0.9, 30: 0.9, 31: 0.9, 32: 1.0, 33: 1.0, 34: 0.7, 35: 1.0, 36: 0.9473684210526315, 37: 1.0, 38: 0.85, 39: 1.0, 40: 0.9, 41: 1.0, 42: 0.85, 43: 0.85, 44: 0.9473684210526315, 45: 0.9, 46: 0.9, 47: 0.2, 48: 0.8, 49: 0.9473684210526315, 50: 0.95, 51: 0.8888888888888888, 52: 0.6666666666666666, 53: 1.0, 54: 1.0, 55: 0.9473684210526315, 56: 0.9473684210526315, 57: 0.9, 58: 1.0, 59: 0.7777777777777778, 60: 0.9, 61: 0.7368421052631579, 62: 0.5789473684210527, 63: 0.8421052631578947, 64: 0.9, 65: 0.85, 66: 0.95, 67: 0.7, 68: 0.8888888888888888, 69: 1.0, 70: 0.85, 71: 0.9, 72: 1.0, 73: 0.9473684210526315, 74: 0.95, 75: 0.9, 76: 0.7368421052631579, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.7, 83: 1.0, 84: 0.8, 85: 1.0, 86: 0.7, 87: 0.8823529411764706, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.95, 92: 1.0, 93: 0.9, 94: 1.0, 95: 1.0, 96: 0.6470588235294118, 97: 0.6, 98: 0.6842105263157895, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.8, 104: 0.7, 105: 0.85, 106: 1.0, 107: 0.8, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.9, 113: 0.95, 114: 0.95, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 0.95, 122: 0.7, 123: 1.0, 124: 1.0, 125: 0.85, 126: 0.8, 127: 0.8, 128: 0.9, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.9473684210526315, 133: 1.0, 134: 0.75, 135: 0.85, 136: 1.0, 137: 0.85, 138: 0.9, 139: 0.9, 140: 0.65, 141: 1.0, 142: 0.8, 143: 1.0, 144: 0.95, 145: 0.9473684210526315, 146: 1.0, 147: 0.75, 148: 0.85, 149: 0.9473684210526315, 150: 0.75, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.9, 155: 0.85, 156: 0.7894736842105263, 157: 0.85, 158: 0.9411764705882353, 159: 1.0, 160: 0.85, 161: 0.85, 162: 1.0, 163: 0.9, 164: 0.9473684210526315, 165: 0.65, 166: 0.9, 167: 0.95, 168: 0.95, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.7, 173: 0.9, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.95, 184: 0.95, 185: 0.95, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 0.95, 202: 1.0, 203: 0.8, 204: 0.8, 205: 0.9, 206: 0.3333333333333333, 207: 0.8, 208: 0.9, 209: 0.9, 210: 0.9, 211: 0.9, 212: 0.6470588235294118, 213: 0.85, 214: 0.9, 215: 0.9, 216: 0.75, 217: 0.85, 218: 0.75, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.9}

2024-10-12 12:09:53,387 [INFO] [7] TRAIN  loss: 0.11320872560415521 acc: 0.9644532916251956
2024-10-12 12:09:53,387 [INFO] [7] TRAIN  loss dict: {'classification_loss': 0.11320872560415521}
2024-10-12 12:09:53,388 [INFO] [7] VALIDATION loss: 0.4056107641907245 VALIDATION  acc: 0.8915799004074242
2024-10-12 12:09:53,388 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 0.4056107641907245}
2024-10-12 12:09:53,388 [INFO] 
2024-10-12 12:11:22,032 [INFO] Step[50/938]: training loss : 0.09859765952453017 TRAIN  loss dict:  {'classification_loss': 0.09859765952453017}
2024-10-12 12:12:16,490 [INFO] Step[100/938]: training loss : 0.08914579307194799 TRAIN  loss dict:  {'classification_loss': 0.08914579307194799}
2024-10-12 12:13:11,271 [INFO] Step[150/938]: training loss : 0.09756071771495044 TRAIN  loss dict:  {'classification_loss': 0.09756071771495044}
2024-10-12 12:14:05,046 [INFO] Step[200/938]: training loss : 0.0927851084060967 TRAIN  loss dict:  {'classification_loss': 0.0927851084060967}
2024-10-12 12:14:59,834 [INFO] Step[250/938]: training loss : 0.12000614213757217 TRAIN  loss dict:  {'classification_loss': 0.12000614213757217}
2024-10-12 12:15:54,228 [INFO] Step[300/938]: training loss : 0.09336180035024881 TRAIN  loss dict:  {'classification_loss': 0.09336180035024881}
2024-10-12 12:16:48,986 [INFO] Step[350/938]: training loss : 0.08738346185535192 TRAIN  loss dict:  {'classification_loss': 0.08738346185535192}
2024-10-12 12:17:43,559 [INFO] Step[400/938]: training loss : 0.09606042795814573 TRAIN  loss dict:  {'classification_loss': 0.09606042795814573}
2024-10-12 12:18:37,896 [INFO] Step[450/938]: training loss : 0.09315991153940559 TRAIN  loss dict:  {'classification_loss': 0.09315991153940559}
2024-10-12 12:19:32,720 [INFO] Step[500/938]: training loss : 0.10262829380109906 TRAIN  loss dict:  {'classification_loss': 0.10262829380109906}
2024-10-12 12:20:27,271 [INFO] Step[550/938]: training loss : 0.10515689568594098 TRAIN  loss dict:  {'classification_loss': 0.10515689568594098}
2024-10-12 12:21:22,067 [INFO] Step[600/938]: training loss : 0.0821839577704668 TRAIN  loss dict:  {'classification_loss': 0.0821839577704668}
2024-10-12 12:22:16,723 [INFO] Step[650/938]: training loss : 0.10832023395225406 TRAIN  loss dict:  {'classification_loss': 0.10832023395225406}
2024-10-12 12:23:10,756 [INFO] Step[700/938]: training loss : 0.08649177115410567 TRAIN  loss dict:  {'classification_loss': 0.08649177115410567}
2024-10-12 12:24:04,692 [INFO] Step[750/938]: training loss : 0.10228118486702442 TRAIN  loss dict:  {'classification_loss': 0.10228118486702442}
2024-10-12 12:24:58,667 [INFO] Step[800/938]: training loss : 0.09463111801072956 TRAIN  loss dict:  {'classification_loss': 0.09463111801072956}
2024-10-12 12:25:52,845 [INFO] Step[850/938]: training loss : 0.12110548565164209 TRAIN  loss dict:  {'classification_loss': 0.12110548565164209}
2024-10-12 12:26:46,320 [INFO] Step[900/938]: training loss : 0.10632109466940165 TRAIN  loss dict:  {'classification_loss': 0.10632109466940165}
2024-10-12 12:29:41,253 [INFO] Label accuracies statistics:
2024-10-12 12:29:41,254 [INFO] {0: 0.75, 1: 0.8421052631578947, 2: 0.85, 3: 0.9473684210526315, 4: 0.95, 5: 0.6, 6: 0.3076923076923077, 7: 1.0, 8: 0.95, 9: 0.8947368421052632, 10: 1.0, 11: 0.85, 12: 0.631578947368421, 13: 0.85, 14: 1.0, 15: 1.0, 16: 0.8, 17: 0.6666666666666666, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 0.7894736842105263, 22: 0.95, 23: 0.55, 24: 0.5263157894736842, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.9, 34: 0.65, 35: 1.0, 36: 1.0, 37: 0.85, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 1.0, 44: 0.9473684210526315, 45: 1.0, 46: 0.9, 47: 0.65, 48: 0.8, 49: 0.9473684210526315, 50: 1.0, 51: 0.8333333333333334, 52: 0.7777777777777778, 53: 1.0, 54: 0.8, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.8125, 59: 0.7222222222222222, 60: 0.9, 61: 0.7894736842105263, 62: 0.5789473684210527, 63: 0.8421052631578947, 64: 0.9, 65: 0.75, 66: 1.0, 67: 0.8, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.85, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.8, 76: 0.8421052631578947, 77: 1.0, 78: 0.8, 79: 1.0, 80: 1.0, 81: 0.75, 82: 0.85, 83: 1.0, 84: 0.9, 85: 1.0, 86: 0.7, 87: 0.8235294117647058, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.8, 92: 0.8, 93: 0.95, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.6, 98: 0.631578947368421, 99: 1.0, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.7, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.8, 112: 1.0, 113: 0.9, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.8, 121: 0.95, 122: 0.65, 123: 0.6, 124: 1.0, 125: 0.9, 126: 0.7, 127: 0.8, 128: 0.95, 129: 0.85, 130: 1.0, 131: 0.8125, 132: 0.631578947368421, 133: 1.0, 134: 0.9, 135: 0.95, 136: 1.0, 137: 0.9, 138: 0.95, 139: 0.8, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.65, 148: 1.0, 149: 1.0, 150: 0.7, 151: 1.0, 152: 0.8, 153: 0.8, 154: 0.8, 155: 0.8, 156: 0.8421052631578947, 157: 0.95, 158: 0.7647058823529411, 159: 1.0, 160: 0.85, 161: 0.85, 162: 1.0, 163: 1.0, 164: 1.0, 165: 0.55, 166: 0.85, 167: 0.95, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.7, 173: 0.8, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.5, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.95, 184: 1.0, 185: 0.85, 186: 0.95, 187: 0.7894736842105263, 188: 0.75, 189: 1.0, 190: 1.0, 191: 1.0, 192: 0.95, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.8, 203: 0.85, 204: 0.85, 205: 0.85, 206: 0.4444444444444444, 207: 0.85, 208: 0.95, 209: 0.85, 210: 1.0, 211: 1.0, 212: 0.8823529411764706, 213: 0.85, 214: 0.95, 215: 0.9, 216: 0.8, 217: 0.95, 218: 1.0, 219: 0.95, 220: 1.0, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.6, 225: 0.9}

2024-10-12 12:29:41,332 [INFO] [8] TRAIN  loss: 0.09789495480813777 acc: 0.9689321768804209
2024-10-12 12:29:41,332 [INFO] [8] TRAIN  loss dict: {'classification_loss': 0.09789495480813777}
2024-10-12 12:29:41,332 [INFO] [8] VALIDATION loss: 0.43273286658616084 VALIDATION  acc: 0.8904481665912177
2024-10-12 12:29:41,332 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 0.43273286658616084}
2024-10-12 12:29:41,333 [INFO] 
2024-10-12 12:31:58,418 [INFO] Step[50/938]: training loss : 0.09109867727383972 TRAIN  loss dict:  {'classification_loss': 0.09109867727383972}
2024-10-12 12:32:52,995 [INFO] Step[100/938]: training loss : 0.072007573293522 TRAIN  loss dict:  {'classification_loss': 0.072007573293522}
2024-10-12 12:33:48,156 [INFO] Step[150/938]: training loss : 0.0811367741972208 TRAIN  loss dict:  {'classification_loss': 0.0811367741972208}
2024-10-12 12:34:44,310 [INFO] Step[200/938]: training loss : 0.08978882417082787 TRAIN  loss dict:  {'classification_loss': 0.08978882417082787}
2024-10-12 12:35:35,707 [INFO] Step[250/938]: training loss : 0.0876724475901574 TRAIN  loss dict:  {'classification_loss': 0.0876724475901574}
2024-10-12 12:36:30,298 [INFO] Step[300/938]: training loss : 0.10080310921184718 TRAIN  loss dict:  {'classification_loss': 0.10080310921184718}
2024-10-12 12:37:25,408 [INFO] Step[350/938]: training loss : 0.07786027347669006 TRAIN  loss dict:  {'classification_loss': 0.07786027347669006}
2024-10-12 12:38:19,611 [INFO] Step[400/938]: training loss : 0.08817986276000739 TRAIN  loss dict:  {'classification_loss': 0.08817986276000739}
2024-10-12 12:39:15,084 [INFO] Step[450/938]: training loss : 0.060638723857700826 TRAIN  loss dict:  {'classification_loss': 0.060638723857700826}
2024-10-12 12:40:10,855 [INFO] Step[500/938]: training loss : 0.09363297495059669 TRAIN  loss dict:  {'classification_loss': 0.09363297495059669}
2024-10-12 12:41:07,730 [INFO] Step[550/938]: training loss : 0.09106423357501627 TRAIN  loss dict:  {'classification_loss': 0.09106423357501627}
2024-10-12 12:41:59,745 [INFO] Step[600/938]: training loss : 0.09739979963749647 TRAIN  loss dict:  {'classification_loss': 0.09739979963749647}
2024-10-12 12:42:56,369 [INFO] Step[650/938]: training loss : 0.07996211152523756 TRAIN  loss dict:  {'classification_loss': 0.07996211152523756}
2024-10-12 12:43:53,946 [INFO] Step[700/938]: training loss : 0.09295443629845977 TRAIN  loss dict:  {'classification_loss': 0.09295443629845977}
2024-10-12 12:44:48,057 [INFO] Step[750/938]: training loss : 0.11840730427764357 TRAIN  loss dict:  {'classification_loss': 0.11840730427764357}
2024-10-12 12:45:41,855 [INFO] Step[800/938]: training loss : 0.09402963515371084 TRAIN  loss dict:  {'classification_loss': 0.09402963515371084}
2024-10-12 12:46:37,792 [INFO] Step[850/938]: training loss : 0.07570135708898305 TRAIN  loss dict:  {'classification_loss': 0.07570135708898305}
2024-10-12 12:47:32,406 [INFO] Step[900/938]: training loss : 0.0760559328366071 TRAIN  loss dict:  {'classification_loss': 0.0760559328366071}
2024-10-12 12:50:38,421 [INFO] Label accuracies statistics:
2024-10-12 12:50:38,421 [INFO] {0: 0.85, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.9, 5: 0.95, 6: 0.46153846153846156, 7: 0.9, 8: 0.95, 9: 1.0, 10: 1.0, 11: 0.85, 12: 0.8421052631578947, 13: 0.75, 14: 0.9, 15: 0.8, 16: 0.85, 17: 0.8888888888888888, 18: 0.7058823529411765, 19: 0.9473684210526315, 20: 0.8947368421052632, 21: 0.8421052631578947, 22: 0.85, 23: 0.7, 24: 0.7894736842105263, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.9, 31: 1.0, 32: 1.0, 33: 0.95, 34: 0.7, 35: 1.0, 36: 0.9473684210526315, 37: 0.95, 38: 0.9, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.9, 43: 0.95, 44: 0.9473684210526315, 45: 1.0, 46: 0.9, 47: 0.5, 48: 0.7, 49: 0.8947368421052632, 50: 1.0, 51: 0.9444444444444444, 52: 0.5555555555555556, 53: 0.8, 54: 0.85, 55: 0.8947368421052632, 56: 1.0, 57: 1.0, 58: 0.6875, 59: 0.6666666666666666, 60: 0.9, 61: 0.7368421052631579, 62: 0.6842105263157895, 63: 0.8947368421052632, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.75, 68: 0.7777777777777778, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.9, 76: 1.0, 77: 1.0, 78: 0.65, 79: 1.0, 80: 1.0, 81: 0.75, 82: 0.7, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 1.0, 92: 1.0, 93: 0.8, 94: 1.0, 95: 0.9166666666666666, 96: 0.35294117647058826, 97: 0.75, 98: 0.6842105263157895, 99: 1.0, 100: 0.95, 101: 1.0, 102: 0.9473684210526315, 103: 0.75, 104: 0.9, 105: 0.95, 106: 1.0, 107: 0.9, 108: 0.85, 109: 1.0, 110: 1.0, 111: 0.9, 112: 1.0, 113: 0.95, 114: 0.95, 115: 0.9411764705882353, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.45, 123: 0.8, 124: 1.0, 125: 0.8, 126: 0.6, 127: 0.95, 128: 0.9, 129: 0.7, 130: 1.0, 131: 0.9375, 132: 0.9473684210526315, 133: 1.0, 134: 0.9, 135: 0.95, 136: 0.95, 137: 0.85, 138: 0.9, 139: 0.9, 140: 0.95, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.65, 145: 0.8421052631578947, 146: 1.0, 147: 0.85, 148: 1.0, 149: 0.8947368421052632, 150: 0.45, 151: 1.0, 152: 0.85, 153: 0.95, 154: 0.9, 155: 1.0, 156: 0.9473684210526315, 157: 0.9, 158: 0.7647058823529411, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.95, 163: 0.95, 164: 0.7894736842105263, 165: 0.6, 166: 0.8, 167: 0.95, 168: 0.95, 169: 1.0, 170: 0.8421052631578947, 171: 1.0, 172: 0.55, 173: 0.75, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.75, 184: 1.0, 185: 0.95, 186: 0.8, 187: 0.7894736842105263, 188: 0.8, 189: 1.0, 190: 0.95, 191: 1.0, 192: 0.95, 193: 1.0, 194: 0.9, 195: 0.9444444444444444, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8947368421052632, 201: 1.0, 202: 1.0, 203: 1.0, 204: 0.9, 205: 0.95, 206: 0.3888888888888889, 207: 0.85, 208: 0.85, 209: 0.85, 210: 1.0, 211: 0.95, 212: 0.8823529411764706, 213: 0.95, 214: 0.85, 215: 0.9, 216: 0.95, 217: 0.95, 218: 0.9, 219: 1.0, 220: 0.9, 221: 0.55, 222: 1.0, 223: 0.95, 224: 1.0, 225: 1.0}

2024-10-12 12:50:38,498 [INFO] [9] TRAIN  loss: 0.08679263406733015 acc: 0.9728778615100242
2024-10-12 12:50:38,499 [INFO] [9] TRAIN  loss dict: {'classification_loss': 0.08679263406733015}
2024-10-12 12:50:38,499 [INFO] [9] VALIDATION loss: 0.4427744339572618 VALIDATION  acc: 0.8949751018560435
2024-10-12 12:50:38,499 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 0.4427744339572618}
2024-10-12 12:50:38,499 [INFO] 
2024-10-12 12:52:40,759 [INFO] Step[50/938]: training loss : 0.10292004599235952 TRAIN  loss dict:  {'classification_loss': 0.10292004599235952}
2024-10-12 12:53:37,009 [INFO] Step[100/938]: training loss : 0.08195414656773209 TRAIN  loss dict:  {'classification_loss': 0.08195414656773209}
2024-10-12 12:54:33,224 [INFO] Step[150/938]: training loss : 0.08001012251712382 TRAIN  loss dict:  {'classification_loss': 0.08001012251712382}
2024-10-12 12:55:24,540 [INFO] Step[200/938]: training loss : 0.10024280259385705 TRAIN  loss dict:  {'classification_loss': 0.10024280259385705}
2024-10-12 12:56:21,082 [INFO] Step[250/938]: training loss : 0.06651868045330048 TRAIN  loss dict:  {'classification_loss': 0.06651868045330048}
2024-10-12 12:57:15,512 [INFO] Step[300/938]: training loss : 0.06026902014389634 TRAIN  loss dict:  {'classification_loss': 0.06026902014389634}
2024-10-12 12:58:11,543 [INFO] Step[350/938]: training loss : 0.07855211775749922 TRAIN  loss dict:  {'classification_loss': 0.07855211775749922}
2024-10-12 12:59:07,938 [INFO] Step[400/938]: training loss : 0.06571504688821733 TRAIN  loss dict:  {'classification_loss': 0.06571504688821733}
2024-10-12 13:00:04,416 [INFO] Step[450/938]: training loss : 0.08197445206344128 TRAIN  loss dict:  {'classification_loss': 0.08197445206344128}
2024-10-12 13:00:59,876 [INFO] Step[500/938]: training loss : 0.07004600943997502 TRAIN  loss dict:  {'classification_loss': 0.07004600943997502}
2024-10-12 13:01:51,964 [INFO] Step[550/938]: training loss : 0.08482522428035737 TRAIN  loss dict:  {'classification_loss': 0.08482522428035737}
2024-10-12 13:02:48,530 [INFO] Step[600/938]: training loss : 0.07513522973284126 TRAIN  loss dict:  {'classification_loss': 0.07513522973284126}
2024-10-12 13:03:47,328 [INFO] Step[650/938]: training loss : 0.06070155017077923 TRAIN  loss dict:  {'classification_loss': 0.06070155017077923}
2024-10-12 13:04:40,566 [INFO] Step[700/938]: training loss : 0.08964555600658058 TRAIN  loss dict:  {'classification_loss': 0.08964555600658058}
2024-10-12 13:05:35,684 [INFO] Step[750/938]: training loss : 0.08623733140528202 TRAIN  loss dict:  {'classification_loss': 0.08623733140528202}
2024-10-12 13:06:32,458 [INFO] Step[800/938]: training loss : 0.08183228268288076 TRAIN  loss dict:  {'classification_loss': 0.08183228268288076}
2024-10-12 13:07:27,191 [INFO] Step[850/938]: training loss : 0.10184327081777156 TRAIN  loss dict:  {'classification_loss': 0.10184327081777156}
2024-10-12 13:08:20,795 [INFO] Step[900/938]: training loss : 0.08364689639769494 TRAIN  loss dict:  {'classification_loss': 0.08364689639769494}
2024-10-12 13:12:09,936 [INFO] Label accuracies statistics:
2024-10-12 13:12:09,937 [INFO] {0: 0.9, 1: 1.0, 2: 0.85, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.46153846153846156, 7: 0.9, 8: 0.9, 9: 0.7894736842105263, 10: 1.0, 11: 0.9, 12: 0.7894736842105263, 13: 0.95, 14: 1.0, 15: 0.95, 16: 0.45, 17: 0.7777777777777778, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.7894736842105263, 21: 0.8947368421052632, 22: 0.75, 23: 0.65, 24: 0.5789473684210527, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.8, 29: 1.0, 30: 0.85, 31: 0.95, 32: 1.0, 33: 1.0, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.85, 38: 1.0, 39: 1.0, 40: 0.95, 41: 1.0, 42: 1.0, 43: 0.9, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.5, 48: 0.8, 49: 0.9473684210526315, 50: 0.75, 51: 0.9444444444444444, 52: 0.7222222222222222, 53: 0.9, 54: 0.9, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.7777777777777778, 60: 0.9, 61: 0.7368421052631579, 62: 0.5789473684210527, 63: 0.7368421052631579, 64: 0.9, 65: 0.75, 66: 1.0, 67: 0.85, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.8, 76: 0.8421052631578947, 77: 1.0, 78: 0.7, 79: 1.0, 80: 0.95, 81: 0.9, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 1.0, 93: 0.9, 94: 1.0, 95: 1.0, 96: 0.5882352941176471, 97: 0.3, 98: 0.631578947368421, 99: 0.9, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.8, 104: 0.85, 105: 0.95, 106: 1.0, 107: 0.85, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.8, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 0.9, 122: 0.5, 123: 0.9, 124: 1.0, 125: 0.75, 126: 0.55, 127: 0.9, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.9375, 132: 0.8947368421052632, 133: 1.0, 134: 0.4, 135: 0.7, 136: 1.0, 137: 0.8, 138: 0.9, 139: 1.0, 140: 0.65, 141: 1.0, 142: 0.9, 143: 0.9, 144: 0.85, 145: 0.9473684210526315, 146: 1.0, 147: 0.7, 148: 1.0, 149: 1.0, 150: 0.8, 151: 1.0, 152: 0.8, 153: 0.8, 154: 0.9, 155: 0.95, 156: 0.7894736842105263, 157: 0.9, 158: 0.8235294117647058, 159: 1.0, 160: 1.0, 161: 0.85, 162: 0.8, 163: 1.0, 164: 0.8421052631578947, 165: 0.6, 166: 0.95, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.85, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.9, 179: 0.9, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.95, 184: 0.95, 185: 0.85, 186: 0.9, 187: 0.7894736842105263, 188: 0.75, 189: 1.0, 190: 0.9, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.85, 203: 0.7, 204: 0.9, 205: 0.95, 206: 0.5, 207: 0.85, 208: 0.9, 209: 0.95, 210: 1.0, 211: 0.9, 212: 0.8823529411764706, 213: 0.85, 214: 0.85, 215: 0.9, 216: 1.0, 217: 0.8, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.85}

2024-10-12 13:12:10,040 [INFO] [10] TRAIN  loss: 0.0804456954197422 acc: 0.9741219963031423
2024-10-12 13:12:10,040 [INFO] [10] TRAIN  loss dict: {'classification_loss': 0.0804456954197422}
2024-10-12 13:12:10,041 [INFO] [10] VALIDATION loss: 0.43875442669141684 VALIDATION  acc: 0.8918062471706655
2024-10-12 13:12:10,041 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 0.43875442669141684}
2024-10-12 13:12:10,041 [INFO] 
2024-10-12 13:14:30,031 [INFO] Step[50/938]: training loss : 0.057560497261583805 TRAIN  loss dict:  {'classification_loss': 0.057560497261583805}
2024-10-12 13:15:20,967 [INFO] Step[100/938]: training loss : 0.0663449182547629 TRAIN  loss dict:  {'classification_loss': 0.0663449182547629}
2024-10-12 13:16:08,539 [INFO] Step[150/938]: training loss : 0.03948774874676019 TRAIN  loss dict:  {'classification_loss': 0.03948774874676019}
2024-10-12 13:16:50,008 [INFO] Step[200/938]: training loss : 0.06597987967543303 TRAIN  loss dict:  {'classification_loss': 0.06597987967543303}
2024-10-12 13:17:45,912 [INFO] Step[250/938]: training loss : 0.07672015798278153 TRAIN  loss dict:  {'classification_loss': 0.07672015798278153}
2024-10-12 13:18:24,736 [INFO] Step[300/938]: training loss : 0.04872680342756212 TRAIN  loss dict:  {'classification_loss': 0.04872680342756212}
2024-10-12 13:19:21,319 [INFO] Step[350/938]: training loss : 0.05942617881111801 TRAIN  loss dict:  {'classification_loss': 0.05942617881111801}
2024-10-12 13:20:17,850 [INFO] Step[400/938]: training loss : 0.059207901377230886 TRAIN  loss dict:  {'classification_loss': 0.059207901377230886}
2024-10-12 13:21:12,480 [INFO] Step[450/938]: training loss : 0.050649538352154196 TRAIN  loss dict:  {'classification_loss': 0.050649538352154196}
2024-10-12 13:21:51,156 [INFO] Step[500/938]: training loss : 0.06939011887181551 TRAIN  loss dict:  {'classification_loss': 0.06939011887181551}
2024-10-12 13:22:26,025 [INFO] Step[550/938]: training loss : 0.06719249251298606 TRAIN  loss dict:  {'classification_loss': 0.06719249251298606}
2024-10-12 13:23:01,322 [INFO] Step[600/938]: training loss : 0.0652043039444834 TRAIN  loss dict:  {'classification_loss': 0.0652043039444834}
2024-10-12 13:23:56,523 [INFO] Step[650/938]: training loss : 0.0466305180452764 TRAIN  loss dict:  {'classification_loss': 0.0466305180452764}
2024-10-12 13:24:47,770 [INFO] Step[700/938]: training loss : 0.03539686869829893 TRAIN  loss dict:  {'classification_loss': 0.03539686869829893}
2024-10-12 13:25:44,398 [INFO] Step[750/938]: training loss : 0.07801521584391594 TRAIN  loss dict:  {'classification_loss': 0.07801521584391594}
2024-10-12 13:26:44,813 [INFO] Step[800/938]: training loss : 0.05517252651508898 TRAIN  loss dict:  {'classification_loss': 0.05517252651508898}
2024-10-12 13:27:29,033 [INFO] Step[850/938]: training loss : 0.04714521373156458 TRAIN  loss dict:  {'classification_loss': 0.04714521373156458}
2024-10-12 13:28:04,087 [INFO] Step[900/938]: training loss : 0.05794891530647874 TRAIN  loss dict:  {'classification_loss': 0.05794891530647874}
2024-10-12 13:31:06,754 [INFO] Label accuracies statistics:
2024-10-12 13:31:06,755 [INFO] {0: 0.8, 1: 1.0, 2: 0.95, 3: 0.9473684210526315, 4: 1.0, 5: 0.8, 6: 0.46153846153846156, 7: 1.0, 8: 0.95, 9: 0.9473684210526315, 10: 1.0, 11: 0.9, 12: 0.9473684210526315, 13: 1.0, 14: 0.85, 15: 1.0, 16: 0.6, 17: 0.7222222222222222, 18: 0.7058823529411765, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 1.0, 22: 0.85, 23: 0.9, 24: 0.5263157894736842, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.9, 29: 0.95, 30: 0.8, 31: 0.8, 32: 1.0, 33: 0.95, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.8, 38: 0.8, 39: 1.0, 40: 0.95, 41: 1.0, 42: 1.0, 43: 0.95, 44: 1.0, 45: 0.8, 46: 0.9, 47: 0.4, 48: 0.6, 49: 0.9473684210526315, 50: 0.85, 51: 0.8333333333333334, 52: 0.7777777777777778, 53: 0.9, 54: 0.95, 55: 0.9473684210526315, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.7777777777777778, 60: 0.85, 61: 0.8421052631578947, 62: 0.5263157894736842, 63: 0.8947368421052632, 64: 0.85, 65: 0.85, 66: 1.0, 67: 0.9, 68: 0.8888888888888888, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.7, 76: 0.8421052631578947, 77: 1.0, 78: 0.6, 79: 1.0, 80: 1.0, 81: 0.65, 82: 0.75, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.9, 92: 0.9, 93: 0.95, 94: 1.0, 95: 0.9166666666666666, 96: 0.7058823529411765, 97: 0.45, 98: 0.42105263157894735, 99: 1.0, 100: 1.0, 101: 0.9, 102: 1.0, 103: 0.65, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.95, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.45, 123: 0.95, 124: 0.95, 125: 0.9, 126: 0.75, 127: 0.65, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.875, 132: 0.9473684210526315, 133: 1.0, 134: 0.9, 135: 0.65, 136: 0.95, 137: 0.85, 138: 0.9, 139: 0.95, 140: 0.85, 141: 1.0, 142: 0.85, 143: 1.0, 144: 0.9, 145: 0.8947368421052632, 146: 1.0, 147: 0.8, 148: 1.0, 149: 1.0, 150: 0.65, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.9, 155: 0.85, 156: 0.9473684210526315, 157: 0.9, 158: 0.7647058823529411, 159: 1.0, 160: 0.95, 161: 0.9, 162: 0.95, 163: 0.9, 164: 0.9473684210526315, 165: 0.65, 166: 1.0, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.7, 173: 0.9, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.9, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.95, 184: 0.95, 185: 0.9, 186: 0.9, 187: 0.6842105263157895, 188: 0.85, 189: 0.9, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.85, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.85, 203: 0.85, 204: 1.0, 205: 0.95, 206: 0.3888888888888889, 207: 0.85, 208: 0.95, 209: 0.95, 210: 0.95, 211: 0.95, 212: 0.8823529411764706, 213: 0.95, 214: 0.9, 215: 0.9, 216: 0.95, 217: 0.95, 218: 0.9, 219: 1.0, 220: 0.9, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.85}

2024-10-12 13:31:06,872 [INFO] [11] TRAIN  loss: 0.05790194580261943 acc: 0.981444618228352
2024-10-12 13:31:06,872 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.05790194580261943}
2024-10-12 13:31:06,872 [INFO] [11] VALIDATION loss: 0.42053889201338895 VALIDATION  acc: 0.8997283838841105
2024-10-12 13:31:06,872 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 0.42053889201338895}
2024-10-12 13:31:06,873 [INFO] 
2024-10-12 13:33:27,123 [INFO] Step[50/938]: training loss : 0.03757056276313961 TRAIN  loss dict:  {'classification_loss': 0.03757056276313961}
2024-10-12 13:34:06,490 [INFO] Step[100/938]: training loss : 0.03740901252720505 TRAIN  loss dict:  {'classification_loss': 0.03740901252720505}
2024-10-12 13:34:41,213 [INFO] Step[150/938]: training loss : 0.0483293916657567 TRAIN  loss dict:  {'classification_loss': 0.0483293916657567}
2024-10-12 13:35:17,699 [INFO] Step[200/938]: training loss : 0.05447232839651406 TRAIN  loss dict:  {'classification_loss': 0.05447232839651406}
2024-10-12 13:36:12,567 [INFO] Step[250/938]: training loss : 0.0708039401564747 TRAIN  loss dict:  {'classification_loss': 0.0708039401564747}
2024-10-12 13:37:03,972 [INFO] Step[300/938]: training loss : 0.040338421328924595 TRAIN  loss dict:  {'classification_loss': 0.040338421328924595}
2024-10-12 13:38:01,485 [INFO] Step[350/938]: training loss : 0.05044553993735462 TRAIN  loss dict:  {'classification_loss': 0.05044553993735462}
2024-10-12 13:39:00,710 [INFO] Step[400/938]: training loss : 0.048183186422102155 TRAIN  loss dict:  {'classification_loss': 0.048183186422102155}
2024-10-12 13:39:44,123 [INFO] Step[450/938]: training loss : 0.0585300015937537 TRAIN  loss dict:  {'classification_loss': 0.0585300015937537}
2024-10-12 13:40:19,258 [INFO] Step[500/938]: training loss : 0.07692905909847468 TRAIN  loss dict:  {'classification_loss': 0.07692905909847468}
2024-10-12 13:40:54,416 [INFO] Step[550/938]: training loss : 0.03465565253980458 TRAIN  loss dict:  {'classification_loss': 0.03465565253980458}
2024-10-12 13:41:42,666 [INFO] Step[600/938]: training loss : 0.052534431600943204 TRAIN  loss dict:  {'classification_loss': 0.052534431600943204}
2024-10-12 13:42:34,164 [INFO] Step[650/938]: training loss : 0.047113735117018225 TRAIN  loss dict:  {'classification_loss': 0.047113735117018225}
2024-10-12 13:43:30,257 [INFO] Step[700/938]: training loss : 0.06141427872702479 TRAIN  loss dict:  {'classification_loss': 0.06141427872702479}
2024-10-12 13:44:26,543 [INFO] Step[750/938]: training loss : 0.049144855909980835 TRAIN  loss dict:  {'classification_loss': 0.049144855909980835}
2024-10-12 13:45:19,187 [INFO] Step[800/938]: training loss : 0.05404843424912542 TRAIN  loss dict:  {'classification_loss': 0.05404843424912542}
2024-10-12 13:45:59,032 [INFO] Step[850/938]: training loss : 0.061401986312121154 TRAIN  loss dict:  {'classification_loss': 0.061401986312121154}
2024-10-12 13:46:34,528 [INFO] Step[900/938]: training loss : 0.06248908907640725 TRAIN  loss dict:  {'classification_loss': 0.06248908907640725}
2024-10-12 13:50:22,693 [INFO] Label accuracies statistics:
2024-10-12 13:50:22,693 [INFO] {0: 0.75, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.95, 5: 0.75, 6: 0.5384615384615384, 7: 0.95, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.85, 12: 0.8947368421052632, 13: 0.75, 14: 0.95, 15: 1.0, 16: 0.65, 17: 0.8333333333333334, 18: 0.7058823529411765, 19: 0.8947368421052632, 20: 1.0, 21: 0.9473684210526315, 22: 0.8, 23: 0.9, 24: 0.8421052631578947, 25: 1.0, 26: 0.8421052631578947, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.85, 31: 0.95, 32: 1.0, 33: 0.9, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.9, 38: 1.0, 39: 1.0, 40: 0.95, 41: 1.0, 42: 0.95, 43: 1.0, 44: 1.0, 45: 0.9, 46: 0.9, 47: 0.45, 48: 0.75, 49: 1.0, 50: 0.95, 51: 0.8333333333333334, 52: 0.8333333333333334, 53: 0.85, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.95, 58: 0.5625, 59: 0.8333333333333334, 60: 0.8, 61: 0.7894736842105263, 62: 0.6842105263157895, 63: 0.8947368421052632, 64: 0.95, 65: 0.85, 66: 1.0, 67: 0.85, 68: 0.7777777777777778, 69: 1.0, 70: 0.95, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.95, 76: 1.0, 77: 1.0, 78: 0.7, 79: 1.0, 80: 1.0, 81: 0.8, 82: 0.8, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 0.95, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 1.0, 93: 0.95, 94: 0.9473684210526315, 95: 1.0, 96: 0.6470588235294118, 97: 0.35, 98: 0.7368421052631579, 99: 0.9, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.85, 104: 0.9, 105: 0.95, 106: 1.0, 107: 0.8, 108: 0.95, 109: 1.0, 110: 0.9, 111: 0.85, 112: 0.9, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.7, 123: 0.9, 124: 1.0, 125: 0.9, 126: 0.75, 127: 0.95, 128: 1.0, 129: 0.85, 130: 1.0, 131: 0.875, 132: 1.0, 133: 1.0, 134: 0.95, 135: 0.85, 136: 0.95, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.7, 141: 1.0, 142: 1.0, 143: 0.9, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 0.9, 149: 0.9473684210526315, 150: 0.7, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.5, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.8235294117647058, 159: 1.0, 160: 0.9, 161: 0.9, 162: 0.9, 163: 0.8, 164: 1.0, 165: 0.65, 166: 0.9, 167: 0.95, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.8, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.95, 185: 0.9, 186: 0.85, 187: 1.0, 188: 0.8, 189: 1.0, 190: 0.5, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.9444444444444444, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 1.0, 204: 1.0, 205: 0.9, 206: 0.3333333333333333, 207: 0.85, 208: 1.0, 209: 1.0, 210: 1.0, 211: 0.85, 212: 0.8823529411764706, 213: 0.95, 214: 1.0, 215: 0.9, 216: 1.0, 217: 0.85, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.95}

2024-10-12 13:50:23,494 [INFO] [12] TRAIN  loss: 0.05222685022233948 acc: 0.9840395279397128
2024-10-12 13:50:23,494 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.05222685022233948}
2024-10-12 13:50:23,494 [INFO] [12] VALIDATION loss: 0.3942507066810346 VALIDATION  acc: 0.9119511090991399
2024-10-12 13:50:23,494 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 0.3942507066810346}
2024-10-12 13:50:23,494 [INFO] 
2024-10-12 13:52:26,521 [INFO] Step[50/938]: training loss : 0.05978856215020642 TRAIN  loss dict:  {'classification_loss': 0.05978856215020642}
2024-10-12 13:53:22,714 [INFO] Step[100/938]: training loss : 0.046302680312655865 TRAIN  loss dict:  {'classification_loss': 0.046302680312655865}
2024-10-12 13:54:18,579 [INFO] Step[150/938]: training loss : 0.04891933783423155 TRAIN  loss dict:  {'classification_loss': 0.04891933783423155}
2024-10-12 13:55:12,532 [INFO] Step[200/938]: training loss : 0.06188284514471889 TRAIN  loss dict:  {'classification_loss': 0.06188284514471889}
2024-10-12 13:56:08,437 [INFO] Step[250/938]: training loss : 0.05473613444250077 TRAIN  loss dict:  {'classification_loss': 0.05473613444250077}
2024-10-12 13:57:05,986 [INFO] Step[300/938]: training loss : 0.0371052304469049 TRAIN  loss dict:  {'classification_loss': 0.0371052304469049}
2024-10-12 13:57:58,528 [INFO] Step[350/938]: training loss : 0.05010002060327679 TRAIN  loss dict:  {'classification_loss': 0.05010002060327679}
2024-10-12 13:58:55,280 [INFO] Step[400/938]: training loss : 0.05139426668174565 TRAIN  loss dict:  {'classification_loss': 0.05139426668174565}
2024-10-12 13:59:51,981 [INFO] Step[450/938]: training loss : 0.06426551308482885 TRAIN  loss dict:  {'classification_loss': 0.06426551308482885}
2024-10-12 14:00:48,044 [INFO] Step[500/938]: training loss : 0.041564236474223436 TRAIN  loss dict:  {'classification_loss': 0.041564236474223436}
2024-10-12 14:01:43,569 [INFO] Step[550/938]: training loss : 0.04931695076171309 TRAIN  loss dict:  {'classification_loss': 0.04931695076171309}
2024-10-12 14:02:40,371 [INFO] Step[600/938]: training loss : 0.050698071115184574 TRAIN  loss dict:  {'classification_loss': 0.050698071115184574}
2024-10-12 14:03:38,583 [INFO] Step[650/938]: training loss : 0.0424244230799377 TRAIN  loss dict:  {'classification_loss': 0.0424244230799377}
2024-10-12 14:04:32,424 [INFO] Step[700/938]: training loss : 0.03936079253675416 TRAIN  loss dict:  {'classification_loss': 0.03936079253675416}
2024-10-12 14:05:28,905 [INFO] Step[750/938]: training loss : 0.03345256634522229 TRAIN  loss dict:  {'classification_loss': 0.03345256634522229}
2024-10-12 14:06:24,731 [INFO] Step[800/938]: training loss : 0.06643680097651668 TRAIN  loss dict:  {'classification_loss': 0.06643680097651668}
2024-10-12 14:07:18,541 [INFO] Step[850/938]: training loss : 0.045801125997677446 TRAIN  loss dict:  {'classification_loss': 0.045801125997677446}
2024-10-12 14:08:12,863 [INFO] Step[900/938]: training loss : 0.04019718852825463 TRAIN  loss dict:  {'classification_loss': 0.04019718852825463}
2024-10-12 14:11:37,336 [INFO] Label accuracies statistics:
2024-10-12 14:11:37,336 [INFO] {0: 0.75, 1: 1.0, 2: 0.95, 3: 1.0, 4: 0.9, 5: 0.95, 6: 0.46153846153846156, 7: 0.9, 8: 0.9, 9: 0.9473684210526315, 10: 1.0, 11: 0.9, 12: 0.8947368421052632, 13: 0.95, 14: 0.95, 15: 0.9, 16: 0.65, 17: 0.6666666666666666, 18: 0.7647058823529411, 19: 0.8421052631578947, 20: 0.8421052631578947, 21: 0.8947368421052632, 22: 0.8, 23: 0.9, 24: 0.47368421052631576, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 0.9, 30: 0.85, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.95, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.9, 44: 0.9473684210526315, 45: 1.0, 46: 0.9, 47: 0.5, 48: 0.9, 49: 1.0, 50: 0.95, 51: 0.8333333333333334, 52: 0.9444444444444444, 53: 0.85, 54: 1.0, 55: 0.8421052631578947, 56: 1.0, 57: 0.9, 58: 0.75, 59: 0.7777777777777778, 60: 0.9, 61: 0.8947368421052632, 62: 0.6842105263157895, 63: 0.8947368421052632, 64: 1.0, 65: 0.85, 66: 1.0, 67: 0.6, 68: 0.8888888888888888, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.9473684210526315, 74: 0.95, 75: 0.85, 76: 0.8421052631578947, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.7, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 1.0, 93: 0.9, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.8, 98: 0.8947368421052632, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.65, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.8, 112: 0.9, 113: 0.9, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.85, 122: 0.8, 123: 0.95, 124: 1.0, 125: 0.9, 126: 0.65, 127: 0.85, 128: 1.0, 129: 0.45, 130: 1.0, 131: 0.9375, 132: 0.8947368421052632, 133: 1.0, 134: 0.6, 135: 0.65, 136: 1.0, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.7, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 1.0, 149: 1.0, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.9, 155: 1.0, 156: 1.0, 157: 0.85, 158: 0.7647058823529411, 159: 1.0, 160: 1.0, 161: 0.85, 162: 0.85, 163: 1.0, 164: 0.8947368421052632, 165: 0.45, 166: 0.95, 167: 1.0, 168: 0.85, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.7, 173: 0.9, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.9, 184: 0.95, 185: 0.95, 186: 0.9, 187: 0.8947368421052632, 188: 0.8, 189: 0.95, 190: 0.95, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.8, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.85, 203: 0.5, 204: 0.9, 205: 0.9, 206: 0.5, 207: 0.8, 208: 1.0, 209: 0.9, 210: 1.0, 211: 0.8, 212: 0.8823529411764706, 213: 0.85, 214: 0.85, 215: 0.9, 216: 0.85, 217: 0.95, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.95}

2024-10-12 14:11:37,389 [INFO] [13] TRAIN  loss: 0.04963859362692298 acc: 0.9844660884402104
2024-10-12 14:11:37,389 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.04963859362692298}
2024-10-12 14:11:37,389 [INFO] [13] VALIDATION loss: 0.40960587279609956 VALIDATION  acc: 0.9044816659121775
2024-10-12 14:11:37,389 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 0.40960587279609956}
2024-10-12 14:11:37,389 [INFO] 
2024-10-12 14:13:37,909 [INFO] Step[50/938]: training loss : 0.047079542584251614 TRAIN  loss dict:  {'classification_loss': 0.047079542584251614}
2024-10-12 14:14:35,439 [INFO] Step[100/938]: training loss : 0.041426837879698725 TRAIN  loss dict:  {'classification_loss': 0.041426837879698725}
2024-10-12 14:15:33,697 [INFO] Step[150/938]: training loss : 0.0360157801094465 TRAIN  loss dict:  {'classification_loss': 0.0360157801094465}
2024-10-12 14:16:25,768 [INFO] Step[200/938]: training loss : 0.03188747307052836 TRAIN  loss dict:  {'classification_loss': 0.03188747307052836}
2024-10-12 14:17:22,492 [INFO] Step[250/938]: training loss : 0.036666421368718144 TRAIN  loss dict:  {'classification_loss': 0.036666421368718144}
2024-10-12 14:18:19,116 [INFO] Step[300/938]: training loss : 0.042429499083664265 TRAIN  loss dict:  {'classification_loss': 0.042429499083664265}
2024-10-12 14:19:14,316 [INFO] Step[350/938]: training loss : 0.032247242745943365 TRAIN  loss dict:  {'classification_loss': 0.032247242745943365}
2024-10-12 14:20:12,254 [INFO] Step[400/938]: training loss : 0.03941681204829365 TRAIN  loss dict:  {'classification_loss': 0.03941681204829365}
2024-10-12 14:21:12,498 [INFO] Step[450/938]: training loss : 0.037748931425157936 TRAIN  loss dict:  {'classification_loss': 0.037748931425157936}
2024-10-12 14:22:05,102 [INFO] Step[500/938]: training loss : 0.0627003675326705 TRAIN  loss dict:  {'classification_loss': 0.0627003675326705}
2024-10-12 14:23:02,523 [INFO] Step[550/938]: training loss : 0.04489217603579163 TRAIN  loss dict:  {'classification_loss': 0.04489217603579163}
2024-10-12 14:23:58,696 [INFO] Step[600/938]: training loss : 0.06124750575982034 TRAIN  loss dict:  {'classification_loss': 0.06124750575982034}
2024-10-12 14:24:53,911 [INFO] Step[650/938]: training loss : 0.03996275385143235 TRAIN  loss dict:  {'classification_loss': 0.03996275385143235}
2024-10-12 14:25:50,815 [INFO] Step[700/938]: training loss : 0.05076546549331397 TRAIN  loss dict:  {'classification_loss': 0.05076546549331397}
2024-10-12 14:26:49,576 [INFO] Step[750/938]: training loss : 0.05671419685706496 TRAIN  loss dict:  {'classification_loss': 0.05671419685706496}
2024-10-12 14:27:43,651 [INFO] Step[800/938]: training loss : 0.05621087960433215 TRAIN  loss dict:  {'classification_loss': 0.05621087960433215}
2024-10-12 14:28:40,505 [INFO] Step[850/938]: training loss : 0.0446128693036735 TRAIN  loss dict:  {'classification_loss': 0.0446128693036735}
2024-10-12 14:29:37,005 [INFO] Step[900/938]: training loss : 0.043573688839096576 TRAIN  loss dict:  {'classification_loss': 0.043573688839096576}
2024-10-12 14:33:24,744 [INFO] Label accuracies statistics:
2024-10-12 14:33:24,744 [INFO] {0: 0.75, 1: 1.0, 2: 0.85, 3: 1.0, 4: 0.95, 5: 0.85, 6: 0.6153846153846154, 7: 0.95, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.9473684210526315, 13: 0.9, 14: 0.9, 15: 0.95, 16: 0.35, 17: 0.6111111111111112, 18: 0.8823529411764706, 19: 0.8947368421052632, 20: 0.8421052631578947, 21: 1.0, 22: 0.85, 23: 0.85, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.9, 29: 1.0, 30: 0.9, 31: 0.95, 32: 1.0, 33: 0.85, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.75, 38: 0.95, 39: 1.0, 40: 0.8, 41: 0.95, 42: 0.9, 43: 0.9, 44: 0.8947368421052632, 45: 0.95, 46: 0.9, 47: 0.2, 48: 0.7, 49: 1.0, 50: 0.95, 51: 0.8333333333333334, 52: 0.8888888888888888, 53: 0.8, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.8333333333333334, 60: 0.9, 61: 0.7894736842105263, 62: 0.5789473684210527, 63: 0.7894736842105263, 64: 0.8, 65: 0.85, 66: 1.0, 67: 0.9, 68: 0.7777777777777778, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.75, 76: 0.8421052631578947, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.75, 82: 0.8, 83: 1.0, 84: 0.8, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.95, 92: 1.0, 93: 0.9, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.8, 98: 0.7368421052631579, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.9473684210526315, 103: 0.7, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.8, 108: 0.9, 109: 1.0, 110: 1.0, 111: 0.95, 112: 1.0, 113: 0.9, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.75, 123: 0.9, 124: 1.0, 125: 0.85, 126: 0.75, 127: 0.65, 128: 0.95, 129: 0.75, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 1.0, 135: 0.8, 136: 0.85, 137: 0.85, 138: 0.9, 139: 0.85, 140: 0.9, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.8947368421052632, 146: 0.95, 147: 0.85, 148: 0.95, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.95, 153: 0.8, 154: 0.7, 155: 0.9, 156: 0.7894736842105263, 157: 1.0, 158: 0.7647058823529411, 159: 1.0, 160: 1.0, 161: 0.85, 162: 0.9, 163: 0.9, 164: 0.8421052631578947, 165: 0.55, 166: 1.0, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.8, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.9, 184: 0.95, 185: 0.85, 186: 0.8, 187: 0.7894736842105263, 188: 0.85, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 0.9444444444444444, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 1.0, 201: 0.95, 202: 0.95, 203: 0.6, 204: 0.9, 205: 0.95, 206: 0.3333333333333333, 207: 0.85, 208: 1.0, 209: 0.85, 210: 1.0, 211: 0.85, 212: 0.8823529411764706, 213: 0.85, 214: 0.85, 215: 0.9, 216: 0.85, 217: 0.95, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 0.95, 224: 0.9, 225: 1.0}

2024-10-12 14:33:24,809 [INFO] [14] TRAIN  loss: 0.044260735055114 acc: 0.9867410777761979
2024-10-12 14:33:24,809 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.044260735055114}
2024-10-12 14:33:24,810 [INFO] [14] VALIDATION loss: 0.42966737387689286 VALIDATION  acc: 0.8988229968311453
2024-10-12 14:33:24,810 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 0.42966737387689286}
2024-10-12 14:33:24,810 [INFO] 
2024-10-12 14:35:07,502 [INFO] Step[50/938]: training loss : 0.046485112174414096 TRAIN  loss dict:  {'classification_loss': 0.046485112174414096}
2024-10-12 14:36:02,910 [INFO] Step[100/938]: training loss : 0.04151172354118898 TRAIN  loss dict:  {'classification_loss': 0.04151172354118898}
2024-10-12 14:36:57,129 [INFO] Step[150/938]: training loss : 0.030764069254510105 TRAIN  loss dict:  {'classification_loss': 0.030764069254510105}
2024-10-12 14:37:53,800 [INFO] Step[200/938]: training loss : 0.04223495780956 TRAIN  loss dict:  {'classification_loss': 0.04223495780956}
2024-10-12 14:38:50,291 [INFO] Step[250/938]: training loss : 0.03604331699665636 TRAIN  loss dict:  {'classification_loss': 0.03604331699665636}
2024-10-12 14:39:43,805 [INFO] Step[300/938]: training loss : 0.03205885102273896 TRAIN  loss dict:  {'classification_loss': 0.03205885102273896}
2024-10-12 14:40:40,064 [INFO] Step[350/938]: training loss : 0.04025723934173584 TRAIN  loss dict:  {'classification_loss': 0.04025723934173584}
2024-10-12 14:41:36,859 [INFO] Step[400/938]: training loss : 0.04543086932040751 TRAIN  loss dict:  {'classification_loss': 0.04543086932040751}
2024-10-12 14:42:32,501 [INFO] Step[450/938]: training loss : 0.0303104738984257 TRAIN  loss dict:  {'classification_loss': 0.0303104738984257}
2024-10-12 14:43:26,804 [INFO] Step[500/938]: training loss : 0.03828042637789622 TRAIN  loss dict:  {'classification_loss': 0.03828042637789622}
2024-10-12 14:44:23,622 [INFO] Step[550/938]: training loss : 0.032876542648300526 TRAIN  loss dict:  {'classification_loss': 0.032876542648300526}
2024-10-12 14:45:19,733 [INFO] Step[600/938]: training loss : 0.04428339982405305 TRAIN  loss dict:  {'classification_loss': 0.04428339982405305}
2024-10-12 14:46:13,687 [INFO] Step[650/938]: training loss : 0.05760513342684135 TRAIN  loss dict:  {'classification_loss': 0.05760513342684135}
2024-10-12 14:47:10,312 [INFO] Step[700/938]: training loss : 0.0402771666587796 TRAIN  loss dict:  {'classification_loss': 0.0402771666587796}
2024-10-12 14:48:07,439 [INFO] Step[750/938]: training loss : 0.03834644867107272 TRAIN  loss dict:  {'classification_loss': 0.03834644867107272}
2024-10-12 14:49:01,871 [INFO] Step[800/938]: training loss : 0.04110475146677345 TRAIN  loss dict:  {'classification_loss': 0.04110475146677345}
2024-10-12 14:49:56,323 [INFO] Step[850/938]: training loss : 0.04533238261006772 TRAIN  loss dict:  {'classification_loss': 0.04533238261006772}
2024-10-12 14:50:54,202 [INFO] Step[900/938]: training loss : 0.030674748672172427 TRAIN  loss dict:  {'classification_loss': 0.030674748672172427}
2024-10-12 14:54:11,920 [INFO] Label accuracies statistics:
2024-10-12 14:54:11,920 [INFO] {0: 0.95, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.85, 5: 0.75, 6: 0.6923076923076923, 7: 0.95, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.9, 12: 0.8947368421052632, 13: 1.0, 14: 0.9, 15: 1.0, 16: 0.7, 17: 0.7222222222222222, 18: 0.8823529411764706, 19: 1.0, 20: 0.9473684210526315, 21: 1.0, 22: 0.8, 23: 0.95, 24: 0.631578947368421, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 0.8, 29: 0.95, 30: 0.9, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.8, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.95, 42: 1.0, 43: 0.9, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.35, 48: 0.7, 49: 0.9473684210526315, 50: 0.8, 51: 0.9444444444444444, 52: 0.8333333333333334, 53: 0.85, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.95, 58: 0.8125, 59: 0.8888888888888888, 60: 0.8, 61: 0.7368421052631579, 62: 0.8421052631578947, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.85, 68: 0.7222222222222222, 69: 0.8888888888888888, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.8, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.75, 82: 0.8, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.95, 92: 0.95, 93: 0.95, 94: 1.0, 95: 1.0, 96: 0.5882352941176471, 97: 0.8, 98: 0.6842105263157895, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.65, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.95, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.85, 122: 0.65, 123: 0.95, 124: 0.95, 125: 0.6, 126: 0.6, 127: 0.85, 128: 0.95, 129: 0.6, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.6, 135: 0.7, 136: 1.0, 137: 0.9, 138: 0.9, 139: 1.0, 140: 0.8, 141: 1.0, 142: 0.95, 143: 1.0, 144: 0.95, 145: 0.8421052631578947, 146: 0.95, 147: 0.8, 148: 1.0, 149: 1.0, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.85, 154: 0.9, 155: 0.9, 156: 1.0, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 0.85, 161: 0.9, 162: 0.85, 163: 0.95, 164: 0.8421052631578947, 165: 0.55, 166: 0.95, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.7, 173: 0.85, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.65, 184: 0.95, 185: 0.85, 186: 0.9, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.9, 191: 1.0, 192: 1.0, 193: 0.9, 194: 0.95, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.95, 203: 1.0, 204: 0.95, 205: 0.95, 206: 0.5, 207: 0.85, 208: 0.95, 209: 0.9, 210: 1.0, 211: 0.95, 212: 0.8823529411764706, 213: 0.9, 214: 0.85, 215: 0.9, 216: 0.8, 217: 0.95, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.95}

2024-10-12 14:54:12,022 [INFO] [15] TRAIN  loss: 0.03971386131929057 acc: 0.9875586520688184
2024-10-12 14:54:12,023 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.03971386131929057}
2024-10-12 14:54:12,023 [INFO] [15] VALIDATION loss: 0.39905457433338304 VALIDATION  acc: 0.908103214124038
2024-10-12 14:54:12,023 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 0.39905457433338304}
2024-10-12 14:54:12,024 [INFO] 
2024-10-12 14:56:16,186 [INFO] Step[50/938]: training loss : 0.03046283471630886 TRAIN  loss dict:  {'classification_loss': 0.03046283471630886}
2024-10-12 14:57:11,952 [INFO] Step[100/938]: training loss : 0.042767728716135024 TRAIN  loss dict:  {'classification_loss': 0.042767728716135024}
2024-10-12 14:58:10,932 [INFO] Step[150/938]: training loss : 0.04173327832017094 TRAIN  loss dict:  {'classification_loss': 0.04173327832017094}
2024-10-12 14:59:01,426 [INFO] Step[200/938]: training loss : 0.04435959431808442 TRAIN  loss dict:  {'classification_loss': 0.04435959431808442}
2024-10-12 14:59:57,738 [INFO] Step[250/938]: training loss : 0.04341302122920752 TRAIN  loss dict:  {'classification_loss': 0.04341302122920752}
2024-10-12 15:00:53,048 [INFO] Step[300/938]: training loss : 0.04295463328482583 TRAIN  loss dict:  {'classification_loss': 0.04295463328482583}
2024-10-12 15:01:46,063 [INFO] Step[350/938]: training loss : 0.04447354359319434 TRAIN  loss dict:  {'classification_loss': 0.04447354359319434}
2024-10-12 15:02:43,568 [INFO] Step[400/938]: training loss : 0.03986105361836963 TRAIN  loss dict:  {'classification_loss': 0.03986105361836963}
2024-10-12 15:03:43,557 [INFO] Step[450/938]: training loss : 0.03508308629272506 TRAIN  loss dict:  {'classification_loss': 0.03508308629272506}
2024-10-12 15:04:35,880 [INFO] Step[500/938]: training loss : 0.031966181055177005 TRAIN  loss dict:  {'classification_loss': 0.031966181055177005}
2024-10-12 15:05:31,459 [INFO] Step[550/938]: training loss : 0.0316785405902192 TRAIN  loss dict:  {'classification_loss': 0.0316785405902192}
2024-10-12 15:06:28,060 [INFO] Step[600/938]: training loss : 0.03851188796805218 TRAIN  loss dict:  {'classification_loss': 0.03851188796805218}
2024-10-12 15:07:23,634 [INFO] Step[650/938]: training loss : 0.03984335856745019 TRAIN  loss dict:  {'classification_loss': 0.03984335856745019}
2024-10-12 15:08:20,508 [INFO] Step[700/938]: training loss : 0.042885778499767185 TRAIN  loss dict:  {'classification_loss': 0.042885778499767185}
2024-10-12 15:09:17,702 [INFO] Step[750/938]: training loss : 0.040484122573398056 TRAIN  loss dict:  {'classification_loss': 0.040484122573398056}
2024-10-12 15:10:12,512 [INFO] Step[800/938]: training loss : 0.046952748659532514 TRAIN  loss dict:  {'classification_loss': 0.046952748659532514}
2024-10-12 15:11:06,907 [INFO] Step[850/938]: training loss : 0.03723380152601749 TRAIN  loss dict:  {'classification_loss': 0.03723380152601749}
2024-10-12 15:12:03,468 [INFO] Step[900/938]: training loss : 0.04897337734233588 TRAIN  loss dict:  {'classification_loss': 0.04897337734233588}
2024-10-12 15:15:49,379 [INFO] Label accuracies statistics:
2024-10-12 15:15:49,379 [INFO] {0: 0.85, 1: 1.0, 2: 0.85, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.46153846153846156, 7: 0.95, 8: 0.95, 9: 1.0, 10: 1.0, 11: 0.85, 12: 0.8421052631578947, 13: 0.85, 14: 1.0, 15: 0.85, 16: 0.35, 17: 0.8333333333333334, 18: 0.8823529411764706, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 0.8947368421052632, 22: 0.85, 23: 0.95, 24: 0.7894736842105263, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.9, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.8, 38: 0.9, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.75, 43: 0.9, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.55, 48: 0.65, 49: 1.0, 50: 1.0, 51: 0.8333333333333334, 52: 0.7222222222222222, 53: 1.0, 54: 1.0, 55: 0.9473684210526315, 56: 1.0, 57: 0.9, 58: 0.9375, 59: 0.8333333333333334, 60: 0.9, 61: 0.8421052631578947, 62: 0.8421052631578947, 63: 0.8947368421052632, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.7, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8421052631578947, 74: 1.0, 75: 0.8, 76: 1.0, 77: 1.0, 78: 0.8, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.8, 83: 1.0, 84: 0.8, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 0.95, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.6470588235294118, 97: 0.7, 98: 0.5263157894736842, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.9473684210526315, 103: 0.7, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.9, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.75, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.9, 122: 0.9, 123: 0.8, 124: 1.0, 125: 0.85, 126: 0.7, 127: 0.9, 128: 0.95, 129: 0.8, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 0.7, 135: 0.75, 136: 1.0, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.85, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 0.85, 149: 1.0, 150: 0.8, 151: 1.0, 152: 0.8, 153: 0.8, 154: 0.75, 155: 0.9, 156: 1.0, 157: 0.95, 158: 0.8235294117647058, 159: 1.0, 160: 0.9, 161: 0.85, 162: 0.8, 163: 1.0, 164: 0.7894736842105263, 165: 0.65, 166: 0.8, 167: 0.95, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.9, 184: 1.0, 185: 0.9, 186: 0.9, 187: 0.8421052631578947, 188: 0.8, 189: 1.0, 190: 0.85, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 0.7777777777777778, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 0.95, 204: 0.95, 205: 1.0, 206: 0.2222222222222222, 207: 0.8, 208: 0.9, 209: 1.0, 210: 1.0, 211: 0.9, 212: 0.8823529411764706, 213: 0.9, 214: 1.0, 215: 0.9, 216: 0.85, 217: 0.85, 218: 1.0, 219: 1.0, 220: 0.95, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.8, 225: 0.9}

2024-10-12 15:15:50,046 [INFO] [16] TRAIN  loss: 0.04003155456208286 acc: 0.9873453718185696
2024-10-12 15:15:50,046 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.04003155456208286}
2024-10-12 15:15:50,046 [INFO] [16] VALIDATION loss: 0.38816733496590844 VALIDATION  acc: 0.906518786781349
2024-10-12 15:15:50,046 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 0.38816733496590844}
2024-10-12 15:15:50,046 [INFO] 
2024-10-12 15:17:35,383 [INFO] Step[50/938]: training loss : 0.030038523575058207 TRAIN  loss dict:  {'classification_loss': 0.030038523575058207}
2024-10-12 15:18:31,514 [INFO] Step[100/938]: training loss : 0.03324454742949456 TRAIN  loss dict:  {'classification_loss': 0.03324454742949456}
2024-10-12 15:19:24,966 [INFO] Step[150/938]: training loss : 0.038347803162760104 TRAIN  loss dict:  {'classification_loss': 0.038347803162760104}
2024-10-12 15:20:20,460 [INFO] Step[200/938]: training loss : 0.04281831972999498 TRAIN  loss dict:  {'classification_loss': 0.04281831972999498}
2024-10-12 15:21:18,410 [INFO] Step[250/938]: training loss : 0.040236603184603155 TRAIN  loss dict:  {'classification_loss': 0.040236603184603155}
2024-10-12 15:22:12,135 [INFO] Step[300/938]: training loss : 0.04251613477477804 TRAIN  loss dict:  {'classification_loss': 0.04251613477477804}
2024-10-12 15:23:06,926 [INFO] Step[350/938]: training loss : 0.04032048303866759 TRAIN  loss dict:  {'classification_loss': 0.04032048303866759}
2024-10-12 15:24:03,654 [INFO] Step[400/938]: training loss : 0.02116938610211946 TRAIN  loss dict:  {'classification_loss': 0.02116938610211946}
2024-10-12 15:24:56,721 [INFO] Step[450/938]: training loss : 0.028164303024532274 TRAIN  loss dict:  {'classification_loss': 0.028164303024532274}
2024-10-12 15:25:51,066 [INFO] Step[500/938]: training loss : 0.04758081038948148 TRAIN  loss dict:  {'classification_loss': 0.04758081038948148}
2024-10-12 15:26:46,923 [INFO] Step[550/938]: training loss : 0.051365030788583683 TRAIN  loss dict:  {'classification_loss': 0.051365030788583683}
2024-10-12 15:27:45,674 [INFO] Step[600/938]: training loss : 0.0376003568735905 TRAIN  loss dict:  {'classification_loss': 0.0376003568735905}
2024-10-12 15:28:38,475 [INFO] Step[650/938]: training loss : 0.0372387732914649 TRAIN  loss dict:  {'classification_loss': 0.0372387732914649}
2024-10-12 15:29:34,904 [INFO] Step[700/938]: training loss : 0.029224006179720163 TRAIN  loss dict:  {'classification_loss': 0.029224006179720163}
2024-10-12 15:30:31,164 [INFO] Step[750/938]: training loss : 0.03653141170507297 TRAIN  loss dict:  {'classification_loss': 0.03653141170507297}
2024-10-12 15:31:25,881 [INFO] Step[800/938]: training loss : 0.05197718351148069 TRAIN  loss dict:  {'classification_loss': 0.05197718351148069}
2024-10-12 15:32:23,745 [INFO] Step[850/938]: training loss : 0.03342980422545225 TRAIN  loss dict:  {'classification_loss': 0.03342980422545225}
2024-10-12 15:33:18,442 [INFO] Step[900/938]: training loss : 0.0391109749826137 TRAIN  loss dict:  {'classification_loss': 0.0391109749826137}
2024-10-12 15:36:33,634 [INFO] Label accuracies statistics:
2024-10-12 15:36:33,635 [INFO] {0: 0.75, 1: 1.0, 2: 0.85, 3: 1.0, 4: 0.9, 5: 0.8, 6: 0.5384615384615384, 7: 0.9, 8: 1.0, 9: 0.8947368421052632, 10: 1.0, 11: 0.95, 12: 1.0, 13: 0.95, 14: 1.0, 15: 1.0, 16: 0.55, 17: 0.5555555555555556, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.8947368421052632, 21: 1.0, 22: 0.75, 23: 0.9, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 0.9, 29: 1.0, 30: 0.85, 31: 0.7, 32: 1.0, 33: 0.9, 34: 0.7, 35: 1.0, 36: 0.9473684210526315, 37: 0.9, 38: 0.95, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.95, 44: 1.0, 45: 0.9, 46: 0.9, 47: 0.4, 48: 0.7, 49: 1.0, 50: 0.95, 51: 0.8333333333333334, 52: 0.6666666666666666, 53: 1.0, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.8125, 59: 0.7777777777777778, 60: 0.95, 61: 0.7894736842105263, 62: 0.6842105263157895, 63: 0.8421052631578947, 64: 0.9, 65: 0.8, 66: 1.0, 67: 0.7, 68: 0.8888888888888888, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.9473684210526315, 77: 1.0, 78: 0.75, 79: 1.0, 80: 1.0, 81: 0.8, 82: 0.7, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.75, 91: 0.85, 92: 0.9, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.7647058823529411, 97: 0.7, 98: 0.5789473684210527, 99: 1.0, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.85, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.95, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.85, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.6, 123: 0.9, 124: 0.95, 125: 0.85, 126: 0.7, 127: 0.85, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.875, 132: 0.7894736842105263, 133: 1.0, 134: 0.65, 135: 0.9, 136: 1.0, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.7, 141: 1.0, 142: 1.0, 143: 0.95, 144: 0.9, 145: 0.9473684210526315, 146: 0.95, 147: 0.85, 148: 1.0, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.65, 155: 1.0, 156: 0.8947368421052632, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 0.9, 161: 0.85, 162: 0.85, 163: 0.9, 164: 0.8947368421052632, 165: 0.55, 166: 0.8, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.85, 173: 0.9, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.95, 184: 1.0, 185: 0.9, 186: 0.95, 187: 0.8421052631578947, 188: 0.85, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8421052631578947, 201: 1.0, 202: 1.0, 203: 0.8, 204: 1.0, 205: 1.0, 206: 0.2777777777777778, 207: 0.85, 208: 0.9, 209: 0.95, 210: 1.0, 211: 1.0, 212: 1.0, 213: 0.9, 214: 1.0, 215: 0.9, 216: 0.8, 217: 0.95, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 1.0}

2024-10-12 15:36:33,731 [INFO] [17] TRAIN  loss: 0.037246109087990455 acc: 0.9883406796530642
2024-10-12 15:36:33,731 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.037246109087990455}
2024-10-12 15:36:33,732 [INFO] [17] VALIDATION loss: 0.4148852644347416 VALIDATION  acc: 0.906518786781349
2024-10-12 15:36:33,732 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 0.4148852644347416}
2024-10-12 15:36:33,733 [INFO] 
2024-10-12 15:38:36,667 [INFO] Step[50/938]: training loss : 0.03580342360539362 TRAIN  loss dict:  {'classification_loss': 0.03580342360539362}
2024-10-12 15:39:33,103 [INFO] Step[100/938]: training loss : 0.027555095576681198 TRAIN  loss dict:  {'classification_loss': 0.027555095576681198}
2024-10-12 15:40:26,146 [INFO] Step[150/938]: training loss : 0.02305618237471208 TRAIN  loss dict:  {'classification_loss': 0.02305618237471208}
2024-10-12 15:41:19,433 [INFO] Step[200/938]: training loss : 0.03362312742276117 TRAIN  loss dict:  {'classification_loss': 0.03362312742276117}
2024-10-12 15:42:15,714 [INFO] Step[250/938]: training loss : 0.03225754034006968 TRAIN  loss dict:  {'classification_loss': 0.03225754034006968}
2024-10-12 15:43:08,997 [INFO] Step[300/938]: training loss : 0.022135737631469966 TRAIN  loss dict:  {'classification_loss': 0.022135737631469966}
2024-10-12 15:44:02,846 [INFO] Step[350/938]: training loss : 0.03784398879739456 TRAIN  loss dict:  {'classification_loss': 0.03784398879739456}
2024-10-12 15:44:59,710 [INFO] Step[400/938]: training loss : 0.033068310299422594 TRAIN  loss dict:  {'classification_loss': 0.033068310299422594}
2024-10-12 15:45:58,273 [INFO] Step[450/938]: training loss : 0.03997675102786161 TRAIN  loss dict:  {'classification_loss': 0.03997675102786161}
2024-10-12 15:46:49,986 [INFO] Step[500/938]: training loss : 0.06941953517962247 TRAIN  loss dict:  {'classification_loss': 0.06941953517962247}
2024-10-12 15:47:46,790 [INFO] Step[550/938]: training loss : 0.04148474324028939 TRAIN  loss dict:  {'classification_loss': 0.04148474324028939}
2024-10-12 15:48:42,845 [INFO] Step[600/938]: training loss : 0.025836114805424585 TRAIN  loss dict:  {'classification_loss': 0.025836114805424585}
2024-10-12 15:49:35,931 [INFO] Step[650/938]: training loss : 0.03483909766189754 TRAIN  loss dict:  {'classification_loss': 0.03483909766189754}
2024-10-12 15:50:31,423 [INFO] Step[700/938]: training loss : 0.03620613234234042 TRAIN  loss dict:  {'classification_loss': 0.03620613234234042}
2024-10-12 15:51:30,109 [INFO] Step[750/938]: training loss : 0.03402654674951919 TRAIN  loss dict:  {'classification_loss': 0.03402654674951919}
2024-10-12 15:52:24,184 [INFO] Step[800/938]: training loss : 0.03416331642307341 TRAIN  loss dict:  {'classification_loss': 0.03416331642307341}
2024-10-12 15:53:20,217 [INFO] Step[850/938]: training loss : 0.025826613111421468 TRAIN  loss dict:  {'classification_loss': 0.025826613111421468}
2024-10-12 15:54:16,489 [INFO] Step[900/938]: training loss : 0.02236396596534178 TRAIN  loss dict:  {'classification_loss': 0.02236396596534178}
2024-10-12 15:57:36,500 [INFO] Label accuracies statistics:
2024-10-12 15:57:36,500 [INFO] {0: 0.95, 1: 1.0, 2: 0.8, 3: 1.0, 4: 0.85, 5: 0.8, 6: 0.46153846153846156, 7: 0.95, 8: 0.85, 9: 0.8947368421052632, 10: 0.7894736842105263, 11: 1.0, 12: 0.8947368421052632, 13: 0.8, 14: 1.0, 15: 0.95, 16: 0.6, 17: 0.6111111111111112, 18: 0.7647058823529411, 19: 1.0, 20: 1.0, 21: 0.9473684210526315, 22: 0.8, 23: 0.9, 24: 0.631578947368421, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 1.0, 29: 1.0, 30: 0.95, 31: 1.0, 32: 0.95, 33: 1.0, 34: 0.9, 35: 1.0, 36: 1.0, 37: 0.75, 38: 0.9, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.95, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.55, 48: 0.7, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.6111111111111112, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.7777777777777778, 60: 0.9, 61: 0.7894736842105263, 62: 0.7894736842105263, 63: 0.8947368421052632, 64: 0.9, 65: 0.9, 66: 0.85, 67: 0.85, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.85, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.85, 82: 0.8, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 0.8235294117647058, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.9, 92: 0.95, 93: 1.0, 94: 1.0, 95: 0.9166666666666666, 96: 0.7058823529411765, 97: 0.75, 98: 0.6842105263157895, 99: 0.95, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.75, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.75, 123: 0.85, 124: 1.0, 125: 0.85, 126: 0.85, 127: 0.8, 128: 1.0, 129: 0.65, 130: 1.0, 131: 0.9375, 132: 1.0, 133: 1.0, 134: 0.9, 135: 0.7, 136: 1.0, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.85, 141: 0.95, 142: 0.9, 143: 0.95, 144: 0.95, 145: 0.9473684210526315, 146: 0.95, 147: 0.85, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.9, 153: 1.0, 154: 0.8, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 0.9, 161: 0.9, 162: 0.95, 163: 1.0, 164: 0.8947368421052632, 165: 0.55, 166: 0.9, 167: 0.95, 168: 0.85, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.65, 173: 0.85, 174: 0.95, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.95, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.65, 184: 1.0, 185: 0.9, 186: 0.9, 187: 0.8947368421052632, 188: 0.75, 189: 0.85, 190: 0.7, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 1.0, 201: 1.0, 202: 0.95, 203: 0.8, 204: 1.0, 205: 0.95, 206: 0.5, 207: 0.6, 208: 0.95, 209: 0.95, 210: 1.0, 211: 0.9, 212: 0.8823529411764706, 213: 0.9, 214: 0.95, 215: 0.9, 216: 0.85, 217: 1.0, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.85}

2024-10-12 15:57:36,996 [INFO] [18] TRAIN  loss: 0.03440536841444089 acc: 0.9889449736954358
2024-10-12 15:57:36,996 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.03440536841444089}
2024-10-12 15:57:36,996 [INFO] [18] VALIDATION loss: 0.37794450491988707 VALIDATION  acc: 0.9099139882299683
2024-10-12 15:57:36,996 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 0.37794450491988707}
2024-10-12 15:57:36,997 [INFO] 
2024-10-12 15:59:06,545 [INFO] Step[50/938]: training loss : 0.03770715365651995 TRAIN  loss dict:  {'classification_loss': 0.03770715365651995}
2024-10-12 16:00:01,287 [INFO] Step[100/938]: training loss : 0.03491809323662892 TRAIN  loss dict:  {'classification_loss': 0.03491809323662892}
2024-10-12 16:00:56,053 [INFO] Step[150/938]: training loss : 0.02556495917029679 TRAIN  loss dict:  {'classification_loss': 0.02556495917029679}
2024-10-12 16:01:50,684 [INFO] Step[200/938]: training loss : 0.036541544570354745 TRAIN  loss dict:  {'classification_loss': 0.036541544570354745}
2024-10-12 16:02:45,332 [INFO] Step[250/938]: training loss : 0.04489386033732444 TRAIN  loss dict:  {'classification_loss': 0.04489386033732444}
2024-10-12 16:03:39,740 [INFO] Step[300/938]: training loss : 0.04137094815261662 TRAIN  loss dict:  {'classification_loss': 0.04137094815261662}
2024-10-12 16:04:34,348 [INFO] Step[350/938]: training loss : 0.037248718834016474 TRAIN  loss dict:  {'classification_loss': 0.037248718834016474}
2024-10-12 16:05:28,697 [INFO] Step[400/938]: training loss : 0.03763847910799086 TRAIN  loss dict:  {'classification_loss': 0.03763847910799086}
2024-10-12 16:06:22,856 [INFO] Step[450/938]: training loss : 0.03474669502465986 TRAIN  loss dict:  {'classification_loss': 0.03474669502465986}
2024-10-12 16:07:17,356 [INFO] Step[500/938]: training loss : 0.04826008010655641 TRAIN  loss dict:  {'classification_loss': 0.04826008010655641}
2024-10-12 16:08:11,747 [INFO] Step[550/938]: training loss : 0.0335420734109357 TRAIN  loss dict:  {'classification_loss': 0.0335420734109357}
2024-10-12 16:09:06,102 [INFO] Step[600/938]: training loss : 0.027470360229490325 TRAIN  loss dict:  {'classification_loss': 0.027470360229490325}
2024-10-12 16:10:00,402 [INFO] Step[650/938]: training loss : 0.04083071878179908 TRAIN  loss dict:  {'classification_loss': 0.04083071878179908}
2024-10-12 16:10:54,604 [INFO] Step[700/938]: training loss : 0.02843795103719458 TRAIN  loss dict:  {'classification_loss': 0.02843795103719458}
2024-10-12 16:11:48,994 [INFO] Step[750/938]: training loss : 0.028115945112658663 TRAIN  loss dict:  {'classification_loss': 0.028115945112658663}
2024-10-12 16:12:43,137 [INFO] Step[800/938]: training loss : 0.03665238299407065 TRAIN  loss dict:  {'classification_loss': 0.03665238299407065}
2024-10-12 16:13:37,509 [INFO] Step[850/938]: training loss : 0.03360555493389256 TRAIN  loss dict:  {'classification_loss': 0.03360555493389256}
2024-10-12 16:14:31,039 [INFO] Step[900/938]: training loss : 0.030924858928192408 TRAIN  loss dict:  {'classification_loss': 0.030924858928192408}
2024-10-12 16:17:23,897 [INFO] Label accuracies statistics:
2024-10-12 16:17:23,897 [INFO] {0: 0.75, 1: 1.0, 2: 0.95, 3: 0.9473684210526315, 4: 0.85, 5: 0.8, 6: 0.46153846153846156, 7: 0.85, 8: 0.85, 9: 1.0, 10: 1.0, 11: 0.95, 12: 0.9473684210526315, 13: 1.0, 14: 1.0, 15: 1.0, 16: 0.45, 17: 0.7222222222222222, 18: 0.8235294117647058, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 1.0, 22: 0.75, 23: 0.8, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.9, 31: 0.85, 32: 1.0, 33: 1.0, 34: 0.8, 35: 1.0, 36: 0.9473684210526315, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.9, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.45, 48: 0.65, 49: 1.0, 50: 0.85, 51: 0.8888888888888888, 52: 0.6666666666666666, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.7777777777777778, 60: 0.85, 61: 0.7894736842105263, 62: 0.7894736842105263, 63: 0.7894736842105263, 64: 0.9, 65: 0.9, 66: 1.0, 67: 1.0, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.8, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.8, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.75, 92: 0.95, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.47058823529411764, 97: 0.6, 98: 0.47368421052631576, 99: 1.0, 100: 0.9, 101: 0.9, 102: 1.0, 103: 0.75, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.9, 109: 0.95, 110: 0.95, 111: 0.75, 112: 0.95, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 1.0, 120: 0.95, 121: 0.95, 122: 0.65, 123: 0.95, 124: 1.0, 125: 0.8, 126: 0.8, 127: 0.8, 128: 1.0, 129: 0.65, 130: 1.0, 131: 0.875, 132: 1.0, 133: 1.0, 134: 0.7, 135: 0.9, 136: 1.0, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.6, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.95, 145: 1.0, 146: 0.95, 147: 0.85, 148: 0.9, 149: 1.0, 150: 0.7, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.85, 155: 0.95, 156: 1.0, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 0.95, 161: 0.85, 162: 0.9, 163: 1.0, 164: 0.8421052631578947, 165: 0.55, 166: 1.0, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.75, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 0.85, 181: 1.0, 182: 0.7, 183: 0.8, 184: 1.0, 185: 0.9, 186: 0.9, 187: 1.0, 188: 1.0, 189: 0.95, 190: 0.8, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.7, 203: 1.0, 204: 0.85, 205: 1.0, 206: 0.4444444444444444, 207: 0.75, 208: 0.95, 209: 0.85, 210: 1.0, 211: 1.0, 212: 0.8823529411764706, 213: 1.0, 214: 0.85, 215: 0.7, 216: 0.95, 217: 0.95, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 1.0}

2024-10-12 16:17:23,943 [INFO] [19] TRAIN  loss: 0.03575458205390676 acc: 0.9891938006540595
2024-10-12 16:17:23,943 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.03575458205390676}
2024-10-12 16:17:23,943 [INFO] [19] VALIDATION loss: 0.43404380246903274 VALIDATION  acc: 0.9058397464916251
2024-10-12 16:17:23,943 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 0.43404380246903274}
2024-10-12 16:17:23,943 [INFO] 
2024-10-12 16:18:52,269 [INFO] Step[50/938]: training loss : 0.036274510280927645 TRAIN  loss dict:  {'classification_loss': 0.036274510280927645}
2024-10-12 16:19:46,384 [INFO] Step[100/938]: training loss : 0.031962082479149105 TRAIN  loss dict:  {'classification_loss': 0.031962082479149105}
2024-10-12 16:20:40,603 [INFO] Step[150/938]: training loss : 0.03293006504070945 TRAIN  loss dict:  {'classification_loss': 0.03293006504070945}
2024-10-12 16:21:34,841 [INFO] Step[200/938]: training loss : 0.033628045488148926 TRAIN  loss dict:  {'classification_loss': 0.033628045488148926}
2024-10-12 16:22:28,964 [INFO] Step[250/938]: training loss : 0.030096651543863116 TRAIN  loss dict:  {'classification_loss': 0.030096651543863116}
2024-10-12 16:23:23,287 [INFO] Step[300/938]: training loss : 0.05064846990630031 TRAIN  loss dict:  {'classification_loss': 0.05064846990630031}
2024-10-12 16:24:17,855 [INFO] Step[350/938]: training loss : 0.028730329513782637 TRAIN  loss dict:  {'classification_loss': 0.028730329513782637}
2024-10-12 16:25:12,338 [INFO] Step[400/938]: training loss : 0.02692183173960075 TRAIN  loss dict:  {'classification_loss': 0.02692183173960075}
2024-10-12 16:26:06,660 [INFO] Step[450/938]: training loss : 0.03654921772307716 TRAIN  loss dict:  {'classification_loss': 0.03654921772307716}
2024-10-12 16:27:00,943 [INFO] Step[500/938]: training loss : 0.020992819353705273 TRAIN  loss dict:  {'classification_loss': 0.020992819353705273}
2024-10-12 16:27:55,364 [INFO] Step[550/938]: training loss : 0.03578626754693687 TRAIN  loss dict:  {'classification_loss': 0.03578626754693687}
2024-10-12 16:28:53,106 [INFO] Step[600/938]: training loss : 0.030733709677588195 TRAIN  loss dict:  {'classification_loss': 0.030733709677588195}
2024-10-12 16:29:51,161 [INFO] Step[650/938]: training loss : 0.042862515999004244 TRAIN  loss dict:  {'classification_loss': 0.042862515999004244}
2024-10-12 16:30:41,625 [INFO] Step[700/938]: training loss : 0.034917676269542425 TRAIN  loss dict:  {'classification_loss': 0.034917676269542425}
2024-10-12 16:31:35,892 [INFO] Step[750/938]: training loss : 0.02847053658333607 TRAIN  loss dict:  {'classification_loss': 0.02847053658333607}
2024-10-12 16:32:31,047 [INFO] Step[800/938]: training loss : 0.03452429366763681 TRAIN  loss dict:  {'classification_loss': 0.03452429366763681}
2024-10-12 16:33:24,587 [INFO] Step[850/938]: training loss : 0.03706051993649453 TRAIN  loss dict:  {'classification_loss': 0.03706051993649453}
2024-10-12 16:34:18,351 [INFO] Step[900/938]: training loss : 0.03326148535124958 TRAIN  loss dict:  {'classification_loss': 0.03326148535124958}
2024-10-12 16:38:02,007 [INFO] Label accuracies statistics:
2024-10-12 16:38:02,008 [INFO] {0: 0.9, 1: 1.0, 2: 0.8, 3: 0.8947368421052632, 4: 0.85, 5: 0.85, 6: 0.6153846153846154, 7: 0.9, 8: 0.95, 9: 0.9473684210526315, 10: 0.6842105263157895, 11: 0.9, 12: 0.8421052631578947, 13: 0.95, 14: 0.95, 15: 0.95, 16: 0.6, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 1.0, 22: 0.7, 23: 0.9, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.7, 31: 0.85, 32: 1.0, 33: 0.9, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.8, 38: 0.9, 39: 1.0, 40: 0.95, 41: 1.0, 42: 0.95, 43: 0.95, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.5, 48: 0.7, 49: 1.0, 50: 0.9, 51: 0.7777777777777778, 52: 0.6666666666666666, 53: 0.9, 54: 0.95, 55: 0.7894736842105263, 56: 1.0, 57: 0.9, 58: 0.8125, 59: 0.7777777777777778, 60: 0.8, 61: 0.8947368421052632, 62: 0.8421052631578947, 63: 0.9473684210526315, 64: 1.0, 65: 0.8, 66: 1.0, 67: 0.75, 68: 0.7222222222222222, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.7, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.8, 83: 1.0, 84: 0.9, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.85, 92: 0.95, 93: 1.0, 94: 1.0, 95: 0.9166666666666666, 96: 0.5882352941176471, 97: 0.7, 98: 0.42105263157894735, 99: 1.0, 100: 1.0, 101: 0.9, 102: 0.9473684210526315, 103: 0.75, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.9, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.85, 112: 0.95, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.45, 123: 0.95, 124: 0.95, 125: 0.85, 126: 0.8, 127: 0.65, 128: 0.95, 129: 0.55, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 0.9, 135: 0.9, 136: 1.0, 137: 0.85, 138: 0.95, 139: 1.0, 140: 0.85, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.85, 145: 0.9473684210526315, 146: 0.95, 147: 0.85, 148: 1.0, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.85, 155: 1.0, 156: 1.0, 157: 1.0, 158: 1.0, 159: 1.0, 160: 1.0, 161: 0.9, 162: 0.95, 163: 1.0, 164: 0.8947368421052632, 165: 0.6, 166: 0.8, 167: 0.95, 168: 0.95, 169: 0.95, 170: 1.0, 171: 1.0, 172: 0.75, 173: 0.85, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.85, 179: 0.9, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.8, 184: 1.0, 185: 0.85, 186: 0.9, 187: 0.9473684210526315, 188: 0.75, 189: 0.95, 190: 0.9, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 0.9444444444444444, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.85, 200: 0.9473684210526315, 201: 1.0, 202: 1.0, 203: 0.75, 204: 0.85, 205: 0.95, 206: 0.3888888888888889, 207: 0.85, 208: 1.0, 209: 1.0, 210: 1.0, 211: 1.0, 212: 1.0, 213: 0.85, 214: 0.85, 215: 0.9, 216: 0.9, 217: 1.0, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.95, 225: 1.0}

2024-10-12 16:38:02,057 [INFO] [20] TRAIN  loss: 0.03357202048189561 acc: 0.9894070809043083
2024-10-12 16:38:02,057 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.03357202048189561}
2024-10-12 16:38:02,057 [INFO] [20] VALIDATION loss: 0.42984831092168885 VALIDATION  acc: 0.9026708918062472
2024-10-12 16:38:02,057 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 0.42984831092168885}
2024-10-12 16:38:02,057 [INFO] 
2024-10-12 16:39:34,162 [INFO] Step[50/938]: training loss : 0.030815461813472212 TRAIN  loss dict:  {'classification_loss': 0.030815461813472212}
2024-10-12 16:40:27,071 [INFO] Step[100/938]: training loss : 0.024395791676361113 TRAIN  loss dict:  {'classification_loss': 0.024395791676361113}
2024-10-12 16:41:24,339 [INFO] Step[150/938]: training loss : 0.02518683013622649 TRAIN  loss dict:  {'classification_loss': 0.02518683013622649}
2024-10-12 16:42:23,457 [INFO] Step[200/938]: training loss : 0.02057544222450815 TRAIN  loss dict:  {'classification_loss': 0.02057544222450815}
2024-10-12 16:43:11,225 [INFO] Step[250/938]: training loss : 0.016377542042173444 TRAIN  loss dict:  {'classification_loss': 0.016377542042173444}
2024-10-12 16:43:50,603 [INFO] Step[300/938]: training loss : 0.01911146219645161 TRAIN  loss dict:  {'classification_loss': 0.01911146219645161}
2024-10-12 16:44:29,689 [INFO] Step[350/938]: training loss : 0.03141370162775274 TRAIN  loss dict:  {'classification_loss': 0.03141370162775274}
2024-10-12 16:45:26,570 [INFO] Step[400/938]: training loss : 0.0352636070526205 TRAIN  loss dict:  {'classification_loss': 0.0352636070526205}
2024-10-12 16:46:17,417 [INFO] Step[450/938]: training loss : 0.023882842090097257 TRAIN  loss dict:  {'classification_loss': 0.023882842090097257}
2024-10-12 16:47:16,561 [INFO] Step[500/938]: training loss : 0.02503560007258784 TRAIN  loss dict:  {'classification_loss': 0.02503560007258784}
2024-10-12 16:48:15,512 [INFO] Step[550/938]: training loss : 0.016403333763591946 TRAIN  loss dict:  {'classification_loss': 0.016403333763591946}
2024-10-12 16:49:05,956 [INFO] Step[600/938]: training loss : 0.02467693917453289 TRAIN  loss dict:  {'classification_loss': 0.02467693917453289}
2024-10-12 16:49:45,109 [INFO] Step[650/938]: training loss : 0.03262062806054018 TRAIN  loss dict:  {'classification_loss': 0.03262062806054018}
2024-10-12 16:50:29,187 [INFO] Step[700/938]: training loss : 0.01619046976324171 TRAIN  loss dict:  {'classification_loss': 0.01619046976324171}
2024-10-12 16:51:23,577 [INFO] Step[750/938]: training loss : 0.020471521636354736 TRAIN  loss dict:  {'classification_loss': 0.020471521636354736}
2024-10-12 16:52:17,529 [INFO] Step[800/938]: training loss : 0.015704606713261456 TRAIN  loss dict:  {'classification_loss': 0.015704606713261456}
2024-10-12 16:53:17,207 [INFO] Step[850/938]: training loss : 0.025054520640987902 TRAIN  loss dict:  {'classification_loss': 0.025054520640987902}
2024-10-12 16:54:11,558 [INFO] Step[900/938]: training loss : 0.019788745779078454 TRAIN  loss dict:  {'classification_loss': 0.019788745779078454}
2024-10-12 16:57:21,349 [INFO] Label accuracies statistics:
2024-10-12 16:57:21,350 [INFO] {0: 0.7, 1: 1.0, 2: 0.95, 3: 0.9473684210526315, 4: 0.8, 5: 0.85, 6: 0.6153846153846154, 7: 0.85, 8: 0.95, 9: 0.7894736842105263, 10: 0.8421052631578947, 11: 0.95, 12: 0.9473684210526315, 13: 0.9, 14: 1.0, 15: 0.95, 16: 0.5, 17: 0.7777777777777778, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 1.0, 21: 0.8421052631578947, 22: 0.75, 23: 0.9, 24: 0.9473684210526315, 25: 0.9, 26: 0.8947368421052632, 27: 0.95, 28: 0.95, 29: 1.0, 30: 0.95, 31: 0.9, 32: 0.95, 33: 1.0, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 1.0, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.55, 48: 0.65, 49: 1.0, 50: 0.8, 51: 0.9444444444444444, 52: 0.7222222222222222, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.6875, 59: 0.7777777777777778, 60: 0.9, 61: 0.8947368421052632, 62: 0.7368421052631579, 63: 0.8947368421052632, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.8, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.8, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.8, 87: 0.8823529411764706, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.8, 92: 0.95, 93: 1.0, 94: 0.8947368421052632, 95: 1.0, 96: 0.5882352941176471, 97: 0.7, 98: 0.631578947368421, 99: 1.0, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.75, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.65, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.75, 123: 0.9, 124: 1.0, 125: 0.8, 126: 0.75, 127: 1.0, 128: 0.95, 129: 0.65, 130: 1.0, 131: 0.75, 132: 0.8947368421052632, 133: 1.0, 134: 0.7, 135: 0.85, 136: 1.0, 137: 0.85, 138: 0.95, 139: 0.95, 140: 0.8, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.8, 148: 0.95, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.9, 155: 0.95, 156: 0.8947368421052632, 157: 1.0, 158: 0.7058823529411765, 159: 1.0, 160: 1.0, 161: 0.9, 162: 0.95, 163: 1.0, 164: 0.9473684210526315, 165: 0.6, 166: 0.65, 167: 1.0, 168: 1.0, 169: 0.95, 170: 1.0, 171: 1.0, 172: 0.85, 173: 0.9, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.9, 184: 1.0, 185: 0.85, 186: 0.8, 187: 0.9473684210526315, 188: 0.85, 189: 0.95, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.9, 203: 0.85, 204: 0.85, 205: 0.9, 206: 0.5, 207: 0.8, 208: 1.0, 209: 1.0, 210: 1.0, 211: 0.9, 212: 0.9411764705882353, 213: 0.95, 214: 0.85, 215: 0.9, 216: 0.75, 217: 0.95, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.85}

2024-10-12 16:57:21,436 [INFO] [21] TRAIN  loss: 0.02350989514849519 acc: 0.9925707379496659
2024-10-12 16:57:21,436 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.02350989514849519}
2024-10-12 16:57:21,437 [INFO] [21] VALIDATION loss: 0.4026857747922878 VALIDATION  acc: 0.9085559076505206
2024-10-12 16:57:21,437 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 0.4026857747922878}
2024-10-12 16:57:21,437 [INFO] 
2024-10-12 16:59:28,249 [INFO] Step[50/938]: training loss : 0.017347611567238345 TRAIN  loss dict:  {'classification_loss': 0.017347611567238345}
2024-10-12 17:00:26,143 [INFO] Step[100/938]: training loss : 0.021732983085676096 TRAIN  loss dict:  {'classification_loss': 0.021732983085676096}
2024-10-12 17:01:16,140 [INFO] Step[150/938]: training loss : 0.029133698806399478 TRAIN  loss dict:  {'classification_loss': 0.029133698806399478}
2024-10-12 17:02:11,803 [INFO] Step[200/938]: training loss : 0.028464852415490894 TRAIN  loss dict:  {'classification_loss': 0.028464852415490894}
2024-10-12 17:03:07,681 [INFO] Step[250/938]: training loss : 0.020364887689938767 TRAIN  loss dict:  {'classification_loss': 0.020364887689938767}
2024-10-12 17:04:01,954 [INFO] Step[300/938]: training loss : 0.02706400416616816 TRAIN  loss dict:  {'classification_loss': 0.02706400416616816}
2024-10-12 17:04:58,447 [INFO] Step[350/938]: training loss : 0.01812322162906639 TRAIN  loss dict:  {'classification_loss': 0.01812322162906639}
2024-10-12 17:05:55,212 [INFO] Step[400/938]: training loss : 0.020135992320720105 TRAIN  loss dict:  {'classification_loss': 0.020135992320720105}
2024-10-12 17:06:56,129 [INFO] Step[450/938]: training loss : 0.02503653144580312 TRAIN  loss dict:  {'classification_loss': 0.02503653144580312}
2024-10-12 17:07:49,428 [INFO] Step[500/938]: training loss : 0.018941946804407053 TRAIN  loss dict:  {'classification_loss': 0.018941946804407053}
2024-10-12 17:08:45,942 [INFO] Step[550/938]: training loss : 0.025814465373987332 TRAIN  loss dict:  {'classification_loss': 0.025814465373987332}
2024-10-12 17:09:41,343 [INFO] Step[600/938]: training loss : 0.020144741964759304 TRAIN  loss dict:  {'classification_loss': 0.020144741964759304}
2024-10-12 17:10:35,840 [INFO] Step[650/938]: training loss : 0.020036742700031026 TRAIN  loss dict:  {'classification_loss': 0.020036742700031026}
2024-10-12 17:11:31,959 [INFO] Step[700/938]: training loss : 0.03463054735213518 TRAIN  loss dict:  {'classification_loss': 0.03463054735213518}
2024-10-12 17:12:30,425 [INFO] Step[750/938]: training loss : 0.02460426885576453 TRAIN  loss dict:  {'classification_loss': 0.02460426885576453}
2024-10-12 17:13:23,143 [INFO] Step[800/938]: training loss : 0.031394638285855765 TRAIN  loss dict:  {'classification_loss': 0.031394638285855765}
2024-10-12 17:14:18,779 [INFO] Step[850/938]: training loss : 0.014839735328569076 TRAIN  loss dict:  {'classification_loss': 0.014839735328569076}
2024-10-12 17:15:14,216 [INFO] Step[900/938]: training loss : 0.014103814315167256 TRAIN  loss dict:  {'classification_loss': 0.014103814315167256}
2024-10-12 17:18:53,004 [INFO] Label accuracies statistics:
2024-10-12 17:18:53,004 [INFO] {0: 0.75, 1: 1.0, 2: 0.9, 3: 0.9473684210526315, 4: 0.95, 5: 0.9, 6: 0.6923076923076923, 7: 0.95, 8: 0.95, 9: 1.0, 10: 1.0, 11: 0.95, 12: 0.9473684210526315, 13: 0.9, 14: 1.0, 15: 1.0, 16: 0.8, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 0.9473684210526315, 21: 0.9473684210526315, 22: 0.75, 23: 0.95, 24: 0.6842105263157895, 25: 1.0, 26: 0.8421052631578947, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.85, 31: 0.95, 32: 1.0, 33: 1.0, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.95, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.65, 48: 0.8, 49: 1.0, 50: 0.95, 51: 0.8333333333333334, 52: 0.7222222222222222, 53: 0.85, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.6875, 59: 0.7777777777777778, 60: 0.9, 61: 0.8947368421052632, 62: 0.7894736842105263, 63: 0.9473684210526315, 64: 0.95, 65: 0.9, 66: 1.0, 67: 0.85, 68: 0.7777777777777778, 69: 1.0, 70: 0.95, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.9, 76: 0.8421052631578947, 77: 1.0, 78: 0.85, 79: 0.9411764705882353, 80: 0.95, 81: 0.95, 82: 0.75, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.9, 92: 0.95, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.6470588235294118, 97: 0.9, 98: 0.6842105263157895, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.85, 109: 1.0, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.75, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.85, 122: 0.6, 123: 0.9, 124: 1.0, 125: 0.9, 126: 0.85, 127: 0.85, 128: 0.9, 129: 0.75, 130: 1.0, 131: 0.875, 132: 1.0, 133: 1.0, 134: 1.0, 135: 0.9, 136: 1.0, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.8, 141: 1.0, 142: 0.85, 143: 1.0, 144: 0.8, 145: 0.9473684210526315, 146: 1.0, 147: 0.9, 148: 1.0, 149: 0.9473684210526315, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.9, 155: 1.0, 156: 0.9473684210526315, 157: 0.95, 158: 0.8235294117647058, 159: 1.0, 160: 0.9, 161: 0.8, 162: 0.95, 163: 1.0, 164: 0.9473684210526315, 165: 0.6, 166: 0.95, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.7, 173: 0.95, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.8, 184: 1.0, 185: 0.9, 186: 0.95, 187: 0.9473684210526315, 188: 0.8, 189: 0.95, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.95, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 1.0, 203: 0.85, 204: 0.8, 205: 1.0, 206: 0.5, 207: 0.85, 208: 1.0, 209: 0.95, 210: 1.0, 211: 0.95, 212: 1.0, 213: 0.9, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.9, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 1.0}

2024-10-12 17:18:53,555 [INFO] [22] TRAIN  loss: 0.022554318570234783 acc: 0.9929262050334139
2024-10-12 17:18:53,555 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.022554318570234783}
2024-10-12 17:18:53,555 [INFO] [22] VALIDATION loss: 0.3640945247662367 VALIDATION  acc: 0.9203259393390675
2024-10-12 17:18:53,555 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 0.3640945247662367}
2024-10-12 17:18:53,556 [INFO] 
2024-10-12 17:20:37,995 [INFO] Step[50/938]: training loss : 0.0228613531292649 TRAIN  loss dict:  {'classification_loss': 0.0228613531292649}
2024-10-12 17:21:32,544 [INFO] Step[100/938]: training loss : 0.016702934606291818 TRAIN  loss dict:  {'classification_loss': 0.016702934606291818}
2024-10-12 17:22:25,852 [INFO] Step[150/938]: training loss : 0.018341411339933986 TRAIN  loss dict:  {'classification_loss': 0.018341411339933986}
2024-10-12 17:23:22,698 [INFO] Step[200/938]: training loss : 0.0159496996877715 TRAIN  loss dict:  {'classification_loss': 0.0159496996877715}
2024-10-12 17:24:21,301 [INFO] Step[250/938]: training loss : 0.02108059510414023 TRAIN  loss dict:  {'classification_loss': 0.02108059510414023}
2024-10-12 17:25:16,445 [INFO] Step[300/938]: training loss : 0.02088510585599579 TRAIN  loss dict:  {'classification_loss': 0.02088510585599579}
2024-10-12 17:26:11,156 [INFO] Step[350/938]: training loss : 0.01947977444739081 TRAIN  loss dict:  {'classification_loss': 0.01947977444739081}
2024-10-12 17:27:07,776 [INFO] Step[400/938]: training loss : 0.013099098056845832 TRAIN  loss dict:  {'classification_loss': 0.013099098056845832}
2024-10-12 17:28:02,174 [INFO] Step[450/938]: training loss : 0.03452648668957409 TRAIN  loss dict:  {'classification_loss': 0.03452648668957409}
2024-10-12 17:28:57,665 [INFO] Step[500/938]: training loss : 0.025841726341168395 TRAIN  loss dict:  {'classification_loss': 0.025841726341168395}
2024-10-12 17:29:54,562 [INFO] Step[550/938]: training loss : 0.02583037654636428 TRAIN  loss dict:  {'classification_loss': 0.02583037654636428}
2024-10-12 17:30:54,460 [INFO] Step[600/938]: training loss : 0.01907765854441095 TRAIN  loss dict:  {'classification_loss': 0.01907765854441095}
2024-10-12 17:31:45,385 [INFO] Step[650/938]: training loss : 0.018510927859460936 TRAIN  loss dict:  {'classification_loss': 0.018510927859460936}
2024-10-12 17:32:42,058 [INFO] Step[700/938]: training loss : 0.020013559967046603 TRAIN  loss dict:  {'classification_loss': 0.020013559967046603}
2024-10-12 17:33:36,941 [INFO] Step[750/938]: training loss : 0.018431514184339904 TRAIN  loss dict:  {'classification_loss': 0.018431514184339904}
2024-10-12 17:34:31,407 [INFO] Step[800/938]: training loss : 0.01706093521148432 TRAIN  loss dict:  {'classification_loss': 0.01706093521148432}
2024-10-12 17:35:29,176 [INFO] Step[850/938]: training loss : 0.018404692191397773 TRAIN  loss dict:  {'classification_loss': 0.018404692191397773}
2024-10-12 17:36:25,591 [INFO] Step[900/938]: training loss : 0.02867977592512034 TRAIN  loss dict:  {'classification_loss': 0.02867977592512034}
2024-10-12 17:39:36,334 [INFO] Label accuracies statistics:
2024-10-12 17:39:36,334 [INFO] {0: 0.75, 1: 1.0, 2: 0.95, 3: 1.0, 4: 0.8, 5: 0.75, 6: 0.46153846153846156, 7: 0.85, 8: 0.8, 9: 0.7894736842105263, 10: 1.0, 11: 0.95, 12: 0.8947368421052632, 13: 0.9, 14: 1.0, 15: 0.95, 16: 0.65, 17: 0.6111111111111112, 18: 0.9411764705882353, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 1.0, 22: 0.8, 23: 0.9, 24: 0.8947368421052632, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.95, 31: 0.85, 32: 1.0, 33: 1.0, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.8, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.85, 44: 1.0, 45: 0.9, 46: 0.9, 47: 0.4, 48: 0.8, 49: 1.0, 50: 0.9, 51: 0.8888888888888888, 52: 0.7777777777777778, 53: 0.95, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.95, 58: 0.8125, 59: 0.7777777777777778, 60: 0.95, 61: 0.7894736842105263, 62: 0.7894736842105263, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.7, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.95, 76: 0.8421052631578947, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.7, 83: 1.0, 84: 0.9, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.8, 92: 0.95, 93: 0.95, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.6, 98: 0.631578947368421, 99: 1.0, 100: 0.85, 101: 1.0, 102: 1.0, 103: 0.85, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.8, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.9, 112: 0.95, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.8, 123: 0.95, 124: 1.0, 125: 0.8, 126: 0.7, 127: 0.95, 128: 0.9, 129: 0.8, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 0.6, 135: 0.85, 136: 0.95, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.8, 141: 0.95, 142: 0.9, 143: 0.95, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.9, 148: 1.0, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.9, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.9411764705882353, 159: 1.0, 160: 0.8, 161: 0.9, 162: 1.0, 163: 0.9, 164: 0.9473684210526315, 165: 0.65, 166: 0.95, 167: 0.95, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.7, 173: 0.9, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.95, 179: 0.95, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.9, 184: 1.0, 185: 0.85, 186: 0.95, 187: 0.8947368421052632, 188: 0.8, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 0.95, 204: 1.0, 205: 0.95, 206: 0.3888888888888889, 207: 0.8, 208: 1.0, 209: 0.9, 210: 1.0, 211: 0.95, 212: 0.8823529411764706, 213: 0.9, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.95, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.75, 225: 1.0}

2024-10-12 17:39:36,418 [INFO] [23] TRAIN  loss: 0.020584001325720948 acc: 0.99363713920091
2024-10-12 17:39:36,419 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.020584001325720948}
2024-10-12 17:39:36,419 [INFO] [23] VALIDATION loss: 0.3897362371436257 VALIDATION  acc: 0.9151199637845179
2024-10-12 17:39:36,419 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 0.3897362371436257}
2024-10-12 17:39:36,420 [INFO] 
2024-10-12 17:41:43,669 [INFO] Step[50/938]: training loss : 0.017599359021987768 TRAIN  loss dict:  {'classification_loss': 0.017599359021987768}
2024-10-12 17:42:44,037 [INFO] Step[100/938]: training loss : 0.018725332366884687 TRAIN  loss dict:  {'classification_loss': 0.018725332366884687}
2024-10-12 17:43:34,065 [INFO] Step[150/938]: training loss : 0.028530632400652393 TRAIN  loss dict:  {'classification_loss': 0.028530632400652393}
2024-10-12 17:44:29,412 [INFO] Step[200/938]: training loss : 0.01716744270757772 TRAIN  loss dict:  {'classification_loss': 0.01716744270757772}
2024-10-12 17:45:25,706 [INFO] Step[250/938]: training loss : 0.02355018543195911 TRAIN  loss dict:  {'classification_loss': 0.02355018543195911}
2024-10-12 17:46:20,190 [INFO] Step[300/938]: training loss : 0.021883966397726908 TRAIN  loss dict:  {'classification_loss': 0.021883966397726908}
2024-10-12 17:47:14,422 [INFO] Step[350/938]: training loss : 0.025782106029218994 TRAIN  loss dict:  {'classification_loss': 0.025782106029218994}
2024-10-12 17:48:12,645 [INFO] Step[400/938]: training loss : 0.030894276065519078 TRAIN  loss dict:  {'classification_loss': 0.030894276065519078}
2024-10-12 17:49:10,662 [INFO] Step[450/938]: training loss : 0.026741288069169967 TRAIN  loss dict:  {'classification_loss': 0.026741288069169967}
2024-10-12 17:50:01,718 [INFO] Step[500/938]: training loss : 0.021303488372359423 TRAIN  loss dict:  {'classification_loss': 0.021303488372359423}
2024-10-12 17:50:58,597 [INFO] Step[550/938]: training loss : 0.020507694769185035 TRAIN  loss dict:  {'classification_loss': 0.020507694769185035}
2024-10-12 17:51:54,417 [INFO] Step[600/938]: training loss : 0.017131258065346627 TRAIN  loss dict:  {'classification_loss': 0.017131258065346627}
2024-10-12 17:52:51,640 [INFO] Step[650/938]: training loss : 0.014288843520334922 TRAIN  loss dict:  {'classification_loss': 0.014288843520334922}
2024-10-12 17:53:47,032 [INFO] Step[700/938]: training loss : 0.0190411424159538 TRAIN  loss dict:  {'classification_loss': 0.0190411424159538}
2024-10-12 17:54:45,130 [INFO] Step[750/938]: training loss : 0.01503876318980474 TRAIN  loss dict:  {'classification_loss': 0.01503876318980474}
2024-10-12 17:55:41,711 [INFO] Step[800/938]: training loss : 0.03025710173882544 TRAIN  loss dict:  {'classification_loss': 0.03025710173882544}
2024-10-12 17:56:34,307 [INFO] Step[850/938]: training loss : 0.015603611279511825 TRAIN  loss dict:  {'classification_loss': 0.015603611279511825}
2024-10-12 17:57:30,572 [INFO] Step[900/938]: training loss : 0.01363145086215809 TRAIN  loss dict:  {'classification_loss': 0.01363145086215809}
2024-10-12 18:01:14,518 [INFO] Label accuracies statistics:
2024-10-12 18:01:14,518 [INFO] {0: 0.75, 1: 1.0, 2: 0.85, 3: 0.9473684210526315, 4: 0.85, 5: 0.95, 6: 0.5384615384615384, 7: 0.9, 8: 0.85, 9: 0.8947368421052632, 10: 1.0, 11: 0.95, 12: 0.9473684210526315, 13: 0.9, 14: 1.0, 15: 0.9, 16: 0.4, 17: 0.6666666666666666, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 1.0, 22: 0.75, 23: 0.7, 24: 0.7368421052631579, 25: 0.95, 26: 0.8947368421052632, 27: 1.0, 28: 0.8, 29: 1.0, 30: 0.9, 31: 0.9, 32: 1.0, 33: 1.0, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.8, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.85, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.5, 48: 0.6, 49: 1.0, 50: 0.95, 51: 0.8888888888888888, 52: 0.6111111111111112, 53: 1.0, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.9, 58: 0.875, 59: 0.7777777777777778, 60: 0.95, 61: 0.7368421052631579, 62: 0.7368421052631579, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.7, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.8947368421052632, 74: 0.95, 75: 0.9, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.75, 83: 1.0, 84: 0.8, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.75, 92: 0.95, 93: 0.9, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.65, 98: 0.5789473684210527, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.95, 106: 1.0, 107: 0.8, 108: 0.9, 109: 0.95, 110: 1.0, 111: 0.85, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 1.0, 122: 0.75, 123: 0.95, 124: 1.0, 125: 0.7, 126: 0.8, 127: 1.0, 128: 0.95, 129: 0.75, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 0.95, 135: 0.8, 136: 1.0, 137: 0.85, 138: 0.95, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.95, 143: 1.0, 144: 0.9, 145: 1.0, 146: 0.95, 147: 0.85, 148: 1.0, 149: 0.8947368421052632, 150: 0.85, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.9, 155: 1.0, 156: 0.7368421052631579, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 0.95, 161: 0.95, 162: 0.95, 163: 0.9, 164: 0.8947368421052632, 165: 0.75, 166: 0.95, 167: 0.95, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.8, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.9, 184: 1.0, 185: 0.85, 186: 0.95, 187: 1.0, 188: 0.85, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 0.9473684210526315, 201: 1.0, 202: 0.85, 203: 0.8, 204: 0.9, 205: 0.95, 206: 0.5, 207: 0.85, 208: 1.0, 209: 1.0, 210: 1.0, 211: 0.95, 212: 0.7647058823529411, 213: 0.9, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.95, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.95, 225: 1.0}

2024-10-12 18:01:14,596 [INFO] [24] TRAIN  loss: 0.021029538340317504 acc: 0.9937082326176596
2024-10-12 18:01:14,596 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.021029538340317504}
2024-10-12 18:01:14,597 [INFO] [24] VALIDATION loss: 0.4152549892307827 VALIDATION  acc: 0.911272068809416
2024-10-12 18:01:14,597 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 0.4152549892307827}
2024-10-12 18:01:14,597 [INFO] 
2024-10-12 18:03:00,039 [INFO] Step[50/938]: training loss : 0.017931084047304466 TRAIN  loss dict:  {'classification_loss': 0.017931084047304466}
2024-10-12 18:03:55,476 [INFO] Step[100/938]: training loss : 0.016666962208400946 TRAIN  loss dict:  {'classification_loss': 0.016666962208400946}
2024-10-12 18:04:49,366 [INFO] Step[150/938]: training loss : 0.03543543294188566 TRAIN  loss dict:  {'classification_loss': 0.03543543294188566}
2024-10-12 18:05:45,948 [INFO] Step[200/938]: training loss : 0.025122615831205623 TRAIN  loss dict:  {'classification_loss': 0.025122615831205623}
2024-10-12 18:06:44,768 [INFO] Step[250/938]: training loss : 0.0251714277244173 TRAIN  loss dict:  {'classification_loss': 0.0251714277244173}
2024-10-12 18:07:38,419 [INFO] Step[300/938]: training loss : 0.02850032465008553 TRAIN  loss dict:  {'classification_loss': 0.02850032465008553}
2024-10-12 18:08:35,386 [INFO] Step[350/938]: training loss : 0.023447203154792078 TRAIN  loss dict:  {'classification_loss': 0.023447203154792078}
2024-10-12 18:09:32,509 [INFO] Step[400/938]: training loss : 0.019248001303058117 TRAIN  loss dict:  {'classification_loss': 0.019248001303058117}
2024-10-12 18:10:29,067 [INFO] Step[450/938]: training loss : 0.028441331626672763 TRAIN  loss dict:  {'classification_loss': 0.028441331626672763}
2024-10-12 18:11:25,771 [INFO] Step[500/938]: training loss : 0.01388623696693685 TRAIN  loss dict:  {'classification_loss': 0.01388623696693685}
2024-10-12 18:12:23,660 [INFO] Step[550/938]: training loss : 0.01289956517633982 TRAIN  loss dict:  {'classification_loss': 0.01289956517633982}
2024-10-12 18:13:21,020 [INFO] Step[600/938]: training loss : 0.021950610625790432 TRAIN  loss dict:  {'classification_loss': 0.021950610625790432}
2024-10-12 18:14:17,413 [INFO] Step[650/938]: training loss : 0.03050739447528031 TRAIN  loss dict:  {'classification_loss': 0.03050739447528031}
2024-10-12 18:15:14,781 [INFO] Step[700/938]: training loss : 0.02097336635168176 TRAIN  loss dict:  {'classification_loss': 0.02097336635168176}
2024-10-12 18:16:10,991 [INFO] Step[750/938]: training loss : 0.022676337902667 TRAIN  loss dict:  {'classification_loss': 0.022676337902667}
2024-10-12 18:17:08,533 [INFO] Step[800/938]: training loss : 0.01629269135184586 TRAIN  loss dict:  {'classification_loss': 0.01629269135184586}
2024-10-12 18:18:08,055 [INFO] Step[850/938]: training loss : 0.01772218197118491 TRAIN  loss dict:  {'classification_loss': 0.01772218197118491}
2024-10-12 18:19:03,939 [INFO] Step[900/938]: training loss : 0.01834093261451926 TRAIN  loss dict:  {'classification_loss': 0.01834093261451926}
2024-10-12 18:22:13,905 [INFO] Label accuracies statistics:
2024-10-12 18:22:13,905 [INFO] {0: 0.9, 1: 1.0, 2: 0.85, 3: 0.9473684210526315, 4: 0.85, 5: 0.85, 6: 0.38461538461538464, 7: 0.9, 8: 0.95, 9: 0.8947368421052632, 10: 0.8947368421052632, 11: 1.0, 12: 0.8421052631578947, 13: 0.85, 14: 1.0, 15: 0.9, 16: 0.55, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 1.0, 22: 0.6, 23: 0.8, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 1.0, 31: 0.9, 32: 1.0, 33: 0.95, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.95, 42: 0.75, 43: 0.85, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.5, 48: 0.7, 49: 1.0, 50: 1.0, 51: 0.9444444444444444, 52: 0.5555555555555556, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.85, 58: 0.875, 59: 0.8333333333333334, 60: 0.85, 61: 0.7894736842105263, 62: 0.6842105263157895, 63: 0.9473684210526315, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.9, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.85, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.95, 76: 0.8947368421052632, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.7, 83: 1.0, 84: 0.7, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 0.95, 93: 0.9, 94: 1.0, 95: 0.9166666666666666, 96: 0.6470588235294118, 97: 0.5, 98: 0.42105263157894735, 99: 0.95, 100: 0.9, 101: 1.0, 102: 0.9473684210526315, 103: 0.7, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.9, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.9, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.65, 123: 0.95, 124: 1.0, 125: 0.85, 126: 0.7, 127: 0.85, 128: 1.0, 129: 0.8, 130: 1.0, 131: 0.875, 132: 0.9473684210526315, 133: 1.0, 134: 0.85, 135: 0.85, 136: 1.0, 137: 0.85, 138: 0.9, 139: 0.9, 140: 0.85, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 1.0, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.8, 155: 1.0, 156: 0.9473684210526315, 157: 0.95, 158: 0.8823529411764706, 159: 1.0, 160: 0.9, 161: 0.75, 162: 0.9, 163: 1.0, 164: 0.8947368421052632, 165: 0.65, 166: 0.95, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.85, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.7, 184: 1.0, 185: 0.95, 186: 0.8, 187: 0.8947368421052632, 188: 0.8, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.95, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.8, 203: 0.9, 204: 0.9, 205: 0.95, 206: 0.4444444444444444, 207: 0.85, 208: 1.0, 209: 0.95, 210: 1.0, 211: 1.0, 212: 0.9411764705882353, 213: 0.95, 214: 1.0, 215: 0.9, 216: 0.85, 217: 0.95, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 1.0}

2024-10-12 18:22:13,953 [INFO] [25] TRAIN  loss: 0.022327541769178127 acc: 0.9930683918669131
2024-10-12 18:22:13,953 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.022327541769178127}
2024-10-12 18:22:13,953 [INFO] [25] VALIDATION loss: 0.43534231187604255 VALIDATION  acc: 0.9078768673607968
2024-10-12 18:22:13,953 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 0.43534231187604255}
2024-10-12 18:22:13,953 [INFO] 
2024-10-12 18:24:30,075 [INFO] Step[50/938]: training loss : 0.013074216271634213 TRAIN  loss dict:  {'classification_loss': 0.013074216271634213}
2024-10-12 18:25:23,341 [INFO] Step[100/938]: training loss : 0.016159611098701135 TRAIN  loss dict:  {'classification_loss': 0.016159611098701135}
2024-10-12 18:26:21,277 [INFO] Step[150/938]: training loss : 0.01524907979881391 TRAIN  loss dict:  {'classification_loss': 0.01524907979881391}
2024-10-12 18:27:17,890 [INFO] Step[200/938]: training loss : 0.019328641995380168 TRAIN  loss dict:  {'classification_loss': 0.019328641995380168}
2024-10-12 18:28:14,087 [INFO] Step[250/938]: training loss : 0.017058310915599575 TRAIN  loss dict:  {'classification_loss': 0.017058310915599575}
2024-10-12 18:29:09,650 [INFO] Step[300/938]: training loss : 0.02165298574138433 TRAIN  loss dict:  {'classification_loss': 0.02165298574138433}
2024-10-12 18:30:07,031 [INFO] Step[350/938]: training loss : 0.019166983465547672 TRAIN  loss dict:  {'classification_loss': 0.019166983465547672}
2024-10-12 18:31:02,423 [INFO] Step[400/938]: training loss : 0.019605508430395276 TRAIN  loss dict:  {'classification_loss': 0.019605508430395276}
2024-10-12 18:31:58,987 [INFO] Step[450/938]: training loss : 0.02712020949809812 TRAIN  loss dict:  {'classification_loss': 0.02712020949809812}
2024-10-12 18:32:56,378 [INFO] Step[500/938]: training loss : 0.02096956658468116 TRAIN  loss dict:  {'classification_loss': 0.02096956658468116}
2024-10-12 18:33:51,118 [INFO] Step[550/938]: training loss : 0.015416612779372372 TRAIN  loss dict:  {'classification_loss': 0.015416612779372372}
2024-10-12 18:34:48,483 [INFO] Step[600/938]: training loss : 0.01494047272746684 TRAIN  loss dict:  {'classification_loss': 0.01494047272746684}
2024-10-12 18:35:46,161 [INFO] Step[650/938]: training loss : 0.013666595582326408 TRAIN  loss dict:  {'classification_loss': 0.013666595582326408}
2024-10-12 18:36:45,029 [INFO] Step[700/938]: training loss : 0.010470759838935919 TRAIN  loss dict:  {'classification_loss': 0.010470759838935919}
2024-10-12 18:37:38,092 [INFO] Step[750/938]: training loss : 0.012721501547202934 TRAIN  loss dict:  {'classification_loss': 0.012721501547202934}
2024-10-12 18:38:34,631 [INFO] Step[800/938]: training loss : 0.02639037833549082 TRAIN  loss dict:  {'classification_loss': 0.02639037833549082}
2024-10-12 18:39:28,919 [INFO] Step[850/938]: training loss : 0.02704628473322373 TRAIN  loss dict:  {'classification_loss': 0.02704628473322373}
2024-10-12 18:40:23,551 [INFO] Step[900/938]: training loss : 0.025038804116193206 TRAIN  loss dict:  {'classification_loss': 0.025038804116193206}
2024-10-12 18:44:05,096 [INFO] Label accuracies statistics:
2024-10-12 18:44:05,096 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.95, 3: 1.0, 4: 1.0, 5: 0.8, 6: 0.46153846153846156, 7: 0.95, 8: 1.0, 9: 0.8947368421052632, 10: 0.9473684210526315, 11: 0.95, 12: 0.9473684210526315, 13: 0.9, 14: 0.95, 15: 0.95, 16: 0.35, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.7894736842105263, 20: 0.7894736842105263, 21: 0.9473684210526315, 22: 0.85, 23: 0.9, 24: 0.6842105263157895, 25: 0.9, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.9, 31: 0.8, 32: 1.0, 33: 1.0, 34: 0.85, 35: 1.0, 36: 0.9473684210526315, 37: 0.9, 38: 1.0, 39: 1.0, 40: 0.8, 41: 1.0, 42: 0.9, 43: 0.85, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.55, 48: 0.6, 49: 1.0, 50: 0.95, 51: 0.8888888888888888, 52: 0.6666666666666666, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.75, 59: 0.7777777777777778, 60: 0.85, 61: 0.8421052631578947, 62: 0.42105263157894735, 63: 0.8947368421052632, 64: 0.95, 65: 0.95, 66: 1.0, 67: 0.85, 68: 0.7222222222222222, 69: 1.0, 70: 0.95, 71: 0.8, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.95, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 0.8235294117647058, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.85, 92: 0.95, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5882352941176471, 97: 0.65, 98: 0.47368421052631576, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.65, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.8, 112: 0.95, 113: 1.0, 114: 0.95, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.7, 123: 0.95, 124: 0.95, 125: 0.7, 126: 0.85, 127: 0.9, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.9375, 132: 0.9473684210526315, 133: 1.0, 134: 0.9, 135: 0.9, 136: 0.95, 137: 0.85, 138: 0.9, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.7, 148: 1.0, 149: 0.9473684210526315, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.85, 155: 1.0, 156: 0.8947368421052632, 157: 0.9, 158: 0.5882352941176471, 159: 1.0, 160: 0.9, 161: 0.9, 162: 0.9, 163: 0.85, 164: 0.8947368421052632, 165: 0.65, 166: 0.7, 167: 1.0, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.85, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.9, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.75, 184: 1.0, 185: 0.95, 186: 0.9, 187: 0.8947368421052632, 188: 0.8, 189: 1.0, 190: 0.95, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.8, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 0.95, 202: 0.85, 203: 0.9, 204: 0.9, 205: 0.8, 206: 0.3888888888888889, 207: 0.75, 208: 0.9, 209: 1.0, 210: 1.0, 211: 0.9, 212: 0.8235294117647058, 213: 0.9, 214: 1.0, 215: 0.9, 216: 0.9, 217: 1.0, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.8, 225: 1.0}

2024-10-12 18:44:05,142 [INFO] [26] TRAIN  loss: 0.019522608827868066 acc: 0.993814872742784
2024-10-12 18:44:05,142 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.019522608827868066}
2024-10-12 18:44:05,142 [INFO] [26] VALIDATION loss: 0.4420623474113224 VALIDATION  acc: 0.9058397464916251
2024-10-12 18:44:05,142 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 0.4420623474113224}
2024-10-12 18:44:05,142 [INFO] 
2024-10-12 18:45:36,458 [INFO] Step[50/938]: training loss : 0.01955555413849652 TRAIN  loss dict:  {'classification_loss': 0.01955555413849652}
2024-10-12 18:46:32,184 [INFO] Step[100/938]: training loss : 0.015253619343275205 TRAIN  loss dict:  {'classification_loss': 0.015253619343275205}
2024-10-12 18:47:28,085 [INFO] Step[150/938]: training loss : 0.024251242568716407 TRAIN  loss dict:  {'classification_loss': 0.024251242568716407}
2024-10-12 18:48:24,300 [INFO] Step[200/938]: training loss : 0.02072451843880117 TRAIN  loss dict:  {'classification_loss': 0.02072451843880117}
2024-10-12 18:49:15,345 [INFO] Step[250/938]: training loss : 0.019846303564263507 TRAIN  loss dict:  {'classification_loss': 0.019846303564263507}
2024-10-12 18:50:11,681 [INFO] Step[300/938]: training loss : 0.013953788669896312 TRAIN  loss dict:  {'classification_loss': 0.013953788669896312}
2024-10-12 18:51:08,141 [INFO] Step[350/938]: training loss : 0.027164808929665014 TRAIN  loss dict:  {'classification_loss': 0.027164808929665014}
2024-10-12 18:52:01,651 [INFO] Step[400/938]: training loss : 0.014619892080372666 TRAIN  loss dict:  {'classification_loss': 0.014619892080372666}
2024-10-12 18:52:57,776 [INFO] Step[450/938]: training loss : 0.03385233893583063 TRAIN  loss dict:  {'classification_loss': 0.03385233893583063}
2024-10-12 18:53:55,053 [INFO] Step[500/938]: training loss : 0.03604496069718152 TRAIN  loss dict:  {'classification_loss': 0.03604496069718152}
2024-10-12 18:54:51,518 [INFO] Step[550/938]: training loss : 0.014262969123665243 TRAIN  loss dict:  {'classification_loss': 0.014262969123665243}
2024-10-12 18:55:44,110 [INFO] Step[600/938]: training loss : 0.017362045994377694 TRAIN  loss dict:  {'classification_loss': 0.017362045994377694}
2024-10-12 18:56:40,454 [INFO] Step[650/938]: training loss : 0.03206191214558203 TRAIN  loss dict:  {'classification_loss': 0.03206191214558203}
2024-10-12 18:57:35,878 [INFO] Step[700/938]: training loss : 0.019649096421780997 TRAIN  loss dict:  {'classification_loss': 0.019649096421780997}
2024-10-12 18:58:29,040 [INFO] Step[750/938]: training loss : 0.019574605523375796 TRAIN  loss dict:  {'classification_loss': 0.019574605523375796}
2024-10-12 18:59:27,246 [INFO] Step[800/938]: training loss : 0.02627302380918991 TRAIN  loss dict:  {'classification_loss': 0.02627302380918991}
2024-10-12 19:00:25,931 [INFO] Step[850/938]: training loss : 0.020727110883453862 TRAIN  loss dict:  {'classification_loss': 0.020727110883453862}
2024-10-12 19:01:19,934 [INFO] Step[900/938]: training loss : 0.02209007160970941 TRAIN  loss dict:  {'classification_loss': 0.02209007160970941}
2024-10-12 19:04:39,320 [INFO] Label accuracies statistics:
2024-10-12 19:04:39,320 [INFO] {0: 0.85, 1: 1.0, 2: 0.95, 3: 1.0, 4: 0.95, 5: 0.85, 6: 0.5384615384615384, 7: 0.8, 8: 0.85, 9: 0.8421052631578947, 10: 1.0, 11: 0.95, 12: 0.7368421052631579, 13: 0.9, 14: 1.0, 15: 1.0, 16: 0.4, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 0.9473684210526315, 21: 1.0, 22: 0.85, 23: 0.85, 24: 0.5789473684210527, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.85, 29: 1.0, 30: 0.9, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.85, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 0.9, 46: 0.9, 47: 0.65, 48: 0.65, 49: 1.0, 50: 1.0, 51: 0.9444444444444444, 52: 0.7222222222222222, 53: 0.9, 54: 1.0, 55: 0.8421052631578947, 56: 1.0, 57: 0.9, 58: 0.875, 59: 0.8333333333333334, 60: 0.9, 61: 0.8421052631578947, 62: 0.7368421052631579, 63: 0.8421052631578947, 64: 0.9, 65: 0.95, 66: 1.0, 67: 1.0, 68: 0.7777777777777778, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.9, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.75, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.75, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.85, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.47058823529411764, 97: 0.6, 98: 0.3157894736842105, 99: 1.0, 100: 0.9, 101: 0.9, 102: 1.0, 103: 0.6, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.85, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 0.95, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.9, 121: 0.95, 122: 0.75, 123: 0.95, 124: 1.0, 125: 0.8, 126: 0.7, 127: 0.8, 128: 0.95, 129: 0.65, 130: 1.0, 131: 1.0, 132: 0.9473684210526315, 133: 1.0, 134: 0.65, 135: 0.8, 136: 0.95, 137: 0.85, 138: 0.95, 139: 1.0, 140: 0.85, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 1.0, 149: 0.9473684210526315, 150: 0.7, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.85, 155: 1.0, 156: 0.8947368421052632, 157: 0.95, 158: 0.8235294117647058, 159: 1.0, 160: 1.0, 161: 0.8, 162: 0.85, 163: 1.0, 164: 0.8947368421052632, 165: 0.65, 166: 1.0, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.9, 172: 0.85, 173: 0.9, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.95, 184: 1.0, 185: 0.85, 186: 0.95, 187: 0.8947368421052632, 188: 0.8, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 0.95, 194: 0.8, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 0.8, 204: 0.85, 205: 0.95, 206: 0.3333333333333333, 207: 0.85, 208: 0.85, 209: 1.0, 210: 1.0, 211: 0.85, 212: 0.8235294117647058, 213: 0.9, 214: 1.0, 215: 0.9, 216: 0.9, 217: 0.9, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.85, 225: 1.0}

2024-10-12 19:04:39,403 [INFO] [27] TRAIN  loss: 0.021942416051872943 acc: 0.9932461254087871
2024-10-12 19:04:39,403 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.021942416051872943}
2024-10-12 19:04:39,404 [INFO] [27] VALIDATION loss: 0.4376245565201955 VALIDATION  acc: 0.9074241738343142
2024-10-12 19:04:39,404 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 0.4376245565201955}
2024-10-12 19:04:39,404 [INFO] 
2024-10-12 19:06:57,849 [INFO] Step[50/938]: training loss : 0.024468400844198185 TRAIN  loss dict:  {'classification_loss': 0.024468400844198185}
2024-10-12 19:07:49,531 [INFO] Step[100/938]: training loss : 0.014953633638797328 TRAIN  loss dict:  {'classification_loss': 0.014953633638797328}
2024-10-12 19:08:45,176 [INFO] Step[150/938]: training loss : 0.01655732560553588 TRAIN  loss dict:  {'classification_loss': 0.01655732560553588}
2024-10-12 19:09:40,854 [INFO] Step[200/938]: training loss : 0.020208348985179328 TRAIN  loss dict:  {'classification_loss': 0.020208348985179328}
2024-10-12 19:10:35,690 [INFO] Step[250/938]: training loss : 0.014972275847103447 TRAIN  loss dict:  {'classification_loss': 0.014972275847103447}
2024-10-12 19:11:33,421 [INFO] Step[300/938]: training loss : 0.03605071709869662 TRAIN  loss dict:  {'classification_loss': 0.03605071709869662}
2024-10-12 19:12:29,788 [INFO] Step[350/938]: training loss : 0.02274733899626881 TRAIN  loss dict:  {'classification_loss': 0.02274733899626881}
2024-10-12 19:13:21,333 [INFO] Step[400/938]: training loss : 0.0254195396634168 TRAIN  loss dict:  {'classification_loss': 0.0254195396634168}
2024-10-12 19:14:18,092 [INFO] Step[450/938]: training loss : 0.010581947619793936 TRAIN  loss dict:  {'classification_loss': 0.010581947619793936}
2024-10-12 19:15:14,216 [INFO] Step[500/938]: training loss : 0.0303001491248142 TRAIN  loss dict:  {'classification_loss': 0.0303001491248142}
2024-10-12 19:16:09,215 [INFO] Step[550/938]: training loss : 0.026033786456100643 TRAIN  loss dict:  {'classification_loss': 0.026033786456100643}
2024-10-12 19:17:07,746 [INFO] Step[600/938]: training loss : 0.02422038985765539 TRAIN  loss dict:  {'classification_loss': 0.02422038985765539}
2024-10-12 19:18:04,857 [INFO] Step[650/938]: training loss : 0.01769656540185679 TRAIN  loss dict:  {'classification_loss': 0.01769656540185679}
2024-10-12 19:19:01,859 [INFO] Step[700/938]: training loss : 0.017394315848359838 TRAIN  loss dict:  {'classification_loss': 0.017394315848359838}
2024-10-12 19:19:54,211 [INFO] Step[750/938]: training loss : 0.016413969434797764 TRAIN  loss dict:  {'classification_loss': 0.016413969434797764}
2024-10-12 19:20:50,506 [INFO] Step[800/938]: training loss : 0.016964507350348868 TRAIN  loss dict:  {'classification_loss': 0.016964507350348868}
2024-10-12 19:21:45,156 [INFO] Step[850/938]: training loss : 0.02287933633022476 TRAIN  loss dict:  {'classification_loss': 0.02287933633022476}
2024-10-12 19:22:38,278 [INFO] Step[900/938]: training loss : 0.026984764277585782 TRAIN  loss dict:  {'classification_loss': 0.026984764277585782}
2024-10-12 19:26:21,066 [INFO] Label accuracies statistics:
2024-10-12 19:26:21,067 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.95, 3: 0.9473684210526315, 4: 0.95, 5: 0.8, 6: 0.6153846153846154, 7: 0.9, 8: 0.85, 9: 0.9473684210526315, 10: 1.0, 11: 0.95, 12: 0.8947368421052632, 13: 0.9, 14: 1.0, 15: 0.95, 16: 0.6, 17: 0.7777777777777778, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.8947368421052632, 21: 1.0, 22: 0.8, 23: 0.8, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.9, 29: 1.0, 30: 0.95, 31: 1.0, 32: 1.0, 33: 0.9, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.85, 38: 0.9, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.8, 43: 0.85, 44: 1.0, 45: 0.9, 46: 0.9, 47: 0.45, 48: 0.65, 49: 1.0, 50: 0.95, 51: 0.8888888888888888, 52: 0.7777777777777778, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.9, 58: 0.875, 59: 0.7777777777777778, 60: 0.95, 61: 0.8421052631578947, 62: 0.631578947368421, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.85, 68: 0.7222222222222222, 69: 1.0, 70: 0.95, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.95, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.8, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.9166666666666666, 96: 0.5882352941176471, 97: 0.55, 98: 0.6842105263157895, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.9, 104: 0.9, 105: 0.95, 106: 1.0, 107: 0.8, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.9, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 0.9, 121: 1.0, 122: 0.55, 123: 1.0, 124: 0.95, 125: 0.85, 126: 0.85, 127: 0.9, 128: 0.9, 129: 0.75, 130: 1.0, 131: 0.9375, 132: 0.8947368421052632, 133: 1.0, 134: 1.0, 135: 0.95, 136: 1.0, 137: 0.85, 138: 0.95, 139: 1.0, 140: 0.95, 141: 1.0, 142: 0.85, 143: 0.9, 144: 0.85, 145: 0.8947368421052632, 146: 1.0, 147: 0.85, 148: 0.9, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 0.95, 153: 1.0, 154: 0.95, 155: 1.0, 156: 0.9473684210526315, 157: 0.95, 158: 0.8235294117647058, 159: 1.0, 160: 0.7, 161: 0.85, 162: 0.9, 163: 1.0, 164: 0.7894736842105263, 165: 0.6, 166: 1.0, 167: 1.0, 168: 0.95, 169: 0.95, 170: 1.0, 171: 0.9, 172: 0.8, 173: 0.95, 174: 1.0, 175: 0.9444444444444444, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.75, 184: 0.9, 185: 0.85, 186: 0.9, 187: 0.8947368421052632, 188: 0.8, 189: 1.0, 190: 0.85, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 1.0, 196: 1.0, 197: 0.95, 198: 1.0, 199: 0.95, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 1.0, 204: 0.95, 205: 1.0, 206: 0.3333333333333333, 207: 0.85, 208: 1.0, 209: 1.0, 210: 1.0, 211: 1.0, 212: 0.8235294117647058, 213: 0.85, 214: 1.0, 215: 0.9, 216: 0.95, 217: 0.9, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.85, 225: 0.9}

2024-10-12 19:26:21,115 [INFO] [28] TRAIN  loss: 0.021406121379306746 acc: 0.9933527655339116
2024-10-12 19:26:21,115 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.021406121379306746}
2024-10-12 19:26:21,115 [INFO] [28] VALIDATION loss: 0.41423353620071746 VALIDATION  acc: 0.9124038026256225
2024-10-12 19:26:21,115 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 0.41423353620071746}
2024-10-12 19:26:21,115 [INFO] 
2024-10-12 19:28:10,654 [INFO] Step[50/938]: training loss : 0.011395215208758601 TRAIN  loss dict:  {'classification_loss': 0.011395215208758601}
2024-10-12 19:29:04,988 [INFO] Step[100/938]: training loss : 0.0148044124658918 TRAIN  loss dict:  {'classification_loss': 0.0148044124658918}
2024-10-12 19:30:00,514 [INFO] Step[150/938]: training loss : 0.02890382079320261 TRAIN  loss dict:  {'classification_loss': 0.02890382079320261}
2024-10-12 19:30:56,328 [INFO] Step[200/938]: training loss : 0.013657927741878666 TRAIN  loss dict:  {'classification_loss': 0.013657927741878666}
2024-10-12 19:31:47,294 [INFO] Step[250/938]: training loss : 0.02641123986511957 TRAIN  loss dict:  {'classification_loss': 0.02641123986511957}
2024-10-12 19:32:42,735 [INFO] Step[300/938]: training loss : 0.018149199932231568 TRAIN  loss dict:  {'classification_loss': 0.018149199932231568}
2024-10-12 19:33:37,967 [INFO] Step[350/938]: training loss : 0.016981127395993098 TRAIN  loss dict:  {'classification_loss': 0.016981127395993098}
2024-10-12 19:34:32,541 [INFO] Step[400/938]: training loss : 0.02491517085407395 TRAIN  loss dict:  {'classification_loss': 0.02491517085407395}
2024-10-12 19:35:30,069 [INFO] Step[450/938]: training loss : 0.012978620470967143 TRAIN  loss dict:  {'classification_loss': 0.012978620470967143}
2024-10-12 19:36:27,626 [INFO] Step[500/938]: training loss : 0.018763439511531033 TRAIN  loss dict:  {'classification_loss': 0.018763439511531033}
2024-10-12 19:37:17,848 [INFO] Step[550/938]: training loss : 0.024683735442813486 TRAIN  loss dict:  {'classification_loss': 0.024683735442813486}
2024-10-12 19:38:13,306 [INFO] Step[600/938]: training loss : 0.027329929015832023 TRAIN  loss dict:  {'classification_loss': 0.027329929015832023}
2024-10-12 19:39:09,127 [INFO] Step[650/938]: training loss : 0.016499400306202006 TRAIN  loss dict:  {'classification_loss': 0.016499400306202006}
2024-10-12 19:40:04,791 [INFO] Step[700/938]: training loss : 0.012215902459865901 TRAIN  loss dict:  {'classification_loss': 0.012215902459865901}
2024-10-12 19:41:00,771 [INFO] Step[750/938]: training loss : 0.016430592082178917 TRAIN  loss dict:  {'classification_loss': 0.016430592082178917}
2024-10-12 19:41:59,059 [INFO] Step[800/938]: training loss : 0.01074482088064542 TRAIN  loss dict:  {'classification_loss': 0.01074482088064542}
2024-10-12 19:42:52,508 [INFO] Step[850/938]: training loss : 0.014962086876912507 TRAIN  loss dict:  {'classification_loss': 0.014962086876912507}
2024-10-12 19:43:46,332 [INFO] Step[900/938]: training loss : 0.0115871823776979 TRAIN  loss dict:  {'classification_loss': 0.0115871823776979}
2024-10-12 19:47:18,372 [INFO] Label accuracies statistics:
2024-10-12 19:47:18,372 [INFO] {0: 0.9, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.85, 5: 0.8, 6: 0.3076923076923077, 7: 0.9, 8: 0.95, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.8947368421052632, 13: 0.8, 14: 1.0, 15: 1.0, 16: 0.75, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 1.0, 21: 0.9473684210526315, 22: 0.8, 23: 0.8, 24: 0.8947368421052632, 25: 0.95, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.85, 31: 0.8, 32: 1.0, 33: 1.0, 34: 0.9, 35: 1.0, 36: 1.0, 37: 0.95, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.85, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.6, 48: 0.8, 49: 0.9473684210526315, 50: 0.9, 51: 0.8333333333333334, 52: 0.8333333333333334, 53: 1.0, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.8125, 59: 0.8333333333333334, 60: 0.9, 61: 0.7894736842105263, 62: 0.6842105263157895, 63: 0.7894736842105263, 64: 0.95, 65: 0.8, 66: 1.0, 67: 0.8, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.7894736842105263, 74: 1.0, 75: 0.8, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.75, 83: 0.95, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.8, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.45, 98: 0.7894736842105263, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.8, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.7, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.55, 123: 1.0, 124: 1.0, 125: 0.9, 126: 0.8, 127: 0.95, 128: 0.9, 129: 0.7, 130: 1.0, 131: 0.9375, 132: 0.8947368421052632, 133: 1.0, 134: 0.75, 135: 0.95, 136: 0.95, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.9, 141: 1.0, 142: 0.9, 143: 0.9, 144: 0.7, 145: 0.8947368421052632, 146: 1.0, 147: 0.85, 148: 1.0, 149: 1.0, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.75, 155: 1.0, 156: 0.9473684210526315, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 1.0, 161: 0.75, 162: 0.8, 163: 1.0, 164: 0.8947368421052632, 165: 0.5, 166: 0.9, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.75, 173: 0.8, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.75, 184: 0.95, 185: 0.85, 186: 0.9, 187: 0.8947368421052632, 188: 0.85, 189: 0.95, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.95, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 0.9473684210526315, 201: 1.0, 202: 0.9, 203: 0.85, 204: 1.0, 205: 0.85, 206: 0.5, 207: 0.85, 208: 1.0, 209: 0.95, 210: 0.95, 211: 0.95, 212: 0.7647058823529411, 213: 0.95, 214: 1.0, 215: 0.9, 216: 0.9, 217: 0.9, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.85, 225: 0.9}

2024-10-12 19:47:18,450 [INFO] [29] TRAIN  loss: 0.01755955565029286 acc: 0.995272287786151
2024-10-12 19:47:18,450 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.01755955565029286}
2024-10-12 19:47:18,451 [INFO] [29] VALIDATION loss: 0.4325335832464908 VALIDATION  acc: 0.9121774558623812
2024-10-12 19:47:18,451 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 0.4325335832464908}
2024-10-12 19:47:18,452 [INFO] 
2024-10-12 19:49:37,071 [INFO] Step[50/938]: training loss : 0.01709167472028639 TRAIN  loss dict:  {'classification_loss': 0.01709167472028639}
2024-10-12 19:50:32,152 [INFO] Step[100/938]: training loss : 0.009777882797934581 TRAIN  loss dict:  {'classification_loss': 0.009777882797934581}
2024-10-12 19:51:27,436 [INFO] Step[150/938]: training loss : 0.01838111484539695 TRAIN  loss dict:  {'classification_loss': 0.01838111484539695}
2024-10-12 19:52:20,190 [INFO] Step[200/938]: training loss : 0.011488333477464039 TRAIN  loss dict:  {'classification_loss': 0.011488333477464039}
2024-10-12 19:53:20,563 [INFO] Step[250/938]: training loss : 0.01263242958841147 TRAIN  loss dict:  {'classification_loss': 0.01263242958841147}
2024-10-12 19:54:19,639 [INFO] Step[300/938]: training loss : 0.010613915016292594 TRAIN  loss dict:  {'classification_loss': 0.010613915016292594}
2024-10-12 19:55:12,386 [INFO] Step[350/938]: training loss : 0.02935824343119748 TRAIN  loss dict:  {'classification_loss': 0.02935824343119748}
2024-10-12 19:56:06,319 [INFO] Step[400/938]: training loss : 0.010565292491810397 TRAIN  loss dict:  {'classification_loss': 0.010565292491810397}
2024-10-12 19:57:00,970 [INFO] Step[450/938]: training loss : 0.022360356083954685 TRAIN  loss dict:  {'classification_loss': 0.022360356083954685}
2024-10-12 19:57:56,119 [INFO] Step[500/938]: training loss : 0.010718963951221667 TRAIN  loss dict:  {'classification_loss': 0.010718963951221667}
2024-10-12 19:58:52,540 [INFO] Step[550/938]: training loss : 0.021643546176492237 TRAIN  loss dict:  {'classification_loss': 0.021643546176492237}
2024-10-12 19:59:49,945 [INFO] Step[600/938]: training loss : 0.020911508033750578 TRAIN  loss dict:  {'classification_loss': 0.020911508033750578}
2024-10-12 20:00:44,735 [INFO] Step[650/938]: training loss : 0.018369344872189684 TRAIN  loss dict:  {'classification_loss': 0.018369344872189684}
2024-10-12 20:01:35,968 [INFO] Step[700/938]: training loss : 0.019608262488618494 TRAIN  loss dict:  {'classification_loss': 0.019608262488618494}
2024-10-12 20:02:32,015 [INFO] Step[750/938]: training loss : 0.020888526374474168 TRAIN  loss dict:  {'classification_loss': 0.020888526374474168}
2024-10-12 20:03:24,931 [INFO] Step[800/938]: training loss : 0.016431733031058684 TRAIN  loss dict:  {'classification_loss': 0.016431733031058684}
2024-10-12 20:04:18,195 [INFO] Step[850/938]: training loss : 0.018763430508552118 TRAIN  loss dict:  {'classification_loss': 0.018763430508552118}
2024-10-12 20:05:15,772 [INFO] Step[900/938]: training loss : 0.01933015747461468 TRAIN  loss dict:  {'classification_loss': 0.01933015747461468}
2024-10-12 20:08:33,291 [INFO] Label accuracies statistics:
2024-10-12 20:08:33,291 [INFO] {0: 0.9, 1: 1.0, 2: 0.7, 3: 0.9473684210526315, 4: 0.75, 5: 0.85, 6: 0.38461538461538464, 7: 0.9, 8: 1.0, 9: 0.9473684210526315, 10: 1.0, 11: 1.0, 12: 0.9473684210526315, 13: 0.8, 14: 1.0, 15: 0.9, 16: 0.8, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.8947368421052632, 21: 1.0, 22: 0.75, 23: 0.9, 24: 0.8421052631578947, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 1.0, 29: 1.0, 30: 1.0, 31: 0.85, 32: 0.95, 33: 1.0, 34: 0.85, 35: 1.0, 36: 0.9473684210526315, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.85, 41: 1.0, 42: 1.0, 43: 0.85, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.55, 48: 0.6, 49: 0.9473684210526315, 50: 0.95, 51: 0.8888888888888888, 52: 0.9444444444444444, 53: 0.95, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.9, 58: 0.9375, 59: 0.7777777777777778, 60: 0.9, 61: 0.7368421052631579, 62: 0.6842105263157895, 63: 0.8421052631578947, 64: 0.95, 65: 0.85, 66: 1.0, 67: 0.8, 68: 0.8333333333333334, 69: 0.8888888888888888, 70: 1.0, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.85, 76: 1.0, 77: 1.0, 78: 0.8, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.75, 83: 1.0, 84: 0.8, 85: 1.0, 86: 0.75, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.9, 92: 1.0, 93: 0.9, 94: 0.8947368421052632, 95: 1.0, 96: 0.7058823529411765, 97: 0.55, 98: 0.3684210526315789, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.7, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.6, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.55, 123: 0.9, 124: 1.0, 125: 0.8, 126: 0.85, 127: 0.95, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.875, 132: 1.0, 133: 1.0, 134: 0.85, 135: 0.85, 136: 1.0, 137: 0.85, 138: 0.9, 139: 0.95, 140: 0.65, 141: 1.0, 142: 0.9, 143: 0.95, 144: 0.8, 145: 0.9473684210526315, 146: 0.95, 147: 0.85, 148: 0.9, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.8, 155: 1.0, 156: 0.9473684210526315, 157: 0.9, 158: 0.9411764705882353, 159: 1.0, 160: 0.95, 161: 0.85, 162: 0.85, 163: 1.0, 164: 0.9473684210526315, 165: 0.6, 166: 1.0, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.7, 173: 0.9, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.95, 184: 0.95, 185: 0.85, 186: 0.95, 187: 0.8947368421052632, 188: 0.8, 189: 0.85, 190: 0.95, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8947368421052632, 201: 1.0, 202: 0.95, 203: 0.85, 204: 0.85, 205: 0.95, 206: 0.4444444444444444, 207: 0.85, 208: 1.0, 209: 0.9, 210: 1.0, 211: 1.0, 212: 0.8823529411764706, 213: 0.75, 214: 0.9, 215: 0.9, 216: 0.75, 217: 0.75, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.6, 222: 1.0, 223: 1.0, 224: 0.95, 225: 1.0}

2024-10-12 20:08:33,342 [INFO] [30] TRAIN  loss: 0.016902576298881714 acc: 0.9948101805772785
2024-10-12 20:08:33,342 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.016902576298881714}
2024-10-12 20:08:33,342 [INFO] [30] VALIDATION loss: 0.43018856363898916 VALIDATION  acc: 0.9058397464916251
2024-10-12 20:08:33,342 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 0.43018856363898916}
2024-10-12 20:08:33,342 [INFO] 
2024-10-12 20:10:41,743 [INFO] Step[50/938]: training loss : 0.020898909947136418 TRAIN  loss dict:  {'classification_loss': 0.020898909947136418}
2024-10-12 20:11:42,176 [INFO] Step[100/938]: training loss : 0.01874057695851661 TRAIN  loss dict:  {'classification_loss': 0.01874057695851661}
2024-10-12 20:12:39,228 [INFO] Step[150/938]: training loss : 0.01678274449717719 TRAIN  loss dict:  {'classification_loss': 0.01678274449717719}
2024-10-12 20:13:29,837 [INFO] Step[200/938]: training loss : 0.008239272319187876 TRAIN  loss dict:  {'classification_loss': 0.008239272319187876}
2024-10-12 20:14:25,691 [INFO] Step[250/938]: training loss : 0.00999951710255118 TRAIN  loss dict:  {'classification_loss': 0.00999951710255118}
2024-10-12 20:15:21,481 [INFO] Step[300/938]: training loss : 0.0171644822799135 TRAIN  loss dict:  {'classification_loss': 0.0171644822799135}
2024-10-12 20:16:18,446 [INFO] Step[350/938]: training loss : 0.014246579010796267 TRAIN  loss dict:  {'classification_loss': 0.014246579010796267}
2024-10-12 20:17:13,648 [INFO] Step[400/938]: training loss : 0.013049214560887777 TRAIN  loss dict:  {'classification_loss': 0.013049214560887777}
2024-10-12 20:18:11,746 [INFO] Step[450/938]: training loss : 0.0182026937516639 TRAIN  loss dict:  {'classification_loss': 0.0182026937516639}
2024-10-12 20:19:10,178 [INFO] Step[500/938]: training loss : 0.015039668271201663 TRAIN  loss dict:  {'classification_loss': 0.015039668271201663}
2024-10-12 20:20:01,117 [INFO] Step[550/938]: training loss : 0.010190449578221888 TRAIN  loss dict:  {'classification_loss': 0.010190449578221888}
2024-10-12 20:20:56,657 [INFO] Step[600/938]: training loss : 0.012644020272418857 TRAIN  loss dict:  {'classification_loss': 0.012644020272418857}
2024-10-12 20:21:51,156 [INFO] Step[650/938]: training loss : 0.009730025268509053 TRAIN  loss dict:  {'classification_loss': 0.009730025268509053}
2024-10-12 20:22:45,483 [INFO] Step[700/938]: training loss : 0.02353314326785039 TRAIN  loss dict:  {'classification_loss': 0.02353314326785039}
2024-10-12 20:23:43,530 [INFO] Step[750/938]: training loss : 0.00961078261723742 TRAIN  loss dict:  {'classification_loss': 0.00961078261723742}
2024-10-12 20:24:41,116 [INFO] Step[800/938]: training loss : 0.007831648838327964 TRAIN  loss dict:  {'classification_loss': 0.007831648838327964}
2024-10-12 20:25:32,635 [INFO] Step[850/938]: training loss : 0.010690643896814435 TRAIN  loss dict:  {'classification_loss': 0.010690643896814435}
2024-10-12 20:26:28,146 [INFO] Step[900/938]: training loss : 0.014869875609292649 TRAIN  loss dict:  {'classification_loss': 0.014869875609292649}
2024-10-12 20:30:22,443 [INFO] Label accuracies statistics:
2024-10-12 20:30:22,444 [INFO] {0: 0.8, 1: 1.0, 2: 0.8, 3: 1.0, 4: 0.85, 5: 0.9, 6: 0.3076923076923077, 7: 0.85, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.7894736842105263, 13: 0.9, 14: 1.0, 15: 1.0, 16: 0.55, 17: 0.7222222222222222, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 1.0, 21: 0.9473684210526315, 22: 0.85, 23: 0.9, 24: 0.8421052631578947, 25: 1.0, 26: 0.8421052631578947, 27: 1.0, 28: 1.0, 29: 0.95, 30: 0.85, 31: 0.9, 32: 0.95, 33: 1.0, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.95, 41: 1.0, 42: 0.85, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.5, 48: 0.6, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.8333333333333334, 53: 0.75, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.9, 58: 0.9375, 59: 0.8888888888888888, 60: 0.9, 61: 0.7368421052631579, 62: 0.631578947368421, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.75, 68: 0.8888888888888888, 69: 1.0, 70: 0.95, 71: 0.9, 72: 0.9473684210526315, 73: 0.8947368421052632, 74: 1.0, 75: 0.95, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 1.0, 93: 1.0, 94: 0.7894736842105263, 95: 1.0, 96: 0.47058823529411764, 97: 0.65, 98: 0.42105263157894735, 99: 0.9, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.8, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.95, 113: 0.9, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 0.95, 121: 1.0, 122: 0.85, 123: 0.9, 124: 1.0, 125: 0.8, 126: 0.7, 127: 0.95, 128: 1.0, 129: 0.8, 130: 1.0, 131: 0.875, 132: 1.0, 133: 1.0, 134: 0.7, 135: 1.0, 136: 0.95, 137: 0.75, 138: 0.95, 139: 0.95, 140: 0.75, 141: 0.95, 142: 0.95, 143: 1.0, 144: 0.9, 145: 0.8947368421052632, 146: 0.95, 147: 0.8, 148: 0.85, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.95, 155: 0.95, 156: 0.8421052631578947, 157: 1.0, 158: 0.8235294117647058, 159: 1.0, 160: 0.95, 161: 0.9, 162: 0.85, 163: 0.95, 164: 0.8947368421052632, 165: 0.6, 166: 1.0, 167: 1.0, 168: 0.95, 169: 0.9, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.85, 174: 1.0, 175: 0.9444444444444444, 176: 0.95, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.9, 184: 0.8, 185: 0.9, 186: 0.9, 187: 0.8947368421052632, 188: 0.9, 189: 0.95, 190: 0.95, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.7, 195: 0.9444444444444444, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.8, 203: 0.9, 204: 0.85, 205: 0.95, 206: 0.3333333333333333, 207: 0.85, 208: 1.0, 209: 0.95, 210: 1.0, 211: 0.8, 212: 0.8823529411764706, 213: 0.95, 214: 1.0, 215: 0.9, 216: 0.85, 217: 0.95, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.7, 225: 0.9}

2024-10-12 20:30:22,536 [INFO] [31] TRAIN  loss: 0.013724420743800245 acc: 0.9958765818285227
2024-10-12 20:30:22,536 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.013724420743800245}
2024-10-12 20:30:22,536 [INFO] [31] VALIDATION loss: 0.427033889318753 VALIDATION  acc: 0.9069714803078316
2024-10-12 20:30:22,536 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 0.427033889318753}
2024-10-12 20:30:22,537 [INFO] 
2024-10-12 20:32:25,362 [INFO] Step[50/938]: training loss : 0.015139080047956667 TRAIN  loss dict:  {'classification_loss': 0.015139080047956667}
2024-10-12 20:33:20,094 [INFO] Step[100/938]: training loss : 0.007932907811336917 TRAIN  loss dict:  {'classification_loss': 0.007932907811336917}
2024-10-12 20:34:13,686 [INFO] Step[150/938]: training loss : 0.011780845953762765 TRAIN  loss dict:  {'classification_loss': 0.011780845953762765}
2024-10-12 20:35:07,068 [INFO] Step[200/938]: training loss : 0.009162262476747856 TRAIN  loss dict:  {'classification_loss': 0.009162262476747856}
2024-10-12 20:36:03,945 [INFO] Step[250/938]: training loss : 0.020813688990892844 TRAIN  loss dict:  {'classification_loss': 0.020813688990892844}
2024-10-12 20:37:02,839 [INFO] Step[300/938]: training loss : 0.01519689662149176 TRAIN  loss dict:  {'classification_loss': 0.01519689662149176}
2024-10-12 20:37:54,252 [INFO] Step[350/938]: training loss : 0.00904825967445504 TRAIN  loss dict:  {'classification_loss': 0.00904825967445504}
2024-10-12 20:38:50,148 [INFO] Step[400/938]: training loss : 0.009938557695713826 TRAIN  loss dict:  {'classification_loss': 0.009938557695713826}
2024-10-12 20:39:44,886 [INFO] Step[450/938]: training loss : 0.011046298811706948 TRAIN  loss dict:  {'classification_loss': 0.011046298811706948}
2024-10-12 20:40:39,215 [INFO] Step[500/938]: training loss : 0.012022666458215099 TRAIN  loss dict:  {'classification_loss': 0.012022666458215099}
2024-10-12 20:41:34,737 [INFO] Step[550/938]: training loss : 0.014607208728557452 TRAIN  loss dict:  {'classification_loss': 0.014607208728557452}
2024-10-12 20:42:31,627 [INFO] Step[600/938]: training loss : 0.009805132193141617 TRAIN  loss dict:  {'classification_loss': 0.009805132193141617}
2024-10-12 20:43:24,567 [INFO] Step[650/938]: training loss : 0.018126100534864235 TRAIN  loss dict:  {'classification_loss': 0.018126100534864235}
2024-10-12 20:44:19,048 [INFO] Step[700/938]: training loss : 0.013352806577458978 TRAIN  loss dict:  {'classification_loss': 0.013352806577458978}
2024-10-12 20:45:13,798 [INFO] Step[750/938]: training loss : 0.013962535473401658 TRAIN  loss dict:  {'classification_loss': 0.013962535473401658}
2024-10-12 20:46:08,678 [INFO] Step[800/938]: training loss : 0.01608827927237144 TRAIN  loss dict:  {'classification_loss': 0.01608827927237144}
2024-10-12 20:47:05,603 [INFO] Step[850/938]: training loss : 0.009739579648594373 TRAIN  loss dict:  {'classification_loss': 0.009739579648594373}
2024-10-12 20:48:01,646 [INFO] Step[900/938]: training loss : 0.013266268407023744 TRAIN  loss dict:  {'classification_loss': 0.013266268407023744}
2024-10-12 20:51:09,867 [INFO] Label accuracies statistics:
2024-10-12 20:51:09,867 [INFO] {0: 0.85, 1: 1.0, 2: 1.0, 3: 0.9473684210526315, 4: 0.9, 5: 0.9, 6: 0.46153846153846156, 7: 0.9, 8: 0.95, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.95, 15: 0.95, 16: 0.75, 17: 0.8333333333333334, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 0.9473684210526315, 22: 0.8, 23: 0.9, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.95, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.7, 35: 1.0, 36: 0.9473684210526315, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.95, 41: 1.0, 42: 0.95, 43: 0.95, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.65, 48: 0.65, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.3333333333333333, 53: 0.9, 54: 1.0, 55: 0.9473684210526315, 56: 0.9473684210526315, 57: 0.9, 58: 0.9375, 59: 0.8333333333333334, 60: 0.9, 61: 0.7368421052631579, 62: 0.5789473684210527, 63: 0.8421052631578947, 64: 0.95, 65: 0.9, 66: 1.0, 67: 0.95, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.9, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.75, 83: 1.0, 84: 0.9, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.95, 92: 1.0, 93: 1.0, 94: 0.8421052631578947, 95: 0.8333333333333334, 96: 0.5882352941176471, 97: 0.6, 98: 0.6842105263157895, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.85, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.9, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 0.95, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.85, 126: 0.85, 127: 0.9, 128: 1.0, 129: 0.8, 130: 1.0, 131: 0.9375, 132: 1.0, 133: 1.0, 134: 0.75, 135: 0.95, 136: 0.95, 137: 0.85, 138: 0.9, 139: 1.0, 140: 0.85, 141: 0.95, 142: 1.0, 143: 0.95, 144: 0.75, 145: 0.7894736842105263, 146: 1.0, 147: 0.85, 148: 1.0, 149: 0.9473684210526315, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.75, 155: 1.0, 156: 0.8947368421052632, 157: 0.95, 158: 0.8823529411764706, 159: 1.0, 160: 0.95, 161: 0.85, 162: 0.85, 163: 1.0, 164: 0.9473684210526315, 165: 0.8, 166: 0.9, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.8, 173: 0.9, 174: 1.0, 175: 1.0, 176: 0.95, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.85, 184: 0.95, 185: 0.9, 186: 0.9, 187: 0.8421052631578947, 188: 0.85, 189: 0.95, 190: 0.9, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.85, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.9, 203: 0.9, 204: 0.85, 205: 0.95, 206: 0.3888888888888889, 207: 0.85, 208: 1.0, 209: 1.0, 210: 1.0, 211: 0.85, 212: 0.8823529411764706, 213: 1.0, 214: 1.0, 215: 0.9, 216: 0.95, 217: 0.95, 218: 0.8, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.8, 225: 0.9}

2024-10-12 20:51:10,023 [INFO] [32] TRAIN  loss: 0.01269395113827246 acc: 0.9962675956206455
2024-10-12 20:51:10,023 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.01269395113827246}
2024-10-12 20:51:10,023 [INFO] [32] VALIDATION loss: 0.3920759527710946 VALIDATION  acc: 0.9185151652331371
2024-10-12 20:51:10,023 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 0.3920759527710946}
2024-10-12 20:51:10,023 [INFO] 
2024-10-12 20:53:14,322 [INFO] Step[50/938]: training loss : 0.010766497769218404 TRAIN  loss dict:  {'classification_loss': 0.010766497769218404}
2024-10-12 20:54:10,874 [INFO] Step[100/938]: training loss : 0.0053845084973727355 TRAIN  loss dict:  {'classification_loss': 0.0053845084973727355}
2024-10-12 20:55:09,890 [INFO] Step[150/938]: training loss : 0.013311166139610578 TRAIN  loss dict:  {'classification_loss': 0.013311166139610578}
2024-10-12 20:56:01,525 [INFO] Step[200/938]: training loss : 0.014389903506380506 TRAIN  loss dict:  {'classification_loss': 0.014389903506380506}
2024-10-12 20:56:57,034 [INFO] Step[250/938]: training loss : 0.01689860785700148 TRAIN  loss dict:  {'classification_loss': 0.01689860785700148}
2024-10-12 20:57:51,740 [INFO] Step[300/938]: training loss : 0.004820073843875434 TRAIN  loss dict:  {'classification_loss': 0.004820073843875434}
2024-10-12 20:58:46,878 [INFO] Step[350/938]: training loss : 0.012510129806760233 TRAIN  loss dict:  {'classification_loss': 0.012510129806760233}
2024-10-12 20:59:45,145 [INFO] Step[400/938]: training loss : 0.01102468830300495 TRAIN  loss dict:  {'classification_loss': 0.01102468830300495}
2024-10-12 21:00:43,832 [INFO] Step[450/938]: training loss : 0.018012902297778056 TRAIN  loss dict:  {'classification_loss': 0.018012902297778056}
2024-10-12 21:01:34,118 [INFO] Step[500/938]: training loss : 0.010124402146029752 TRAIN  loss dict:  {'classification_loss': 0.010124402146029752}
2024-10-12 21:02:29,806 [INFO] Step[550/938]: training loss : 0.011389883871015628 TRAIN  loss dict:  {'classification_loss': 0.011389883871015628}
2024-10-12 21:03:25,208 [INFO] Step[600/938]: training loss : 0.006966932736977469 TRAIN  loss dict:  {'classification_loss': 0.006966932736977469}
2024-10-12 21:04:19,644 [INFO] Step[650/938]: training loss : 0.011332035009691026 TRAIN  loss dict:  {'classification_loss': 0.011332035009691026}
2024-10-12 21:05:15,754 [INFO] Step[700/938]: training loss : 0.012106132923072437 TRAIN  loss dict:  {'classification_loss': 0.012106132923072437}
2024-10-12 21:06:14,840 [INFO] Step[750/938]: training loss : 0.01434381429629866 TRAIN  loss dict:  {'classification_loss': 0.01434381429629866}
2024-10-12 21:07:12,372 [INFO] Step[800/938]: training loss : 0.005273280146066099 TRAIN  loss dict:  {'classification_loss': 0.005273280146066099}
2024-10-12 21:08:05,519 [INFO] Step[850/938]: training loss : 0.006753991309233242 TRAIN  loss dict:  {'classification_loss': 0.006753991309233242}
2024-10-12 21:09:01,016 [INFO] Step[900/938]: training loss : 0.00935496806894662 TRAIN  loss dict:  {'classification_loss': 0.00935496806894662}
2024-10-12 21:12:49,115 [INFO] Label accuracies statistics:
2024-10-12 21:12:49,115 [INFO] {0: 0.8, 1: 1.0, 2: 0.9, 3: 1.0, 4: 1.0, 5: 0.9, 6: 0.5384615384615384, 7: 0.9, 8: 1.0, 9: 1.0, 10: 0.8947368421052632, 11: 0.95, 12: 0.8421052631578947, 13: 1.0, 14: 1.0, 15: 0.95, 16: 0.55, 17: 0.5555555555555556, 18: 0.8235294117647058, 19: 0.7894736842105263, 20: 0.9473684210526315, 21: 0.8947368421052632, 22: 0.85, 23: 0.9, 24: 0.9473684210526315, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.95, 31: 0.95, 32: 1.0, 33: 0.95, 34: 0.75, 35: 1.0, 36: 0.9473684210526315, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.95, 41: 0.95, 42: 0.95, 43: 0.95, 44: 0.9473684210526315, 45: 1.0, 46: 0.9, 47: 0.55, 48: 0.6, 49: 1.0, 50: 0.95, 51: 0.8888888888888888, 52: 0.6666666666666666, 53: 0.95, 54: 0.95, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.8125, 59: 0.8333333333333334, 60: 0.9, 61: 0.7368421052631579, 62: 0.6842105263157895, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.8, 68: 0.6666666666666666, 69: 0.9444444444444444, 70: 1.0, 71: 0.85, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.95, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.9, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.8333333333333334, 96: 0.6470588235294118, 97: 0.65, 98: 0.6842105263157895, 99: 1.0, 100: 0.95, 101: 1.0, 102: 0.9473684210526315, 103: 0.85, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.9, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.8, 112: 0.95, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 0.95, 122: 0.65, 123: 1.0, 124: 0.95, 125: 0.8, 126: 0.8, 127: 0.9, 128: 0.95, 129: 0.75, 130: 1.0, 131: 0.9375, 132: 1.0, 133: 1.0, 134: 0.95, 135: 0.85, 136: 1.0, 137: 0.9, 138: 0.95, 139: 1.0, 140: 0.85, 141: 0.95, 142: 1.0, 143: 0.9, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 1.0, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.7, 154: 1.0, 155: 1.0, 156: 0.8947368421052632, 157: 1.0, 158: 0.8823529411764706, 159: 1.0, 160: 0.95, 161: 0.85, 162: 0.9, 163: 0.9, 164: 0.9473684210526315, 165: 0.6, 166: 1.0, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.75, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.95, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.9, 184: 1.0, 185: 0.9, 186: 0.9, 187: 0.9473684210526315, 188: 0.85, 189: 1.0, 190: 0.95, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.95, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 1.0, 203: 0.9, 204: 0.8, 205: 0.95, 206: 0.5, 207: 0.8, 208: 0.85, 209: 0.95, 210: 1.0, 211: 0.9, 212: 0.8823529411764706, 213: 1.0, 214: 0.95, 215: 0.9, 216: 0.85, 217: 0.9, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.7, 225: 1.0}

2024-10-12 21:12:49,223 [INFO] [33] TRAIN  loss: 0.010714853473930997 acc: 0.9969429830797668
2024-10-12 21:12:49,223 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.010714853473930997}
2024-10-12 21:12:49,224 [INFO] [33] VALIDATION loss: 0.40568428550353486 VALIDATION  acc: 0.9164780443639656
2024-10-12 21:12:49,224 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 0.40568428550353486}
2024-10-12 21:12:49,225 [INFO] 
2024-10-12 21:14:42,504 [INFO] Step[50/938]: training loss : 0.006012095485639293 TRAIN  loss dict:  {'classification_loss': 0.006012095485639293}
2024-10-12 21:15:36,984 [INFO] Step[100/938]: training loss : 0.012015658627497032 TRAIN  loss dict:  {'classification_loss': 0.012015658627497032}
2024-10-12 21:16:31,833 [INFO] Step[150/938]: training loss : 0.007471898428557324 TRAIN  loss dict:  {'classification_loss': 0.007471898428557324}
2024-10-12 21:17:25,996 [INFO] Step[200/938]: training loss : 0.010304174532211618 TRAIN  loss dict:  {'classification_loss': 0.010304174532211618}
2024-10-12 21:18:22,474 [INFO] Step[250/938]: training loss : 0.012481841278495267 TRAIN  loss dict:  {'classification_loss': 0.012481841278495267}
2024-10-12 21:19:19,523 [INFO] Step[300/938]: training loss : 0.011611278578930068 TRAIN  loss dict:  {'classification_loss': 0.011611278578930068}
2024-10-12 21:20:11,031 [INFO] Step[350/938]: training loss : 0.008322028429829516 TRAIN  loss dict:  {'classification_loss': 0.008322028429829516}
2024-10-12 21:21:06,809 [INFO] Step[400/938]: training loss : 0.006193613181676483 TRAIN  loss dict:  {'classification_loss': 0.006193613181676483}
2024-10-12 21:22:02,269 [INFO] Step[450/938]: training loss : 0.008362723251630087 TRAIN  loss dict:  {'classification_loss': 0.008362723251630087}
2024-10-12 21:22:55,831 [INFO] Step[500/938]: training loss : 0.014078668481379281 TRAIN  loss dict:  {'classification_loss': 0.014078668481379281}
2024-10-12 21:23:53,665 [INFO] Step[550/938]: training loss : 0.020464182907599025 TRAIN  loss dict:  {'classification_loss': 0.020464182907599025}
2024-10-12 21:24:51,880 [INFO] Step[600/938]: training loss : 0.019421955253637862 TRAIN  loss dict:  {'classification_loss': 0.019421955253637862}
2024-10-12 21:25:42,754 [INFO] Step[650/938]: training loss : 0.008874654730316251 TRAIN  loss dict:  {'classification_loss': 0.008874654730316251}
2024-10-12 21:26:37,582 [INFO] Step[700/938]: training loss : 0.021020648334815633 TRAIN  loss dict:  {'classification_loss': 0.021020648334815633}
2024-10-12 21:27:33,228 [INFO] Step[750/938]: training loss : 0.024843337674392386 TRAIN  loss dict:  {'classification_loss': 0.024843337674392386}
2024-10-12 21:28:26,993 [INFO] Step[800/938]: training loss : 0.019013892738730647 TRAIN  loss dict:  {'classification_loss': 0.019013892738730647}
2024-10-12 21:29:23,573 [INFO] Step[850/938]: training loss : 0.008125881697051227 TRAIN  loss dict:  {'classification_loss': 0.008125881697051227}
2024-10-12 21:30:18,918 [INFO] Step[900/938]: training loss : 0.013653712713858113 TRAIN  loss dict:  {'classification_loss': 0.013653712713858113}
2024-10-12 21:33:28,784 [INFO] Label accuracies statistics:
2024-10-12 21:33:28,785 [INFO] {0: 0.85, 1: 1.0, 2: 0.95, 3: 0.9473684210526315, 4: 0.85, 5: 1.0, 6: 0.5384615384615384, 7: 0.9, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.7368421052631579, 13: 1.0, 14: 0.85, 15: 0.95, 16: 0.7, 17: 0.6111111111111112, 18: 0.7647058823529411, 19: 0.8947368421052632, 20: 1.0, 21: 0.9473684210526315, 22: 0.95, 23: 0.85, 24: 0.8947368421052632, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.9, 31: 1.0, 32: 1.0, 33: 0.85, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 1.0, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.45, 48: 0.7, 49: 1.0, 50: 0.95, 51: 0.8888888888888888, 52: 0.8888888888888888, 53: 1.0, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.95, 58: 0.75, 59: 0.7777777777777778, 60: 0.95, 61: 0.7894736842105263, 62: 0.5789473684210527, 63: 0.8947368421052632, 64: 0.85, 65: 0.9, 66: 1.0, 67: 0.6, 68: 0.7777777777777778, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8421052631578947, 74: 1.0, 75: 0.9, 76: 1.0, 77: 1.0, 78: 0.8, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.85, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.9166666666666666, 96: 0.5882352941176471, 97: 0.7, 98: 0.15789473684210525, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.85, 109: 1.0, 110: 1.0, 111: 0.85, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.9, 121: 0.95, 122: 0.8, 123: 0.75, 124: 0.95, 125: 0.9, 126: 0.85, 127: 0.95, 128: 0.9, 129: 0.85, 130: 1.0, 131: 0.9375, 132: 0.9473684210526315, 133: 1.0, 134: 0.9, 135: 0.9, 136: 1.0, 137: 0.9, 138: 0.9, 139: 0.95, 140: 0.95, 141: 0.95, 142: 0.9, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.8, 148: 0.7, 149: 1.0, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.8, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.7647058823529411, 159: 1.0, 160: 1.0, 161: 0.85, 162: 0.95, 163: 1.0, 164: 0.9473684210526315, 165: 0.5, 166: 1.0, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.8, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.85, 184: 1.0, 185: 0.9, 186: 0.95, 187: 0.8421052631578947, 188: 0.95, 189: 0.95, 190: 0.95, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.85, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8421052631578947, 201: 1.0, 202: 0.9, 203: 0.85, 204: 0.85, 205: 0.9, 206: 0.4444444444444444, 207: 0.8, 208: 0.9, 209: 1.0, 210: 1.0, 211: 0.85, 212: 0.8823529411764706, 213: 0.9, 214: 1.0, 215: 0.9, 216: 0.8, 217: 0.95, 218: 0.95, 219: 1.0, 220: 1.0, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.95, 225: 1.0}

2024-10-12 21:33:28,880 [INFO] [34] TRAIN  loss: 0.012812655706515456 acc: 0.9961965022038959
2024-10-12 21:33:28,880 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.012812655706515456}
2024-10-12 21:33:28,880 [INFO] [34] VALIDATION loss: 0.44285955572618024 VALIDATION  acc: 0.9133091896785875
2024-10-12 21:33:28,880 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 0.44285955572618024}
2024-10-12 21:33:28,880 [INFO] 
2024-10-12 21:35:28,434 [INFO] Step[50/938]: training loss : 0.02194295241992222 TRAIN  loss dict:  {'classification_loss': 0.02194295241992222}
2024-10-12 21:36:26,465 [INFO] Step[100/938]: training loss : 0.01422098410752369 TRAIN  loss dict:  {'classification_loss': 0.01422098410752369}
2024-10-12 21:37:23,645 [INFO] Step[150/938]: training loss : 0.004516411337535828 TRAIN  loss dict:  {'classification_loss': 0.004516411337535828}
2024-10-12 21:38:15,878 [INFO] Step[200/938]: training loss : 0.00966028059454402 TRAIN  loss dict:  {'classification_loss': 0.00966028059454402}
2024-10-12 21:39:11,259 [INFO] Step[250/938]: training loss : 0.012102905398933217 TRAIN  loss dict:  {'classification_loss': 0.012102905398933217}
2024-10-12 21:40:05,378 [INFO] Step[300/938]: training loss : 0.011727069371845573 TRAIN  loss dict:  {'classification_loss': 0.011727069371845573}
2024-10-12 21:40:59,602 [INFO] Step[350/938]: training loss : 0.01811100272054318 TRAIN  loss dict:  {'classification_loss': 0.01811100272054318}
2024-10-12 21:41:57,856 [INFO] Step[400/938]: training loss : 0.008744260983075947 TRAIN  loss dict:  {'classification_loss': 0.008744260983075947}
2024-10-12 21:42:55,399 [INFO] Step[450/938]: training loss : 0.014174363198690117 TRAIN  loss dict:  {'classification_loss': 0.014174363198690117}
2024-10-12 21:43:47,564 [INFO] Step[500/938]: training loss : 0.008981863248336594 TRAIN  loss dict:  {'classification_loss': 0.008981863248336594}
2024-10-12 21:44:42,755 [INFO] Step[550/938]: training loss : 0.013675056604479324 TRAIN  loss dict:  {'classification_loss': 0.013675056604479324}
2024-10-12 21:45:39,762 [INFO] Step[600/938]: training loss : 0.0077956947396160105 TRAIN  loss dict:  {'classification_loss': 0.0077956947396160105}
2024-10-12 21:46:34,590 [INFO] Step[650/938]: training loss : 0.012362795792869292 TRAIN  loss dict:  {'classification_loss': 0.012362795792869292}
2024-10-12 21:47:30,204 [INFO] Step[700/938]: training loss : 0.012390767183969729 TRAIN  loss dict:  {'classification_loss': 0.012390767183969729}
2024-10-12 21:48:29,295 [INFO] Step[750/938]: training loss : 0.012848151301441249 TRAIN  loss dict:  {'classification_loss': 0.012848151301441249}
2024-10-12 21:49:24,357 [INFO] Step[800/938]: training loss : 0.017751234414172357 TRAIN  loss dict:  {'classification_loss': 0.017751234414172357}
2024-10-12 21:50:17,903 [INFO] Step[850/938]: training loss : 0.012140349565597716 TRAIN  loss dict:  {'classification_loss': 0.012140349565597716}
2024-10-12 21:51:13,093 [INFO] Step[900/938]: training loss : 0.025753406186704523 TRAIN  loss dict:  {'classification_loss': 0.025753406186704523}
2024-10-12 21:54:58,748 [INFO] Label accuracies statistics:
2024-10-12 21:54:58,749 [INFO] {0: 0.9, 1: 1.0, 2: 0.95, 3: 1.0, 4: 0.9, 5: 0.85, 6: 0.46153846153846156, 7: 0.9, 8: 0.85, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.8421052631578947, 13: 0.9, 14: 1.0, 15: 0.95, 16: 0.65, 17: 0.6666666666666666, 18: 0.8823529411764706, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 0.9473684210526315, 22: 0.85, 23: 0.9, 24: 0.7894736842105263, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.95, 31: 0.9, 32: 0.95, 33: 0.9, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.95, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.6, 48: 0.7, 49: 1.0, 50: 0.85, 51: 0.9444444444444444, 52: 0.8333333333333334, 53: 0.85, 54: 0.95, 55: 0.8947368421052632, 56: 1.0, 57: 0.9, 58: 0.8125, 59: 0.7222222222222222, 60: 0.9, 61: 0.7894736842105263, 62: 0.631578947368421, 63: 0.8421052631578947, 64: 0.9, 65: 0.8, 66: 1.0, 67: 0.8, 68: 0.6666666666666666, 69: 1.0, 70: 0.9, 71: 0.95, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.95, 76: 1.0, 77: 1.0, 78: 0.85, 79: 1.0, 80: 0.9, 81: 1.0, 82: 0.7, 83: 1.0, 84: 0.95, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.8, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.4117647058823529, 97: 0.55, 98: 0.5263157894736842, 99: 1.0, 100: 0.9, 101: 1.0, 102: 1.0, 103: 0.8, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.7, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.9, 121: 0.95, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.85, 126: 0.85, 127: 0.85, 128: 0.95, 129: 0.75, 130: 1.0, 131: 0.9375, 132: 0.9473684210526315, 133: 1.0, 134: 0.95, 135: 0.8, 136: 1.0, 137: 0.85, 138: 0.9, 139: 0.9, 140: 0.9, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 1.0, 149: 1.0, 150: 0.85, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.85, 155: 1.0, 156: 0.8947368421052632, 157: 1.0, 158: 0.8235294117647058, 159: 1.0, 160: 0.95, 161: 0.7, 162: 0.9, 163: 1.0, 164: 0.9473684210526315, 165: 0.5, 166: 1.0, 167: 1.0, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.85, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.9, 184: 0.9, 185: 0.9, 186: 0.9, 187: 0.8421052631578947, 188: 0.75, 189: 0.95, 190: 0.8, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 0.9, 204: 0.8, 205: 0.95, 206: 0.3888888888888889, 207: 0.85, 208: 0.95, 209: 0.95, 210: 1.0, 211: 0.8, 212: 0.8823529411764706, 213: 0.95, 214: 1.0, 215: 0.9, 216: 0.85, 217: 0.95, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.7, 225: 1.0}

2024-10-12 21:54:58,820 [INFO] [35] TRAIN  loss: 0.013590751917499432 acc: 0.9954855680363999
2024-10-12 21:54:58,820 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.013590751917499432}
2024-10-12 21:54:58,820 [INFO] [35] VALIDATION loss: 0.4017934490717085 VALIDATION  acc: 0.9121774558623812
2024-10-12 21:54:58,820 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 0.4017934490717085}
2024-10-12 21:54:58,820 [INFO] 
2024-10-12 21:56:44,916 [INFO] Step[50/938]: training loss : 0.006121964704070706 TRAIN  loss dict:  {'classification_loss': 0.006121964704070706}
2024-10-12 21:57:40,160 [INFO] Step[100/938]: training loss : 0.011413054487784393 TRAIN  loss dict:  {'classification_loss': 0.011413054487784393}
2024-10-12 21:58:34,826 [INFO] Step[150/938]: training loss : 0.010010874782892643 TRAIN  loss dict:  {'classification_loss': 0.010010874782892643}
2024-10-12 21:59:32,340 [INFO] Step[200/938]: training loss : 0.011095586149895097 TRAIN  loss dict:  {'classification_loss': 0.011095586149895097}
2024-10-12 22:00:31,363 [INFO] Step[250/938]: training loss : 0.018598034192691557 TRAIN  loss dict:  {'classification_loss': 0.018598034192691557}
2024-10-12 22:01:23,702 [INFO] Step[300/938]: training loss : 0.010716119553835597 TRAIN  loss dict:  {'classification_loss': 0.010716119553835597}
2024-10-12 22:02:18,375 [INFO] Step[350/938]: training loss : 0.016589801652589813 TRAIN  loss dict:  {'classification_loss': 0.016589801652589813}
2024-10-12 22:03:13,935 [INFO] Step[400/938]: training loss : 0.008845605670503574 TRAIN  loss dict:  {'classification_loss': 0.008845605670503574}
2024-10-12 22:04:07,977 [INFO] Step[450/938]: training loss : 0.021911974407266825 TRAIN  loss dict:  {'classification_loss': 0.021911974407266825}
2024-10-12 22:05:05,425 [INFO] Step[500/938]: training loss : 0.010089927330700448 TRAIN  loss dict:  {'classification_loss': 0.010089927330700448}
2024-10-12 22:06:01,021 [INFO] Step[550/938]: training loss : 0.0070512007447541694 TRAIN  loss dict:  {'classification_loss': 0.0070512007447541694}
2024-10-12 22:06:59,710 [INFO] Step[600/938]: training loss : 0.013248245724244044 TRAIN  loss dict:  {'classification_loss': 0.013248245724244044}
2024-10-12 22:07:50,919 [INFO] Step[650/938]: training loss : 0.006954662511998322 TRAIN  loss dict:  {'classification_loss': 0.006954662511998322}
2024-10-12 22:08:46,541 [INFO] Step[700/938]: training loss : 0.009545476172934286 TRAIN  loss dict:  {'classification_loss': 0.009545476172934286}
2024-10-12 22:09:41,582 [INFO] Step[750/938]: training loss : 0.00931938706926303 TRAIN  loss dict:  {'classification_loss': 0.00931938706926303}
2024-10-12 22:10:35,242 [INFO] Step[800/938]: training loss : 0.019318206775933502 TRAIN  loss dict:  {'classification_loss': 0.019318206775933502}
2024-10-12 22:11:35,311 [INFO] Step[850/938]: training loss : 0.011745753989962394 TRAIN  loss dict:  {'classification_loss': 0.011745753989962394}
2024-10-12 22:12:30,229 [INFO] Step[900/938]: training loss : 0.015015766438154969 TRAIN  loss dict:  {'classification_loss': 0.015015766438154969}
2024-10-12 22:15:38,785 [INFO] Label accuracies statistics:
2024-10-12 22:15:38,785 [INFO] {0: 0.75, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.9, 5: 0.9, 6: 0.38461538461538464, 7: 0.9, 8: 0.9, 9: 1.0, 10: 1.0, 11: 0.95, 12: 0.8947368421052632, 13: 0.85, 14: 1.0, 15: 0.95, 16: 0.3, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 1.0, 20: 1.0, 21: 1.0, 22: 0.85, 23: 0.9, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.85, 31: 0.8, 32: 1.0, 33: 1.0, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.4, 48: 0.7, 49: 1.0, 50: 1.0, 51: 0.9444444444444444, 52: 0.4444444444444444, 53: 0.95, 54: 1.0, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 0.9, 58: 0.75, 59: 0.7777777777777778, 60: 0.85, 61: 0.7894736842105263, 62: 0.6842105263157895, 63: 0.8421052631578947, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.8, 68: 0.8333333333333334, 69: 1.0, 70: 0.95, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.9, 76: 0.9473684210526315, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.85, 92: 1.0, 93: 0.95, 94: 0.8947368421052632, 95: 1.0, 96: 0.7058823529411765, 97: 0.65, 98: 0.47368421052631576, 99: 1.0, 100: 0.95, 101: 0.95, 102: 1.0, 103: 0.75, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.85, 112: 1.0, 113: 0.9, 114: 0.95, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.65, 123: 0.95, 124: 0.95, 125: 0.8, 126: 0.8, 127: 0.85, 128: 0.95, 129: 0.85, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 0.8, 136: 1.0, 137: 0.85, 138: 0.95, 139: 0.75, 140: 0.85, 141: 1.0, 142: 0.95, 143: 1.0, 144: 0.9, 145: 0.8947368421052632, 146: 1.0, 147: 0.8, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.8, 155: 0.9, 156: 0.8947368421052632, 157: 0.95, 158: 0.8235294117647058, 159: 1.0, 160: 0.95, 161: 0.9, 162: 1.0, 163: 0.95, 164: 0.9473684210526315, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.7, 173: 0.85, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.85, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.85, 184: 0.95, 185: 0.95, 186: 0.9, 187: 0.8421052631578947, 188: 0.95, 189: 0.95, 190: 0.95, 191: 1.0, 192: 0.95, 193: 0.9, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.9, 203: 0.8, 204: 0.85, 205: 1.0, 206: 0.3888888888888889, 207: 0.85, 208: 0.95, 209: 0.9, 210: 1.0, 211: 0.8, 212: 0.8823529411764706, 213: 1.0, 214: 0.95, 215: 0.9, 216: 0.85, 217: 0.9, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.95}

2024-10-12 22:15:38,865 [INFO] [36] TRAIN  loss: 0.012222856850689289 acc: 0.9962675956206455
2024-10-12 22:15:38,865 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.012222856850689289}
2024-10-12 22:15:38,866 [INFO] [36] VALIDATION loss: 0.43627283542180617 VALIDATION  acc: 0.9103666817564509
2024-10-12 22:15:38,866 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 0.43627283542180617}
2024-10-12 22:15:38,866 [INFO] 
2024-10-12 22:17:48,819 [INFO] Step[50/938]: training loss : 0.006877762181393337 TRAIN  loss dict:  {'classification_loss': 0.006877762181393337}
2024-10-12 22:18:46,468 [INFO] Step[100/938]: training loss : 0.010330821281822864 TRAIN  loss dict:  {'classification_loss': 0.010330821281822864}
2024-10-12 22:19:38,117 [INFO] Step[150/938]: training loss : 0.013728801033284981 TRAIN  loss dict:  {'classification_loss': 0.013728801033284981}
2024-10-12 22:20:33,996 [INFO] Step[200/938]: training loss : 0.01586018127403804 TRAIN  loss dict:  {'classification_loss': 0.01586018127403804}
2024-10-12 22:21:30,761 [INFO] Step[250/938]: training loss : 0.010540370437956881 TRAIN  loss dict:  {'classification_loss': 0.010540370437956881}
2024-10-12 22:22:23,718 [INFO] Step[300/938]: training loss : 0.010516060476147686 TRAIN  loss dict:  {'classification_loss': 0.010516060476147686}
2024-10-12 22:23:18,879 [INFO] Step[350/938]: training loss : 0.011248060760553926 TRAIN  loss dict:  {'classification_loss': 0.011248060760553926}
2024-10-12 22:24:18,091 [INFO] Step[400/938]: training loss : 0.010924825214897283 TRAIN  loss dict:  {'classification_loss': 0.010924825214897283}
2024-10-12 22:25:13,088 [INFO] Step[450/938]: training loss : 0.014730346162978095 TRAIN  loss dict:  {'classification_loss': 0.014730346162978095}
2024-10-12 22:26:04,698 [INFO] Step[500/938]: training loss : 0.011021964143728837 TRAIN  loss dict:  {'classification_loss': 0.011021964143728837}
2024-10-12 22:27:00,721 [INFO] Step[550/938]: training loss : 0.007984410279750592 TRAIN  loss dict:  {'classification_loss': 0.007984410279750592}
2024-10-12 22:27:57,613 [INFO] Step[600/938]: training loss : 0.016179462208529 TRAIN  loss dict:  {'classification_loss': 0.016179462208529}
2024-10-12 22:28:50,873 [INFO] Step[650/938]: training loss : 0.016846066436992258 TRAIN  loss dict:  {'classification_loss': 0.016846066436992258}
2024-10-12 22:29:44,429 [INFO] Step[700/938]: training loss : 0.021515361154451965 TRAIN  loss dict:  {'classification_loss': 0.021515361154451965}
2024-10-12 22:30:40,998 [INFO] Step[750/938]: training loss : 0.011749371449113824 TRAIN  loss dict:  {'classification_loss': 0.011749371449113824}
2024-10-12 22:31:36,259 [INFO] Step[800/938]: training loss : 0.009760613671533065 TRAIN  loss dict:  {'classification_loss': 0.009760613671533065}
2024-10-12 22:32:31,334 [INFO] Step[850/938]: training loss : 0.01639255562084145 TRAIN  loss dict:  {'classification_loss': 0.01639255562084145}
2024-10-12 22:33:25,137 [INFO] Step[900/938]: training loss : 0.011273965165892151 TRAIN  loss dict:  {'classification_loss': 0.011273965165892151}
2024-10-12 22:36:51,056 [INFO] Label accuracies statistics:
2024-10-12 22:36:51,056 [INFO] {0: 0.75, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.85, 5: 0.85, 6: 0.46153846153846156, 7: 0.95, 8: 0.95, 9: 1.0, 10: 1.0, 11: 0.9, 12: 0.8947368421052632, 13: 0.85, 14: 0.85, 15: 1.0, 16: 0.55, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 1.0, 20: 1.0, 21: 0.9473684210526315, 22: 0.8, 23: 0.75, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.9, 31: 0.95, 32: 1.0, 33: 1.0, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.8, 38: 1.0, 39: 1.0, 40: 0.95, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.9, 47: 0.6, 48: 0.7, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.7222222222222222, 53: 0.95, 54: 1.0, 55: 0.8421052631578947, 56: 1.0, 57: 0.95, 58: 0.875, 59: 0.7777777777777778, 60: 0.85, 61: 0.7894736842105263, 62: 0.7368421052631579, 63: 0.8421052631578947, 64: 0.95, 65: 0.9, 66: 1.0, 67: 0.9, 68: 0.7222222222222222, 69: 0.9444444444444444, 70: 1.0, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.9, 76: 0.8421052631578947, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.85, 82: 0.75, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.75, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.85, 91: 0.9, 92: 1.0, 93: 0.95, 94: 0.8947368421052632, 95: 1.0, 96: 0.5882352941176471, 97: 0.7, 98: 0.5789473684210527, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.8, 104: 0.95, 105: 1.0, 106: 0.95, 107: 0.85, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.9, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.95, 120: 0.95, 121: 0.95, 122: 0.8, 123: 0.95, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.85, 128: 0.95, 129: 0.8, 130: 1.0, 131: 0.9375, 132: 0.9473684210526315, 133: 1.0, 134: 0.75, 135: 0.8, 136: 1.0, 137: 0.85, 138: 0.95, 139: 0.95, 140: 0.7, 141: 1.0, 142: 0.95, 143: 0.9, 144: 0.8, 145: 0.8947368421052632, 146: 1.0, 147: 0.8, 148: 0.8, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.8, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.7647058823529411, 159: 1.0, 160: 0.95, 161: 0.75, 162: 0.95, 163: 0.9, 164: 0.8947368421052632, 165: 0.4, 166: 1.0, 167: 0.95, 168: 0.8, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.85, 173: 0.85, 174: 1.0, 175: 1.0, 176: 0.95, 177: 1.0, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.8, 184: 0.9, 185: 0.9, 186: 0.9, 187: 0.8947368421052632, 188: 1.0, 189: 1.0, 190: 0.9, 191: 1.0, 192: 0.9, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.9, 203: 0.9, 204: 0.85, 205: 0.95, 206: 0.5, 207: 0.85, 208: 1.0, 209: 0.9, 210: 1.0, 211: 0.9, 212: 0.7647058823529411, 213: 1.0, 214: 1.0, 215: 0.85, 216: 0.85, 217: 0.9, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.75, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.8}

2024-10-12 22:36:51,103 [INFO] [37] TRAIN  loss: 0.012504367449627001 acc: 0.9960543153703967
2024-10-12 22:36:51,103 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.012504367449627001}
2024-10-12 22:36:51,103 [INFO] [37] VALIDATION loss: 0.4280796610768989 VALIDATION  acc: 0.9117247623358986
2024-10-12 22:36:51,103 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 0.4280796610768989}
2024-10-12 22:36:51,103 [INFO] 
2024-10-12 22:36:51,103 [INFO] 

***Stop training***


2024-10-12 22:36:51,104 [INFO] 
Testing checkpointed models starting...

2024-10-12 22:39:07,725 [INFO] Label accuracies statistics:
2024-10-12 22:39:07,726 [INFO] {0: 0.75, 1: 0.9375, 2: 1.0, 3: 0.9411764705882353, 4: 1.0, 5: 0.8235294117647058, 6: 0.7647058823529411, 7: 0.9411764705882353, 8: 0.9411764705882353, 9: 1.0, 10: 1.0, 11: 0.8125, 12: 1.0, 13: 0.9375, 14: 1.0, 15: 0.7333333333333333, 16: 1.0, 17: 0.625, 18: 0.9411764705882353, 19: 0.7647058823529411, 20: 1.0, 21: 1.0, 22: 0.5294117647058824, 23: 0.875, 24: 0.8125, 25: 0.875, 26: 0.9411764705882353, 27: 0.6470588235294118, 28: 1.0, 29: 1.0, 30: 0.9411764705882353, 31: 1.0, 32: 0.8823529411764706, 33: 1.0, 34: 0.9411764705882353, 35: 1.0, 36: 1.0, 37: 0.9411764705882353, 38: 0.9411764705882353, 39: 0.9375, 40: 0.9411764705882353, 41: 1.0, 42: 0.7647058823529411, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 0.7857142857142857, 48: 0.9411764705882353, 49: 1.0, 50: 1.0, 51: 0.6875, 52: 1.0, 53: 0.9411764705882353, 54: 1.0, 55: 0.8823529411764706, 56: 1.0, 57: 1.0, 58: 1.0, 59: 1.0, 60: 1.0, 61: 0.8235294117647058, 62: 0.9411764705882353, 63: 1.0, 64: 1.0, 65: 0.9333333333333333, 66: 1.0, 67: 0.9333333333333333, 68: 0.9375, 69: 1.0, 70: 1.0, 71: 0.9375, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.8125, 76: 0.8823529411764706, 77: 1.0, 78: 0.8823529411764706, 79: 0.8181818181818182, 80: 0.9411764705882353, 81: 0.7647058823529411, 82: 1.0, 83: 1.0, 84: 0.8235294117647058, 85: 1.0, 86: 1.0, 87: 1.0, 88: 1.0, 89: 0.8235294117647058, 90: 1.0, 91: 1.0, 92: 0.8235294117647058, 93: 0.9411764705882353, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.9411764705882353, 98: 1.0, 99: 0.7647058823529411, 100: 0.7058823529411765, 101: 0.8235294117647058, 102: 0.9411764705882353, 103: 0.8125, 104: 0.7647058823529411, 105: 1.0, 106: 1.0, 107: 0.8823529411764706, 108: 0.9375, 109: 0.8235294117647058, 110: 1.0, 111: 0.8823529411764706, 112: 1.0, 113: 0.7647058823529411, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9285714285714286, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.9411764705882353, 122: 0.5882352941176471, 123: 1.0, 124: 0.8823529411764706, 125: 1.0, 126: 0.9375, 127: 0.8235294117647058, 128: 0.9411764705882353, 129: 0.9411764705882353, 130: 0.9411764705882353, 131: 0.7142857142857143, 132: 1.0, 133: 1.0, 134: 1.0, 135: 0.8823529411764706, 136: 0.8125, 137: 1.0, 138: 0.9411764705882353, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.8235294117647058, 143: 1.0, 144: 0.35294117647058826, 145: 1.0, 146: 1.0, 147: 0.9411764705882353, 148: 0.7058823529411765, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.8235294117647058, 155: 1.0, 156: 0.9411764705882353, 157: 1.0, 158: 0.9411764705882353, 159: 1.0, 160: 1.0, 161: 0.8823529411764706, 162: 0.8823529411764706, 163: 0.5882352941176471, 164: 0.8235294117647058, 165: 0.9411764705882353, 166: 0.8823529411764706, 167: 1.0, 168: 1.0, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.6363636363636364, 173: 0.9411764705882353, 174: 1.0, 175: 0.7647058823529411, 176: 0.9333333333333333, 177: 0.9411764705882353, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.8823529411764706, 182: 0.625, 183: 0.8125, 184: 1.0, 185: 0.8823529411764706, 186: 0.8125, 187: 0.9411764705882353, 188: 1.0, 189: 0.9411764705882353, 190: 1.0, 191: 1.0, 192: 0.9411764705882353, 193: 1.0, 194: 1.0, 195: 0.7333333333333333, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 1.0, 203: 1.0, 204: 0.9411764705882353, 205: 0.7647058823529411, 206: 0.8571428571428571, 207: 0.8235294117647058, 208: 0.9411764705882353, 209: 1.0, 210: 0.8823529411764706, 211: 1.0, 212: 0.8823529411764706, 213: 0.8235294117647058, 214: 0.8235294117647058, 215: 1.0, 216: 0.9411764705882353, 217: 1.0, 218: 1.0, 219: 1.0, 220: 1.0, 221: 0.8235294117647058, 222: 1.0, 223: 0.9411764705882353, 224: 1.0, 225: 0.7647058823529411}

2024-10-12 22:39:07,935 [INFO] 
Testing accuracy: 0.9232825447741245
