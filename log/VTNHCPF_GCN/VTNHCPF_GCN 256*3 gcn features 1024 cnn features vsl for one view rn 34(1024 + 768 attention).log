2024-10-12 12:29:01,270 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN 256*3 gcn features 1024 cnn features vsl for one view rn 34(1024 + 768 attention)...


2024-10-12 12:29:23,622 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN 256*3 gcn features 1024 cnn features vsl for one view rn 34(1024 + 768 attention)...


2024-10-12 12:32:20,330 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN 256*3 gcn features 1024 cnn features vsl for one view rn 34(1024 + 768 attention)...


2024-10-12 12:35:10,054 [INFO] Step[50/144]: training loss : 5.963249073028565 TRAIN  loss dict:  {'classification_loss': 5.963249073028565}
2024-10-12 12:36:08,988 [INFO] Step[100/144]: training loss : 5.504756679534912 TRAIN  loss dict:  {'classification_loss': 5.504756679534912}
2024-10-12 12:38:34,143 [INFO] Label accuracies statistics:
2024-10-12 12:38:34,143 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.5, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.25, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.25, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.5, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.25, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.25, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.5, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.5, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-12 12:38:34,936 [INFO] [1] TRAIN  loss: 5.643177628517151 acc: 0.0037071362372567192
2024-10-12 12:38:34,936 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.643177628517151}
2024-10-12 12:38:34,936 [INFO] [1] VALIDATION loss: 5.260198080981219 VALIDATION  acc: 0.022727272727272728
2024-10-12 12:38:34,936 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.260198080981219}
2024-10-12 12:38:34,936 [INFO] 
2024-10-12 12:41:16,659 [INFO] Step[50/144]: training loss : 5.073464641571045 TRAIN  loss dict:  {'classification_loss': 5.073464641571045}
2024-10-12 12:42:17,767 [INFO] Step[100/144]: training loss : 4.766926279067993 TRAIN  loss dict:  {'classification_loss': 4.766926279067993}
2024-10-12 12:44:57,532 [INFO] Label accuracies statistics:
2024-10-12 12:44:57,532 [INFO] {0: 0.0, 1: 0.0, 2: 0.5, 3: 0.5, 4: 0.0, 5: 0.0, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.25, 24: 0.0, 25: 0.75, 26: 0.0, 27: 0.0, 28: 0.25, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.25, 33: 0.25, 34: 0.0, 35: 0.0, 36: 0.5, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.5, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.5, 60: 0.0, 61: 0.0, 62: 0.5, 63: 0.0, 64: 0.0, 65: 0.5, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 1.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.0, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.75, 103: 0.0, 104: 0.0, 105: 0.25, 106: 0.0, 107: 0.75, 108: 0.5, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.5, 119: 1.0, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.0, 124: 0.5, 125: 0.0, 126: 0.5, 127: 0.0, 128: 0.25, 129: 0.0, 130: 0.0, 131: 0.25, 132: 0.0, 133: 0.25, 134: 0.25, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.25, 140: 0.0, 141: 0.0, 142: 0.25, 143: 0.0, 144: 0.75, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.5, 149: 0.0, 150: 0.0, 151: 0.25, 152: 0.0, 153: 0.25, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.5, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.75, 174: 0.0, 175: 0.25, 176: 0.0, 177: 0.25, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.25, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.25, 193: 0.0, 194: 0.5, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-12 12:44:59,034 [INFO] [2] TRAIN  loss: 4.764991874496142 acc: 0.041473586654309544
2024-10-12 12:44:59,034 [INFO] [2] TRAIN  loss dict: {'classification_loss': 4.764991874496142}
2024-10-12 12:44:59,034 [INFO] [2] VALIDATION loss: 4.019489102893406 VALIDATION  acc: 0.1111111111111111
2024-10-12 12:44:59,034 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.019489102893406}
2024-10-12 12:44:59,034 [INFO] 
2024-10-12 12:47:38,394 [INFO] Step[50/144]: training loss : 3.706434416770935 TRAIN  loss dict:  {'classification_loss': 3.706434416770935}
2024-10-12 12:48:38,152 [INFO] Step[100/144]: training loss : 3.275529775619507 TRAIN  loss dict:  {'classification_loss': 3.275529775619507}
2024-10-12 12:51:53,515 [INFO] Label accuracies statistics:
2024-10-12 12:51:53,515 [INFO] {0: 0.0, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.5, 10: 0.25, 11: 1.0, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.6666666666666666, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.0, 23: 0.5, 24: 1.0, 25: 0.0, 26: 1.0, 27: 0.0, 28: 0.0, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.25, 33: 0.25, 34: 0.75, 35: 0.0, 36: 0.5, 37: 0.5, 38: 0.0, 39: 0.0, 40: 1.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.75, 45: 0.5, 46: 0.5, 47: 1.0, 48: 0.5, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.0, 57: 0.0, 58: 0.25, 59: 0.0, 60: 0.0, 61: 0.75, 62: 0.25, 63: 0.0, 64: 0.5, 65: 0.0, 66: 0.25, 67: 0.0, 68: 0.75, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.25, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.5, 81: 0.5, 82: 0.0, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.75, 88: 0.25, 89: 0.0, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 0.25, 96: 0.0, 97: 0.5, 98: 0.75, 99: 0.6, 100: 0.25, 101: 0.5, 102: 1.0, 103: 0.25, 104: 0.5, 105: 0.75, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 1.0, 111: 0.25, 112: 1.0, 113: 0.25, 114: 0.25, 115: 0.0, 116: 0.75, 117: 0.25, 118: 0.75, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.5, 123: 0.0, 124: 0.0, 125: 0.5, 126: 0.25, 127: 0.5, 128: 0.5, 129: 0.75, 130: 0.0, 131: 0.25, 132: 0.25, 133: 0.0, 134: 1.0, 135: 1.0, 136: 0.25, 137: 0.0, 138: 0.25, 139: 0.0, 140: 0.75, 141: 0.0, 142: 0.5, 143: 0.0, 144: 0.0, 145: 0.5, 146: 0.5, 147: 0.0, 148: 0.5, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.0, 153: 0.5, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.5, 158: 1.0, 159: 0.5, 160: 0.0, 161: 0.5, 162: 0.0, 163: 0.75, 164: 0.0, 165: 1.0, 166: 0.25, 167: 0.5, 168: 1.0, 169: 0.25, 170: 0.25, 171: 0.0, 172: 0.25, 173: 0.5, 174: 0.25, 175: 0.5, 176: 0.0, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.25, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 0.75, 186: 0.75, 187: 0.5, 188: 0.25, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.75, 194: 0.25, 195: 0.25, 196: 0.0, 197: 0.25, 198: 0.5}

2024-10-12 12:51:57,859 [INFO] [3] TRAIN  loss: 3.3649989349974527 acc: 0.2057460611677479
2024-10-12 12:51:57,859 [INFO] [3] TRAIN  loss dict: {'classification_loss': 3.3649989349974527}
2024-10-12 12:51:57,860 [INFO] [3] VALIDATION loss: 2.63760213498716 VALIDATION  acc: 0.34595959595959597
2024-10-12 12:51:57,860 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 2.63760213498716}
2024-10-12 12:51:57,860 [INFO] 
2024-10-12 12:54:43,977 [INFO] Step[50/144]: training loss : 2.4892592000961304 TRAIN  loss dict:  {'classification_loss': 2.4892592000961304}
2024-10-12 12:55:41,536 [INFO] Step[100/144]: training loss : 2.1448594188690184 TRAIN  loss dict:  {'classification_loss': 2.1448594188690184}
2024-10-12 12:58:02,534 [INFO] Label accuracies statistics:
2024-10-12 12:58:02,534 [INFO] {0: 0.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.5, 19: 0.5, 20: 0.0, 21: 0.75, 22: 0.25, 23: 1.0, 24: 1.0, 25: 0.25, 26: 1.0, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 0.75, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.0, 52: 0.25, 53: 0.5, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.25, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.25, 65: 0.25, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.25, 77: 0.5, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.25, 82: 0.75, 83: 0.0, 84: 0.5, 85: 0.25, 86: 0.0, 87: 0.5, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.5, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.75, 98: 0.75, 99: 0.8, 100: 0.25, 101: 0.75, 102: 1.0, 103: 0.25, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 0.75, 109: 0.25, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.0, 114: 1.0, 115: 0.5, 116: 0.0, 117: 0.0, 118: 0.75, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.5, 124: 0.5, 125: 0.0, 126: 0.0, 127: 0.5, 128: 0.75, 129: 0.25, 130: 0.5, 131: 0.75, 132: 0.75, 133: 0.25, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.0, 141: 0.5, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.0, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.0, 153: 0.75, 154: 0.0, 155: 0.75, 156: 0.0, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.0, 162: 0.75, 163: 1.0, 164: 0.0, 165: 0.25, 166: 0.5, 167: 1.0, 168: 0.25, 169: 0.5, 170: 1.0, 171: 0.75, 172: 0.5, 173: 1.0, 174: 0.5, 175: 0.75, 176: 0.0, 177: 1.0, 178: 0.25, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-12 12:58:19,809 [INFO] [4] TRAIN  loss: 2.2584664730562105 acc: 0.4128822984244671
2024-10-12 12:58:19,809 [INFO] [4] TRAIN  loss dict: {'classification_loss': 2.2584664730562105}
2024-10-12 12:58:19,809 [INFO] [4] VALIDATION loss: 1.713647449458087 VALIDATION  acc: 0.5505050505050505
2024-10-12 12:58:19,809 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 1.713647449458087}
2024-10-12 12:58:19,809 [INFO] 
2024-10-12 13:01:05,536 [INFO] Step[50/144]: training loss : 1.7229081583023071 TRAIN  loss dict:  {'classification_loss': 1.7229081583023071}
2024-10-12 13:02:03,219 [INFO] Step[100/144]: training loss : 1.558088767528534 TRAIN  loss dict:  {'classification_loss': 1.558088767528534}
2024-10-12 13:04:54,016 [INFO] Label accuracies statistics:
2024-10-12 13:04:54,016 [INFO] {0: 1.0, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.0, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.0, 10: 0.75, 11: 0.75, 12: 0.0, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.5, 19: 0.5, 20: 0.25, 21: 0.25, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.25, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.25, 31: 1.0, 32: 0.5, 33: 0.75, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.0, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.25, 56: 1.0, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.25, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.0, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.5, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.5, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.5, 82: 0.25, 83: 0.5, 84: 0.5, 85: 0.0, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.4, 100: 0.75, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.5, 110: 0.75, 111: 0.5, 112: 1.0, 113: 0.25, 114: 0.5, 115: 0.5, 116: 0.25, 117: 0.5, 118: 0.5, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.25, 126: 0.5, 127: 0.5, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.5, 147: 1.0, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.25, 153: 0.75, 154: 0.5, 155: 0.75, 156: 0.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.0, 161: 0.0, 162: 0.75, 163: 1.0, 164: 0.0, 165: 0.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.5, 183: 0.25, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.0, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-12 13:04:55,537 [INFO] [5] TRAIN  loss: 1.6117736316389508 acc: 0.5669601482854495
2024-10-12 13:04:55,537 [INFO] [5] TRAIN  loss dict: {'classification_loss': 1.6117736316389508}
2024-10-12 13:04:55,537 [INFO] [5] VALIDATION loss: 1.4454520300582603 VALIDATION  acc: 0.6186868686868687
2024-10-12 13:04:55,537 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 1.4454520300582603}
2024-10-12 13:04:55,537 [INFO] 
2024-10-12 13:07:40,080 [INFO] Step[50/144]: training loss : 1.2378941404819488 TRAIN  loss dict:  {'classification_loss': 1.2378941404819488}
2024-10-12 13:08:35,257 [INFO] Step[100/144]: training loss : 1.2259444272518158 TRAIN  loss dict:  {'classification_loss': 1.2259444272518158}
2024-10-12 13:11:22,380 [INFO] Label accuracies statistics:
2024-10-12 13:11:22,380 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.0, 5: 1.0, 6: 0.75, 7: 0.0, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.0, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.5, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.25, 26: 1.0, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.5, 46: 0.75, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.5, 52: 0.5, 53: 0.5, 54: 0.25, 55: 0.75, 56: 1.0, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.25, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.25, 84: 0.5, 85: 0.0, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.0, 97: 0.75, 98: 1.0, 99: 0.8, 100: 1.0, 101: 0.5, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.75, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.5, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.75, 114: 0.0, 115: 0.75, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.75, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.25, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.25, 144: 0.25, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 1.0, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.5, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.25, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.0}

2024-10-12 13:11:39,163 [INFO] [6] TRAIN  loss: 1.2170105737944443 acc: 0.6686746987951807
2024-10-12 13:11:39,163 [INFO] [6] TRAIN  loss dict: {'classification_loss': 1.2170105737944443}
2024-10-12 13:11:39,163 [INFO] [6] VALIDATION loss: 1.1118010337705966 VALIDATION  acc: 0.6919191919191919
2024-10-12 13:11:39,163 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 1.1118010337705966}
2024-10-12 13:11:39,163 [INFO] 
2024-10-12 13:14:33,992 [INFO] Step[50/144]: training loss : 0.9700820112228393 TRAIN  loss dict:  {'classification_loss': 0.9700820112228393}
2024-10-12 13:15:31,841 [INFO] Step[100/144]: training loss : 0.9456584024429321 TRAIN  loss dict:  {'classification_loss': 0.9456584024429321}
2024-10-12 13:18:04,005 [INFO] Label accuracies statistics:
2024-10-12 13:18:04,005 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 1.0, 7: 0.0, 8: 0.5, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.25, 20: 0.0, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.0, 42: 1.0, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.0, 55: 1.0, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.25, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.5, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.25, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.5, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.25, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.0, 138: 0.75, 139: 1.0, 140: 0.5, 141: 0.75, 142: 0.25, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.0, 161: 0.25, 162: 1.0, 163: 1.0, 164: 0.5, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.5, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.0, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-12 13:18:27,886 [INFO] [7] TRAIN  loss: 0.9489204606248273 acc: 0.7395736793327155
2024-10-12 13:18:27,887 [INFO] [7] TRAIN  loss dict: {'classification_loss': 0.9489204606248273}
2024-10-12 13:18:27,887 [INFO] [7] VALIDATION loss: 1.0651098401458174 VALIDATION  acc: 0.702020202020202
2024-10-12 13:18:27,887 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.0651098401458174}
2024-10-12 13:18:27,887 [INFO] 
2024-10-12 13:21:14,691 [INFO] Step[50/144]: training loss : 0.7606819868087769 TRAIN  loss dict:  {'classification_loss': 0.7606819868087769}
2024-10-12 13:22:11,289 [INFO] Step[100/144]: training loss : 0.7335294938087463 TRAIN  loss dict:  {'classification_loss': 0.7335294938087463}
2024-10-12 13:24:27,200 [INFO] Label accuracies statistics:
2024-10-12 13:24:27,200 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.75, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.0, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.5, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.5, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 1.0, 56: 1.0, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.5, 95: 1.0, 96: 0.25, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.25, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.0, 145: 1.0, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.25, 162: 0.75, 163: 1.0, 164: 0.25, 165: 0.75, 166: 0.5, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.25, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 1.0, 185: 0.5, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-12 13:24:28,685 [INFO] [8] TRAIN  loss: 0.7660987010846535 acc: 0.7870713623725671
2024-10-12 13:24:28,685 [INFO] [8] TRAIN  loss dict: {'classification_loss': 0.7660987010846535}
2024-10-12 13:24:28,685 [INFO] [8] VALIDATION loss: 1.0398656598947666 VALIDATION  acc: 0.7222222222222222
2024-10-12 13:24:28,685 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.0398656598947666}
2024-10-12 13:24:28,685 [INFO] 
2024-10-12 13:27:10,153 [INFO] Step[50/144]: training loss : 0.5836136066913604 TRAIN  loss dict:  {'classification_loss': 0.5836136066913604}
2024-10-12 13:28:06,176 [INFO] Step[100/144]: training loss : 0.6386262428760529 TRAIN  loss dict:  {'classification_loss': 0.6386262428760529}
2024-10-12 13:30:33,611 [INFO] Label accuracies statistics:
2024-10-12 13:30:33,611 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 1.0, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.5, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.25, 68: 1.0, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.75, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.25, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 1.0, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.75, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.5, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-12 13:30:34,957 [INFO] [9] TRAIN  loss: 0.6374787497851584 acc: 0.8215940685820204
2024-10-12 13:30:34,957 [INFO] [9] TRAIN  loss dict: {'classification_loss': 0.6374787497851584}
2024-10-12 13:30:34,957 [INFO] [9] VALIDATION loss: 0.8816624714268578 VALIDATION  acc: 0.7714646464646465
2024-10-12 13:30:34,957 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 0.8816624714268578}
2024-10-12 13:30:34,957 [INFO] 
2024-10-12 13:33:26,486 [INFO] Step[50/144]: training loss : 0.5214583063125611 TRAIN  loss dict:  {'classification_loss': 0.5214583063125611}
2024-10-12 13:34:24,463 [INFO] Step[100/144]: training loss : 0.4954401844739914 TRAIN  loss dict:  {'classification_loss': 0.4954401844739914}
2024-10-12 13:36:39,836 [INFO] Label accuracies statistics:
2024-10-12 13:36:39,836 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.0, 59: 1.0, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.0, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.25, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.5, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.5, 167: 1.0, 168: 0.25, 169: 0.75, 170: 0.75, 171: 1.0, 172: 0.75, 173: 1.0, 174: 0.5, 175: 1.0, 176: 1.0, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 1.0, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-12 13:36:39,917 [INFO] [10] TRAIN  loss: 0.5215336684551504 acc: 0.8595922150139017
2024-10-12 13:36:39,917 [INFO] [10] TRAIN  loss dict: {'classification_loss': 0.5215336684551504}
2024-10-12 13:36:39,917 [INFO] [10] VALIDATION loss: 0.9342079990439944 VALIDATION  acc: 0.7462121212121212
2024-10-12 13:36:39,917 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 0.9342079990439944}
2024-10-12 13:36:39,917 [INFO] 
2024-10-12 13:39:20,216 [INFO] Step[50/144]: training loss : 0.42366695135831833 TRAIN  loss dict:  {'classification_loss': 0.42366695135831833}
2024-10-12 13:40:17,099 [INFO] Step[100/144]: training loss : 0.44865959107875825 TRAIN  loss dict:  {'classification_loss': 0.44865959107875825}
2024-10-12 13:42:34,615 [INFO] Label accuracies statistics:
2024-10-12 13:42:34,616 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.5, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.0, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 1.0, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.25, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.25, 165: 1.0, 166: 0.75, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 1.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.5, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.75, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 13:42:36,053 [INFO] [11] TRAIN  loss: 0.42006146762933994 acc: 0.8804448563484708
2024-10-12 13:42:36,054 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.42006146762933994}
2024-10-12 13:42:36,054 [INFO] [11] VALIDATION loss: 0.7582433110585919 VALIDATION  acc: 0.7929292929292929
2024-10-12 13:42:36,054 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 0.7582433110585919}
2024-10-12 13:42:36,054 [INFO] 
2024-10-12 13:45:18,350 [INFO] Step[50/144]: training loss : 0.33394484370946886 TRAIN  loss dict:  {'classification_loss': 0.33394484370946886}
2024-10-12 13:46:16,089 [INFO] Step[100/144]: training loss : 0.3110164101421833 TRAIN  loss dict:  {'classification_loss': 0.3110164101421833}
2024-10-12 13:48:51,429 [INFO] Label accuracies statistics:
2024-10-12 13:48:51,429 [INFO] {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.25, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 0.25, 109: 0.75, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.75, 114: 0.0, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 1.0, 122: 0.5, 123: 1.0, 124: 0.75, 125: 0.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.75, 169: 0.5, 170: 1.0, 171: 1.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-12 13:48:51,511 [INFO] [12] TRAIN  loss: 0.3264556517307129 acc: 0.9107970342910102
2024-10-12 13:48:51,511 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.3264556517307129}
2024-10-12 13:48:51,511 [INFO] [12] VALIDATION loss: 0.7779127927841963 VALIDATION  acc: 0.7790404040404041
2024-10-12 13:48:51,511 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 0.7779127927841963}
2024-10-12 13:48:51,511 [INFO] 
2024-10-12 13:51:31,015 [INFO] Step[50/144]: training loss : 0.2888906139135361 TRAIN  loss dict:  {'classification_loss': 0.2888906139135361}
2024-10-12 13:52:34,931 [INFO] Step[100/144]: training loss : 0.2771939228475094 TRAIN  loss dict:  {'classification_loss': 0.2771939228475094}
2024-10-12 13:54:51,868 [INFO] Label accuracies statistics:
2024-10-12 13:54:51,868 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.25, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 0.5, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 1.0, 141: 0.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 1.0, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.75, 192: 0.75, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-12 13:54:51,942 [INFO] [13] TRAIN  loss: 0.2925705058603651 acc: 0.9161260426320668
2024-10-12 13:54:51,942 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.2925705058603651}
2024-10-12 13:54:51,942 [INFO] [13] VALIDATION loss: 0.7808541605869929 VALIDATION  acc: 0.7866161616161617
2024-10-12 13:54:51,942 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 0.7808541605869929}
2024-10-12 13:54:51,943 [INFO] 
2024-10-12 13:57:34,350 [INFO] Step[50/144]: training loss : 0.25388131871819497 TRAIN  loss dict:  {'classification_loss': 0.25388131871819497}
2024-10-12 13:58:30,740 [INFO] Step[100/144]: training loss : 0.2593620282411575 TRAIN  loss dict:  {'classification_loss': 0.2593620282411575}
2024-10-12 14:01:23,412 [INFO] Label accuracies statistics:
2024-10-12 14:01:23,412 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.25, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.5, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.5, 141: 0.75, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 0.75, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.25, 165: 1.0, 166: 0.75, 167: 1.0, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.5, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-12 14:01:28,819 [INFO] [14] TRAIN  loss: 0.26088592164321905 acc: 0.9235403151065802
2024-10-12 14:01:28,819 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.26088592164321905}
2024-10-12 14:01:28,819 [INFO] [14] VALIDATION loss: 0.6932749087335887 VALIDATION  acc: 0.8131313131313131
2024-10-12 14:01:28,819 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 0.6932749087335887}
2024-10-12 14:01:28,819 [INFO] 
2024-10-12 14:04:11,001 [INFO] Step[50/144]: training loss : 0.23966336935758592 TRAIN  loss dict:  {'classification_loss': 0.23966336935758592}
2024-10-12 14:05:07,019 [INFO] Step[100/144]: training loss : 0.24983145266771317 TRAIN  loss dict:  {'classification_loss': 0.24983145266771317}
2024-10-12 14:07:23,154 [INFO] Label accuracies statistics:
2024-10-12 14:07:23,154 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.75, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.25, 162: 0.75, 163: 1.0, 164: 0.25, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.5, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-12 14:07:23,231 [INFO] [15] TRAIN  loss: 0.2531387491358651 acc: 0.9235403151065802
2024-10-12 14:07:23,231 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.2531387491358651}
2024-10-12 14:07:23,231 [INFO] [15] VALIDATION loss: 0.7615343737933371 VALIDATION  acc: 0.7878787878787878
2024-10-12 14:07:23,232 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 0.7615343737933371}
2024-10-12 14:07:23,232 [INFO] 
2024-10-12 14:09:55,423 [INFO] Step[50/144]: training loss : 0.22268219143152237 TRAIN  loss dict:  {'classification_loss': 0.22268219143152237}
2024-10-12 14:10:56,121 [INFO] Step[100/144]: training loss : 0.23014225900173188 TRAIN  loss dict:  {'classification_loss': 0.23014225900173188}
2024-10-12 14:13:33,971 [INFO] Label accuracies statistics:
2024-10-12 14:13:33,972 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.25, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.25, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.25, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 1.0, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.25, 165: 1.0, 166: 1.0, 167: 0.75, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 1.0, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 14:13:34,048 [INFO] [16] TRAIN  loss: 0.22399348046423662 acc: 0.9351251158480074
2024-10-12 14:13:34,048 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.22399348046423662}
2024-10-12 14:13:34,049 [INFO] [16] VALIDATION loss: 0.779481040796748 VALIDATION  acc: 0.8055555555555556
2024-10-12 14:13:34,049 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 0.779481040796748}
2024-10-12 14:13:34,049 [INFO] 
2024-10-12 14:16:12,352 [INFO] Step[50/144]: training loss : 0.20390100188553334 TRAIN  loss dict:  {'classification_loss': 0.20390100188553334}
2024-10-12 14:17:08,792 [INFO] Step[100/144]: training loss : 0.19864365343004464 TRAIN  loss dict:  {'classification_loss': 0.19864365343004464}
2024-10-12 14:19:22,495 [INFO] Label accuracies statistics:
2024-10-12 14:19:22,495 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.25, 13: 0.25, 14: 0.75, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 1.0, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-12 14:19:22,568 [INFO] [17] TRAIN  loss: 0.2109314370771042 acc: 0.9362835959221502
2024-10-12 14:19:22,568 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.2109314370771042}
2024-10-12 14:19:22,568 [INFO] [17] VALIDATION loss: 0.7881827657973325 VALIDATION  acc: 0.803030303030303
2024-10-12 14:19:22,568 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 0.7881827657973325}
2024-10-12 14:19:22,568 [INFO] 
2024-10-12 14:22:01,072 [INFO] Step[50/144]: training loss : 0.1923183512687683 TRAIN  loss dict:  {'classification_loss': 0.1923183512687683}
2024-10-12 14:22:57,763 [INFO] Step[100/144]: training loss : 0.18428943827748298 TRAIN  loss dict:  {'classification_loss': 0.18428943827748298}
2024-10-12 14:25:12,058 [INFO] Label accuracies statistics:
2024-10-12 14:25:12,058 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.5, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.75, 58: 1.0, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 14:25:13,431 [INFO] [18] TRAIN  loss: 0.19362338534038928 acc: 0.9453197405004634
2024-10-12 14:25:13,431 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.19362338534038928}
2024-10-12 14:25:13,431 [INFO] [18] VALIDATION loss: 0.6838692962019531 VALIDATION  acc: 0.8143939393939394
2024-10-12 14:25:13,431 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 0.6838692962019531}
2024-10-12 14:25:13,431 [INFO] 
2024-10-12 14:27:54,866 [INFO] Step[50/144]: training loss : 0.17213693708181382 TRAIN  loss dict:  {'classification_loss': 0.17213693708181382}
2024-10-12 14:28:51,638 [INFO] Step[100/144]: training loss : 0.2068500639498234 TRAIN  loss dict:  {'classification_loss': 0.2068500639498234}
2024-10-12 14:31:04,230 [INFO] Label accuracies statistics:
2024-10-12 14:31:04,231 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.25, 9: 1.0, 10: 0.5, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 0.75, 31: 1.0, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 1.0, 59: 0.25, 60: 0.25, 61: 1.0, 62: 0.5, 63: 0.25, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 1.0, 69: 1.0, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 1.0, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 1.0, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 14:31:04,355 [INFO] [19] TRAIN  loss: 0.19593243727770945 acc: 0.940917516218721
2024-10-12 14:31:04,355 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.19593243727770945}
2024-10-12 14:31:04,356 [INFO] [19] VALIDATION loss: 0.7461156037946542 VALIDATION  acc: 0.8017676767676768
2024-10-12 14:31:04,356 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 0.7461156037946542}
2024-10-12 14:31:04,356 [INFO] 
2024-10-12 14:33:50,105 [INFO] Step[50/144]: training loss : 0.1563594400882721 TRAIN  loss dict:  {'classification_loss': 0.1563594400882721}
2024-10-12 14:34:54,659 [INFO] Step[100/144]: training loss : 0.17317810468375683 TRAIN  loss dict:  {'classification_loss': 0.17317810468375683}
2024-10-12 14:37:10,185 [INFO] Label accuracies statistics:
2024-10-12 14:37:10,185 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.0, 14: 1.0, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.5, 68: 1.0, 69: 0.75, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.25, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 1.0, 173: 0.5, 174: 1.0, 175: 1.0, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-12 14:37:10,267 [INFO] [20] TRAIN  loss: 0.1675066388884766 acc: 0.9520389249304912
2024-10-12 14:37:10,267 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.1675066388884766}
2024-10-12 14:37:10,267 [INFO] [20] VALIDATION loss: 0.8339983790561005 VALIDATION  acc: 0.7967171717171717
2024-10-12 14:37:10,267 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 0.8339983790561005}
2024-10-12 14:37:10,267 [INFO] 
2024-10-12 14:39:51,062 [INFO] Step[50/144]: training loss : 0.13212628118693828 TRAIN  loss dict:  {'classification_loss': 0.13212628118693828}
2024-10-12 14:40:47,165 [INFO] Step[100/144]: training loss : 0.142309018522501 TRAIN  loss dict:  {'classification_loss': 0.142309018522501}
2024-10-12 14:43:04,178 [INFO] Label accuracies statistics:
2024-10-12 14:43:04,178 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.5, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 1.0, 95: 0.75, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 1.0, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 0.75, 171: 1.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 14:43:04,256 [INFO] [21] TRAIN  loss: 0.13550800294615328 acc: 0.9589898053753475
2024-10-12 14:43:04,257 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.13550800294615328}
2024-10-12 14:43:04,257 [INFO] [21] VALIDATION loss: 0.7348879768892571 VALIDATION  acc: 0.8232323232323232
2024-10-12 14:43:04,257 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 0.7348879768892571}
2024-10-12 14:43:04,257 [INFO] 
2024-10-12 14:45:46,907 [INFO] Step[50/144]: training loss : 0.11956735763698817 TRAIN  loss dict:  {'classification_loss': 0.11956735763698817}
2024-10-12 14:46:43,925 [INFO] Step[100/144]: training loss : 0.15528046751394867 TRAIN  loss dict:  {'classification_loss': 0.15528046751394867}
2024-10-12 14:49:32,633 [INFO] Label accuracies statistics:
2024-10-12 14:49:32,633 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.5, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 0.75, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 1.0, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-12 14:49:32,719 [INFO] [22] TRAIN  loss: 0.13194349283326623 acc: 0.9624652455977757
2024-10-12 14:49:32,719 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.13194349283326623}
2024-10-12 14:49:32,719 [INFO] [22] VALIDATION loss: 0.8441291385226779 VALIDATION  acc: 0.7954545454545454
2024-10-12 14:49:32,719 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 0.8441291385226779}
2024-10-12 14:49:32,719 [INFO] 
2024-10-12 14:52:05,685 [INFO] Step[50/144]: training loss : 0.11518325120210647 TRAIN  loss dict:  {'classification_loss': 0.11518325120210647}
2024-10-12 14:53:10,181 [INFO] Step[100/144]: training loss : 0.10918215069919825 TRAIN  loss dict:  {'classification_loss': 0.10918215069919825}
2024-10-12 14:55:50,083 [INFO] Label accuracies statistics:
2024-10-12 14:55:50,083 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 1.0, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 1.0, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.75, 114: 0.5, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 1.0, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.5, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-12 14:55:50,162 [INFO] [23] TRAIN  loss: 0.11040588314386292 acc: 0.9673308619091752
2024-10-12 14:55:50,162 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.11040588314386292}
2024-10-12 14:55:50,163 [INFO] [23] VALIDATION loss: 0.7109375484287739 VALIDATION  acc: 0.8181818181818182
2024-10-12 14:55:50,163 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 0.7109375484287739}
2024-10-12 14:55:50,163 [INFO] 
2024-10-12 14:58:31,871 [INFO] Step[50/144]: training loss : 0.1002693260088563 TRAIN  loss dict:  {'classification_loss': 0.1002693260088563}
2024-10-12 14:59:28,990 [INFO] Step[100/144]: training loss : 0.10488013327121734 TRAIN  loss dict:  {'classification_loss': 0.10488013327121734}
2024-10-12 15:01:46,916 [INFO] Label accuracies statistics:
2024-10-12 15:01:46,916 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.25, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 1.0, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.5, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 15:01:46,990 [INFO] [24] TRAIN  loss: 0.10166124482121733 acc: 0.9698795180722891
2024-10-12 15:01:46,990 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.10166124482121733}
2024-10-12 15:01:46,990 [INFO] [24] VALIDATION loss: 0.8272344472783583 VALIDATION  acc: 0.8017676767676768
2024-10-12 15:01:46,990 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 0.8272344472783583}
2024-10-12 15:01:46,990 [INFO] 
2024-10-12 15:04:28,178 [INFO] Step[50/144]: training loss : 0.10699554078280926 TRAIN  loss dict:  {'classification_loss': 0.10699554078280926}
2024-10-12 15:05:25,155 [INFO] Step[100/144]: training loss : 0.09788042595610022 TRAIN  loss dict:  {'classification_loss': 0.09788042595610022}
2024-10-12 15:07:42,554 [INFO] Label accuracies statistics:
2024-10-12 15:07:42,554 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.25, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 1.0, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.25, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 1.0, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 1.0, 164: 0.5, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 1.0, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.75, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 1.0}

2024-10-12 15:07:42,630 [INFO] [25] TRAIN  loss: 0.1099716182345421 acc: 0.9682576459684893
2024-10-12 15:07:42,630 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.1099716182345421}
2024-10-12 15:07:42,630 [INFO] [25] VALIDATION loss: 0.7309432718902826 VALIDATION  acc: 0.8282828282828283
2024-10-12 15:07:42,630 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 0.7309432718902826}
2024-10-12 15:07:42,630 [INFO] 
2024-10-12 15:10:23,621 [INFO] Step[50/144]: training loss : 0.10017295002937317 TRAIN  loss dict:  {'classification_loss': 0.10017295002937317}
2024-10-12 15:11:20,318 [INFO] Step[100/144]: training loss : 0.09504708167165518 TRAIN  loss dict:  {'classification_loss': 0.09504708167165518}
2024-10-12 15:13:36,506 [INFO] Label accuracies statistics:
2024-10-12 15:13:36,506 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 0.5, 142: 0.75, 143: 0.5, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 1.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 1.0, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-12 15:13:36,870 [INFO] [26] TRAIN  loss: 0.09630718829187875 acc: 0.9724281742354032
2024-10-12 15:13:36,870 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.09630718829187875}
2024-10-12 15:13:36,871 [INFO] [26] VALIDATION loss: 0.7698882442243673 VALIDATION  acc: 0.8156565656565656
2024-10-12 15:13:36,871 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 0.7698882442243673}
2024-10-12 15:13:36,871 [INFO] 
2024-10-12 15:16:17,401 [INFO] Step[50/144]: training loss : 0.09440943632274866 TRAIN  loss dict:  {'classification_loss': 0.09440943632274866}
2024-10-12 15:17:22,002 [INFO] Step[100/144]: training loss : 0.08910009603947401 TRAIN  loss dict:  {'classification_loss': 0.08910009603947401}
2024-10-12 15:19:37,877 [INFO] Label accuracies statistics:
2024-10-12 15:19:37,878 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.0, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.25, 68: 1.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 1.0, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.75, 185: 0.5, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-12 15:19:37,976 [INFO] [27] TRAIN  loss: 0.09725567064661947 acc: 0.9724281742354032
2024-10-12 15:19:37,976 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.09725567064661947}
2024-10-12 15:19:37,976 [INFO] [27] VALIDATION loss: 0.9086812044735308 VALIDATION  acc: 0.7866161616161617
2024-10-12 15:19:37,976 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 0.9086812044735308}
2024-10-12 15:19:37,976 [INFO] 
2024-10-12 15:22:17,638 [INFO] Step[50/144]: training loss : 0.10494820903986693 TRAIN  loss dict:  {'classification_loss': 0.10494820903986693}
2024-10-12 15:23:14,487 [INFO] Step[100/144]: training loss : 0.08089115878567099 TRAIN  loss dict:  {'classification_loss': 0.08089115878567099}
2024-10-12 15:25:30,382 [INFO] Label accuracies statistics:
2024-10-12 15:25:30,382 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.0, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.75, 114: 0.25, 115: 0.5, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.25, 165: 0.75, 166: 1.0, 167: 0.75, 168: 1.0, 169: 0.5, 170: 0.75, 171: 1.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.25, 198: 0.75}

2024-10-12 15:25:30,462 [INFO] [28] TRAIN  loss: 0.08801506999103974 acc: 0.977062094531974
2024-10-12 15:25:30,462 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.08801506999103974}
2024-10-12 15:25:30,462 [INFO] [28] VALIDATION loss: 0.7608081034764096 VALIDATION  acc: 0.8017676767676768
2024-10-12 15:25:30,462 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 0.7608081034764096}
2024-10-12 15:25:30,462 [INFO] 
2024-10-12 15:28:11,752 [INFO] Step[50/144]: training loss : 0.0749872916098684 TRAIN  loss dict:  {'classification_loss': 0.0749872916098684}
2024-10-12 15:29:08,386 [INFO] Step[100/144]: training loss : 0.0918979997932911 TRAIN  loss dict:  {'classification_loss': 0.0918979997932911}
2024-10-12 15:31:23,874 [INFO] Label accuracies statistics:
2024-10-12 15:31:23,874 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 1.0, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.5, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.0, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-12 15:31:23,951 [INFO] [29] TRAIN  loss: 0.08984208864664349 acc: 0.9731232622798888
2024-10-12 15:31:23,951 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.08984208864664349}
2024-10-12 15:31:23,951 [INFO] [29] VALIDATION loss: 0.7760902694254009 VALIDATION  acc: 0.8042929292929293
2024-10-12 15:31:23,951 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 0.7760902694254009}
2024-10-12 15:31:23,951 [INFO] 
2024-10-12 15:33:56,592 [INFO] Step[50/144]: training loss : 0.07339714778587222 TRAIN  loss dict:  {'classification_loss': 0.07339714778587222}
2024-10-12 15:35:03,634 [INFO] Step[100/144]: training loss : 0.08963596347719431 TRAIN  loss dict:  {'classification_loss': 0.08963596347719431}
2024-10-12 15:37:59,210 [INFO] Label accuracies statistics:
2024-10-12 15:37:59,210 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.5, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.75, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.5, 171: 1.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-12 15:37:59,321 [INFO] [30] TRAIN  loss: 0.0830341584320801 acc: 0.9772937905468025
2024-10-12 15:37:59,321 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.0830341584320801}
2024-10-12 15:37:59,321 [INFO] [30] VALIDATION loss: 0.8087374867388496 VALIDATION  acc: 0.8005050505050505
2024-10-12 15:37:59,322 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 0.8087374867388496}
2024-10-12 15:37:59,322 [INFO] 
2024-10-12 15:40:39,664 [INFO] Step[50/144]: training loss : 0.07700330007821321 TRAIN  loss dict:  {'classification_loss': 0.07700330007821321}
2024-10-12 15:41:36,299 [INFO] Step[100/144]: training loss : 0.07259582374244929 TRAIN  loss dict:  {'classification_loss': 0.07259582374244929}
2024-10-12 15:43:52,558 [INFO] Label accuracies statistics:
2024-10-12 15:43:52,558 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 1.0, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 1.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 1.0, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 1.0, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 1.0, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-12 15:43:52,639 [INFO] [31] TRAIN  loss: 0.07503878934787483 acc: 0.9777571825764597
2024-10-12 15:43:52,639 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.07503878934787483}
2024-10-12 15:43:52,639 [INFO] [31] VALIDATION loss: 0.690515498182288 VALIDATION  acc: 0.8093434343434344
2024-10-12 15:43:52,639 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 0.690515498182288}
2024-10-12 15:43:52,639 [INFO] 
2024-10-12 15:46:33,015 [INFO] Step[50/144]: training loss : 0.06323930891230703 TRAIN  loss dict:  {'classification_loss': 0.06323930891230703}
2024-10-12 15:47:29,633 [INFO] Step[100/144]: training loss : 0.08494075998663903 TRAIN  loss dict:  {'classification_loss': 0.08494075998663903}
2024-10-12 15:49:45,666 [INFO] Label accuracies statistics:
2024-10-12 15:49:45,666 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.75, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 1.0, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.5, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-12 15:49:45,758 [INFO] [32] TRAIN  loss: 0.0769357274338189 acc: 0.9789156626506024
2024-10-12 15:49:45,758 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.0769357274338189}
2024-10-12 15:49:45,758 [INFO] [32] VALIDATION loss: 0.7185625453238134 VALIDATION  acc: 0.8320707070707071
2024-10-12 15:49:45,758 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 0.7185625453238134}
2024-10-12 15:49:45,758 [INFO] 
2024-10-12 15:52:25,663 [INFO] Step[50/144]: training loss : 0.07272788608446717 TRAIN  loss dict:  {'classification_loss': 0.07272788608446717}
2024-10-12 15:53:22,303 [INFO] Step[100/144]: training loss : 0.05541229946538806 TRAIN  loss dict:  {'classification_loss': 0.05541229946538806}
2024-10-12 15:55:35,530 [INFO] Label accuracies statistics:
2024-10-12 15:55:35,530 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 1.0, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 1.0, 191: 0.75, 192: 0.75, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-12 15:55:35,644 [INFO] [33] TRAIN  loss: 0.06871327748942552 acc: 0.9805375347544022
2024-10-12 15:55:35,644 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.06871327748942552}
2024-10-12 15:55:35,645 [INFO] [33] VALIDATION loss: 0.6975074248664357 VALIDATION  acc: 0.8345959595959596
2024-10-12 15:55:35,645 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 0.6975074248664357}
2024-10-12 15:55:35,645 [INFO] 
2024-10-12 15:55:35,646 [INFO] 

***Stop training***


2024-10-12 15:55:35,649 [INFO] 
Testing checkpointed models starting...

2024-10-12 15:56:59,046 [INFO] Label accuracies statistics:
2024-10-12 15:56:59,047 [INFO] {0: 0.6666666666666666, 1: 0.5, 2: 1.0, 3: 1.0, 4: 0.5, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 1.0, 16: 0.5, 17: 0.3333333333333333, 18: 0.75, 19: 0.75, 20: 0.25, 21: 1.0, 22: 1.0, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.75, 44: 0.5, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 1.0, 54: 0.75, 55: 0.75, 56: 0.25, 57: 1.0, 58: 0.5, 59: 1.0, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 1.0, 67: 0.5, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 1.0, 77: 1.0, 78: 0.75, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.75, 84: 1.0, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.5, 89: 1.0, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.75, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 0.75, 136: 0.5, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.25, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 1.0, 160: 0.75, 161: 0.25, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 0.75, 188: 0.75, 189: 1.0, 190: 0.75, 191: 1.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.25, 198: 1.0}

2024-10-12 15:56:59,112 [INFO] 
Testing accuracy: 0.8242730720606827
