2024-10-10 16:43:28,114 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample 128*2 gcn features 1024:2 cnn features vsl for one view (512 + 256 attention)...


2024-10-10 16:45:46,263 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample 128*2 gcn features 1024:2 cnn features vsl for one view (512 + 256 attention)...


2024-10-10 16:47:26,799 [INFO] Step[50/144]: training loss : 5.476861400604248 TRAIN  loss dict:  {'classification_loss': 5.476861400604248}
2024-10-10 16:48:28,391 [INFO] Step[100/144]: training loss : 5.412059030532837 TRAIN  loss dict:  {'classification_loss': 5.412059030532837}
2024-10-10 16:50:41,646 [INFO] Label accuracies statistics:
2024-10-10 16:50:41,646 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.25, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.5, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.25, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.25, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.25, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 16:50:42,060 [INFO] [1] TRAIN  loss: 5.414223783546024 acc: 0.004402224281742354
2024-10-10 16:50:42,060 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.414223783546024}
2024-10-10 16:50:42,060 [INFO] [1] VALIDATION loss: 5.235789510938856 VALIDATION  acc: 0.015151515151515152
2024-10-10 16:50:42,060 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.235789510938856}
2024-10-10 16:50:42,060 [INFO] 
2024-10-10 16:52:39,379 [INFO] Step[50/144]: training loss : 5.150869636535645 TRAIN  loss dict:  {'classification_loss': 5.150869636535645}
2024-10-10 16:53:39,971 [INFO] Step[100/144]: training loss : 5.0027938747406 TRAIN  loss dict:  {'classification_loss': 5.0027938747406}
2024-10-10 16:55:47,112 [INFO] Label accuracies statistics:
2024-10-10 16:55:47,112 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.25, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.25, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.5, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.25, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.25, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.75, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.5, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.5, 184: 0.0, 185: 0.0, 186: 0.25, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 16:55:47,631 [INFO] [2] TRAIN  loss: 5.020442065265444 acc: 0.016450417052826693
2024-10-10 16:55:47,631 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.020442065265444}
2024-10-10 16:55:47,632 [INFO] [2] VALIDATION loss: 4.983321207541007 VALIDATION  acc: 0.020202020202020204
2024-10-10 16:55:47,632 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.983321207541007}
2024-10-10 16:55:47,632 [INFO] 
2024-10-10 16:57:32,110 [INFO] Step[50/144]: training loss : 4.732226457595825 TRAIN  loss dict:  {'classification_loss': 4.732226457595825}
2024-10-10 16:58:32,678 [INFO] Step[100/144]: training loss : 4.637852220535279 TRAIN  loss dict:  {'classification_loss': 4.637852220535279}
2024-10-10 17:00:42,877 [INFO] Label accuracies statistics:
2024-10-10 17:00:42,877 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.5, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.25, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.25, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.25, 40: 0.25, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.25, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.25, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.25, 84: 0.0, 85: 0.0, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.75, 94: 0.0, 95: 0.25, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.75, 105: 0.0, 106: 0.25, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.5, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.25, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 1.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.75, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.75, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.25, 175: 0.0, 176: 0.0, 177: 0.25, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.25, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 17:00:43,436 [INFO] [3] TRAIN  loss: 4.644756085342831 acc: 0.03985171455050973
2024-10-10 17:00:43,436 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.644756085342831}
2024-10-10 17:00:43,436 [INFO] [3] VALIDATION loss: 4.5897088404055 VALIDATION  acc: 0.056818181818181816
2024-10-10 17:00:43,436 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.5897088404055}
2024-10-10 17:00:43,437 [INFO] 
2024-10-10 17:02:25,482 [INFO] Step[50/144]: training loss : 4.340173368453979 TRAIN  loss dict:  {'classification_loss': 4.340173368453979}
2024-10-10 17:03:27,297 [INFO] Step[100/144]: training loss : 4.23763566493988 TRAIN  loss dict:  {'classification_loss': 4.23763566493988}
2024-10-10 17:05:35,394 [INFO] Label accuracies statistics:
2024-10-10 17:05:35,394 [INFO] {0: 0.0, 1: 0.0, 2: 0.25, 3: 0.25, 4: 0.25, 5: 0.0, 6: 0.5, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.25, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.5, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.25, 25: 0.0, 26: 0.25, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.25, 34: 0.25, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.5, 40: 0.75, 41: 0.25, 42: 0.0, 43: 0.5, 44: 0.0, 45: 0.0, 46: 0.75, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.75, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.5, 63: 0.0, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.25, 80: 0.0, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.75, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.0, 100: 0.25, 101: 0.5, 102: 0.25, 103: 0.0, 104: 0.25, 105: 0.25, 106: 0.75, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.75, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.5, 127: 0.0, 128: 0.5, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.0, 135: 0.75, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.75, 140: 0.0, 141: 0.0, 142: 0.5, 143: 0.25, 144: 0.5, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.25, 149: 0.0, 150: 0.0, 151: 0.5, 152: 0.25, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.5, 171: 0.0, 172: 0.0, 173: 1.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.75, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.5, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.25, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 17:05:36,036 [INFO] [4] TRAIN  loss: 4.244127656022708 acc: 0.08155699721964782
2024-10-10 17:05:36,036 [INFO] [4] TRAIN  loss dict: {'classification_loss': 4.244127656022708}
2024-10-10 17:05:36,036 [INFO] [4] VALIDATION loss: 4.097489100915414 VALIDATION  acc: 0.11868686868686869
2024-10-10 17:05:36,036 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 4.097489100915414}
2024-10-10 17:05:36,036 [INFO] 
2024-10-10 17:07:22,038 [INFO] Step[50/144]: training loss : 3.903002209663391 TRAIN  loss dict:  {'classification_loss': 3.903002209663391}
2024-10-10 17:08:24,526 [INFO] Step[100/144]: training loss : 3.8009206295013427 TRAIN  loss dict:  {'classification_loss': 3.8009206295013427}
2024-10-10 17:10:32,754 [INFO] Label accuracies statistics:
2024-10-10 17:10:32,754 [INFO] {0: 0.0, 1: 0.0, 2: 0.5, 3: 0.25, 4: 0.25, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.25, 21: 0.0, 22: 0.5, 23: 0.25, 24: 0.25, 25: 0.25, 26: 0.0, 27: 0.0, 28: 0.25, 29: 0.25, 30: 0.0, 31: 0.5, 32: 0.0, 33: 0.25, 34: 0.25, 35: 0.5, 36: 0.0, 37: 0.0, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.25, 43: 0.0, 44: 0.25, 45: 0.0, 46: 0.5, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.25, 53: 0.25, 54: 0.0, 55: 0.5, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.25, 62: 0.75, 63: 0.0, 64: 1.0, 65: 0.5, 66: 0.0, 67: 0.25, 68: 0.25, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.5, 81: 0.0, 82: 0.5, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.5, 102: 0.25, 103: 0.0, 104: 0.75, 105: 0.75, 106: 0.5, 107: 0.25, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.5, 113: 0.0, 114: 0.0, 115: 0.25, 116: 0.0, 117: 0.0, 118: 0.25, 119: 0.25, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.0, 124: 0.75, 125: 0.25, 126: 0.5, 127: 0.0, 128: 0.5, 129: 0.25, 130: 0.25, 131: 0.0, 132: 0.25, 133: 0.25, 134: 1.0, 135: 0.5, 136: 0.0, 137: 0.5, 138: 0.0, 139: 0.75, 140: 0.0, 141: 0.5, 142: 0.0, 143: 1.0, 144: 0.0, 145: 0.25, 146: 0.5, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.5, 152: 0.25, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.5, 174: 0.0, 175: 0.0, 176: 0.25, 177: 1.0, 178: 0.25, 179: 0.0, 180: 0.0, 181: 0.25, 182: 0.0, 183: 0.5, 184: 0.0, 185: 0.75, 186: 0.0, 187: 1.0, 188: 0.0, 189: 0.0, 190: 0.25, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-10 17:10:33,367 [INFO] [5] TRAIN  loss: 3.789925394786729 acc: 0.1524559777571826
2024-10-10 17:10:33,367 [INFO] [5] TRAIN  loss dict: {'classification_loss': 3.789925394786729}
2024-10-10 17:10:33,367 [INFO] [5] VALIDATION loss: 3.6908128967991582 VALIDATION  acc: 0.19318181818181818
2024-10-10 17:10:33,367 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 3.6908128967991582}
2024-10-10 17:10:33,367 [INFO] 
2024-10-10 17:12:15,185 [INFO] Step[50/144]: training loss : 3.4549146604537966 TRAIN  loss dict:  {'classification_loss': 3.4549146604537966}
2024-10-10 17:13:17,431 [INFO] Step[100/144]: training loss : 3.316629996299744 TRAIN  loss dict:  {'classification_loss': 3.316629996299744}
2024-10-10 17:15:26,452 [INFO] Label accuracies statistics:
2024-10-10 17:15:26,452 [INFO] {0: 0.0, 1: 0.3333333333333333, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.25, 8: 0.0, 9: 0.25, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.5, 19: 0.0, 20: 0.25, 21: 0.0, 22: 0.5, 23: 0.25, 24: 0.5, 25: 0.25, 26: 0.25, 27: 0.25, 28: 0.0, 29: 0.75, 30: 0.25, 31: 0.0, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.25, 39: 0.5, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.25, 44: 0.5, 45: 0.5, 46: 0.5, 47: 0.25, 48: 0.5, 49: 0.0, 50: 0.0, 51: 0.5, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.0, 62: 0.5, 63: 0.25, 64: 0.0, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.5, 72: 0.0, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.0, 77: 0.25, 78: 0.25, 79: 0.25, 80: 0.75, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.25, 90: 0.0, 91: 0.75, 92: 0.75, 93: 0.25, 94: 0.0, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.0, 100: 0.25, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.5, 105: 0.75, 106: 0.5, 107: 0.75, 108: 0.75, 109: 0.25, 110: 0.0, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.5, 115: 0.5, 116: 0.25, 117: 0.25, 118: 0.25, 119: 0.5, 120: 0.25, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.5, 125: 0.25, 126: 0.0, 127: 0.0, 128: 0.5, 129: 0.0, 130: 0.0, 131: 0.25, 132: 0.5, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.0, 141: 0.5, 142: 0.0, 143: 1.0, 144: 1.0, 145: 0.0, 146: 0.5, 147: 0.25, 148: 0.5, 149: 0.25, 150: 0.25, 151: 0.75, 152: 0.25, 153: 0.0, 154: 0.75, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.25, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.25, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.75, 171: 0.0, 172: 0.0, 173: 1.0, 174: 0.5, 175: 0.0, 176: 0.25, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.25, 182: 0.0, 183: 0.25, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.5, 194: 0.25, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-10 17:15:27,018 [INFO] [6] TRAIN  loss: 3.330642133951187 acc: 0.22822057460611678
2024-10-10 17:15:27,018 [INFO] [6] TRAIN  loss dict: {'classification_loss': 3.330642133951187}
2024-10-10 17:15:27,018 [INFO] [6] VALIDATION loss: 3.2284885777367487 VALIDATION  acc: 0.2601010101010101
2024-10-10 17:15:27,018 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 3.2284885777367487}
2024-10-10 17:15:27,018 [INFO] 
2024-10-10 17:17:09,241 [INFO] Step[50/144]: training loss : 2.9546038007736204 TRAIN  loss dict:  {'classification_loss': 2.9546038007736204}
2024-10-10 17:18:12,517 [INFO] Step[100/144]: training loss : 2.8980189752578736 TRAIN  loss dict:  {'classification_loss': 2.8980189752578736}
2024-10-10 17:20:20,165 [INFO] Label accuracies statistics:
2024-10-10 17:20:20,165 [INFO] {0: 0.0, 1: 0.0, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.0, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.25, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.25, 18: 0.75, 19: 0.0, 20: 0.25, 21: 0.0, 22: 0.5, 23: 0.75, 24: 0.75, 25: 0.25, 26: 0.0, 27: 0.25, 28: 0.0, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.25, 34: 0.75, 35: 0.5, 36: 0.0, 37: 0.25, 38: 0.0, 39: 0.25, 40: 0.5, 41: 0.25, 42: 0.25, 43: 0.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 1.0, 49: 0.0, 50: 0.0, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.25, 55: 0.0, 56: 0.25, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.0, 62: 0.75, 63: 0.25, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.25, 73: 0.25, 74: 0.0, 75: 1.0, 76: 0.25, 77: 0.0, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.5, 82: 0.25, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.5, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.5, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.6, 100: 0.25, 101: 0.0, 102: 0.75, 103: 0.0, 104: 0.25, 105: 0.75, 106: 0.5, 107: 0.5, 108: 0.25, 109: 0.25, 110: 0.25, 111: 0.25, 112: 0.0, 113: 0.25, 114: 0.25, 115: 0.5, 116: 0.0, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.5, 125: 0.5, 126: 0.5, 127: 0.75, 128: 0.5, 129: 0.75, 130: 1.0, 131: 0.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.0, 137: 0.5, 138: 0.0, 139: 0.5, 140: 0.0, 141: 1.0, 142: 0.0, 143: 0.75, 144: 1.0, 145: 0.0, 146: 0.5, 147: 0.75, 148: 0.75, 149: 0.5, 150: 0.0, 151: 1.0, 152: 0.0, 153: 0.0, 154: 0.5, 155: 0.25, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.25, 161: 0.5, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.0, 169: 0.75, 170: 0.5, 171: 0.0, 172: 0.0, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 0.5, 179: 0.0, 180: 0.5, 181: 0.5, 182: 0.0, 183: 0.5, 184: 0.0, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.5, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.5}

2024-10-10 17:20:20,713 [INFO] [7] TRAIN  loss: 2.893940433859825 acc: 0.3097775718257646
2024-10-10 17:20:20,713 [INFO] [7] TRAIN  loss dict: {'classification_loss': 2.893940433859825}
2024-10-10 17:20:20,713 [INFO] [7] VALIDATION loss: 2.907191695990386 VALIDATION  acc: 0.33207070707070707
2024-10-10 17:20:20,713 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 2.907191695990386}
2024-10-10 17:20:20,713 [INFO] 
2024-10-10 17:22:01,290 [INFO] Step[50/144]: training loss : 2.657618942260742 TRAIN  loss dict:  {'classification_loss': 2.657618942260742}
2024-10-10 17:23:05,060 [INFO] Step[100/144]: training loss : 2.543699541091919 TRAIN  loss dict:  {'classification_loss': 2.543699541091919}
2024-10-10 17:25:14,277 [INFO] Label accuracies statistics:
2024-10-10 17:25:14,277 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.25, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.25, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.5, 23: 0.5, 24: 0.25, 25: 0.25, 26: 0.5, 27: 0.25, 28: 0.25, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.25, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.25, 38: 0.5, 39: 0.75, 40: 0.5, 41: 0.0, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.75, 50: 0.25, 51: 0.25, 52: 0.25, 53: 0.5, 54: 0.0, 55: 0.0, 56: 0.25, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.25, 61: 0.0, 62: 0.75, 63: 0.25, 64: 0.75, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.25, 72: 0.5, 73: 0.75, 74: 0.0, 75: 1.0, 76: 0.25, 77: 0.25, 78: 0.75, 79: 0.0, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.5, 87: 0.25, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.25, 99: 0.8, 100: 0.0, 101: 0.0, 102: 0.5, 103: 0.25, 104: 0.0, 105: 0.5, 106: 0.0, 107: 0.25, 108: 0.5, 109: 0.5, 110: 0.75, 111: 0.5, 112: 0.0, 113: 0.0, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.0, 124: 0.25, 125: 0.75, 126: 0.5, 127: 0.25, 128: 0.5, 129: 0.75, 130: 0.5, 131: 0.25, 132: 0.0, 133: 0.75, 134: 0.0, 135: 1.0, 136: 0.0, 137: 0.5, 138: 0.0, 139: 0.5, 140: 0.25, 141: 0.25, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.25, 148: 0.25, 149: 0.5, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.75, 154: 0.75, 155: 0.0, 156: 0.25, 157: 0.0, 158: 0.0, 159: 0.5, 160: 0.25, 161: 0.25, 162: 0.0, 163: 0.0, 164: 0.25, 165: 0.25, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.25, 170: 0.5, 171: 0.25, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.0, 176: 0.25, 177: 0.75, 178: 0.25, 179: 1.0, 180: 0.25, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.5, 188: 0.0, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.25, 194: 0.75, 195: 0.5, 196: 0.0, 197: 0.25, 198: 0.0}

2024-10-10 17:25:14,833 [INFO] [8] TRAIN  loss: 2.5578737987412348 acc: 0.38461538461538464
2024-10-10 17:25:14,833 [INFO] [8] TRAIN  loss dict: {'classification_loss': 2.5578737987412348}
2024-10-10 17:25:14,833 [INFO] [8] VALIDATION loss: 2.5714470368844493 VALIDATION  acc: 0.39141414141414144
2024-10-10 17:25:14,833 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 2.5714470368844493}
2024-10-10 17:25:14,833 [INFO] 
2024-10-10 17:26:57,229 [INFO] Step[50/144]: training loss : 2.2960234332084655 TRAIN  loss dict:  {'classification_loss': 2.2960234332084655}
2024-10-10 17:28:00,255 [INFO] Step[100/144]: training loss : 2.1939922523498536 TRAIN  loss dict:  {'classification_loss': 2.1939922523498536}
2024-10-10 17:30:06,911 [INFO] Label accuracies statistics:
2024-10-10 17:30:06,911 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.25, 7: 0.5, 8: 0.0, 9: 1.0, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.25, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.25, 29: 0.75, 30: 0.0, 31: 0.5, 32: 0.5, 33: 0.0, 34: 0.5, 35: 0.25, 36: 0.0, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.25, 50: 0.25, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.75, 56: 0.25, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.25, 61: 0.25, 62: 0.5, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.25, 70: 0.5, 71: 0.0, 72: 0.25, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.25, 83: 0.0, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.25, 88: 0.0, 89: 0.0, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.8, 100: 0.75, 101: 0.0, 102: 0.75, 103: 0.25, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 0.75, 123: 0.5, 124: 0.0, 125: 0.75, 126: 0.0, 127: 0.25, 128: 0.5, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.5, 134: 0.0, 135: 1.0, 136: 0.0, 137: 0.0, 138: 0.75, 139: 0.0, 140: 0.25, 141: 0.5, 142: 0.0, 143: 0.0, 144: 0.5, 145: 0.25, 146: 0.75, 147: 0.0, 148: 0.0, 149: 1.0, 150: 0.0, 151: 0.5, 152: 0.5, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.0, 157: 0.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.0, 165: 0.5, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.75, 170: 0.0, 171: 0.0, 172: 0.5, 173: 0.5, 174: 0.5, 175: 0.25, 176: 0.25, 177: 0.5, 178: 1.0, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.75, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.25, 191: 0.5, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.25, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-10 17:30:07,414 [INFO] [9] TRAIN  loss: 2.223942753341463 acc: 0.47335495829471735
2024-10-10 17:30:07,414 [INFO] [9] TRAIN  loss dict: {'classification_loss': 2.223942753341463}
2024-10-10 17:30:07,414 [INFO] [9] VALIDATION loss: 2.504777272542318 VALIDATION  acc: 0.40404040404040403
2024-10-10 17:30:07,414 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 2.504777272542318}
2024-10-10 17:30:07,414 [INFO] 
2024-10-10 17:31:42,950 [INFO] Step[50/144]: training loss : 1.99416748046875 TRAIN  loss dict:  {'classification_loss': 1.99416748046875}
2024-10-10 17:32:51,791 [INFO] Step[100/144]: training loss : 1.9232597541809082 TRAIN  loss dict:  {'classification_loss': 1.9232597541809082}
2024-10-10 17:35:00,044 [INFO] Label accuracies statistics:
2024-10-10 17:35:00,044 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.6666666666666666, 16: 0.0, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.25, 26: 0.25, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.5, 34: 0.5, 35: 0.0, 36: 0.25, 37: 0.25, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.0, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.25, 49: 0.75, 50: 0.25, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.25, 61: 0.5, 62: 0.5, 63: 0.25, 64: 0.75, 65: 0.25, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.75, 72: 0.5, 73: 0.75, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.25, 84: 0.0, 85: 0.5, 86: 0.75, 87: 0.25, 88: 0.0, 89: 0.25, 90: 0.75, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.25, 99: 0.6, 100: 0.5, 101: 0.0, 102: 0.75, 103: 0.25, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.25, 121: 0.25, 122: 0.25, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.0, 127: 0.25, 128: 0.75, 129: 0.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.25, 137: 0.25, 138: 0.25, 139: 0.5, 140: 0.25, 141: 1.0, 142: 0.0, 143: 0.0, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.5, 148: 0.75, 149: 0.75, 150: 0.5, 151: 0.5, 152: 0.0, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.25, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.0, 171: 0.25, 172: 0.25, 173: 0.75, 174: 0.75, 175: 0.25, 176: 0.25, 177: 0.25, 178: 0.75, 179: 0.6666666666666666, 180: 0.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 0.75, 195: 0.5, 196: 0.0, 197: 0.25, 198: 0.0}

2024-10-10 17:35:00,589 [INFO] [10] TRAIN  loss: 1.9357662027080853 acc: 0.5472659870250232
2024-10-10 17:35:00,589 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.9357662027080853}
2024-10-10 17:35:00,590 [INFO] [10] VALIDATION loss: 2.135824622931304 VALIDATION  acc: 0.4823232323232323
2024-10-10 17:35:00,590 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 2.135824622931304}
2024-10-10 17:35:00,590 [INFO] 
2024-10-10 17:36:37,246 [INFO] Step[50/144]: training loss : 1.7406887531280517 TRAIN  loss dict:  {'classification_loss': 1.7406887531280517}
2024-10-10 17:37:44,295 [INFO] Step[100/144]: training loss : 1.7230344462394713 TRAIN  loss dict:  {'classification_loss': 1.7230344462394713}
2024-10-10 17:39:53,198 [INFO] Label accuracies statistics:
2024-10-10 17:39:53,198 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.0, 22: 0.25, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.25, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.25, 37: 1.0, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.0, 42: 0.5, 43: 0.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.25, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.0, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.25, 62: 0.5, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.0, 67: 0.25, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.25, 85: 0.5, 86: 0.5, 87: 0.5, 88: 0.0, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.6, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 0.5, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.5, 138: 0.0, 139: 0.75, 140: 0.5, 141: 0.0, 142: 1.0, 143: 0.25, 144: 0.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.0, 157: 0.75, 158: 0.0, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.0, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.25, 167: 0.25, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.25, 196: 0.25, 197: 0.75, 198: 0.25}

2024-10-10 17:39:53,748 [INFO] [11] TRAIN  loss: 1.6910391218132443 acc: 0.6049582947173309
2024-10-10 17:39:53,748 [INFO] [11] TRAIN  loss dict: {'classification_loss': 1.6910391218132443}
2024-10-10 17:39:53,748 [INFO] [11] VALIDATION loss: 1.8883747745443273 VALIDATION  acc: 0.571969696969697
2024-10-10 17:39:53,748 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.8883747745443273}
2024-10-10 17:39:53,749 [INFO] 
2024-10-10 17:41:28,398 [INFO] Step[50/144]: training loss : 1.4954886579513549 TRAIN  loss dict:  {'classification_loss': 1.4954886579513549}
2024-10-10 17:42:37,880 [INFO] Step[100/144]: training loss : 1.5005274987220765 TRAIN  loss dict:  {'classification_loss': 1.5005274987220765}
2024-10-10 17:44:47,413 [INFO] Label accuracies statistics:
2024-10-10 17:44:47,414 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.25, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.0, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.25, 48: 1.0, 49: 0.5, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.25, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.25, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.0, 97: 0.0, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 0.25, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.25, 126: 0.5, 127: 0.5, 128: 0.75, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.5, 139: 0.75, 140: 0.25, 141: 0.5, 142: 0.0, 143: 0.25, 144: 0.0, 145: 1.0, 146: 0.5, 147: 0.25, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.25, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.25, 162: 0.0, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.0, 167: 0.0, 168: 0.25, 169: 1.0, 170: 0.25, 171: 0.0, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 1.0, 180: 0.25, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.0, 189: 0.25, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.5, 196: 0.25, 197: 1.0, 198: 0.0}

2024-10-10 17:44:47,495 [INFO] [12] TRAIN  loss: 1.5023829912145932 acc: 0.6594068582020389
2024-10-10 17:44:47,496 [INFO] [12] TRAIN  loss dict: {'classification_loss': 1.5023829912145932}
2024-10-10 17:44:47,496 [INFO] [12] VALIDATION loss: 1.9506421089172363 VALIDATION  acc: 0.5265151515151515
2024-10-10 17:44:47,496 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.9506421089172363}
2024-10-10 17:44:47,496 [INFO] 
2024-10-10 17:46:22,340 [INFO] Step[50/144]: training loss : 1.33010413646698 TRAIN  loss dict:  {'classification_loss': 1.33010413646698}
2024-10-10 17:47:32,470 [INFO] Step[100/144]: training loss : 1.3418511438369751 TRAIN  loss dict:  {'classification_loss': 1.3418511438369751}
2024-10-10 17:49:41,796 [INFO] Label accuracies statistics:
2024-10-10 17:49:41,796 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.25, 32: 0.25, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.0, 115: 0.75, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.25, 127: 0.75, 128: 0.75, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.0, 143: 0.75, 144: 0.5, 145: 0.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.25, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.25, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 0.75, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-10 17:49:42,311 [INFO] [13] TRAIN  loss: 1.3412969186902046 acc: 0.6899907321594069
2024-10-10 17:49:42,311 [INFO] [13] TRAIN  loss dict: {'classification_loss': 1.3412969186902046}
2024-10-10 17:49:42,311 [INFO] [13] VALIDATION loss: 1.6878914259098194 VALIDATION  acc: 0.6047979797979798
2024-10-10 17:49:42,311 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.6878914259098194}
2024-10-10 17:49:42,311 [INFO] 
2024-10-10 17:51:16,267 [INFO] Step[50/144]: training loss : 1.20872607588768 TRAIN  loss dict:  {'classification_loss': 1.20872607588768}
2024-10-10 17:52:26,070 [INFO] Step[100/144]: training loss : 1.2152383947372436 TRAIN  loss dict:  {'classification_loss': 1.2152383947372436}
2024-10-10 17:54:34,930 [INFO] Label accuracies statistics:
2024-10-10 17:54:34,930 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.0, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.0, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.25, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.0, 32: 0.25, 33: 0.5, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.0, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.0, 65: 0.0, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.5, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.25, 104: 0.25, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.25, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.5, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.0, 143: 0.25, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.75, 166: 0.25, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.25, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 1.0, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.0, 189: 0.5, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-10 17:54:35,491 [INFO] [14] TRAIN  loss: 1.2151288013491366 acc: 0.7177942539388322
2024-10-10 17:54:35,491 [INFO] [14] TRAIN  loss dict: {'classification_loss': 1.2151288013491366}
2024-10-10 17:54:35,491 [INFO] [14] VALIDATION loss: 1.6568128576985113 VALIDATION  acc: 0.5858585858585859
2024-10-10 17:54:35,491 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.6568128576985113}
2024-10-10 17:54:35,491 [INFO] 
2024-10-10 17:56:10,002 [INFO] Step[50/144]: training loss : 1.0942835080623627 TRAIN  loss dict:  {'classification_loss': 1.0942835080623627}
2024-10-10 17:57:23,428 [INFO] Step[100/144]: training loss : 1.1283525431156158 TRAIN  loss dict:  {'classification_loss': 1.1283525431156158}
2024-10-10 17:59:06,631 [INFO] Label accuracies statistics:
2024-10-10 17:59:06,631 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.0, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.25, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 1.0, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.0, 66: 0.0, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.5, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 0.75, 105: 0.5, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.75, 143: 0.25, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.0, 157: 0.5, 158: 1.0, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.25, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.25, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.25, 197: 1.0, 198: 0.0}

2024-10-10 17:59:07,092 [INFO] [15] TRAIN  loss: 1.0937034086220794 acc: 0.747451343836886
2024-10-10 17:59:07,092 [INFO] [15] TRAIN  loss dict: {'classification_loss': 1.0937034086220794}
2024-10-10 17:59:07,092 [INFO] [15] VALIDATION loss: 1.6177191336949666 VALIDATION  acc: 0.5909090909090909
2024-10-10 17:59:07,092 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.6177191336949666}
2024-10-10 17:59:07,093 [INFO] 
2024-10-10 18:00:24,862 [INFO] Step[50/144]: training loss : 0.989841787815094 TRAIN  loss dict:  {'classification_loss': 0.989841787815094}
2024-10-10 18:01:19,840 [INFO] Step[100/144]: training loss : 1.0038385963439942 TRAIN  loss dict:  {'classification_loss': 1.0038385963439942}
2024-10-10 18:02:57,115 [INFO] Label accuracies statistics:
2024-10-10 18:02:57,115 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.0, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.25, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.25, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 1.0, 103: 0.25, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.5, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.75, 138: 0.25, 139: 0.25, 140: 0.25, 141: 0.5, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.5, 152: 0.5, 153: 0.25, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-10 18:02:57,570 [INFO] [16] TRAIN  loss: 0.9876858964562416 acc: 0.7689990732159406
2024-10-10 18:02:57,570 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.9876858964562416}
2024-10-10 18:02:57,570 [INFO] [16] VALIDATION loss: 1.5471932291984558 VALIDATION  acc: 0.6161616161616161
2024-10-10 18:02:57,570 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.5471932291984558}
2024-10-10 18:02:57,571 [INFO] 
2024-10-10 18:04:14,869 [INFO] Step[50/144]: training loss : 0.9001732337474823 TRAIN  loss dict:  {'classification_loss': 0.9001732337474823}
2024-10-10 18:05:09,735 [INFO] Step[100/144]: training loss : 0.8757970547676086 TRAIN  loss dict:  {'classification_loss': 0.8757970547676086}
2024-10-10 18:06:47,094 [INFO] Label accuracies statistics:
2024-10-10 18:06:47,094 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.25, 27: 0.5, 28: 0.5, 29: 0.5, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.25, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.5, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.25, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.25, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.0, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.75, 141: 0.25, 142: 0.25, 143: 0.75, 144: 0.25, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.25, 161: 0.5, 162: 0.75, 163: 0.25, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.75, 170: 0.25, 171: 0.25, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.0, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.0}

2024-10-10 18:06:47,526 [INFO] [17] TRAIN  loss: 0.8868667719264826 acc: 0.794253938832252
2024-10-10 18:06:47,526 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.8868667719264826}
2024-10-10 18:06:47,526 [INFO] [17] VALIDATION loss: 1.4855630640630368 VALIDATION  acc: 0.6224747474747475
2024-10-10 18:06:47,526 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.4855630640630368}
2024-10-10 18:06:47,527 [INFO] 
2024-10-10 18:08:04,334 [INFO] Step[50/144]: training loss : 0.8275440311431885 TRAIN  loss dict:  {'classification_loss': 0.8275440311431885}
2024-10-10 18:08:59,064 [INFO] Step[100/144]: training loss : 0.7815693801641465 TRAIN  loss dict:  {'classification_loss': 0.7815693801641465}
2024-10-10 18:10:35,901 [INFO] Label accuracies statistics:
2024-10-10 18:10:35,901 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.25, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.5, 162: 1.0, 163: 0.0, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.25, 170: 0.25, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-10 18:10:36,353 [INFO] [18] TRAIN  loss: 0.8122898222257694 acc: 0.8102409638554217
2024-10-10 18:10:36,353 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.8122898222257694}
2024-10-10 18:10:36,353 [INFO] [18] VALIDATION loss: 1.3415269156297047 VALIDATION  acc: 0.6452020202020202
2024-10-10 18:10:36,353 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.3415269156297047}
2024-10-10 18:10:36,353 [INFO] 
2024-10-10 18:11:53,870 [INFO] Step[50/144]: training loss : 0.752736856341362 TRAIN  loss dict:  {'classification_loss': 0.752736856341362}
2024-10-10 18:12:48,834 [INFO] Step[100/144]: training loss : 0.7489760529994964 TRAIN  loss dict:  {'classification_loss': 0.7489760529994964}
2024-10-10 18:14:25,711 [INFO] Label accuracies statistics:
2024-10-10 18:14:25,711 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.0, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.6666666666666666, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.25, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 1.0, 165: 0.5, 166: 0.5, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.5, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 18:14:26,159 [INFO] [19] TRAIN  loss: 0.7429871898558404 acc: 0.829935125115848
2024-10-10 18:14:26,160 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.7429871898558404}
2024-10-10 18:14:26,160 [INFO] [19] VALIDATION loss: 1.3270894962328452 VALIDATION  acc: 0.6540404040404041
2024-10-10 18:14:26,160 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.3270894962328452}
2024-10-10 18:14:26,160 [INFO] 
2024-10-10 18:15:43,371 [INFO] Step[50/144]: training loss : 0.6642330974340439 TRAIN  loss dict:  {'classification_loss': 0.6642330974340439}
2024-10-10 18:16:38,080 [INFO] Step[100/144]: training loss : 0.6665797418355942 TRAIN  loss dict:  {'classification_loss': 0.6665797418355942}
2024-10-10 18:18:15,324 [INFO] Label accuracies statistics:
2024-10-10 18:18:15,324 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.25, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.25, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-10 18:18:15,739 [INFO] [20] TRAIN  loss: 0.6728023888750209 acc: 0.8389712696941612
2024-10-10 18:18:15,739 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.6728023888750209}
2024-10-10 18:18:15,739 [INFO] [20] VALIDATION loss: 1.3263960867016404 VALIDATION  acc: 0.6641414141414141
2024-10-10 18:18:15,739 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.3263960867016404}
2024-10-10 18:18:15,739 [INFO] 
2024-10-10 18:19:33,167 [INFO] Step[50/144]: training loss : 0.5824950057268142 TRAIN  loss dict:  {'classification_loss': 0.5824950057268142}
2024-10-10 18:20:27,853 [INFO] Step[100/144]: training loss : 0.595405576825142 TRAIN  loss dict:  {'classification_loss': 0.595405576825142}
2024-10-10 18:22:04,982 [INFO] Label accuracies statistics:
2024-10-10 18:22:04,982 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.0, 15: 0.6666666666666666, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.25, 28: 1.0, 29: 0.5, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.75, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.5, 158: 1.0, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.25, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-10 18:22:05,393 [INFO] [21] TRAIN  loss: 0.5962223977678351 acc: 0.8739573679332715
2024-10-10 18:22:05,393 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.5962223977678351}
2024-10-10 18:22:05,393 [INFO] [21] VALIDATION loss: 1.321843124098248 VALIDATION  acc: 0.6578282828282829
2024-10-10 18:22:05,393 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.321843124098248}
2024-10-10 18:22:05,394 [INFO] 
2024-10-10 18:23:22,947 [INFO] Step[50/144]: training loss : 0.5328049546480179 TRAIN  loss dict:  {'classification_loss': 0.5328049546480179}
2024-10-10 18:24:17,580 [INFO] Step[100/144]: training loss : 0.5597316411137581 TRAIN  loss dict:  {'classification_loss': 0.5597316411137581}
2024-10-10 18:25:54,393 [INFO] Label accuracies statistics:
2024-10-10 18:25:54,393 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.0, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.25, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 1.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.5, 105: 0.75, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.5, 166: 1.0, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.25, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.5, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-10 18:25:54,844 [INFO] [22] TRAIN  loss: 0.5447664984191457 acc: 0.8790546802594995
2024-10-10 18:25:54,844 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.5447664984191457}
2024-10-10 18:25:54,844 [INFO] [22] VALIDATION loss: 1.2446032795641158 VALIDATION  acc: 0.6628787878787878
2024-10-10 18:25:54,844 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.2446032795641158}
2024-10-10 18:25:54,844 [INFO] 
2024-10-10 18:27:12,305 [INFO] Step[50/144]: training loss : 0.46665133237838746 TRAIN  loss dict:  {'classification_loss': 0.46665133237838746}
2024-10-10 18:28:07,198 [INFO] Step[100/144]: training loss : 0.5026827186346055 TRAIN  loss dict:  {'classification_loss': 0.5026827186346055}
2024-10-10 18:29:43,814 [INFO] Label accuracies statistics:
2024-10-10 18:29:43,814 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.0, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.0, 14: 0.0, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 1.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.25, 166: 0.5, 167: 0.25, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.25}

2024-10-10 18:29:44,258 [INFO] [23] TRAIN  loss: 0.497319125259916 acc: 0.8936515291936978
2024-10-10 18:29:44,258 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.497319125259916}
2024-10-10 18:29:44,258 [INFO] [23] VALIDATION loss: 1.1788588149680033 VALIDATION  acc: 0.6881313131313131
2024-10-10 18:29:44,258 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.1788588149680033}
2024-10-10 18:29:44,259 [INFO] 
2024-10-10 18:31:01,660 [INFO] Step[50/144]: training loss : 0.4409526973962784 TRAIN  loss dict:  {'classification_loss': 0.4409526973962784}
2024-10-10 18:31:56,499 [INFO] Step[100/144]: training loss : 0.4968644607067108 TRAIN  loss dict:  {'classification_loss': 0.4968644607067108}
2024-10-10 18:33:33,619 [INFO] Label accuracies statistics:
2024-10-10 18:33:33,619 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.0, 15: 0.6666666666666666, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.0, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 18:33:33,691 [INFO] [24] TRAIN  loss: 0.46155131691031986 acc: 0.8964318813716404
2024-10-10 18:33:33,691 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.46155131691031986}
2024-10-10 18:33:33,691 [INFO] [24] VALIDATION loss: 1.1950260312468917 VALIDATION  acc: 0.6881313131313131
2024-10-10 18:33:33,691 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.1950260312468917}
2024-10-10 18:33:33,692 [INFO] 
2024-10-10 18:34:51,691 [INFO] Step[50/144]: training loss : 0.4244975343346596 TRAIN  loss dict:  {'classification_loss': 0.4244975343346596}
2024-10-10 18:35:46,316 [INFO] Step[100/144]: training loss : 0.4103230118751526 TRAIN  loss dict:  {'classification_loss': 0.4103230118751526}
2024-10-10 18:37:23,467 [INFO] Label accuracies statistics:
2024-10-10 18:37:23,467 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 1.0, 113: 1.0, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-10 18:37:23,916 [INFO] [25] TRAIN  loss: 0.42561308201402426 acc: 0.9089434661723819
2024-10-10 18:37:23,916 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.42561308201402426}
2024-10-10 18:37:23,916 [INFO] [25] VALIDATION loss: 1.1319060342179403 VALIDATION  acc: 0.7045454545454546
2024-10-10 18:37:23,917 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.1319060342179403}
2024-10-10 18:37:23,917 [INFO] 
2024-10-10 18:38:41,480 [INFO] Step[50/144]: training loss : 0.3751577290892601 TRAIN  loss dict:  {'classification_loss': 0.3751577290892601}
2024-10-10 18:39:36,338 [INFO] Step[100/144]: training loss : 0.39214790642261504 TRAIN  loss dict:  {'classification_loss': 0.39214790642261504}
2024-10-10 18:41:13,430 [INFO] Label accuracies statistics:
2024-10-10 18:41:13,430 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 1.0, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.5, 141: 0.5, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 18:41:13,503 [INFO] [26] TRAIN  loss: 0.3853816541118754 acc: 0.9230769230769231
2024-10-10 18:41:13,503 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.3853816541118754}
2024-10-10 18:41:13,503 [INFO] [26] VALIDATION loss: 1.134383874910849 VALIDATION  acc: 0.6881313131313131
2024-10-10 18:41:13,503 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.134383874910849}
2024-10-10 18:41:13,503 [INFO] 
2024-10-10 18:42:30,620 [INFO] Step[50/144]: training loss : 0.32989481508731844 TRAIN  loss dict:  {'classification_loss': 0.32989481508731844}
2024-10-10 18:43:25,463 [INFO] Step[100/144]: training loss : 0.37244431644678117 TRAIN  loss dict:  {'classification_loss': 0.37244431644678117}
2024-10-10 18:45:02,716 [INFO] Label accuracies statistics:
2024-10-10 18:45:02,716 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.5, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.0, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.25, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.75, 106: 0.5, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-10 18:45:02,787 [INFO] [27] TRAIN  loss: 0.3663817844871018 acc: 0.9186746987951807
2024-10-10 18:45:02,787 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.3663817844871018}
2024-10-10 18:45:02,787 [INFO] [27] VALIDATION loss: 1.170582053286058 VALIDATION  acc: 0.6881313131313131
2024-10-10 18:45:02,787 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.170582053286058}
2024-10-10 18:45:02,787 [INFO] 
2024-10-10 18:46:19,967 [INFO] Step[50/144]: training loss : 0.318935182094574 TRAIN  loss dict:  {'classification_loss': 0.318935182094574}
2024-10-10 18:47:14,735 [INFO] Step[100/144]: training loss : 0.32587896794080734 TRAIN  loss dict:  {'classification_loss': 0.32587896794080734}
2024-10-10 18:48:51,925 [INFO] Label accuracies statistics:
2024-10-10 18:48:51,925 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.6666666666666666, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 0.5, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.0, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.0, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.25, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 18:48:51,996 [INFO] [28] TRAIN  loss: 0.3238143688067794 acc: 0.9358202038924931
2024-10-10 18:48:51,996 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.3238143688067794}
2024-10-10 18:48:51,997 [INFO] [28] VALIDATION loss: 1.2114535691561523 VALIDATION  acc: 0.6856060606060606
2024-10-10 18:48:51,997 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.2114535691561523}
2024-10-10 18:48:51,997 [INFO] 
2024-10-10 18:50:09,883 [INFO] Step[50/144]: training loss : 0.3003739929199219 TRAIN  loss dict:  {'classification_loss': 0.3003739929199219}
2024-10-10 18:51:04,742 [INFO] Step[100/144]: training loss : 0.33698644161224367 TRAIN  loss dict:  {'classification_loss': 0.33698644161224367}
2024-10-10 18:52:41,584 [INFO] Label accuracies statistics:
2024-10-10 18:52:41,584 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.25, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.5, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 1.0, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.25, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-10 18:52:41,654 [INFO] [29] TRAIN  loss: 0.32105398385061157 acc: 0.932808155699722
2024-10-10 18:52:41,654 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.32105398385061157}
2024-10-10 18:52:41,654 [INFO] [29] VALIDATION loss: 1.169867608834196 VALIDATION  acc: 0.6868686868686869
2024-10-10 18:52:41,654 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.169867608834196}
2024-10-10 18:52:41,654 [INFO] 
2024-10-10 18:53:59,140 [INFO] Step[50/144]: training loss : 0.2931936520338059 TRAIN  loss dict:  {'classification_loss': 0.2931936520338059}
2024-10-10 18:54:54,002 [INFO] Step[100/144]: training loss : 0.31667306214571 TRAIN  loss dict:  {'classification_loss': 0.31667306214571}
2024-10-10 18:56:31,057 [INFO] Label accuracies statistics:
2024-10-10 18:56:31,057 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.5, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.25, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-10 18:56:31,130 [INFO] [30] TRAIN  loss: 0.30829869117587805 acc: 0.9309545875810936
2024-10-10 18:56:31,130 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.30829869117587805}
2024-10-10 18:56:31,130 [INFO] [30] VALIDATION loss: 1.1465467391190705 VALIDATION  acc: 0.6957070707070707
2024-10-10 18:56:31,130 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.1465467391190705}
2024-10-10 18:56:31,130 [INFO] 
2024-10-10 18:57:47,914 [INFO] Step[50/144]: training loss : 0.2784544688463211 TRAIN  loss dict:  {'classification_loss': 0.2784544688463211}
2024-10-10 18:58:42,711 [INFO] Step[100/144]: training loss : 0.2723653887212276 TRAIN  loss dict:  {'classification_loss': 0.2723653887212276}
2024-10-10 19:00:19,768 [INFO] Label accuracies statistics:
2024-10-10 19:00:19,768 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.5, 166: 1.0, 167: 0.25, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.5, 173: 0.75, 174: 0.75, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-10 19:00:19,839 [INFO] [31] TRAIN  loss: 0.2719566309307184 acc: 0.9446246524559777
2024-10-10 19:00:19,839 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.2719566309307184}
2024-10-10 19:00:19,839 [INFO] [31] VALIDATION loss: 1.1451904944799565 VALIDATION  acc: 0.7007575757575758
2024-10-10 19:00:19,839 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.1451904944799565}
2024-10-10 19:00:19,839 [INFO] 
2024-10-10 19:01:37,176 [INFO] Step[50/144]: training loss : 0.23115215986967086 TRAIN  loss dict:  {'classification_loss': 0.23115215986967086}
2024-10-10 19:02:31,772 [INFO] Step[100/144]: training loss : 0.25597038090229035 TRAIN  loss dict:  {'classification_loss': 0.25597038090229035}
2024-10-10 19:04:08,703 [INFO] Label accuracies statistics:
2024-10-10 19:04:08,703 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.0, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.0, 197: 0.75, 198: 0.25}

2024-10-10 19:04:21,645 [INFO] [32] TRAIN  loss: 0.24265417942984235 acc: 0.953660797034291
2024-10-10 19:04:21,645 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.24265417942984235}
2024-10-10 19:04:21,646 [INFO] [32] VALIDATION loss: 1.1213687299578279 VALIDATION  acc: 0.6957070707070707
2024-10-10 19:04:21,646 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.1213687299578279}
2024-10-10 19:04:21,646 [INFO] 
2024-10-10 19:05:39,084 [INFO] Step[50/144]: training loss : 0.20701599091291428 TRAIN  loss dict:  {'classification_loss': 0.20701599091291428}
2024-10-10 19:06:33,969 [INFO] Step[100/144]: training loss : 0.23654123961925508 TRAIN  loss dict:  {'classification_loss': 0.23654123961925508}
2024-10-10 19:08:11,182 [INFO] Label accuracies statistics:
2024-10-10 19:08:11,182 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-10 19:08:11,620 [INFO] [33] TRAIN  loss: 0.22695935326110986 acc: 0.9550509731232623
2024-10-10 19:08:11,620 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.22695935326110986}
2024-10-10 19:08:11,620 [INFO] [33] VALIDATION loss: 1.0461186120907466 VALIDATION  acc: 0.7159090909090909
2024-10-10 19:08:11,620 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 1.0461186120907466}
2024-10-10 19:08:11,620 [INFO] 
2024-10-10 19:09:28,546 [INFO] Step[50/144]: training loss : 0.21378163009881973 TRAIN  loss dict:  {'classification_loss': 0.21378163009881973}
2024-10-10 19:10:23,398 [INFO] Step[100/144]: training loss : 0.2060514472424984 TRAIN  loss dict:  {'classification_loss': 0.2060514472424984}
2024-10-10 19:12:00,532 [INFO] Label accuracies statistics:
2024-10-10 19:12:00,532 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.75, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.5, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 1.0, 167: 0.25, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.0, 197: 1.0, 198: 0.75}

2024-10-10 19:12:00,602 [INFO] [34] TRAIN  loss: 0.21899325147064197 acc: 0.9575996292863763
2024-10-10 19:12:00,602 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.21899325147064197}
2024-10-10 19:12:00,603 [INFO] [34] VALIDATION loss: 1.122904310899752 VALIDATION  acc: 0.7083333333333334
2024-10-10 19:12:00,603 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.122904310899752}
2024-10-10 19:12:00,603 [INFO] 
2024-10-10 19:13:18,086 [INFO] Step[50/144]: training loss : 0.21452738896012305 TRAIN  loss dict:  {'classification_loss': 0.21452738896012305}
2024-10-10 19:14:12,790 [INFO] Step[100/144]: training loss : 0.20517346426844596 TRAIN  loss dict:  {'classification_loss': 0.20517346426844596}
2024-10-10 19:15:49,492 [INFO] Label accuracies statistics:
2024-10-10 19:15:49,493 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.5, 10: 1.0, 11: 0.75, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.25, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 1.0, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 19:15:49,903 [INFO] [35] TRAIN  loss: 0.20904559414419863 acc: 0.9571362372567191
2024-10-10 19:15:49,904 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.20904559414419863}
2024-10-10 19:15:49,904 [INFO] [35] VALIDATION loss: 1.024014506627012 VALIDATION  acc: 0.7348484848484849
2024-10-10 19:15:49,904 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.024014506627012}
2024-10-10 19:15:49,904 [INFO] 
2024-10-10 19:17:07,141 [INFO] Step[50/144]: training loss : 0.19397294864058495 TRAIN  loss dict:  {'classification_loss': 0.19397294864058495}
2024-10-10 19:18:01,760 [INFO] Step[100/144]: training loss : 0.19548058718442918 TRAIN  loss dict:  {'classification_loss': 0.19548058718442918}
2024-10-10 19:19:39,196 [INFO] Label accuracies statistics:
2024-10-10 19:19:39,196 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-10 19:19:39,266 [INFO] [36] TRAIN  loss: 0.19702058213038576 acc: 0.9636237256719185
2024-10-10 19:19:39,266 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.19702058213038576}
2024-10-10 19:19:39,266 [INFO] [36] VALIDATION loss: 1.0703903784354527 VALIDATION  acc: 0.7310606060606061
2024-10-10 19:19:39,266 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.0703903784354527}
2024-10-10 19:19:39,266 [INFO] 
2024-10-10 19:20:55,875 [INFO] Step[50/144]: training loss : 0.1756668768823147 TRAIN  loss dict:  {'classification_loss': 0.1756668768823147}
2024-10-10 19:21:50,677 [INFO] Step[100/144]: training loss : 0.1682641562819481 TRAIN  loss dict:  {'classification_loss': 0.1682641562819481}
2024-10-10 19:23:27,854 [INFO] Label accuracies statistics:
2024-10-10 19:23:27,854 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.75, 14: 0.0, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.5, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 19:23:27,924 [INFO] [37] TRAIN  loss: 0.17716244261504877 acc: 0.9659406858202039
2024-10-10 19:23:27,924 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.17716244261504877}
2024-10-10 19:23:27,924 [INFO] [37] VALIDATION loss: 1.0399047445367884 VALIDATION  acc: 0.726010101010101
2024-10-10 19:23:27,924 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.0399047445367884}
2024-10-10 19:23:27,924 [INFO] 
2024-10-10 19:24:44,883 [INFO] Step[50/144]: training loss : 0.17048853173851966 TRAIN  loss dict:  {'classification_loss': 0.17048853173851966}
2024-10-10 19:25:39,552 [INFO] Step[100/144]: training loss : 0.1896746525168419 TRAIN  loss dict:  {'classification_loss': 0.1896746525168419}
2024-10-10 19:27:16,865 [INFO] Label accuracies statistics:
2024-10-10 19:27:16,865 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.25, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 1.0, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.25, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 19:27:16,935 [INFO] [38] TRAIN  loss: 0.17825555014941427 acc: 0.964318813716404
2024-10-10 19:27:16,935 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.17825555014941427}
2024-10-10 19:27:16,935 [INFO] [38] VALIDATION loss: 1.0710955438790497 VALIDATION  acc: 0.7184343434343434
2024-10-10 19:27:16,935 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.0710955438790497}
2024-10-10 19:27:16,935 [INFO] 
2024-10-10 19:28:34,862 [INFO] Step[50/144]: training loss : 0.14424306988716126 TRAIN  loss dict:  {'classification_loss': 0.14424306988716126}
2024-10-10 19:29:29,655 [INFO] Step[100/144]: training loss : 0.189531891644001 TRAIN  loss dict:  {'classification_loss': 0.189531891644001}
2024-10-10 19:31:07,007 [INFO] Label accuracies statistics:
2024-10-10 19:31:07,007 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.25, 67: 1.0, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-10 19:31:07,077 [INFO] [39] TRAIN  loss: 0.1673145650161637 acc: 0.9698795180722891
2024-10-10 19:31:07,077 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.1673145650161637}
2024-10-10 19:31:07,077 [INFO] [39] VALIDATION loss: 1.0543665516155738 VALIDATION  acc: 0.7184343434343434
2024-10-10 19:31:07,077 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.0543665516155738}
2024-10-10 19:31:07,077 [INFO] 
2024-10-10 19:32:24,417 [INFO] Step[50/144]: training loss : 0.1456916946172714 TRAIN  loss dict:  {'classification_loss': 0.1456916946172714}
2024-10-10 19:33:19,032 [INFO] Step[100/144]: training loss : 0.17071162462234496 TRAIN  loss dict:  {'classification_loss': 0.17071162462234496}
2024-10-10 19:34:56,573 [INFO] Label accuracies statistics:
2024-10-10 19:34:56,573 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.25, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 19:34:56,646 [INFO] [40] TRAIN  loss: 0.17254579962334698 acc: 0.9654772937905468
2024-10-10 19:34:56,646 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.17254579962334698}
2024-10-10 19:34:56,646 [INFO] [40] VALIDATION loss: 1.0835410450343732 VALIDATION  acc: 0.7272727272727273
2024-10-10 19:34:56,646 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.0835410450343732}
2024-10-10 19:34:56,646 [INFO] 
2024-10-10 19:36:13,792 [INFO] Step[50/144]: training loss : 0.1272479359060526 TRAIN  loss dict:  {'classification_loss': 0.1272479359060526}
2024-10-10 19:37:08,486 [INFO] Step[100/144]: training loss : 0.14102503307163716 TRAIN  loss dict:  {'classification_loss': 0.14102503307163716}
2024-10-10 19:38:45,381 [INFO] Label accuracies statistics:
2024-10-10 19:38:45,381 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.5, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 19:38:45,451 [INFO] [41] TRAIN  loss: 0.13537382694064742 acc: 0.9763670064874884
2024-10-10 19:38:45,451 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.13537382694064742}
2024-10-10 19:38:45,451 [INFO] [41] VALIDATION loss: 1.0438951557433163 VALIDATION  acc: 0.7159090909090909
2024-10-10 19:38:45,451 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.0438951557433163}
2024-10-10 19:38:45,451 [INFO] 
2024-10-10 19:40:02,788 [INFO] Step[50/144]: training loss : 0.128145367577672 TRAIN  loss dict:  {'classification_loss': 0.128145367577672}
2024-10-10 19:40:57,678 [INFO] Step[100/144]: training loss : 0.12498213805258274 TRAIN  loss dict:  {'classification_loss': 0.12498213805258274}
2024-10-10 19:42:34,479 [INFO] Label accuracies statistics:
2024-10-10 19:42:34,479 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 1.0, 29: 0.5, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.5, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.25, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 19:42:34,550 [INFO] [42] TRAIN  loss: 0.13131265538848108 acc: 0.9759036144578314
2024-10-10 19:42:34,550 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.13131265538848108}
2024-10-10 19:42:34,550 [INFO] [42] VALIDATION loss: 1.0522045244773228 VALIDATION  acc: 0.7222222222222222
2024-10-10 19:42:34,550 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.0522045244773228}
2024-10-10 19:42:34,550 [INFO] 
2024-10-10 19:43:52,150 [INFO] Step[50/144]: training loss : 0.12493704736232758 TRAIN  loss dict:  {'classification_loss': 0.12493704736232758}
2024-10-10 19:44:46,910 [INFO] Step[100/144]: training loss : 0.12114386558532715 TRAIN  loss dict:  {'classification_loss': 0.12114386558532715}
2024-10-10 19:46:23,762 [INFO] Label accuracies statistics:
2024-10-10 19:46:23,762 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 19:46:23,832 [INFO] [43] TRAIN  loss: 0.12452138712008794 acc: 0.9803058387395737
2024-10-10 19:46:23,832 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.12452138712008794}
2024-10-10 19:46:23,832 [INFO] [43] VALIDATION loss: 1.0564411812358432 VALIDATION  acc: 0.7272727272727273
2024-10-10 19:46:23,832 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.0564411812358432}
2024-10-10 19:46:23,832 [INFO] 
2024-10-10 19:47:40,693 [INFO] Step[50/144]: training loss : 0.1232658302038908 TRAIN  loss dict:  {'classification_loss': 0.1232658302038908}
2024-10-10 19:48:35,469 [INFO] Step[100/144]: training loss : 0.10364895559847355 TRAIN  loss dict:  {'classification_loss': 0.10364895559847355}
2024-10-10 19:50:13,004 [INFO] Label accuracies statistics:
2024-10-10 19:50:13,004 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 19:50:13,073 [INFO] [44] TRAIN  loss: 0.1178472497396999 acc: 0.9803058387395737
2024-10-10 19:50:13,073 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.1178472497396999}
2024-10-10 19:50:13,073 [INFO] [44] VALIDATION loss: 1.1040536998598665 VALIDATION  acc: 0.7209595959595959
2024-10-10 19:50:13,073 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.1040536998598665}
2024-10-10 19:50:13,073 [INFO] 
2024-10-10 19:51:29,825 [INFO] Step[50/144]: training loss : 0.10486360095441341 TRAIN  loss dict:  {'classification_loss': 0.10486360095441341}
2024-10-10 19:52:24,631 [INFO] Step[100/144]: training loss : 0.11750395148992539 TRAIN  loss dict:  {'classification_loss': 0.11750395148992539}
2024-10-10 19:54:01,608 [INFO] Label accuracies statistics:
2024-10-10 19:54:01,608 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.25, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-10 19:54:01,680 [INFO] [45] TRAIN  loss: 0.11264850664883852 acc: 0.9823911028730306
2024-10-10 19:54:01,680 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.11264850664883852}
2024-10-10 19:54:01,680 [INFO] [45] VALIDATION loss: 1.064619987099259 VALIDATION  acc: 0.7222222222222222
2024-10-10 19:54:01,680 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.064619987099259}
2024-10-10 19:54:01,680 [INFO] 
2024-10-10 19:55:18,859 [INFO] Step[50/144]: training loss : 0.13278771951794624 TRAIN  loss dict:  {'classification_loss': 0.13278771951794624}
2024-10-10 19:56:13,606 [INFO] Step[100/144]: training loss : 0.1031012050062418 TRAIN  loss dict:  {'classification_loss': 0.1031012050062418}
2024-10-10 19:57:49,783 [INFO] Label accuracies statistics:
2024-10-10 19:57:49,783 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.5, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 19:57:49,853 [INFO] [46] TRAIN  loss: 0.11762663533186747 acc: 0.9779888785912882
2024-10-10 19:57:49,853 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.11762663533186747}
2024-10-10 19:57:49,853 [INFO] [46] VALIDATION loss: 1.060725273495471 VALIDATION  acc: 0.73989898989899
2024-10-10 19:57:49,853 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.060725273495471}
2024-10-10 19:57:49,853 [INFO] 
2024-10-10 19:59:06,632 [INFO] Step[50/144]: training loss : 0.09824337668716908 TRAIN  loss dict:  {'classification_loss': 0.09824337668716908}
2024-10-10 20:00:01,336 [INFO] Step[100/144]: training loss : 0.10908069014549256 TRAIN  loss dict:  {'classification_loss': 0.10908069014549256}
2024-10-10 20:01:38,489 [INFO] Label accuracies statistics:
2024-10-10 20:01:38,490 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 1.0, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 20:01:38,560 [INFO] [47] TRAIN  loss: 0.10772444328500165 acc: 0.9775254865616312
2024-10-10 20:01:38,560 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.10772444328500165}
2024-10-10 20:01:38,560 [INFO] [47] VALIDATION loss: 1.0287497322316523 VALIDATION  acc: 0.7436868686868687
2024-10-10 20:01:38,560 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.0287497322316523}
2024-10-10 20:01:38,560 [INFO] 
2024-10-10 20:02:55,791 [INFO] Step[50/144]: training loss : 0.10161920130252838 TRAIN  loss dict:  {'classification_loss': 0.10161920130252838}
2024-10-10 20:03:50,569 [INFO] Step[100/144]: training loss : 0.09692821972072124 TRAIN  loss dict:  {'classification_loss': 0.09692821972072124}
2024-10-10 20:05:28,033 [INFO] Label accuracies statistics:
2024-10-10 20:05:28,033 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.25, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.25, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 20:05:28,103 [INFO] [48] TRAIN  loss: 0.1055301167588267 acc: 0.9819277108433735
2024-10-10 20:05:28,103 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.1055301167588267}
2024-10-10 20:05:28,104 [INFO] [48] VALIDATION loss: 1.0801869614256754 VALIDATION  acc: 0.7297979797979798
2024-10-10 20:05:28,104 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.0801869614256754}
2024-10-10 20:05:28,104 [INFO] 
2024-10-10 20:06:44,952 [INFO] Step[50/144]: training loss : 0.11134299114346505 TRAIN  loss dict:  {'classification_loss': 0.11134299114346505}
2024-10-10 20:07:39,696 [INFO] Step[100/144]: training loss : 0.10727728232741356 TRAIN  loss dict:  {'classification_loss': 0.10727728232741356}
2024-10-10 20:09:16,583 [INFO] Label accuracies statistics:
2024-10-10 20:09:16,583 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 1.0, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.25, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.25, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.25, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-10 20:09:16,655 [INFO] [49] TRAIN  loss: 0.10240858256454682 acc: 0.9798424467099166
2024-10-10 20:09:16,655 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.10240858256454682}
2024-10-10 20:09:16,655 [INFO] [49] VALIDATION loss: 1.0864804607850533 VALIDATION  acc: 0.7222222222222222
2024-10-10 20:09:16,655 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.0864804607850533}
2024-10-10 20:09:16,655 [INFO] 
2024-10-10 20:10:33,248 [INFO] Step[50/144]: training loss : 0.08700141914188862 TRAIN  loss dict:  {'classification_loss': 0.08700141914188862}
2024-10-10 20:11:27,925 [INFO] Step[100/144]: training loss : 0.08628160003572702 TRAIN  loss dict:  {'classification_loss': 0.08628160003572702}
2024-10-10 20:13:04,889 [INFO] Label accuracies statistics:
2024-10-10 20:13:04,889 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 1.0, 26: 0.75, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 1.0, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 20:13:04,959 [INFO] [50] TRAIN  loss: 0.09303608522491737 acc: 0.9849397590361446
2024-10-10 20:13:04,959 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.09303608522491737}
2024-10-10 20:13:04,959 [INFO] [50] VALIDATION loss: 1.0475212893000356 VALIDATION  acc: 0.7436868686868687
2024-10-10 20:13:04,959 [INFO] [50] VALIDATION  loss dict: {'classification_loss': 1.0475212893000356}
2024-10-10 20:13:04,959 [INFO] 
2024-10-10 20:13:04,959 [INFO] 

***Stop training***


2024-10-10 20:13:04,960 [INFO] 
Testing checkpointed models starting...

2024-10-10 20:13:46,667 [INFO] Label accuracies statistics:
2024-10-10 20:13:46,668 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.25, 13: 1.0, 14: 0.5, 15: 0.25, 16: 1.0, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.75, 24: 1.0, 25: 1.0, 26: 0.5, 27: 0.75, 28: 0.5, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.25, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.25, 43: 0.75, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.75, 58: 0.5, 59: 0.5, 60: 1.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.25, 72: 1.0, 73: 0.75, 74: 1.0, 75: 0.75, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.75, 97: 0.25, 98: 1.0, 99: 0.75, 100: 1.0, 101: 0.5, 102: 1.0, 103: 0.75, 104: 0.5, 105: 0.5, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.5, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.5, 116: 0.75, 117: 0.5, 118: 0.5, 119: 0.75, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.25, 128: 1.0, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 0.5, 137: 0.75, 138: 0.25, 139: 0.5, 140: 0.25, 141: 1.0, 142: 0.5, 143: 0.25, 144: 0.5, 145: 0.25, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.5, 167: 1.0, 168: 1.0, 169: 0.25, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.25, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-10 20:13:46,731 [INFO] 
Testing accuracy: 0.683944374209861
