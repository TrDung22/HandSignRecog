2024-10-10 08:30:34,762 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention)...


2024-10-10 08:31:55,447 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention)...


2024-10-10 08:32:36,245 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention)...


2024-10-10 08:34:00,095 [INFO] Step[50/144]: training loss : 5.410210933685303 TRAIN  loss dict:  {'classification_loss': 5.410210933685303}
2024-10-10 08:34:55,608 [INFO] Step[100/144]: training loss : 4.970841865539551 TRAIN  loss dict:  {'classification_loss': 4.970841865539551}
2024-10-10 08:36:39,765 [INFO] Label accuracies statistics:
2024-10-10 08:36:39,765 [INFO] {0: 0.0, 1: 0.6666666666666666, 2: 0.25, 3: 0.75, 4: 0.0, 5: 0.25, 6: 0.5, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.0, 21: 0.25, 22: 0.0, 23: 0.75, 24: 0.5, 25: 0.0, 26: 0.0, 27: 0.0, 28: 1.0, 29: 0.75, 30: 0.0, 31: 0.5, 32: 0.25, 33: 0.25, 34: 0.25, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.25, 39: 0.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.25, 44: 0.0, 45: 0.0, 46: 0.25, 47: 0.0, 48: 0.5, 49: 0.5, 50: 0.25, 51: 0.0, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.5, 62: 0.5, 63: 0.0, 64: 0.0, 65: 0.5, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.0, 73: 0.0, 74: 0.5, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.75, 79: 0.0, 80: 0.0, 81: 0.25, 82: 0.0, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.2, 100: 0.5, 101: 0.75, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.5, 106: 0.0, 107: 0.75, 108: 0.25, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.25, 116: 0.25, 117: 0.0, 118: 0.75, 119: 0.5, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.0, 124: 0.75, 125: 0.0, 126: 0.0, 127: 0.5, 128: 0.5, 129: 0.25, 130: 0.25, 131: 0.0, 132: 0.0, 133: 0.25, 134: 1.0, 135: 0.0, 136: 0.5, 137: 0.5, 138: 0.25, 139: 0.0, 140: 0.25, 141: 0.25, 142: 0.0, 143: 0.0, 144: 1.0, 145: 0.75, 146: 0.25, 147: 0.0, 148: 0.0, 149: 0.25, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 0.25, 155: 0.0, 156: 0.0, 157: 0.25, 158: 0.0, 159: 0.75, 160: 0.0, 161: 0.25, 162: 0.25, 163: 0.0, 164: 0.5, 165: 0.0, 166: 0.0, 167: 0.25, 168: 0.0, 169: 0.25, 170: 1.0, 171: 0.75, 172: 0.5, 173: 0.5, 174: 0.25, 175: 0.25, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.5, 182: 0.0, 183: 0.25, 184: 0.0, 185: 0.75, 186: 0.0, 187: 0.5, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.25}

2024-10-10 08:36:40,232 [INFO] [1] TRAIN  loss: 4.930811824070083 acc: 0.04911955514365153
2024-10-10 08:36:40,232 [INFO] [1] TRAIN  loss dict: {'classification_loss': 4.930811824070083}
2024-10-10 08:36:40,232 [INFO] [1] VALIDATION loss: 3.676185060430456 VALIDATION  acc: 0.2159090909090909
2024-10-10 08:36:40,232 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 3.676185060430456}
2024-10-10 08:36:40,232 [INFO] 
2024-10-10 08:37:59,353 [INFO] Step[50/144]: training loss : 3.4985980415344238 TRAIN  loss dict:  {'classification_loss': 3.4985980415344238}
2024-10-10 08:38:55,336 [INFO] Step[100/144]: training loss : 2.9530247402191163 TRAIN  loss dict:  {'classification_loss': 2.9530247402191163}
2024-10-10 08:41:00,849 [INFO] Label accuracies statistics:
2024-10-10 08:41:00,849 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.25, 11: 0.75, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.6666666666666666, 16: 0.0, 17: 0.75, 18: 0.5, 19: 0.5, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.0, 29: 0.25, 30: 0.0, 31: 0.25, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.25, 37: 0.5, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.0, 42: 0.25, 43: 0.0, 44: 0.5, 45: 0.25, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.5, 50: 0.25, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.25, 64: 0.5, 65: 0.25, 66: 0.0, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.0, 71: 0.75, 72: 0.25, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.5, 78: 0.75, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.5, 87: 0.25, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.5, 99: 0.8, 100: 0.75, 101: 0.25, 102: 0.5, 103: 0.75, 104: 0.75, 105: 0.5, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.25, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.5, 116: 0.0, 117: 0.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.0, 123: 0.5, 124: 1.0, 125: 0.0, 126: 0.75, 127: 0.25, 128: 0.75, 129: 0.5, 130: 0.5, 131: 0.75, 132: 0.0, 133: 0.25, 134: 0.75, 135: 0.75, 136: 0.5, 137: 0.0, 138: 0.25, 139: 0.5, 140: 0.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.0, 145: 0.25, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.0, 154: 0.25, 155: 0.0, 156: 0.0, 157: 0.0, 158: 1.0, 159: 0.75, 160: 0.25, 161: 0.5, 162: 0.5, 163: 0.5, 164: 0.75, 165: 0.25, 166: 0.5, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.5, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.0, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.0, 191: 0.0, 192: 1.0, 193: 0.25, 194: 0.25, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.0}

2024-10-10 08:41:01,732 [INFO] [2] TRAIN  loss: 3.042305784093009 acc: 0.31533827618164967
2024-10-10 08:41:01,732 [INFO] [2] TRAIN  loss dict: {'classification_loss': 3.042305784093009}
2024-10-10 08:41:01,732 [INFO] [2] VALIDATION loss: 2.2248742712868586 VALIDATION  acc: 0.4684343434343434
2024-10-10 08:41:01,732 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 2.2248742712868586}
2024-10-10 08:41:01,733 [INFO] 
2024-10-10 08:42:38,437 [INFO] Step[50/144]: training loss : 2.040004813671112 TRAIN  loss dict:  {'classification_loss': 2.040004813671112}
2024-10-10 08:43:49,673 [INFO] Step[100/144]: training loss : 1.9347820711135864 TRAIN  loss dict:  {'classification_loss': 1.9347820711135864}
2024-10-10 08:45:56,034 [INFO] Label accuracies statistics:
2024-10-10 08:45:56,034 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.0, 13: 0.5, 14: 0.75, 15: 0.0, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.25, 27: 0.5, 28: 0.5, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.25, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.25, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.0, 108: 1.0, 109: 0.25, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 0.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.5, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.5, 134: 0.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 0.75, 155: 1.0, 156: 0.0, 157: 0.5, 158: 1.0, 159: 0.5, 160: 0.25, 161: 0.5, 162: 0.25, 163: 0.5, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.5, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.5, 187: 0.75, 188: 0.0, 189: 0.75, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.25, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-10 08:45:56,921 [INFO] [3] TRAIN  loss: 1.9047166009744008 acc: 0.5391566265060241
2024-10-10 08:45:56,921 [INFO] [3] TRAIN  loss dict: {'classification_loss': 1.9047166009744008}
2024-10-10 08:45:56,922 [INFO] [3] VALIDATION loss: 1.6144780295866508 VALIDATION  acc: 0.6111111111111112
2024-10-10 08:45:56,922 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 1.6144780295866508}
2024-10-10 08:45:56,922 [INFO] 
2024-10-10 08:47:34,811 [INFO] Step[50/144]: training loss : 1.4110135650634765 TRAIN  loss dict:  {'classification_loss': 1.4110135650634765}
2024-10-10 08:48:45,708 [INFO] Step[100/144]: training loss : 1.2866605281829835 TRAIN  loss dict:  {'classification_loss': 1.2866605281829835}
2024-10-10 08:50:53,698 [INFO] Label accuracies statistics:
2024-10-10 08:50:53,698 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.0, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.25, 25: 0.5, 26: 0.75, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.0, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.5, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.25, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.0, 89: 0.5, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.5, 142: 0.75, 143: 0.25, 144: 0.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.5, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.5, 163: 0.75, 164: 0.25, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 0.75, 188: 0.0, 189: 0.5, 190: 0.5, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 08:50:54,596 [INFO] [4] TRAIN  loss: 1.313487378673421 acc: 0.6758572752548656
2024-10-10 08:50:54,596 [INFO] [4] TRAIN  loss dict: {'classification_loss': 1.313487378673421}
2024-10-10 08:50:54,597 [INFO] [4] VALIDATION loss: 1.3251450150101274 VALIDATION  acc: 0.6578282828282829
2024-10-10 08:50:54,597 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 1.3251450150101274}
2024-10-10 08:50:54,597 [INFO] 
2024-10-10 08:52:31,386 [INFO] Step[50/144]: training loss : 1.0026499688625337 TRAIN  loss dict:  {'classification_loss': 1.0026499688625337}
2024-10-10 08:53:43,812 [INFO] Step[100/144]: training loss : 0.9760133516788483 TRAIN  loss dict:  {'classification_loss': 0.9760133516788483}
2024-10-10 08:55:50,938 [INFO] Label accuracies statistics:
2024-10-10 08:55:50,938 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.0, 13: 0.0, 14: 0.75, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.25, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.0, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.75, 86: 1.0, 87: 1.0, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 0.75, 132: 0.25, 133: 1.0, 134: 0.5, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 0.75, 155: 1.0, 156: 1.0, 157: 0.25, 158: 1.0, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.25, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.5}

2024-10-10 08:55:51,865 [INFO] [5] TRAIN  loss: 0.9872789084911346 acc: 0.7599629286376274
2024-10-10 08:55:51,865 [INFO] [5] TRAIN  loss dict: {'classification_loss': 0.9872789084911346}
2024-10-10 08:55:51,865 [INFO] [5] VALIDATION loss: 1.210374312820258 VALIDATION  acc: 0.6906565656565656
2024-10-10 08:55:51,865 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 1.210374312820258}
2024-10-10 08:55:51,865 [INFO] 
2024-10-10 08:57:29,734 [INFO] Step[50/144]: training loss : 0.7115255618095397 TRAIN  loss dict:  {'classification_loss': 0.7115255618095397}
2024-10-10 08:58:42,161 [INFO] Step[100/144]: training loss : 0.8240481728315353 TRAIN  loss dict:  {'classification_loss': 0.8240481728315353}
2024-10-10 09:00:50,461 [INFO] Label accuracies statistics:
2024-10-10 09:00:50,461 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.0, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.25, 62: 0.75, 63: 0.25, 64: 0.25, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.25, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.0, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 09:00:51,414 [INFO] [6] TRAIN  loss: 0.7799670957028866 acc: 0.8032900834105653
2024-10-10 09:00:51,414 [INFO] [6] TRAIN  loss dict: {'classification_loss': 0.7799670957028866}
2024-10-10 09:00:51,414 [INFO] [6] VALIDATION loss: 1.1656344229424442 VALIDATION  acc: 0.6843434343434344
2024-10-10 09:00:51,414 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 1.1656344229424442}
2024-10-10 09:00:51,414 [INFO] 
2024-10-10 09:02:28,136 [INFO] Step[50/144]: training loss : 0.6073531317710876 TRAIN  loss dict:  {'classification_loss': 0.6073531317710876}
2024-10-10 09:03:39,666 [INFO] Step[100/144]: training loss : 0.645708766579628 TRAIN  loss dict:  {'classification_loss': 0.645708766579628}
2024-10-10 09:05:48,524 [INFO] Label accuracies statistics:
2024-10-10 09:05:48,524 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.25, 14: 0.75, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.25, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 0.75, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.5, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.25, 133: 0.5, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 0.75, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.25, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.5, 198: 1.0}

2024-10-10 09:05:49,378 [INFO] [7] TRAIN  loss: 0.6231169195638763 acc: 0.8412882298424467
2024-10-10 09:05:49,378 [INFO] [7] TRAIN  loss dict: {'classification_loss': 0.6231169195638763}
2024-10-10 09:05:49,378 [INFO] [7] VALIDATION loss: 1.0406325790617201 VALIDATION  acc: 0.73989898989899
2024-10-10 09:05:49,378 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.0406325790617201}
2024-10-10 09:05:49,378 [INFO] 
2024-10-10 09:07:25,702 [INFO] Step[50/144]: training loss : 0.5070118010044098 TRAIN  loss dict:  {'classification_loss': 0.5070118010044098}
2024-10-10 09:08:36,337 [INFO] Step[100/144]: training loss : 0.494200747013092 TRAIN  loss dict:  {'classification_loss': 0.494200747013092}
2024-10-10 09:10:46,631 [INFO] Label accuracies statistics:
2024-10-10 09:10:46,631 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.25, 17: 0.75, 18: 0.5, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 0.75, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.75, 86: 1.0, 87: 1.0, 88: 0.5, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.5, 166: 1.0, 167: 1.0, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.25, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 09:10:47,516 [INFO] [8] TRAIN  loss: 0.514043344805638 acc: 0.8651529193697869
2024-10-10 09:10:47,516 [INFO] [8] TRAIN  loss dict: {'classification_loss': 0.514043344805638}
2024-10-10 09:10:47,516 [INFO] [8] VALIDATION loss: 0.9632978665607946 VALIDATION  acc: 0.7348484848484849
2024-10-10 09:10:47,516 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 0.9632978665607946}
2024-10-10 09:10:47,516 [INFO] 
2024-10-10 09:12:24,521 [INFO] Step[50/144]: training loss : 0.38313938677310944 TRAIN  loss dict:  {'classification_loss': 0.38313938677310944}
2024-10-10 09:13:35,192 [INFO] Step[100/144]: training loss : 0.4267705526947975 TRAIN  loss dict:  {'classification_loss': 0.4267705526947975}
2024-10-10 09:15:45,200 [INFO] Label accuracies statistics:
2024-10-10 09:15:45,200 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 09:15:45,286 [INFO] [9] TRAIN  loss: 0.4365748396764199 acc: 0.8860055607043559
2024-10-10 09:15:45,286 [INFO] [9] TRAIN  loss dict: {'classification_loss': 0.4365748396764199}
2024-10-10 09:15:45,286 [INFO] [9] VALIDATION loss: 0.9764214489195082 VALIDATION  acc: 0.7436868686868687
2024-10-10 09:15:45,286 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 0.9764214489195082}
2024-10-10 09:15:45,286 [INFO] 
2024-10-10 09:17:22,508 [INFO] Step[50/144]: training loss : 0.377118498980999 TRAIN  loss dict:  {'classification_loss': 0.377118498980999}
2024-10-10 09:18:34,509 [INFO] Step[100/144]: training loss : 0.38402045637369153 TRAIN  loss dict:  {'classification_loss': 0.38402045637369153}
2024-10-10 09:20:45,234 [INFO] Label accuracies statistics:
2024-10-10 09:20:45,235 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 0.75, 47: 0.25, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.25, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 0.75, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.25, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 0.75, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.25, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 09:20:45,318 [INFO] [10] TRAIN  loss: 0.37811738350946045 acc: 0.8968952734012975
2024-10-10 09:20:45,318 [INFO] [10] TRAIN  loss dict: {'classification_loss': 0.37811738350946045}
2024-10-10 09:20:45,318 [INFO] [10] VALIDATION loss: 0.9669820663553698 VALIDATION  acc: 0.73989898989899
2024-10-10 09:20:45,318 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 0.9669820663553698}
2024-10-10 09:20:45,318 [INFO] 
2024-10-10 09:22:23,596 [INFO] Step[50/144]: training loss : 0.25395799666643143 TRAIN  loss dict:  {'classification_loss': 0.25395799666643143}
2024-10-10 09:23:34,882 [INFO] Step[100/144]: training loss : 0.3107695128023624 TRAIN  loss dict:  {'classification_loss': 0.3107695128023624}
2024-10-10 09:25:44,380 [INFO] Label accuracies statistics:
2024-10-10 09:25:44,380 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.25, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 0.5, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.75, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 1.0, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-10 09:25:45,267 [INFO] [11] TRAIN  loss: 0.2977272909031146 acc: 0.9193697868396663
2024-10-10 09:25:45,267 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.2977272909031146}
2024-10-10 09:25:45,268 [INFO] [11] VALIDATION loss: 0.9294847832233818 VALIDATION  acc: 0.7373737373737373
2024-10-10 09:25:45,268 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 0.9294847832233818}
2024-10-10 09:25:45,268 [INFO] 
2024-10-10 09:27:24,011 [INFO] Step[50/144]: training loss : 0.22593076258897782 TRAIN  loss dict:  {'classification_loss': 0.22593076258897782}
2024-10-10 09:28:33,345 [INFO] Step[100/144]: training loss : 0.24572408348321914 TRAIN  loss dict:  {'classification_loss': 0.24572408348321914}
2024-10-10 09:30:41,438 [INFO] Label accuracies statistics:
2024-10-10 09:30:41,439 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 1.0, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 1.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.5, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 09:30:42,354 [INFO] [12] TRAIN  loss: 0.25078127693591845 acc: 0.932808155699722
2024-10-10 09:30:42,354 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.25078127693591845}
2024-10-10 09:30:42,354 [INFO] [12] VALIDATION loss: 0.8750604782943372 VALIDATION  acc: 0.7828282828282829
2024-10-10 09:30:42,354 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 0.8750604782943372}
2024-10-10 09:30:42,354 [INFO] 
2024-10-10 09:32:22,168 [INFO] Step[50/144]: training loss : 0.21337314188480377 TRAIN  loss dict:  {'classification_loss': 0.21337314188480377}
2024-10-10 09:33:29,289 [INFO] Step[100/144]: training loss : 0.24505668595433236 TRAIN  loss dict:  {'classification_loss': 0.24505668595433236}
2024-10-10 09:35:40,334 [INFO] Label accuracies statistics:
2024-10-10 09:35:40,334 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 1.0, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.5}

2024-10-10 09:35:40,422 [INFO] [13] TRAIN  loss: 0.22931781312864688 acc: 0.9399907321594069
2024-10-10 09:35:40,422 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.22931781312864688}
2024-10-10 09:35:40,422 [INFO] [13] VALIDATION loss: 0.9422955214977264 VALIDATION  acc: 0.7575757575757576
2024-10-10 09:35:40,422 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 0.9422955214977264}
2024-10-10 09:35:40,422 [INFO] 
2024-10-10 09:37:20,910 [INFO] Step[50/144]: training loss : 0.2007901581376791 TRAIN  loss dict:  {'classification_loss': 0.2007901581376791}
2024-10-10 09:38:27,195 [INFO] Step[100/144]: training loss : 0.21973974198102952 TRAIN  loss dict:  {'classification_loss': 0.21973974198102952}
2024-10-10 09:40:38,200 [INFO] Label accuracies statistics:
2024-10-10 09:40:38,200 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.75, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 0.75, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 1.0, 177: 1.0, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 09:40:39,053 [INFO] [14] TRAIN  loss: 0.2130469629385819 acc: 0.9404541241890639
2024-10-10 09:40:39,053 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.2130469629385819}
2024-10-10 09:40:39,053 [INFO] [14] VALIDATION loss: 0.8652024314635329 VALIDATION  acc: 0.7651515151515151
2024-10-10 09:40:39,053 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 0.8652024314635329}
2024-10-10 09:40:39,053 [INFO] 
2024-10-10 09:42:29,449 [INFO] Step[50/144]: training loss : 0.1880284869670868 TRAIN  loss dict:  {'classification_loss': 0.1880284869670868}
2024-10-10 09:43:33,634 [INFO] Step[100/144]: training loss : 0.1749991898238659 TRAIN  loss dict:  {'classification_loss': 0.1749991898238659}
2024-10-10 09:45:43,242 [INFO] Label accuracies statistics:
2024-10-10 09:45:43,242 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.5, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 0.5, 142: 0.5, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 1.0, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 09:45:43,331 [INFO] [15] TRAIN  loss: 0.18446097021094626 acc: 0.9545875810936052
2024-10-10 09:45:43,331 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.18446097021094626}
2024-10-10 09:45:43,331 [INFO] [15] VALIDATION loss: 0.9233952575811634 VALIDATION  acc: 0.7487373737373737
2024-10-10 09:45:43,331 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 0.9233952575811634}
2024-10-10 09:45:43,331 [INFO] 
2024-10-10 09:47:28,840 [INFO] Step[50/144]: training loss : 0.15621702156960965 TRAIN  loss dict:  {'classification_loss': 0.15621702156960965}
2024-10-10 09:48:32,567 [INFO] Step[100/144]: training loss : 0.16794010140001775 TRAIN  loss dict:  {'classification_loss': 0.16794010140001775}
2024-10-10 09:50:43,497 [INFO] Label accuracies statistics:
2024-10-10 09:50:43,497 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 1.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 09:50:43,583 [INFO] [16] TRAIN  loss: 0.15874719862929648 acc: 0.9589898053753475
2024-10-10 09:50:43,583 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.15874719862929648}
2024-10-10 09:50:43,584 [INFO] [16] VALIDATION loss: 0.9208768214340564 VALIDATION  acc: 0.7525252525252525
2024-10-10 09:50:43,584 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 0.9208768214340564}
2024-10-10 09:50:43,584 [INFO] 
2024-10-10 09:52:27,726 [INFO] Step[50/144]: training loss : 0.1282549346983433 TRAIN  loss dict:  {'classification_loss': 0.1282549346983433}
2024-10-10 09:53:33,348 [INFO] Step[100/144]: training loss : 0.1669083319604397 TRAIN  loss dict:  {'classification_loss': 0.1669083319604397}
2024-10-10 09:55:42,540 [INFO] Label accuracies statistics:
2024-10-10 09:55:42,540 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 1.0, 7: 0.25, 8: 0.75, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.0, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 1.0, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.0, 115: 0.75, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.25, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.5, 166: 1.0, 167: 1.0, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 09:55:43,431 [INFO] [17] TRAIN  loss: 0.15720312871659795 acc: 0.9543558850787767
2024-10-10 09:55:43,432 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.15720312871659795}
2024-10-10 09:55:43,432 [INFO] [17] VALIDATION loss: 0.7986914123649951 VALIDATION  acc: 0.7967171717171717
2024-10-10 09:55:43,432 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 0.7986914123649951}
2024-10-10 09:55:43,432 [INFO] 
2024-10-10 09:57:27,267 [INFO] Step[50/144]: training loss : 0.11897313512861729 TRAIN  loss dict:  {'classification_loss': 0.11897313512861729}
2024-10-10 09:58:31,447 [INFO] Step[100/144]: training loss : 0.15633167296648026 TRAIN  loss dict:  {'classification_loss': 0.15633167296648026}
2024-10-10 10:00:40,029 [INFO] Label accuracies statistics:
2024-10-10 10:00:40,029 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 0.75, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 1.0, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.0, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 0.75, 76: 1.0, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.0, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.75, 154: 0.75, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.75, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 10:00:40,119 [INFO] [18] TRAIN  loss: 0.14567431724733776 acc: 0.9622335495829472
2024-10-10 10:00:40,119 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.14567431724733776}
2024-10-10 10:00:40,119 [INFO] [18] VALIDATION loss: 0.9083990760975413 VALIDATION  acc: 0.7651515151515151
2024-10-10 10:00:40,119 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 0.9083990760975413}
2024-10-10 10:00:40,119 [INFO] 
2024-10-10 10:02:22,757 [INFO] Step[50/144]: training loss : 0.13013701014220713 TRAIN  loss dict:  {'classification_loss': 0.13013701014220713}
2024-10-10 10:03:27,595 [INFO] Step[100/144]: training loss : 0.14018322821706533 TRAIN  loss dict:  {'classification_loss': 0.14018322821706533}
2024-10-10 10:05:37,964 [INFO] Label accuracies statistics:
2024-10-10 10:05:37,965 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.25, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 1.0, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.75, 122: 1.0, 123: 0.75, 124: 0.5, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 1.0, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.5, 196: 0.25, 197: 0.75, 198: 0.75}

2024-10-10 10:05:38,045 [INFO] [19] TRAIN  loss: 0.13955927451348138 acc: 0.9617701575532901
2024-10-10 10:05:38,045 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.13955927451348138}
2024-10-10 10:05:38,045 [INFO] [19] VALIDATION loss: 1.0411976139854502 VALIDATION  acc: 0.7348484848484849
2024-10-10 10:05:38,045 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.0411976139854502}
2024-10-10 10:05:38,045 [INFO] 
2024-10-10 10:07:21,695 [INFO] Step[50/144]: training loss : 0.1354756212979555 TRAIN  loss dict:  {'classification_loss': 0.1354756212979555}
2024-10-10 10:08:25,247 [INFO] Step[100/144]: training loss : 0.13540972258895637 TRAIN  loss dict:  {'classification_loss': 0.13540972258895637}
2024-10-10 10:10:35,736 [INFO] Label accuracies statistics:
2024-10-10 10:10:35,736 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.25, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 0.5, 45: 0.25, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.5, 90: 1.0, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 0.5, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.75, 155: 0.75, 156: 1.0, 157: 1.0, 158: 1.0, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.5, 181: 1.0, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 10:10:35,827 [INFO] [20] TRAIN  loss: 0.13658832723740488 acc: 0.9622335495829472
2024-10-10 10:10:35,827 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.13658832723740488}
2024-10-10 10:10:35,827 [INFO] [20] VALIDATION loss: 0.9377635282774767 VALIDATION  acc: 0.7588383838383839
2024-10-10 10:10:35,827 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 0.9377635282774767}
2024-10-10 10:10:35,828 [INFO] 
2024-10-10 10:12:17,911 [INFO] Step[50/144]: training loss : 0.10955321062356234 TRAIN  loss dict:  {'classification_loss': 0.10955321062356234}
2024-10-10 10:13:23,209 [INFO] Step[100/144]: training loss : 0.10917966123670339 TRAIN  loss dict:  {'classification_loss': 0.10917966123670339}
2024-10-10 10:15:33,411 [INFO] Label accuracies statistics:
2024-10-10 10:15:33,411 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 1.0, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.5, 87: 1.0, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 0.5, 135: 0.75, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 10:15:33,494 [INFO] [21] TRAIN  loss: 0.1072088027269476 acc: 0.9703429101019463
2024-10-10 10:15:33,494 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.1072088027269476}
2024-10-10 10:15:33,494 [INFO] [21] VALIDATION loss: 0.9105776981623085 VALIDATION  acc: 0.7638888888888888
2024-10-10 10:15:33,494 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 0.9105776981623085}
2024-10-10 10:15:33,495 [INFO] 
2024-10-10 10:17:16,678 [INFO] Step[50/144]: training loss : 0.09656160365790128 TRAIN  loss dict:  {'classification_loss': 0.09656160365790128}
2024-10-10 10:18:22,222 [INFO] Step[100/144]: training loss : 0.11408430874347687 TRAIN  loss dict:  {'classification_loss': 0.11408430874347687}
2024-10-10 10:20:32,482 [INFO] Label accuracies statistics:
2024-10-10 10:20:32,482 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 1.0, 19: 0.0, 20: 1.0, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.0, 89: 0.5, 90: 1.0, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 1.0, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.5, 198: 1.0}

2024-10-10 10:20:32,550 [INFO] [22] TRAIN  loss: 0.10094295654238926 acc: 0.974050046339203
2024-10-10 10:20:32,550 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.10094295654238926}
2024-10-10 10:20:32,550 [INFO] [22] VALIDATION loss: 0.9378582119803738 VALIDATION  acc: 0.7664141414141414
2024-10-10 10:20:32,551 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 0.9378582119803738}
2024-10-10 10:20:32,551 [INFO] 
2024-10-10 10:22:18,268 [INFO] Step[50/144]: training loss : 0.09125486601144076 TRAIN  loss dict:  {'classification_loss': 0.09125486601144076}
2024-10-10 10:23:25,464 [INFO] Step[100/144]: training loss : 0.09448753274977208 TRAIN  loss dict:  {'classification_loss': 0.09448753274977208}
2024-10-10 10:25:34,012 [INFO] Label accuracies statistics:
2024-10-10 10:25:34,012 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.25, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 1.0, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 0.75, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.25, 120: 0.5, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 0.75, 142: 1.0, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.75, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 10:25:34,097 [INFO] [23] TRAIN  loss: 0.09273862853620408 acc: 0.9756719184430028
2024-10-10 10:25:34,097 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.09273862853620408}
2024-10-10 10:25:34,097 [INFO] [23] VALIDATION loss: 0.9041983448658828 VALIDATION  acc: 0.7765151515151515
2024-10-10 10:25:34,097 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 0.9041983448658828}
2024-10-10 10:25:34,098 [INFO] 
2024-10-10 10:27:21,967 [INFO] Step[50/144]: training loss : 0.08292627479881048 TRAIN  loss dict:  {'classification_loss': 0.08292627479881048}
2024-10-10 10:28:27,793 [INFO] Step[100/144]: training loss : 0.10287787567824125 TRAIN  loss dict:  {'classification_loss': 0.10287787567824125}
2024-10-10 10:30:33,564 [INFO] Label accuracies statistics:
2024-10-10 10:30:33,564 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 0.75, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 10:30:33,659 [INFO] [24] TRAIN  loss: 0.09066287825246239 acc: 0.9756719184430028
2024-10-10 10:30:33,659 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.09066287825246239}
2024-10-10 10:30:33,659 [INFO] [24] VALIDATION loss: 0.8887169999587867 VALIDATION  acc: 0.7676767676767676
2024-10-10 10:30:33,659 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 0.8887169999587867}
2024-10-10 10:30:33,659 [INFO] 
2024-10-10 10:32:20,284 [INFO] Step[50/144]: training loss : 0.08939091999083758 TRAIN  loss dict:  {'classification_loss': 0.08939091999083758}
2024-10-10 10:33:26,469 [INFO] Step[100/144]: training loss : 0.0856969826668501 TRAIN  loss dict:  {'classification_loss': 0.0856969826668501}
2024-10-10 10:35:29,875 [INFO] Label accuracies statistics:
2024-10-10 10:35:29,875 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 0.75, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 0.75, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 10:35:29,965 [INFO] [25] TRAIN  loss: 0.09247593576502469 acc: 0.974050046339203
2024-10-10 10:35:29,966 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.09247593576502469}
2024-10-10 10:35:29,966 [INFO] [25] VALIDATION loss: 1.015413793079831 VALIDATION  acc: 0.7449494949494949
2024-10-10 10:35:29,966 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.015413793079831}
2024-10-10 10:35:29,966 [INFO] 
2024-10-10 10:37:13,771 [INFO] Step[50/144]: training loss : 0.06717729806900025 TRAIN  loss dict:  {'classification_loss': 0.06717729806900025}
2024-10-10 10:38:18,206 [INFO] Step[100/144]: training loss : 0.08079826642759144 TRAIN  loss dict:  {'classification_loss': 0.08079826642759144}
2024-10-10 10:40:24,080 [INFO] Label accuracies statistics:
2024-10-10 10:40:24,080 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.5, 7: 0.5, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 0.75, 155: 1.0, 156: 1.0, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 10:40:24,169 [INFO] [26] TRAIN  loss: 0.07366287914272915 acc: 0.9819277108433735
2024-10-10 10:40:24,169 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.07366287914272915}
2024-10-10 10:40:24,169 [INFO] [26] VALIDATION loss: 0.9294984440008799 VALIDATION  acc: 0.76010101010101
2024-10-10 10:40:24,169 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 0.9294984440008799}
2024-10-10 10:40:24,169 [INFO] 
2024-10-10 10:42:10,947 [INFO] Step[50/144]: training loss : 0.07599717170000077 TRAIN  loss dict:  {'classification_loss': 0.07599717170000077}
2024-10-10 10:43:16,797 [INFO] Step[100/144]: training loss : 0.07841800883412361 TRAIN  loss dict:  {'classification_loss': 0.07841800883412361}
2024-10-10 10:45:23,514 [INFO] Label accuracies statistics:
2024-10-10 10:45:23,514 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.75, 70: 1.0, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 10:45:23,617 [INFO] [27] TRAIN  loss: 0.08133171928218669 acc: 0.9779888785912882
2024-10-10 10:45:23,617 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.08133171928218669}
2024-10-10 10:45:23,617 [INFO] [27] VALIDATION loss: 0.9591656990901187 VALIDATION  acc: 0.7638888888888888
2024-10-10 10:45:23,617 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 0.9591656990901187}
2024-10-10 10:45:23,617 [INFO] 
2024-10-10 10:47:10,469 [INFO] Step[50/144]: training loss : 0.05773285079747439 TRAIN  loss dict:  {'classification_loss': 0.05773285079747439}
2024-10-10 10:48:17,526 [INFO] Step[100/144]: training loss : 0.07294790519401431 TRAIN  loss dict:  {'classification_loss': 0.07294790519401431}
2024-10-10 10:50:21,635 [INFO] Label accuracies statistics:
2024-10-10 10:50:21,635 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 1.0, 7: 0.25, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.5, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 1.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.0, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 10:50:21,711 [INFO] [28] TRAIN  loss: 0.0716733903455962 acc: 0.9803058387395737
2024-10-10 10:50:21,711 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.0716733903455962}
2024-10-10 10:50:21,711 [INFO] [28] VALIDATION loss: 0.9398274788701976 VALIDATION  acc: 0.7588383838383839
2024-10-10 10:50:21,711 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 0.9398274788701976}
2024-10-10 10:50:21,711 [INFO] 
2024-10-10 10:52:16,746 [INFO] Step[50/144]: training loss : 0.07795008435845376 TRAIN  loss dict:  {'classification_loss': 0.07795008435845376}
2024-10-10 10:53:23,692 [INFO] Step[100/144]: training loss : 0.07844081560149789 TRAIN  loss dict:  {'classification_loss': 0.07844081560149789}
2024-10-10 10:55:25,210 [INFO] Label accuracies statistics:
2024-10-10 10:55:25,210 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 1.0, 7: 0.5, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 1.0, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.25, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.75, 115: 0.75, 116: 0.5, 117: 0.5, 118: 0.75, 119: 0.75, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 10:55:25,314 [INFO] [29] TRAIN  loss: 0.07600558677869332 acc: 0.9784522706209453
2024-10-10 10:55:25,314 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.07600558677869332}
2024-10-10 10:55:25,314 [INFO] [29] VALIDATION loss: 1.0561452046450641 VALIDATION  acc: 0.7361111111111112
2024-10-10 10:55:25,314 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.0561452046450641}
2024-10-10 10:55:25,314 [INFO] 
2024-10-10 10:57:17,122 [INFO] Step[50/144]: training loss : 0.05362570468336344 TRAIN  loss dict:  {'classification_loss': 0.05362570468336344}
2024-10-10 10:58:23,486 [INFO] Step[100/144]: training loss : 0.06584635382518172 TRAIN  loss dict:  {'classification_loss': 0.06584635382518172}
2024-10-10 11:00:26,123 [INFO] Label accuracies statistics:
2024-10-10 11:00:26,123 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.25, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 1.0, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 11:00:26,218 [INFO] [30] TRAIN  loss: 0.06024872434661827 acc: 0.9835495829471733
2024-10-10 11:00:26,218 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.06024872434661827}
2024-10-10 11:00:26,218 [INFO] [30] VALIDATION loss: 0.9779709531684164 VALIDATION  acc: 0.7613636363636364
2024-10-10 11:00:26,218 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 0.9779709531684164}
2024-10-10 11:00:26,218 [INFO] 
2024-10-10 11:02:13,362 [INFO] Step[50/144]: training loss : 0.06267181395553052 TRAIN  loss dict:  {'classification_loss': 0.06267181395553052}
2024-10-10 11:03:20,201 [INFO] Step[100/144]: training loss : 0.07014185348525644 TRAIN  loss dict:  {'classification_loss': 0.07014185348525644}
2024-10-10 11:05:23,553 [INFO] Label accuracies statistics:
2024-10-10 11:05:23,554 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 1.0, 7: 0.5, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.5, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 0.75, 119: 0.75, 120: 0.75, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 1.0, 174: 0.75, 175: 0.75, 176: 1.0, 177: 1.0, 178: 0.5, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-10 11:05:23,649 [INFO] [31] TRAIN  loss: 0.06673400341080399 acc: 0.9812326227988879
2024-10-10 11:05:23,649 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.06673400341080399}
2024-10-10 11:05:23,649 [INFO] [31] VALIDATION loss: 0.9498800177954965 VALIDATION  acc: 0.7626262626262627
2024-10-10 11:05:23,650 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 0.9498800177954965}
2024-10-10 11:05:23,650 [INFO] 
2024-10-10 11:07:10,089 [INFO] Step[50/144]: training loss : 0.052884361064061525 TRAIN  loss dict:  {'classification_loss': 0.052884361064061525}
2024-10-10 11:08:16,353 [INFO] Step[100/144]: training loss : 0.04841832867823541 TRAIN  loss dict:  {'classification_loss': 0.04841832867823541}
2024-10-10 11:10:17,750 [INFO] Label accuracies statistics:
2024-10-10 11:10:17,750 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 1.0, 7: 0.25, 8: 0.25, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 11:10:17,837 [INFO] [32] TRAIN  loss: 0.05224233877379447 acc: 0.9886468952734013
2024-10-10 11:10:17,837 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.05224233877379447}
2024-10-10 11:10:17,837 [INFO] [32] VALIDATION loss: 0.9031011400813306 VALIDATION  acc: 0.773989898989899
2024-10-10 11:10:17,837 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 0.9031011400813306}
2024-10-10 11:10:17,837 [INFO] 
2024-10-10 11:10:17,838 [INFO] 

***Stop training***


2024-10-10 11:10:17,838 [INFO] 
Testing checkpointed models starting...

2024-10-10 11:11:26,997 [INFO] Label accuracies statistics:
2024-10-10 11:11:26,997 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.5, 14: 0.75, 15: 0.0, 16: 1.0, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 1.0, 23: 1.0, 24: 1.0, 25: 1.0, 26: 0.75, 27: 1.0, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.75, 44: 1.0, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 1.0, 50: 1.0, 51: 1.0, 52: 0.5, 53: 0.75, 54: 0.5, 55: 1.0, 56: 0.5, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 1.0, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.5, 77: 1.0, 78: 1.0, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 1.0, 85: 0.75, 86: 0.25, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.5, 103: 0.25, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.25, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.75, 114: 0.0, 115: 0.75, 116: 0.5, 117: 0.25, 118: 0.75, 119: 0.75, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.25, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 0.75, 150: 1.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.5, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 0.5, 167: 1.0, 168: 0.25, 169: 0.25, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.5, 184: 0.0, 185: 1.0, 186: 1.0, 187: 0.75, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.5, 198: 1.0}

2024-10-10 11:11:27,070 [INFO] 
Testing accuracy: 0.7711757269279393
