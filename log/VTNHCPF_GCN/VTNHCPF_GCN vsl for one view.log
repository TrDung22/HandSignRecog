2024-10-08 08:30:37,738 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:33:57,543 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:36:09,751 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:37:03,091 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:40:12,882 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:44:00,097 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:45:59,060 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:50:08,637 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:53:40,358 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:55:18,447 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 08:58:05,320 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:19:58,361 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:23:42,028 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:27:32,374 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:29:17,243 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:30:10,244 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:31:00,452 [INFO] Step[50/240]: training loss : 6.440857515335083 TRAIN  loss dict:  {'classification_loss': 6.440857515335083}
2024-10-08 09:31:33,363 [INFO] Step[100/240]: training loss : 5.683508834838867 TRAIN  loss dict:  {'classification_loss': 5.683508834838867}
2024-10-08 09:32:06,213 [INFO] Step[150/240]: training loss : 5.52670838356018 TRAIN  loss dict:  {'classification_loss': 5.52670838356018}
2024-10-08 09:32:39,180 [INFO] Step[200/240]: training loss : 5.419162530899047 TRAIN  loss dict:  {'classification_loss': 5.419162530899047}
2024-10-08 09:33:44,951 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:35:01,289 [INFO] Step[50/155]: training loss : 6.431291522979737 TRAIN  loss dict:  {'classification_loss': 6.431291522979737}
2024-10-08 09:35:58,101 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:38:19,138 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:40:56,203 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:44:09,920 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:46:24,155 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 09:47:45,307 [INFO] Step[50/144]: training loss : 6.382305049896241 TRAIN  loss dict:  {'classification_loss': 6.382305049896241}
2024-10-08 09:48:39,205 [INFO] Step[100/144]: training loss : 5.646272916793823 TRAIN  loss dict:  {'classification_loss': 5.646272916793823}
2024-10-08 09:50:21,081 [INFO] Label accuracies statistics:
2024-10-08 09:50:21,081 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.25, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.25, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 09:50:21,461 [INFO] [1] TRAIN  loss: 5.843629108534919 acc: 0.004633920296570899
2024-10-08 09:50:21,462 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.843629108534919}
2024-10-08 09:50:21,462 [INFO] [1] VALIDATION loss: 5.3364837787769455 VALIDATION  acc: 0.005050505050505051
2024-10-08 09:50:21,462 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.3364837787769455}
2024-10-08 09:50:21,462 [INFO] 
2024-10-08 09:51:38,823 [INFO] Step[50/144]: training loss : 5.3255103492736815 TRAIN  loss dict:  {'classification_loss': 5.3255103492736815}
2024-10-08 09:52:33,085 [INFO] Step[100/144]: training loss : 5.291031045913696 TRAIN  loss dict:  {'classification_loss': 5.291031045913696}
2024-10-08 09:54:24,539 [INFO] Label accuracies statistics:
2024-10-08 09:54:24,540 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.25, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.25, 30: 0.5, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.25, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.25, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.25, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.25, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.25, 136: 0.0, 137: 0.75, 138: 0.25, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.25, 144: 0.0, 145: 0.25, 146: 0.25, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.25, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 09:54:25,161 [INFO] [2] TRAIN  loss: 5.276541617181566 acc: 0.010889712696941613
2024-10-08 09:54:25,161 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.276541617181566}
2024-10-08 09:54:25,161 [INFO] [2] VALIDATION loss: 5.075551015359384 VALIDATION  acc: 0.02904040404040404
2024-10-08 09:54:25,161 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 5.075551015359384}
2024-10-08 09:54:25,162 [INFO] 
2024-10-08 09:55:42,120 [INFO] Step[50/144]: training loss : 4.992359972000122 TRAIN  loss dict:  {'classification_loss': 4.992359972000122}
2024-10-08 09:56:36,641 [INFO] Step[100/144]: training loss : 4.868199605941772 TRAIN  loss dict:  {'classification_loss': 4.868199605941772}
2024-10-08 09:58:13,539 [INFO] Label accuracies statistics:
2024-10-08 09:58:13,539 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.5, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.5, 8: 0.0, 9: 0.25, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.25, 30: 0.25, 31: 0.25, 32: 0.0, 33: 0.0, 34: 0.25, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.25, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.75, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.5, 81: 0.0, 82: 0.5, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.5, 106: 0.75, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.25, 128: 1.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 1.0, 135: 0.0, 136: 0.0, 137: 0.5, 138: 0.25, 139: 0.0, 140: 0.0, 141: 0.5, 142: 0.0, 143: 1.0, 144: 0.25, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.25, 151: 0.5, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.5, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.75, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.5, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.5, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.5, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-08 09:58:14,161 [INFO] [3] TRAIN  loss: 4.854540503687328 acc: 0.023169601482854494
2024-10-08 09:58:14,161 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.854540503687328}
2024-10-08 09:58:14,161 [INFO] [3] VALIDATION loss: 4.59045508172777 VALIDATION  acc: 0.07575757575757576
2024-10-08 09:58:14,161 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.59045508172777}
2024-10-08 09:58:14,162 [INFO] 
2024-10-08 09:59:31,194 [INFO] Step[50/144]: training loss : 4.3471930932998655 TRAIN  loss dict:  {'classification_loss': 4.3471930932998655}
2024-10-08 10:00:25,439 [INFO] Step[100/144]: training loss : 4.17441734790802 TRAIN  loss dict:  {'classification_loss': 4.17441734790802}
2024-10-08 10:02:02,071 [INFO] Label accuracies statistics:
2024-10-08 10:02:02,071 [INFO] {0: 0.0, 1: 0.6666666666666666, 2: 0.0, 3: 0.25, 4: 0.25, 5: 0.25, 6: 0.25, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.25, 24: 0.0, 25: 0.25, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.5, 30: 0.0, 31: 0.25, 32: 0.5, 33: 0.25, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.25, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.75, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.25, 60: 0.25, 61: 0.0, 62: 0.25, 63: 0.0, 64: 0.0, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.25, 72: 0.0, 73: 0.25, 74: 0.0, 75: 1.0, 76: 0.25, 77: 0.0, 78: 0.75, 79: 0.25, 80: 0.75, 81: 0.25, 82: 0.0, 83: 0.0, 84: 0.5, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.0, 93: 0.75, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.5, 106: 0.75, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.75, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.25, 127: 0.0, 128: 0.5, 129: 0.0, 130: 0.25, 131: 0.0, 132: 0.25, 133: 0.25, 134: 1.0, 135: 0.0, 136: 0.25, 137: 0.5, 138: 0.75, 139: 0.0, 140: 0.0, 141: 0.75, 142: 0.0, 143: 0.25, 144: 1.0, 145: 0.5, 146: 0.0, 147: 0.25, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.75, 152: 0.0, 153: 0.5, 154: 0.25, 155: 0.0, 156: 0.0, 157: 0.25, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.25, 162: 0.5, 163: 0.0, 164: 0.5, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.25, 175: 0.25, 176: 0.25, 177: 0.75, 178: 0.5, 179: 0.0, 180: 0.25, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.25, 189: 0.0, 190: 0.5, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 10:02:02,675 [INFO] [4] TRAIN  loss: 4.179180473089218 acc: 0.08734939759036145
2024-10-08 10:02:02,675 [INFO] [4] TRAIN  loss dict: {'classification_loss': 4.179180473089218}
2024-10-08 10:02:02,675 [INFO] [4] VALIDATION loss: 3.747199288120976 VALIDATION  acc: 0.1590909090909091
2024-10-08 10:02:02,675 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.747199288120976}
2024-10-08 10:02:02,675 [INFO] 
2024-10-08 10:03:19,376 [INFO] Step[50/144]: training loss : 3.5441082525253296 TRAIN  loss dict:  {'classification_loss': 3.5441082525253296}
2024-10-08 10:04:13,864 [INFO] Step[100/144]: training loss : 3.2962513399124145 TRAIN  loss dict:  {'classification_loss': 3.2962513399124145}
2024-10-08 10:06:20,859 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 10:08:03,698 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN vsl for one view...


2024-10-08 10:09:25,960 [INFO] Step[50/144]: training loss : 5.473168239593506 TRAIN  loss dict:  {'classification_loss': 5.473168239593506}
2024-10-08 10:10:20,279 [INFO] Step[100/144]: training loss : 5.432873392105103 TRAIN  loss dict:  {'classification_loss': 5.432873392105103}
2024-10-08 10:12:01,785 [INFO] Label accuracies statistics:
2024-10-08 10:12:01,785 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.25, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.25, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.25, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.25, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 10:12:02,328 [INFO] [1] TRAIN  loss: 5.428912699222565 acc: 0.004633920296570899
2024-10-08 10:12:02,328 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.428912699222565}
2024-10-08 10:12:02,328 [INFO] [1] VALIDATION loss: 5.280058295638473 VALIDATION  acc: 0.005050505050505051
2024-10-08 10:12:02,328 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.280058295638473}
2024-10-08 10:12:02,329 [INFO] 
2024-10-08 10:13:19,606 [INFO] Step[50/144]: training loss : 5.281689777374267 TRAIN  loss dict:  {'classification_loss': 5.281689777374267}
2024-10-08 10:14:14,112 [INFO] Step[100/144]: training loss : 5.134952621459961 TRAIN  loss dict:  {'classification_loss': 5.134952621459961}
2024-10-08 10:15:50,818 [INFO] Label accuracies statistics:
2024-10-08 10:15:50,818 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.25, 28: 0.25, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.25, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.5, 107: 0.0, 108: 1.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.5, 129: 0.0, 130: 0.25, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.75, 153: 0.0, 154: 0.0, 155: 0.25, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.25, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 10:15:51,356 [INFO] [2] TRAIN  loss: 5.1269683341185255 acc: 0.014365152919369786
2024-10-08 10:15:51,356 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.1269683341185255}
2024-10-08 10:15:51,356 [INFO] [2] VALIDATION loss: 4.893605868021647 VALIDATION  acc: 0.02904040404040404
2024-10-08 10:15:51,356 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.893605868021647}
2024-10-08 10:15:51,356 [INFO] 
2024-10-08 10:17:08,528 [INFO] Step[50/144]: training loss : 4.651885213851929 TRAIN  loss dict:  {'classification_loss': 4.651885213851929}
2024-10-08 10:18:02,998 [INFO] Step[100/144]: training loss : 4.497792701721192 TRAIN  loss dict:  {'classification_loss': 4.497792701721192}
2024-10-08 10:19:39,391 [INFO] Label accuracies statistics:
2024-10-08 10:19:39,391 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.25, 4: 0.0, 5: 0.0, 6: 0.5, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.25, 24: 0.0, 25: 0.25, 26: 0.25, 27: 0.0, 28: 0.25, 29: 0.25, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.5, 39: 0.75, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.25, 55: 0.0, 56: 0.0, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.25, 62: 0.0, 63: 0.0, 64: 0.5, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.25, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.5, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.25, 93: 0.5, 94: 0.25, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.5, 102: 0.5, 103: 0.0, 104: 0.0, 105: 1.0, 106: 0.0, 107: 1.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.5, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.75, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.25, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.0, 135: 0.5, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 1.0, 152: 0.25, 153: 0.5, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.25, 178: 0.75, 179: 0.0, 180: 0.25, 181: 0.0, 182: 0.0, 183: 0.5, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.25, 195: 0.0, 196: 0.25, 197: 0.25, 198: 0.0}

2024-10-08 10:19:39,959 [INFO] [3] TRAIN  loss: 4.484846550557348 acc: 0.051899907321594066
2024-10-08 10:19:39,959 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.484846550557348}
2024-10-08 10:19:39,959 [INFO] [3] VALIDATION loss: 4.039701585416441 VALIDATION  acc: 0.11363636363636363
2024-10-08 10:19:39,959 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.039701585416441}
2024-10-08 10:19:39,959 [INFO] 
2024-10-08 10:20:58,195 [INFO] Step[50/144]: training loss : 3.8623049306869506 TRAIN  loss dict:  {'classification_loss': 3.8623049306869506}
2024-10-08 10:21:52,852 [INFO] Step[100/144]: training loss : 3.626794819831848 TRAIN  loss dict:  {'classification_loss': 3.626794819831848}
2024-10-08 10:23:29,602 [INFO] Label accuracies statistics:
2024-10-08 10:23:29,602 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.0, 5: 0.0, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.5, 19: 0.25, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.75, 24: 0.0, 25: 0.0, 26: 0.25, 27: 0.25, 28: 0.0, 29: 1.0, 30: 0.0, 31: 0.0, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.0, 36: 0.0, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.5, 43: 0.0, 44: 0.25, 45: 0.0, 46: 0.75, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.25, 51: 0.0, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.75, 62: 0.25, 63: 0.25, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.75, 68: 0.25, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.25, 73: 0.25, 74: 0.0, 75: 0.75, 76: 0.5, 77: 0.0, 78: 0.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.25, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.25, 95: 0.25, 96: 0.25, 97: 0.25, 98: 0.25, 99: 0.6, 100: 0.0, 101: 0.25, 102: 0.25, 103: 0.0, 104: 0.25, 105: 0.75, 106: 0.0, 107: 0.25, 108: 0.0, 109: 0.0, 110: 0.25, 111: 0.25, 112: 0.0, 113: 0.25, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.25, 118: 0.25, 119: 0.5, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.5, 126: 0.25, 127: 0.0, 128: 0.75, 129: 0.5, 130: 0.5, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.25, 135: 1.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.5, 140: 0.25, 141: 0.75, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.5, 149: 0.5, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.25, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.0, 161: 0.0, 162: 0.75, 163: 0.0, 164: 0.25, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.25, 171: 0.25, 172: 0.0, 173: 0.5, 174: 0.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 0.0, 179: 0.0, 180: 0.5, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.5, 186: 0.0, 187: 1.0, 188: 0.5, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.75, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-08 10:23:30,182 [INFO] [4] TRAIN  loss: 3.6580804304944143 acc: 0.1628822984244671
2024-10-08 10:23:30,182 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.6580804304944143}
2024-10-08 10:23:30,182 [INFO] [4] VALIDATION loss: 3.244330397358647 VALIDATION  acc: 0.2474747474747475
2024-10-08 10:23:30,182 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.244330397358647}
2024-10-08 10:23:30,182 [INFO] 
2024-10-08 10:24:46,746 [INFO] Step[50/144]: training loss : 3.0265541219711305 TRAIN  loss dict:  {'classification_loss': 3.0265541219711305}
2024-10-08 10:25:41,396 [INFO] Step[100/144]: training loss : 2.8608004379272463 TRAIN  loss dict:  {'classification_loss': 2.8608004379272463}
2024-10-08 10:27:17,996 [INFO] Label accuracies statistics:
2024-10-08 10:27:17,997 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.0, 6: 0.25, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.5, 19: 0.25, 20: 0.0, 21: 0.0, 22: 0.75, 23: 0.25, 24: 0.25, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.25, 33: 0.5, 34: 1.0, 35: 0.25, 36: 0.0, 37: 0.5, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.0, 46: 0.75, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.0, 60: 0.25, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.0, 65: 0.75, 66: 0.5, 67: 0.0, 68: 0.25, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.5, 73: 0.5, 74: 0.75, 75: 0.75, 76: 0.5, 77: 0.0, 78: 0.5, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.0, 87: 0.5, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.6, 100: 0.0, 101: 0.0, 102: 1.0, 103: 0.25, 104: 0.75, 105: 1.0, 106: 0.0, 107: 0.25, 108: 0.5, 109: 0.25, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.0, 115: 0.25, 116: 0.0, 117: 0.25, 118: 1.0, 119: 0.0, 120: 0.25, 121: 0.0, 122: 0.25, 123: 0.0, 124: 0.25, 125: 0.0, 126: 0.25, 127: 0.25, 128: 0.75, 129: 0.5, 130: 0.5, 131: 0.25, 132: 0.25, 133: 0.25, 134: 0.5, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.5, 139: 0.5, 140: 0.0, 141: 0.75, 142: 0.25, 143: 0.0, 144: 0.25, 145: 0.75, 146: 0.75, 147: 0.5, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.25, 153: 0.5, 154: 0.25, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.75, 160: 0.0, 161: 0.5, 162: 0.5, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.25, 171: 0.5, 172: 0.0, 173: 0.25, 174: 0.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.6666666666666666, 180: 0.5, 181: 0.0, 182: 0.0, 183: 1.0, 184: 0.25, 185: 0.75, 186: 0.0, 187: 0.75, 188: 0.25, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-08 10:27:18,544 [INFO] [5] TRAIN  loss: 2.8853964938057794 acc: 0.29240037071362374
2024-10-08 10:27:18,544 [INFO] [5] TRAIN  loss dict: {'classification_loss': 2.8853964938057794}
2024-10-08 10:27:18,544 [INFO] [5] VALIDATION loss: 2.6616921424865723 VALIDATION  acc: 0.35858585858585856
2024-10-08 10:27:18,544 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.6616921424865723}
2024-10-08 10:27:18,545 [INFO] 
2024-10-08 10:28:35,307 [INFO] Step[50/144]: training loss : 2.396883306503296 TRAIN  loss dict:  {'classification_loss': 2.396883306503296}
2024-10-08 10:29:29,888 [INFO] Step[100/144]: training loss : 2.2964934659004212 TRAIN  loss dict:  {'classification_loss': 2.2964934659004212}
2024-10-08 10:31:06,615 [INFO] Label accuracies statistics:
2024-10-08 10:31:06,615 [INFO] {0: 0.3333333333333333, 1: 0.0, 2: 0.25, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.5, 8: 0.0, 9: 0.5, 10: 1.0, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.5, 19: 0.5, 20: 0.0, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.5, 38: 0.75, 39: 1.0, 40: 0.5, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.75, 53: 0.5, 54: 0.0, 55: 0.25, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.75, 61: 0.5, 62: 0.5, 63: 0.25, 64: 0.25, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.25, 71: 0.0, 72: 1.0, 73: 0.5, 74: 0.75, 75: 0.75, 76: 0.5, 77: 0.25, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.25, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.6, 100: 1.0, 101: 0.0, 102: 0.25, 103: 0.25, 104: 0.75, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.0, 110: 0.5, 111: 0.5, 112: 0.75, 113: 0.25, 114: 0.25, 115: 0.25, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.25, 120: 0.5, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.5, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.0, 130: 0.25, 131: 0.75, 132: 0.5, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.5, 138: 0.25, 139: 1.0, 140: 0.25, 141: 0.0, 142: 0.0, 143: 0.5, 144: 0.0, 145: 0.25, 146: 0.25, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.5, 153: 0.75, 154: 0.75, 155: 0.0, 156: 0.25, 157: 0.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.0, 161: 0.25, 162: 0.5, 163: 0.25, 164: 0.0, 165: 0.25, 166: 0.5, 167: 0.0, 168: 0.25, 169: 0.25, 170: 0.25, 171: 0.25, 172: 0.25, 173: 0.75, 174: 0.75, 175: 0.25, 176: 0.25, 177: 0.25, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.0, 196: 0.5, 197: 1.0, 198: 0.0}

2024-10-08 10:31:07,179 [INFO] [6] TRAIN  loss: 2.3230140060186386 acc: 0.4036144578313253
2024-10-08 10:31:07,179 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.3230140060186386}
2024-10-08 10:31:07,179 [INFO] [6] VALIDATION loss: 2.20488761972498 VALIDATION  acc: 0.4494949494949495
2024-10-08 10:31:07,179 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.20488761972498}
2024-10-08 10:31:07,179 [INFO] 
2024-10-08 10:32:24,485 [INFO] Step[50/144]: training loss : 1.9387704348564148 TRAIN  loss dict:  {'classification_loss': 1.9387704348564148}
2024-10-08 10:33:19,030 [INFO] Step[100/144]: training loss : 1.7984830951690673 TRAIN  loss dict:  {'classification_loss': 1.7984830951690673}
2024-10-08 10:34:56,812 [INFO] Label accuracies statistics:
2024-10-08 10:34:56,812 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.25, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.0, 18: 0.5, 19: 0.75, 20: 0.25, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.0, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.0, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.0, 44: 0.75, 45: 0.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.0, 55: 0.75, 56: 0.25, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.0, 72: 0.75, 73: 0.75, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.25, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.5, 88: 0.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 1.0, 100: 1.0, 101: 0.25, 102: 0.5, 103: 0.5, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.25, 109: 0.75, 110: 0.75, 111: 0.25, 112: 0.5, 113: 0.5, 114: 0.0, 115: 0.75, 116: 0.0, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.25, 121: 0.25, 122: 1.0, 123: 0.5, 124: 0.75, 125: 1.0, 126: 0.0, 127: 0.25, 128: 1.0, 129: 0.25, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.25, 139: 0.75, 140: 0.5, 141: 0.0, 142: 0.5, 143: 0.25, 144: 0.0, 145: 0.5, 146: 0.5, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.0, 151: 0.5, 152: 0.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.25, 158: 0.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.5, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.0, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.25, 178: 0.5, 179: 1.0, 180: 0.0, 181: 0.75, 182: 0.5, 183: 0.0, 184: 0.75, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.5, 189: 0.5, 190: 0.0, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.25, 197: 0.25, 198: 0.0}

2024-10-08 10:34:57,364 [INFO] [7] TRAIN  loss: 1.8399337662590876 acc: 0.5345227062094532
2024-10-08 10:34:57,364 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.8399337662590876}
2024-10-08 10:34:57,364 [INFO] [7] VALIDATION loss: 1.9408569048952173 VALIDATION  acc: 0.4861111111111111
2024-10-08 10:34:57,364 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.9408569048952173}
2024-10-08 10:34:57,364 [INFO] 
2024-10-08 10:36:14,521 [INFO] Step[50/144]: training loss : 1.533578679561615 TRAIN  loss dict:  {'classification_loss': 1.533578679561615}
2024-10-08 10:37:09,100 [INFO] Step[100/144]: training loss : 1.4786820650100707 TRAIN  loss dict:  {'classification_loss': 1.4786820650100707}
2024-10-08 10:38:45,960 [INFO] Label accuracies statistics:
2024-10-08 10:38:45,960 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.25, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.25, 40: 0.75, 41: 0.0, 42: 0.25, 43: 0.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.0, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.5, 69: 0.0, 70: 0.5, 71: 0.5, 72: 0.25, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.5, 87: 0.5, 88: 0.0, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.25, 104: 0.25, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.5, 109: 0.5, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 0.5, 125: 0.25, 126: 0.5, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.5, 131: 1.0, 132: 0.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.0, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.25, 144: 0.75, 145: 0.5, 146: 0.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.75, 155: 0.75, 156: 1.0, 157: 0.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.75, 165: 0.0, 166: 0.25, 167: 0.0, 168: 0.75, 169: 0.25, 170: 0.5, 171: 0.0, 172: 0.25, 173: 0.5, 174: 0.75, 175: 0.5, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.25, 196: 0.5, 197: 0.5, 198: 0.0}

2024-10-08 10:38:46,526 [INFO] [8] TRAIN  loss: 1.4947460326883528 acc: 0.6167747914735866
2024-10-08 10:38:46,526 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.4947460326883528}
2024-10-08 10:38:46,526 [INFO] [8] VALIDATION loss: 1.698208005340011 VALIDATION  acc: 0.5416666666666666
2024-10-08 10:38:46,526 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.698208005340011}
2024-10-08 10:38:46,527 [INFO] 
2024-10-08 10:40:03,592 [INFO] Step[50/144]: training loss : 1.225794278383255 TRAIN  loss dict:  {'classification_loss': 1.225794278383255}
2024-10-08 10:40:58,216 [INFO] Step[100/144]: training loss : 1.2257333898544311 TRAIN  loss dict:  {'classification_loss': 1.2257333898544311}
2024-10-08 10:42:34,994 [INFO] Label accuracies statistics:
2024-10-08 10:42:34,994 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.25, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.25, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.0, 55: 0.5, 56: 0.75, 57: 0.25, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.0, 84: 0.5, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.6, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.25, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.0, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.5, 140: 0.5, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.25, 145: 0.25, 146: 0.25, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.25, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.5, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.5, 187: 0.75, 188: 0.25, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.0}

2024-10-08 10:42:35,562 [INFO] [9] TRAIN  loss: 1.2423290200531483 acc: 0.683271547729379
2024-10-08 10:42:35,562 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.2423290200531483}
2024-10-08 10:42:35,562 [INFO] [9] VALIDATION loss: 1.4864803618854947 VALIDATION  acc: 0.5997474747474747
2024-10-08 10:42:35,562 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.4864803618854947}
2024-10-08 10:42:35,563 [INFO] 
2024-10-08 10:43:53,413 [INFO] Step[50/144]: training loss : 1.032823909521103 TRAIN  loss dict:  {'classification_loss': 1.032823909521103}
2024-10-08 10:44:47,887 [INFO] Step[100/144]: training loss : 1.0755262064933777 TRAIN  loss dict:  {'classification_loss': 1.0755262064933777}
2024-10-08 10:46:24,787 [INFO] Label accuracies statistics:
2024-10-08 10:46:24,787 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.75, 18: 0.5, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.25, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.25, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.25, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 0.5, 92: 0.5, 93: 0.5, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.25, 122: 0.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.0, 131: 1.0, 132: 0.25, 133: 0.5, 134: 0.25, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.0, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.25, 194: 0.75, 195: 0.5, 196: 0.5, 197: 1.0, 198: 1.0}

2024-10-08 10:46:25,342 [INFO] [10] TRAIN  loss: 1.0615049161844783 acc: 0.7235866543095458
2024-10-08 10:46:25,342 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.0615049161844783}
2024-10-08 10:46:25,342 [INFO] [10] VALIDATION loss: 1.4713702466752794 VALIDATION  acc: 0.6186868686868687
2024-10-08 10:46:25,342 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.4713702466752794}
2024-10-08 10:46:25,342 [INFO] 
2024-10-08 10:47:42,321 [INFO] Step[50/144]: training loss : 0.8472032696008682 TRAIN  loss dict:  {'classification_loss': 0.8472032696008682}
2024-10-08 10:48:36,776 [INFO] Step[100/144]: training loss : 0.8435168778896331 TRAIN  loss dict:  {'classification_loss': 0.8435168778896331}
2024-10-08 10:50:13,912 [INFO] Label accuracies statistics:
2024-10-08 10:50:13,912 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.25, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.25, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.25, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.0, 123: 0.75, 124: 1.0, 125: 0.5, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.5, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.0, 197: 1.0, 198: 1.0}

2024-10-08 10:50:14,505 [INFO] [11] TRAIN  loss: 0.8547969750232167 acc: 0.7794253938832252
2024-10-08 10:50:14,505 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.8547969750232167}
2024-10-08 10:50:14,505 [INFO] [11] VALIDATION loss: 1.3415155664638236 VALIDATION  acc: 0.648989898989899
2024-10-08 10:50:14,505 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.3415155664638236}
2024-10-08 10:50:14,505 [INFO] 
2024-10-08 10:51:31,541 [INFO] Step[50/144]: training loss : 0.6770624440908432 TRAIN  loss dict:  {'classification_loss': 0.6770624440908432}
2024-10-08 10:52:26,196 [INFO] Step[100/144]: training loss : 0.6968995839357376 TRAIN  loss dict:  {'classification_loss': 0.6968995839357376}
2024-10-08 10:54:03,227 [INFO] Label accuracies statistics:
2024-10-08 10:54:03,227 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.0, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.0, 97: 0.25, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.25, 139: 0.25, 140: 1.0, 141: 0.5, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.5, 157: 0.25, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.0, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-08 10:54:03,787 [INFO] [12] TRAIN  loss: 0.6911247213267617 acc: 0.8313253012048193
2024-10-08 10:54:03,787 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.6911247213267617}
2024-10-08 10:54:03,787 [INFO] [12] VALIDATION loss: 1.3251048039506983 VALIDATION  acc: 0.6401515151515151
2024-10-08 10:54:03,787 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.3251048039506983}
2024-10-08 10:54:03,787 [INFO] 
2024-10-08 10:55:29,827 [INFO] Step[50/144]: training loss : 0.6351140487194061 TRAIN  loss dict:  {'classification_loss': 0.6351140487194061}
2024-10-08 10:56:24,337 [INFO] Step[100/144]: training loss : 0.6327977842092514 TRAIN  loss dict:  {'classification_loss': 0.6327977842092514}
2024-10-08 10:58:01,455 [INFO] Label accuracies statistics:
2024-10-08 10:58:01,455 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.25, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.25, 44: 0.25, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.0, 146: 0.75, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.25, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.0, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 0.5, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-08 10:58:01,526 [INFO] [13] TRAIN  loss: 0.6324941188924842 acc: 0.8341056533827618
2024-10-08 10:58:01,526 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.6324941188924842}
2024-10-08 10:58:01,526 [INFO] [13] VALIDATION loss: 1.3387262280340548 VALIDATION  acc: 0.6477272727272727
2024-10-08 10:58:01,526 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.3387262280340548}
2024-10-08 10:58:01,526 [INFO] 
2024-10-08 10:59:23,296 [INFO] Step[50/144]: training loss : 0.520009092092514 TRAIN  loss dict:  {'classification_loss': 0.520009092092514}
2024-10-08 11:00:17,842 [INFO] Step[100/144]: training loss : 0.5481643173098564 TRAIN  loss dict:  {'classification_loss': 0.5481643173098564}
2024-10-08 11:01:54,638 [INFO] Label accuracies statistics:
2024-10-08 11:01:54,639 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.5, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.25, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.0, 143: 0.5, 144: 0.5, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.25, 164: 1.0, 165: 0.25, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-08 11:01:55,213 [INFO] [14] TRAIN  loss: 0.5492612828190128 acc: 0.8593605189990732
2024-10-08 11:01:55,213 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.5492612828190128}
2024-10-08 11:01:55,214 [INFO] [14] VALIDATION loss: 1.2512509580011721 VALIDATION  acc: 0.6452020202020202
2024-10-08 11:01:55,214 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.2512509580011721}
2024-10-08 11:01:55,214 [INFO] 
2024-10-08 11:03:12,497 [INFO] Step[50/144]: training loss : 0.45258751571178435 TRAIN  loss dict:  {'classification_loss': 0.45258751571178435}
2024-10-08 11:04:07,080 [INFO] Step[100/144]: training loss : 0.47777622401714326 TRAIN  loss dict:  {'classification_loss': 0.47777622401714326}
2024-10-08 11:05:44,543 [INFO] Label accuracies statistics:
2024-10-08 11:05:44,543 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.5, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.25, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.5, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.5, 166: 1.0, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-08 11:05:45,135 [INFO] [15] TRAIN  loss: 0.4708775703070892 acc: 0.8765060240963856
2024-10-08 11:05:45,135 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.4708775703070892}
2024-10-08 11:05:45,135 [INFO] [15] VALIDATION loss: 1.2295942731477596 VALIDATION  acc: 0.6830808080808081
2024-10-08 11:05:45,135 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.2295942731477596}
2024-10-08 11:05:45,135 [INFO] 
2024-10-08 11:07:07,081 [INFO] Step[50/144]: training loss : 0.4082032209634781 TRAIN  loss dict:  {'classification_loss': 0.4082032209634781}
2024-10-08 11:08:01,682 [INFO] Step[100/144]: training loss : 0.41641119480133054 TRAIN  loss dict:  {'classification_loss': 0.41641119480133054}
2024-10-08 11:09:38,808 [INFO] Label accuracies statistics:
2024-10-08 11:09:38,809 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.0, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.25, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.5, 124: 0.5, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 0.25, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 1.0, 151: 0.75, 152: 1.0, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.25, 168: 0.25, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 0.5, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-08 11:09:38,877 [INFO] [16] TRAIN  loss: 0.42491566441539264 acc: 0.8878591288229842
2024-10-08 11:09:38,877 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.42491566441539264}
2024-10-08 11:09:38,877 [INFO] [16] VALIDATION loss: 1.245537335122073 VALIDATION  acc: 0.6654040404040404
2024-10-08 11:09:38,877 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.245537335122073}
2024-10-08 11:09:38,877 [INFO] 
2024-10-08 11:10:55,780 [INFO] Step[50/144]: training loss : 0.37467805862426756 TRAIN  loss dict:  {'classification_loss': 0.37467805862426756}
2024-10-08 11:11:50,543 [INFO] Step[100/144]: training loss : 0.3620238357782364 TRAIN  loss dict:  {'classification_loss': 0.3620238357782364}
2024-10-08 11:13:27,557 [INFO] Label accuracies statistics:
2024-10-08 11:13:27,557 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.25, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.5, 67: 0.25, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 0.75, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.5, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.0}

2024-10-08 11:13:28,110 [INFO] [17] TRAIN  loss: 0.38093914050194955 acc: 0.9045412418906394
2024-10-08 11:13:28,110 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.38093914050194955}
2024-10-08 11:13:28,110 [INFO] [17] VALIDATION loss: 1.2015946711655017 VALIDATION  acc: 0.6919191919191919
2024-10-08 11:13:28,110 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.2015946711655017}
2024-10-08 11:13:28,110 [INFO] 
2024-10-08 11:14:45,202 [INFO] Step[50/144]: training loss : 0.30856026992201807 TRAIN  loss dict:  {'classification_loss': 0.30856026992201807}
2024-10-08 11:15:39,884 [INFO] Step[100/144]: training loss : 0.36748457223176956 TRAIN  loss dict:  {'classification_loss': 0.36748457223176956}
2024-10-08 11:17:16,621 [INFO] Label accuracies statistics:
2024-10-08 11:17:16,621 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.5, 73: 0.5, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 11:17:16,690 [INFO] [18] TRAIN  loss: 0.347868418890155 acc: 0.9075532900834106
2024-10-08 11:17:16,690 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.347868418890155}
2024-10-08 11:17:16,690 [INFO] [18] VALIDATION loss: 1.2595209197865591 VALIDATION  acc: 0.6767676767676768
2024-10-08 11:17:16,690 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.2595209197865591}
2024-10-08 11:17:16,690 [INFO] 
2024-10-08 11:18:34,024 [INFO] Step[50/144]: training loss : 0.3327912871539593 TRAIN  loss dict:  {'classification_loss': 0.3327912871539593}
2024-10-08 11:19:28,488 [INFO] Step[100/144]: training loss : 0.3022943107783794 TRAIN  loss dict:  {'classification_loss': 0.3022943107783794}
2024-10-08 11:21:05,487 [INFO] Label accuracies statistics:
2024-10-08 11:21:05,488 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 11:21:06,033 [INFO] [19] TRAIN  loss: 0.32580511634134585 acc: 0.9177479147358666
2024-10-08 11:21:06,033 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.32580511634134585}
2024-10-08 11:21:06,034 [INFO] [19] VALIDATION loss: 1.0926199729243915 VALIDATION  acc: 0.7108585858585859
2024-10-08 11:21:06,034 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.0926199729243915}
2024-10-08 11:21:06,034 [INFO] 
2024-10-08 11:22:23,519 [INFO] Step[50/144]: training loss : 0.28578857854008677 TRAIN  loss dict:  {'classification_loss': 0.28578857854008677}
2024-10-08 11:23:18,123 [INFO] Step[100/144]: training loss : 0.28556124702095986 TRAIN  loss dict:  {'classification_loss': 0.28556124702095986}
2024-10-08 11:24:55,092 [INFO] Label accuracies statistics:
2024-10-08 11:24:55,092 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.5, 35: 0.25, 36: 0.5, 37: 0.5, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.25, 71: 0.5, 72: 0.5, 73: 0.75, 74: 0.25, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.0, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.5, 198: 0.75}

2024-10-08 11:24:55,160 [INFO] [20] TRAIN  loss: 0.28334993144704235 acc: 0.9274791473586654
2024-10-08 11:24:55,160 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.28334993144704235}
2024-10-08 11:24:55,160 [INFO] [20] VALIDATION loss: 1.1926745408111148 VALIDATION  acc: 0.6755050505050505
2024-10-08 11:24:55,160 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.1926745408111148}
2024-10-08 11:24:55,160 [INFO] 
2024-10-08 11:26:11,787 [INFO] Step[50/144]: training loss : 0.21912441104650499 TRAIN  loss dict:  {'classification_loss': 0.21912441104650499}
2024-10-08 11:27:06,359 [INFO] Step[100/144]: training loss : 0.2367912435531616 TRAIN  loss dict:  {'classification_loss': 0.2367912435531616}
2024-10-08 11:28:43,292 [INFO] Label accuracies statistics:
2024-10-08 11:28:43,292 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.5, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.25, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.25, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-08 11:28:43,360 [INFO] [21] TRAIN  loss: 0.23344377397249141 acc: 0.9478683966635774
2024-10-08 11:28:43,360 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.23344377397249141}
2024-10-08 11:28:43,360 [INFO] [21] VALIDATION loss: 1.1238635419695466 VALIDATION  acc: 0.7045454545454546
2024-10-08 11:28:43,360 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.1238635419695466}
2024-10-08 11:28:43,360 [INFO] 
2024-10-08 11:30:00,707 [INFO] Step[50/144]: training loss : 0.1967947072535753 TRAIN  loss dict:  {'classification_loss': 0.1967947072535753}
2024-10-08 11:30:55,417 [INFO] Step[100/144]: training loss : 0.21554937675595284 TRAIN  loss dict:  {'classification_loss': 0.21554937675595284}
2024-10-08 11:32:31,904 [INFO] Label accuracies statistics:
2024-10-08 11:32:31,904 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.5, 67: 0.25, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.25, 197: 1.0, 198: 0.75}

2024-10-08 11:32:31,972 [INFO] [22] TRAIN  loss: 0.20567280636169016 acc: 0.9534291010194624
2024-10-08 11:32:31,972 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.20567280636169016}
2024-10-08 11:32:31,972 [INFO] [22] VALIDATION loss: 1.1136460271146562 VALIDATION  acc: 0.7095959595959596
2024-10-08 11:32:31,972 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.1136460271146562}
2024-10-08 11:32:31,972 [INFO] 
2024-10-08 11:33:48,885 [INFO] Step[50/144]: training loss : 0.17895331129431724 TRAIN  loss dict:  {'classification_loss': 0.17895331129431724}
2024-10-08 11:34:43,660 [INFO] Step[100/144]: training loss : 0.2008738013356924 TRAIN  loss dict:  {'classification_loss': 0.2008738013356924}
2024-10-08 11:36:20,461 [INFO] Label accuracies statistics:
2024-10-08 11:36:20,461 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.25, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 11:36:20,528 [INFO] [23] TRAIN  loss: 0.19878111601186296 acc: 0.9529657089898054
2024-10-08 11:36:20,528 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.19878111601186296}
2024-10-08 11:36:20,529 [INFO] [23] VALIDATION loss: 1.1089189678982452 VALIDATION  acc: 0.702020202020202
2024-10-08 11:36:20,529 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.1089189678982452}
2024-10-08 11:36:20,529 [INFO] 
2024-10-08 11:37:37,663 [INFO] Step[50/144]: training loss : 0.1770232091844082 TRAIN  loss dict:  {'classification_loss': 0.1770232091844082}
2024-10-08 11:38:32,143 [INFO] Step[100/144]: training loss : 0.17310567282140255 TRAIN  loss dict:  {'classification_loss': 0.17310567282140255}
2024-10-08 11:40:09,207 [INFO] Label accuracies statistics:
2024-10-08 11:40:09,207 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.5, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.25, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.5, 141: 0.75, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-08 11:40:09,791 [INFO] [24] TRAIN  loss: 0.17359443482321998 acc: 0.9636237256719185
2024-10-08 11:40:09,792 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.17359443482321998}
2024-10-08 11:40:09,792 [INFO] [24] VALIDATION loss: 1.075078227177814 VALIDATION  acc: 0.7121212121212122
2024-10-08 11:40:09,792 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.075078227177814}
2024-10-08 11:40:09,792 [INFO] 
2024-10-08 11:41:26,437 [INFO] Step[50/144]: training loss : 0.15356411501765252 TRAIN  loss dict:  {'classification_loss': 0.15356411501765252}
2024-10-08 11:42:21,113 [INFO] Step[100/144]: training loss : 0.16671544432640076 TRAIN  loss dict:  {'classification_loss': 0.16671544432640076}
2024-10-08 11:43:58,483 [INFO] Label accuracies statistics:
2024-10-08 11:43:58,483 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.5, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.0, 166: 1.0, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.0, 197: 1.0, 198: 0.5}

2024-10-08 11:43:58,553 [INFO] [25] TRAIN  loss: 0.16020451672375202 acc: 0.9647822057460612
2024-10-08 11:43:58,553 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.16020451672375202}
2024-10-08 11:43:58,553 [INFO] [25] VALIDATION loss: 1.1011248208858349 VALIDATION  acc: 0.702020202020202
2024-10-08 11:43:58,553 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.1011248208858349}
2024-10-08 11:43:58,553 [INFO] 
2024-10-08 11:45:15,807 [INFO] Step[50/144]: training loss : 0.1477719071507454 TRAIN  loss dict:  {'classification_loss': 0.1477719071507454}
2024-10-08 11:46:10,444 [INFO] Step[100/144]: training loss : 0.1663876636326313 TRAIN  loss dict:  {'classification_loss': 0.1663876636326313}
2024-10-08 11:47:47,394 [INFO] Label accuracies statistics:
2024-10-08 11:47:47,394 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.5, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 11:47:47,462 [INFO] [26] TRAIN  loss: 0.15757501916959882 acc: 0.9626969416126042
2024-10-08 11:47:47,462 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.15757501916959882}
2024-10-08 11:47:47,462 [INFO] [26] VALIDATION loss: 1.098073059210071 VALIDATION  acc: 0.7133838383838383
2024-10-08 11:47:47,462 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.098073059210071}
2024-10-08 11:47:47,463 [INFO] 
2024-10-08 11:49:04,920 [INFO] Step[50/144]: training loss : 0.11726716980338096 TRAIN  loss dict:  {'classification_loss': 0.11726716980338096}
2024-10-08 11:49:59,654 [INFO] Step[100/144]: training loss : 0.1529248792678118 TRAIN  loss dict:  {'classification_loss': 0.1529248792678118}
2024-10-08 11:51:36,352 [INFO] Label accuracies statistics:
2024-10-08 11:51:36,352 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 11:51:36,905 [INFO] [27] TRAIN  loss: 0.13613179706347486 acc: 0.9657089898053753
2024-10-08 11:51:36,905 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.13613179706347486}
2024-10-08 11:51:36,906 [INFO] [27] VALIDATION loss: 1.0725271039538913 VALIDATION  acc: 0.726010101010101
2024-10-08 11:51:36,906 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.0725271039538913}
2024-10-08 11:51:36,906 [INFO] 
2024-10-08 11:52:54,061 [INFO] Step[50/144]: training loss : 0.1250749985128641 TRAIN  loss dict:  {'classification_loss': 0.1250749985128641}
2024-10-08 11:53:48,673 [INFO] Step[100/144]: training loss : 0.1265989688038826 TRAIN  loss dict:  {'classification_loss': 0.1265989688038826}
2024-10-08 11:55:25,648 [INFO] Label accuracies statistics:
2024-10-08 11:55:25,648 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-08 11:55:25,718 [INFO] [28] TRAIN  loss: 0.12882777911403942 acc: 0.9684893419833179
2024-10-08 11:55:25,718 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.12882777911403942}
2024-10-08 11:55:25,718 [INFO] [28] VALIDATION loss: 1.1082699850753501 VALIDATION  acc: 0.7108585858585859
2024-10-08 11:55:25,719 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.1082699850753501}
2024-10-08 11:55:25,719 [INFO] 
2024-10-08 11:56:42,601 [INFO] Step[50/144]: training loss : 0.11150565303862095 TRAIN  loss dict:  {'classification_loss': 0.11150565303862095}
2024-10-08 11:57:37,186 [INFO] Step[100/144]: training loss : 0.12407210037112236 TRAIN  loss dict:  {'classification_loss': 0.12407210037112236}
2024-10-08 11:59:14,035 [INFO] Label accuracies statistics:
2024-10-08 11:59:14,035 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.0, 72: 0.5, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.25, 103: 1.0, 104: 0.5, 105: 0.75, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.0, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-08 11:59:14,106 [INFO] [29] TRAIN  loss: 0.1260962580692851 acc: 0.9661723818350324
2024-10-08 11:59:14,107 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.1260962580692851}
2024-10-08 11:59:14,107 [INFO] [29] VALIDATION loss: 1.1977416939205594 VALIDATION  acc: 0.7108585858585859
2024-10-08 11:59:14,107 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.1977416939205594}
2024-10-08 11:59:14,107 [INFO] 
2024-10-08 12:00:31,994 [INFO] Step[50/144]: training loss : 0.11257072325795889 TRAIN  loss dict:  {'classification_loss': 0.11257072325795889}
2024-10-08 12:01:26,760 [INFO] Step[100/144]: training loss : 0.12239490021020175 TRAIN  loss dict:  {'classification_loss': 0.12239490021020175}
2024-10-08 12:03:03,574 [INFO] Label accuracies statistics:
2024-10-08 12:03:03,574 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.5, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.5, 198: 1.0}

2024-10-08 12:03:03,642 [INFO] [30] TRAIN  loss: 0.12239132583555248 acc: 0.9710379981464319
2024-10-08 12:03:03,642 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.12239132583555248}
2024-10-08 12:03:03,642 [INFO] [30] VALIDATION loss: 1.1089198062265362 VALIDATION  acc: 0.726010101010101
2024-10-08 12:03:03,642 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.1089198062265362}
2024-10-08 12:03:03,642 [INFO] 
2024-10-08 12:04:20,552 [INFO] Step[50/144]: training loss : 0.09821203827857972 TRAIN  loss dict:  {'classification_loss': 0.09821203827857972}
2024-10-08 12:05:15,235 [INFO] Step[100/144]: training loss : 0.10515061654150486 TRAIN  loss dict:  {'classification_loss': 0.10515061654150486}
2024-10-08 12:06:51,862 [INFO] Label accuracies statistics:
2024-10-08 12:06:51,863 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 12:06:51,931 [INFO] [31] TRAIN  loss: 0.1008840676707526 acc: 0.9793790546802595
2024-10-08 12:06:51,931 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.1008840676707526}
2024-10-08 12:06:51,932 [INFO] [31] VALIDATION loss: 1.1178655403631705 VALIDATION  acc: 0.7133838383838383
2024-10-08 12:06:51,932 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.1178655403631705}
2024-10-08 12:06:51,932 [INFO] 
2024-10-08 12:08:09,201 [INFO] Step[50/144]: training loss : 0.08385481085628271 TRAIN  loss dict:  {'classification_loss': 0.08385481085628271}
2024-10-08 12:09:03,760 [INFO] Step[100/144]: training loss : 0.08573835521936417 TRAIN  loss dict:  {'classification_loss': 0.08573835521936417}
2024-10-08 12:10:40,547 [INFO] Label accuracies statistics:
2024-10-08 12:10:40,547 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 0.75, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-08 12:10:40,615 [INFO] [32] TRAIN  loss: 0.08573940724858807 acc: 0.9812326227988879
2024-10-08 12:10:40,615 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.08573940724858807}
2024-10-08 12:10:40,615 [INFO] [32] VALIDATION loss: 1.140130642387602 VALIDATION  acc: 0.7159090909090909
2024-10-08 12:10:40,615 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.140130642387602}
2024-10-08 12:10:40,615 [INFO] 
2024-10-08 12:11:57,472 [INFO] Step[50/144]: training loss : 0.07397083338350058 TRAIN  loss dict:  {'classification_loss': 0.07397083338350058}
2024-10-08 12:12:52,041 [INFO] Step[100/144]: training loss : 0.07212339274585247 TRAIN  loss dict:  {'classification_loss': 0.07212339274585247}
2024-10-08 12:14:29,484 [INFO] Label accuracies statistics:
2024-10-08 12:14:29,484 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 1.0, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 12:14:29,554 [INFO] [33] TRAIN  loss: 0.07424081792123616 acc: 0.9851714550509731
2024-10-08 12:14:29,554 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.07424081792123616}
2024-10-08 12:14:29,554 [INFO] [33] VALIDATION loss: 1.1061512051081215 VALIDATION  acc: 0.7234848484848485
2024-10-08 12:14:29,555 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 1.1061512051081215}
2024-10-08 12:14:29,555 [INFO] 
2024-10-08 12:15:46,843 [INFO] Step[50/144]: training loss : 0.08227354876697063 TRAIN  loss dict:  {'classification_loss': 0.08227354876697063}
2024-10-08 12:16:41,559 [INFO] Step[100/144]: training loss : 0.07671884892508388 TRAIN  loss dict:  {'classification_loss': 0.07671884892508388}
2024-10-08 12:18:18,706 [INFO] Label accuracies statistics:
2024-10-08 12:18:18,706 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 0.75, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.5, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 12:18:19,281 [INFO] [34] TRAIN  loss: 0.07947154729885773 acc: 0.9833178869323448
2024-10-08 12:18:19,281 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.07947154729885773}
2024-10-08 12:18:19,281 [INFO] [34] VALIDATION loss: 1.0562555013845365 VALIDATION  acc: 0.7234848484848485
2024-10-08 12:18:19,281 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.0562555013845365}
2024-10-08 12:18:19,281 [INFO] 
2024-10-08 12:19:41,749 [INFO] Step[50/144]: training loss : 0.07703625608235598 TRAIN  loss dict:  {'classification_loss': 0.07703625608235598}
2024-10-08 12:20:36,385 [INFO] Step[100/144]: training loss : 0.06729798894375563 TRAIN  loss dict:  {'classification_loss': 0.06729798894375563}
2024-10-08 12:22:13,260 [INFO] Label accuracies statistics:
2024-10-08 12:22:13,260 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 12:22:13,329 [INFO] [35] TRAIN  loss: 0.07210897394300748 acc: 0.9840129749768304
2024-10-08 12:22:13,329 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.07210897394300748}
2024-10-08 12:22:13,329 [INFO] [35] VALIDATION loss: 1.146970257576969 VALIDATION  acc: 0.7159090909090909
2024-10-08 12:22:13,329 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.146970257576969}
2024-10-08 12:22:13,329 [INFO] 
2024-10-08 12:23:30,015 [INFO] Step[50/144]: training loss : 0.06201149497181177 TRAIN  loss dict:  {'classification_loss': 0.06201149497181177}
2024-10-08 12:24:24,681 [INFO] Step[100/144]: training loss : 0.0732657140120864 TRAIN  loss dict:  {'classification_loss': 0.0732657140120864}
2024-10-08 12:26:01,482 [INFO] Label accuracies statistics:
2024-10-08 12:26:01,482 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 12:26:01,551 [INFO] [36] TRAIN  loss: 0.06903264984591967 acc: 0.9856348470806302
2024-10-08 12:26:01,551 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.06903264984591967}
2024-10-08 12:26:01,551 [INFO] [36] VALIDATION loss: 1.1248546375168695 VALIDATION  acc: 0.7196969696969697
2024-10-08 12:26:01,551 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.1248546375168695}
2024-10-08 12:26:01,551 [INFO] 
2024-10-08 12:27:18,204 [INFO] Step[50/144]: training loss : 0.062308831159025434 TRAIN  loss dict:  {'classification_loss': 0.062308831159025434}
2024-10-08 12:28:12,705 [INFO] Step[100/144]: training loss : 0.06325915690511465 TRAIN  loss dict:  {'classification_loss': 0.06325915690511465}
2024-10-08 12:29:49,979 [INFO] Label accuracies statistics:
2024-10-08 12:29:49,979 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-08 12:29:50,048 [INFO] [37] TRAIN  loss: 0.06890871411370528 acc: 0.9835495829471733
2024-10-08 12:29:50,048 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.06890871411370528}
2024-10-08 12:29:50,048 [INFO] [37] VALIDATION loss: 1.1098637215241238 VALIDATION  acc: 0.7184343434343434
2024-10-08 12:29:50,048 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.1098637215241238}
2024-10-08 12:29:50,049 [INFO] 
2024-10-08 12:31:07,544 [INFO] Step[50/144]: training loss : 0.06454400315880776 TRAIN  loss dict:  {'classification_loss': 0.06454400315880776}
2024-10-08 12:32:02,157 [INFO] Step[100/144]: training loss : 0.06944756178185343 TRAIN  loss dict:  {'classification_loss': 0.06944756178185343}
2024-10-08 12:33:39,250 [INFO] Label accuracies statistics:
2024-10-08 12:33:39,250 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.0, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.25, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 0.75, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 12:33:39,320 [INFO] [38] TRAIN  loss: 0.06874360684176078 acc: 0.9842446709916589
2024-10-08 12:33:39,320 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.06874360684176078}
2024-10-08 12:33:39,320 [INFO] [38] VALIDATION loss: 1.1793292195846636 VALIDATION  acc: 0.7058080808080808
2024-10-08 12:33:39,320 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.1793292195846636}
2024-10-08 12:33:39,320 [INFO] 
2024-10-08 12:34:55,878 [INFO] Step[50/144]: training loss : 0.05679718496277928 TRAIN  loss dict:  {'classification_loss': 0.05679718496277928}
2024-10-08 12:35:50,477 [INFO] Step[100/144]: training loss : 0.07052297569811344 TRAIN  loss dict:  {'classification_loss': 0.07052297569811344}
2024-10-08 12:37:27,558 [INFO] Label accuracies statistics:
2024-10-08 12:37:27,558 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.25, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 1.0, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-08 12:37:27,630 [INFO] [39] TRAIN  loss: 0.06195962855256059 acc: 0.9842446709916589
2024-10-08 12:37:27,630 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.06195962855256059}
2024-10-08 12:37:27,630 [INFO] [39] VALIDATION loss: 1.174641254875395 VALIDATION  acc: 0.7108585858585859
2024-10-08 12:37:27,630 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.174641254875395}
2024-10-08 12:37:27,631 [INFO] 
2024-10-08 12:38:44,664 [INFO] Step[50/144]: training loss : 0.06619549579918385 TRAIN  loss dict:  {'classification_loss': 0.06619549579918385}
2024-10-08 12:39:39,469 [INFO] Step[100/144]: training loss : 0.07670589584857225 TRAIN  loss dict:  {'classification_loss': 0.07670589584857225}
2024-10-08 12:41:16,038 [INFO] Label accuracies statistics:
2024-10-08 12:41:16,038 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.25, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 12:41:16,105 [INFO] [40] TRAIN  loss: 0.07071724879400183 acc: 0.9835495829471733
2024-10-08 12:41:16,106 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.07071724879400183}
2024-10-08 12:41:16,106 [INFO] [40] VALIDATION loss: 1.1845981853979606 VALIDATION  acc: 0.7108585858585859
2024-10-08 12:41:16,106 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.1845981853979606}
2024-10-08 12:41:16,106 [INFO] 
2024-10-08 12:42:33,247 [INFO] Step[50/144]: training loss : 0.058967430740594864 TRAIN  loss dict:  {'classification_loss': 0.058967430740594864}
2024-10-08 12:43:27,978 [INFO] Step[100/144]: training loss : 0.046518683210015295 TRAIN  loss dict:  {'classification_loss': 0.046518683210015295}
2024-10-08 12:45:05,193 [INFO] Label accuracies statistics:
2024-10-08 12:45:05,193 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-08 12:45:05,260 [INFO] [41] TRAIN  loss: 0.05346789991017431 acc: 0.9879518072289156
2024-10-08 12:45:05,260 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.05346789991017431}
2024-10-08 12:45:05,261 [INFO] [41] VALIDATION loss: 1.081743466840298 VALIDATION  acc: 0.73989898989899
2024-10-08 12:45:05,261 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.081743466840298}
2024-10-08 12:45:05,261 [INFO] 
2024-10-08 12:46:22,526 [INFO] Step[50/144]: training loss : 0.04707039441913366 TRAIN  loss dict:  {'classification_loss': 0.04707039441913366}
2024-10-08 12:47:17,295 [INFO] Step[100/144]: training loss : 0.041449224185198544 TRAIN  loss dict:  {'classification_loss': 0.041449224185198544}
2024-10-08 12:48:54,952 [INFO] Label accuracies statistics:
2024-10-08 12:48:54,952 [INFO] {0: 1.0, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.5, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 12:48:55,021 [INFO] [42] TRAIN  loss: 0.0455111371508489 acc: 0.9905004633920297
2024-10-08 12:48:55,021 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.0455111371508489}
2024-10-08 12:48:55,021 [INFO] [42] VALIDATION loss: 1.118928116366819 VALIDATION  acc: 0.7411616161616161
2024-10-08 12:48:55,021 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.118928116366819}
2024-10-08 12:48:55,021 [INFO] 
2024-10-08 12:50:11,989 [INFO] Step[50/144]: training loss : 0.04415882643312216 TRAIN  loss dict:  {'classification_loss': 0.04415882643312216}
2024-10-08 12:51:06,752 [INFO] Step[100/144]: training loss : 0.05448952862992883 TRAIN  loss dict:  {'classification_loss': 0.05448952862992883}
2024-10-08 12:52:44,009 [INFO] Label accuracies statistics:
2024-10-08 12:52:44,010 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-08 12:52:44,077 [INFO] [43] TRAIN  loss: 0.04800285246973443 acc: 0.9900370713623726
2024-10-08 12:52:44,077 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.04800285246973443}
2024-10-08 12:52:44,077 [INFO] [43] VALIDATION loss: 1.183354935436337 VALIDATION  acc: 0.7159090909090909
2024-10-08 12:52:44,077 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.183354935436337}
2024-10-08 12:52:44,077 [INFO] 
2024-10-08 12:54:01,507 [INFO] Step[50/144]: training loss : 0.0484499042481184 TRAIN  loss dict:  {'classification_loss': 0.0484499042481184}
2024-10-08 12:54:56,096 [INFO] Step[100/144]: training loss : 0.04676426379010081 TRAIN  loss dict:  {'classification_loss': 0.04676426379010081}
2024-10-08 12:56:32,909 [INFO] Label accuracies statistics:
2024-10-08 12:56:32,909 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 12:56:32,976 [INFO] [44] TRAIN  loss: 0.04663712936841572 acc: 0.9886468952734013
2024-10-08 12:56:32,976 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.04663712936841572}
2024-10-08 12:56:32,976 [INFO] [44] VALIDATION loss: 1.1035689408028568 VALIDATION  acc: 0.7323232323232324
2024-10-08 12:56:32,976 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.1035689408028568}
2024-10-08 12:56:32,976 [INFO] 
2024-10-08 12:57:49,696 [INFO] Step[50/144]: training loss : 0.036990935876965524 TRAIN  loss dict:  {'classification_loss': 0.036990935876965524}
2024-10-08 12:58:44,281 [INFO] Step[100/144]: training loss : 0.05532917103730142 TRAIN  loss dict:  {'classification_loss': 0.05532917103730142}
2024-10-08 13:00:21,404 [INFO] Label accuracies statistics:
2024-10-08 13:00:21,404 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.5, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.5, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 13:00:21,472 [INFO] [45] TRAIN  loss: 0.04808987729160839 acc: 0.9895736793327155
2024-10-08 13:00:21,472 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.04808987729160839}
2024-10-08 13:00:21,472 [INFO] [45] VALIDATION loss: 1.1059431559923623 VALIDATION  acc: 0.7247474747474747
2024-10-08 13:00:21,472 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.1059431559923623}
2024-10-08 13:00:21,472 [INFO] 
2024-10-08 13:01:38,371 [INFO] Step[50/144]: training loss : 0.04119608139619231 TRAIN  loss dict:  {'classification_loss': 0.04119608139619231}
2024-10-08 13:02:32,886 [INFO] Step[100/144]: training loss : 0.04861522232182324 TRAIN  loss dict:  {'classification_loss': 0.04861522232182324}
2024-10-08 13:04:10,869 [INFO] Label accuracies statistics:
2024-10-08 13:04:10,869 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-08 13:04:10,934 [INFO] [46] TRAIN  loss: 0.04600147782993089 acc: 0.9884151992585728
2024-10-08 13:04:10,934 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.04600147782993089}
2024-10-08 13:04:10,934 [INFO] [46] VALIDATION loss: 1.1090101898751326 VALIDATION  acc: 0.7361111111111112
2024-10-08 13:04:10,934 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.1090101898751326}
2024-10-08 13:04:10,934 [INFO] 
2024-10-08 13:05:27,842 [INFO] Step[50/144]: training loss : 0.030251797325909137 TRAIN  loss dict:  {'classification_loss': 0.030251797325909137}
2024-10-08 13:06:22,813 [INFO] Step[100/144]: training loss : 0.04029714761301875 TRAIN  loss dict:  {'classification_loss': 0.04029714761301875}
2024-10-08 13:08:00,800 [INFO] Label accuracies statistics:
2024-10-08 13:08:00,800 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.25, 44: 0.25, 45: 0.5, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.25, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 13:08:01,390 [INFO] [47] TRAIN  loss: 0.038690809606729694 acc: 0.9921223354958295
2024-10-08 13:08:01,390 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.038690809606729694}
2024-10-08 13:08:01,390 [INFO] [47] VALIDATION loss: 1.0209737544258435 VALIDATION  acc: 0.75
2024-10-08 13:08:01,390 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.0209737544258435}
2024-10-08 13:08:01,391 [INFO] 
2024-10-08 13:09:18,733 [INFO] Step[50/144]: training loss : 0.032452792245894674 TRAIN  loss dict:  {'classification_loss': 0.032452792245894674}
2024-10-08 13:10:13,658 [INFO] Step[100/144]: training loss : 0.02958912367001176 TRAIN  loss dict:  {'classification_loss': 0.02958912367001176}
2024-10-08 13:11:51,589 [INFO] Label accuracies statistics:
2024-10-08 13:11:51,589 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.0, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 13:11:51,659 [INFO] [48] TRAIN  loss: 0.035361645575095385 acc: 0.9932808155699722
2024-10-08 13:11:51,659 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.035361645575095385}
2024-10-08 13:11:51,659 [INFO] [48] VALIDATION loss: 1.1255438196714278 VALIDATION  acc: 0.7474747474747475
2024-10-08 13:11:51,659 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.1255438196714278}
2024-10-08 13:11:51,659 [INFO] 
2024-10-08 13:13:09,280 [INFO] Step[50/144]: training loss : 0.0321117770113051 TRAIN  loss dict:  {'classification_loss': 0.0321117770113051}
2024-10-08 13:14:04,273 [INFO] Step[100/144]: training loss : 0.039796810522675516 TRAIN  loss dict:  {'classification_loss': 0.039796810522675516}
2024-10-08 13:15:42,453 [INFO] Label accuracies statistics:
2024-10-08 13:15:42,453 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.0, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-08 13:15:42,521 [INFO] [49] TRAIN  loss: 0.03870937034500659 acc: 0.9907321594068582
2024-10-08 13:15:42,521 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.03870937034500659}
2024-10-08 13:15:42,522 [INFO] [49] VALIDATION loss: 1.1315824524671942 VALIDATION  acc: 0.7411616161616161
2024-10-08 13:15:42,522 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.1315824524671942}
2024-10-08 13:15:42,522 [INFO] 
2024-10-08 13:17:00,747 [INFO] Step[50/144]: training loss : 0.03729542271234095 TRAIN  loss dict:  {'classification_loss': 0.03729542271234095}
2024-10-08 13:17:55,729 [INFO] Step[100/144]: training loss : 0.03567129086703062 TRAIN  loss dict:  {'classification_loss': 0.03567129086703062}
2024-10-08 13:19:34,490 [INFO] Label accuracies statistics:
2024-10-08 13:19:34,490 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 13:19:35,057 [INFO] [50] TRAIN  loss: 0.039206619694596156 acc: 0.9914272474513438
2024-10-08 13:19:35,057 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.039206619694596156}
2024-10-08 13:19:35,057 [INFO] [50] VALIDATION loss: 0.9845843052974453 VALIDATION  acc: 0.7638888888888888
2024-10-08 13:19:35,057 [INFO] [50] VALIDATION  loss dict: {'classification_loss': 0.9845843052974453}
2024-10-08 13:19:35,057 [INFO] 
2024-10-08 13:20:53,311 [INFO] Step[50/144]: training loss : 0.03468187129124999 TRAIN  loss dict:  {'classification_loss': 0.03468187129124999}
2024-10-08 13:21:48,577 [INFO] Step[100/144]: training loss : 0.041739771869033576 TRAIN  loss dict:  {'classification_loss': 0.041739771869033576}
2024-10-08 13:23:27,188 [INFO] Label accuracies statistics:
2024-10-08 13:23:27,188 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 13:23:27,257 [INFO] [51] TRAIN  loss: 0.03971862327630839 acc: 0.991890639481001
2024-10-08 13:23:27,257 [INFO] [51] TRAIN  loss dict: {'classification_loss': 0.03971862327630839}
2024-10-08 13:23:27,257 [INFO] [51] VALIDATION loss: 1.0169770100878344 VALIDATION  acc: 0.75
2024-10-08 13:23:27,257 [INFO] [51] VALIDATION  loss dict: {'classification_loss': 1.0169770100878344}
2024-10-08 13:23:27,257 [INFO] 
2024-10-08 13:24:55,122 [INFO] Step[50/144]: training loss : 0.02378801653161645 TRAIN  loss dict:  {'classification_loss': 0.02378801653161645}
2024-10-08 13:25:50,110 [INFO] Step[100/144]: training loss : 0.034744542501866815 TRAIN  loss dict:  {'classification_loss': 0.034744542501866815}
2024-10-08 13:27:28,733 [INFO] Label accuracies statistics:
2024-10-08 13:27:28,733 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 13:27:28,803 [INFO] [52] TRAIN  loss: 0.030184633451022416 acc: 0.9942075996292864
2024-10-08 13:27:28,803 [INFO] [52] TRAIN  loss dict: {'classification_loss': 0.030184633451022416}
2024-10-08 13:27:28,804 [INFO] [52] VALIDATION loss: 1.1010585723927728 VALIDATION  acc: 0.7474747474747475
2024-10-08 13:27:28,804 [INFO] [52] VALIDATION  loss dict: {'classification_loss': 1.1010585723927728}
2024-10-08 13:27:28,804 [INFO] 
2024-10-08 13:28:46,618 [INFO] Step[50/144]: training loss : 0.02600556818768382 TRAIN  loss dict:  {'classification_loss': 0.02600556818768382}
2024-10-08 13:29:41,894 [INFO] Step[100/144]: training loss : 0.02060294504277408 TRAIN  loss dict:  {'classification_loss': 0.02060294504277408}
2024-10-08 13:31:20,044 [INFO] Label accuracies statistics:
2024-10-08 13:31:20,044 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.5, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-08 13:31:20,112 [INFO] [53] TRAIN  loss: 0.024872671893616725 acc: 0.9965245597775718
2024-10-08 13:31:20,112 [INFO] [53] TRAIN  loss dict: {'classification_loss': 0.024872671893616725}
2024-10-08 13:31:20,112 [INFO] [53] VALIDATION loss: 1.117718504500334 VALIDATION  acc: 0.7285353535353535
2024-10-08 13:31:20,112 [INFO] [53] VALIDATION  loss dict: {'classification_loss': 1.117718504500334}
2024-10-08 13:31:20,112 [INFO] 
2024-10-08 13:32:38,888 [INFO] Step[50/144]: training loss : 0.019475107369944452 TRAIN  loss dict:  {'classification_loss': 0.019475107369944452}
2024-10-08 13:33:34,138 [INFO] Step[100/144]: training loss : 0.021511773928068578 TRAIN  loss dict:  {'classification_loss': 0.021511773928068578}
2024-10-08 13:35:12,658 [INFO] Label accuracies statistics:
2024-10-08 13:35:12,658 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 13:35:12,728 [INFO] [54] TRAIN  loss: 0.020755699323166885 acc: 0.9965245597775718
2024-10-08 13:35:12,729 [INFO] [54] TRAIN  loss dict: {'classification_loss': 0.020755699323166885}
2024-10-08 13:35:12,729 [INFO] [54] VALIDATION loss: 1.0702953236522499 VALIDATION  acc: 0.75
2024-10-08 13:35:12,729 [INFO] [54] VALIDATION  loss dict: {'classification_loss': 1.0702953236522499}
2024-10-08 13:35:12,729 [INFO] 
2024-10-08 13:36:31,252 [INFO] Step[50/144]: training loss : 0.03574870388954878 TRAIN  loss dict:  {'classification_loss': 0.03574870388954878}
2024-10-08 13:37:26,384 [INFO] Step[100/144]: training loss : 0.023463527448475362 TRAIN  loss dict:  {'classification_loss': 0.023463527448475362}
2024-10-08 13:39:04,934 [INFO] Label accuracies statistics:
2024-10-08 13:39:04,934 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 13:39:05,002 [INFO] [55] TRAIN  loss: 0.029239350144052878 acc: 0.9937442075996293
2024-10-08 13:39:05,003 [INFO] [55] TRAIN  loss dict: {'classification_loss': 0.029239350144052878}
2024-10-08 13:39:05,003 [INFO] [55] VALIDATION loss: 1.1494578001675781 VALIDATION  acc: 0.7424242424242424
2024-10-08 13:39:05,003 [INFO] [55] VALIDATION  loss dict: {'classification_loss': 1.1494578001675781}
2024-10-08 13:39:05,003 [INFO] 
2024-10-08 13:40:23,153 [INFO] Step[50/144]: training loss : 0.01625941869802773 TRAIN  loss dict:  {'classification_loss': 0.01625941869802773}
2024-10-08 13:41:18,496 [INFO] Step[100/144]: training loss : 0.02054479986894876 TRAIN  loss dict:  {'classification_loss': 0.02054479986894876}
2024-10-08 13:42:56,863 [INFO] Label accuracies statistics:
2024-10-08 13:42:56,864 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.25, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-08 13:42:56,936 [INFO] [56] TRAIN  loss: 0.020302421541095503 acc: 0.9972196478220574
2024-10-08 13:42:56,936 [INFO] [56] TRAIN  loss dict: {'classification_loss': 0.020302421541095503}
2024-10-08 13:42:56,936 [INFO] [56] VALIDATION loss: 1.0868351309801694 VALIDATION  acc: 0.7474747474747475
2024-10-08 13:42:56,936 [INFO] [56] VALIDATION  loss dict: {'classification_loss': 1.0868351309801694}
2024-10-08 13:42:56,936 [INFO] 
2024-10-08 13:44:20,660 [INFO] Step[50/144]: training loss : 0.01772720376495272 TRAIN  loss dict:  {'classification_loss': 0.01772720376495272}
2024-10-08 13:45:15,759 [INFO] Step[100/144]: training loss : 0.020749969761818646 TRAIN  loss dict:  {'classification_loss': 0.020749969761818646}
2024-10-08 13:46:53,911 [INFO] Label accuracies statistics:
2024-10-08 13:46:53,911 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.25, 72: 0.5, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.25, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 13:46:53,982 [INFO] [57] TRAIN  loss: 0.020135572204405133 acc: 0.9965245597775718
2024-10-08 13:46:53,982 [INFO] [57] TRAIN  loss dict: {'classification_loss': 0.020135572204405133}
2024-10-08 13:46:53,982 [INFO] [57] VALIDATION loss: 1.1591995397099741 VALIDATION  acc: 0.7335858585858586
2024-10-08 13:46:53,982 [INFO] [57] VALIDATION  loss dict: {'classification_loss': 1.1591995397099741}
2024-10-08 13:46:53,982 [INFO] 
2024-10-08 13:48:12,546 [INFO] Step[50/144]: training loss : 0.02061438891105354 TRAIN  loss dict:  {'classification_loss': 0.02061438891105354}
2024-10-08 13:49:07,933 [INFO] Step[100/144]: training loss : 0.021346597438678144 TRAIN  loss dict:  {'classification_loss': 0.021346597438678144}
2024-10-08 13:50:46,599 [INFO] Label accuracies statistics:
2024-10-08 13:50:46,599 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-08 13:50:46,668 [INFO] [58] TRAIN  loss: 0.022246705287317228 acc: 0.9958294717330862
2024-10-08 13:50:46,669 [INFO] [58] TRAIN  loss dict: {'classification_loss': 0.022246705287317228}
2024-10-08 13:50:46,669 [INFO] [58] VALIDATION loss: 1.1381251066923141 VALIDATION  acc: 0.7474747474747475
2024-10-08 13:50:46,669 [INFO] [58] VALIDATION  loss dict: {'classification_loss': 1.1381251066923141}
2024-10-08 13:50:46,669 [INFO] 
2024-10-08 13:52:14,484 [INFO] Step[50/144]: training loss : 0.029496482806280255 TRAIN  loss dict:  {'classification_loss': 0.029496482806280255}
2024-10-08 13:53:09,707 [INFO] Step[100/144]: training loss : 0.022399888806976378 TRAIN  loss dict:  {'classification_loss': 0.022399888806976378}
2024-10-08 13:54:48,342 [INFO] Label accuracies statistics:
2024-10-08 13:54:48,343 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.5, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 13:54:48,413 [INFO] [59] TRAIN  loss: 0.02757739750248018 acc: 0.9944392956441149
2024-10-08 13:54:48,413 [INFO] [59] TRAIN  loss dict: {'classification_loss': 0.02757739750248018}
2024-10-08 13:54:48,413 [INFO] [59] VALIDATION loss: 1.149606405860848 VALIDATION  acc: 0.7323232323232324
2024-10-08 13:54:48,413 [INFO] [59] VALIDATION  loss dict: {'classification_loss': 1.149606405860848}
2024-10-08 13:54:48,413 [INFO] 
2024-10-08 13:56:07,296 [INFO] Step[50/144]: training loss : 0.019354873970150947 TRAIN  loss dict:  {'classification_loss': 0.019354873970150947}
2024-10-08 13:57:02,410 [INFO] Step[100/144]: training loss : 0.0173349189478904 TRAIN  loss dict:  {'classification_loss': 0.0173349189478904}
2024-10-08 13:58:40,370 [INFO] Label accuracies statistics:
2024-10-08 13:58:40,370 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 13:58:40,440 [INFO] [60] TRAIN  loss: 0.0210613908226757 acc: 0.9944392956441149
2024-10-08 13:58:40,440 [INFO] [60] TRAIN  loss dict: {'classification_loss': 0.0210613908226757}
2024-10-08 13:58:40,440 [INFO] [60] VALIDATION loss: 1.265160682818128 VALIDATION  acc: 0.7121212121212122
2024-10-08 13:58:40,440 [INFO] [60] VALIDATION  loss dict: {'classification_loss': 1.265160682818128}
2024-10-08 13:58:40,440 [INFO] 
2024-10-08 13:59:58,316 [INFO] Step[50/144]: training loss : 0.018156779995188117 TRAIN  loss dict:  {'classification_loss': 0.018156779995188117}
2024-10-08 14:00:53,176 [INFO] Step[100/144]: training loss : 0.02812047936953604 TRAIN  loss dict:  {'classification_loss': 0.02812047936953604}
2024-10-08 14:02:30,131 [INFO] Label accuracies statistics:
2024-10-08 14:02:30,131 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 14:02:30,203 [INFO] [61] TRAIN  loss: 0.02107930786021623 acc: 0.9958294717330862
2024-10-08 14:02:30,203 [INFO] [61] TRAIN  loss dict: {'classification_loss': 0.02107930786021623}
2024-10-08 14:02:30,203 [INFO] [61] VALIDATION loss: 1.1002704748124987 VALIDATION  acc: 0.7537878787878788
2024-10-08 14:02:30,203 [INFO] [61] VALIDATION  loss dict: {'classification_loss': 1.1002704748124987}
2024-10-08 14:02:30,203 [INFO] 
2024-10-08 14:03:47,489 [INFO] Step[50/144]: training loss : 0.018993502533994615 TRAIN  loss dict:  {'classification_loss': 0.018993502533994615}
2024-10-08 14:04:42,136 [INFO] Step[100/144]: training loss : 0.013291385737247766 TRAIN  loss dict:  {'classification_loss': 0.013291385737247766}
2024-10-08 14:06:19,446 [INFO] Label accuracies statistics:
2024-10-08 14:06:19,446 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 14:06:19,516 [INFO] [62] TRAIN  loss: 0.017016671316620584 acc: 0.9976830398517146
2024-10-08 14:06:19,516 [INFO] [62] TRAIN  loss dict: {'classification_loss': 0.017016671316620584}
2024-10-08 14:06:19,516 [INFO] [62] VALIDATION loss: 1.173032098553247 VALIDATION  acc: 0.7424242424242424
2024-10-08 14:06:19,516 [INFO] [62] VALIDATION  loss dict: {'classification_loss': 1.173032098553247}
2024-10-08 14:06:19,516 [INFO] 
2024-10-08 14:07:36,771 [INFO] Step[50/144]: training loss : 0.016526461844332516 TRAIN  loss dict:  {'classification_loss': 0.016526461844332516}
2024-10-08 14:08:31,577 [INFO] Step[100/144]: training loss : 0.018484133798629045 TRAIN  loss dict:  {'classification_loss': 0.018484133798629045}
2024-10-08 14:10:08,292 [INFO] Label accuracies statistics:
2024-10-08 14:10:08,292 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.0, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.5, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 14:10:08,360 [INFO] [63] TRAIN  loss: 0.020243833161657676 acc: 0.9955977757182577
2024-10-08 14:10:08,360 [INFO] [63] TRAIN  loss dict: {'classification_loss': 0.020243833161657676}
2024-10-08 14:10:08,360 [INFO] [63] VALIDATION loss: 1.1440855541990862 VALIDATION  acc: 0.7436868686868687
2024-10-08 14:10:08,360 [INFO] [63] VALIDATION  loss dict: {'classification_loss': 1.1440855541990862}
2024-10-08 14:10:08,360 [INFO] 
2024-10-08 14:11:26,641 [INFO] Step[50/144]: training loss : 0.022825256790965795 TRAIN  loss dict:  {'classification_loss': 0.022825256790965795}
2024-10-08 14:12:21,505 [INFO] Step[100/144]: training loss : 0.015855760499835014 TRAIN  loss dict:  {'classification_loss': 0.015855760499835014}
2024-10-08 14:13:58,470 [INFO] Label accuracies statistics:
2024-10-08 14:13:58,470 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-08 14:13:58,539 [INFO] [64] TRAIN  loss: 0.018997761703859497 acc: 0.9967562557924003
2024-10-08 14:13:58,539 [INFO] [64] TRAIN  loss dict: {'classification_loss': 0.018997761703859497}
2024-10-08 14:13:58,539 [INFO] [64] VALIDATION loss: 1.106247577816248 VALIDATION  acc: 0.7613636363636364
2024-10-08 14:13:58,539 [INFO] [64] VALIDATION  loss dict: {'classification_loss': 1.106247577816248}
2024-10-08 14:13:58,539 [INFO] 
2024-10-08 14:15:20,258 [INFO] Step[50/144]: training loss : 0.01805465148296207 TRAIN  loss dict:  {'classification_loss': 0.01805465148296207}
2024-10-08 14:16:14,852 [INFO] Step[100/144]: training loss : 0.017120428625494243 TRAIN  loss dict:  {'classification_loss': 0.017120428625494243}
2024-10-08 14:17:51,645 [INFO] Label accuracies statistics:
2024-10-08 14:17:51,645 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 14:17:51,713 [INFO] [65] TRAIN  loss: 0.01863973034616922 acc: 0.9960611677479148
2024-10-08 14:17:51,713 [INFO] [65] TRAIN  loss dict: {'classification_loss': 0.01863973034616922}
2024-10-08 14:17:51,713 [INFO] [65] VALIDATION loss: 1.1476940523350128 VALIDATION  acc: 0.7436868686868687
2024-10-08 14:17:51,713 [INFO] [65] VALIDATION  loss dict: {'classification_loss': 1.1476940523350128}
2024-10-08 14:17:51,713 [INFO] 
2024-10-08 14:17:51,713 [INFO] 

***Stop training***


2024-10-08 14:17:51,713 [INFO] 
Testing checkpointed models starting...

2024-10-08 14:18:33,275 [INFO] Label accuracies statistics:
2024-10-08 14:18:33,276 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.6666666666666666, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 1.0, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 0.5, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 1.0, 55: 1.0, 56: 0.5, 57: 0.75, 58: 0.5, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.25, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 0.75, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.5, 116: 0.75, 117: 0.25, 118: 0.75, 119: 0.75, 120: 0.6666666666666666, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.25, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.5, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.25, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.75, 168: 1.0, 169: 0.5, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 1.0, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.5, 198: 0.75}

2024-10-08 14:18:33,341 [INFO] 
Testing accuracy: 0.7661188369152971
