2024-10-10 20:42:38,992 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample 128 gcn features 1024 cnn features vsl for one view (1024 attention)...


2024-10-10 20:44:06,018 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample 128 gcn features 1024 cnn features vsl for one view (1024 attention)...


2024-10-10 20:45:45,112 [INFO] Step[50/144]: training loss : 5.508427495956421 TRAIN  loss dict:  {'classification_loss': 5.508427495956421}
2024-10-10 20:46:45,931 [INFO] Step[100/144]: training loss : 5.430817985534668 TRAIN  loss dict:  {'classification_loss': 5.430817985534668}
2024-10-10 20:49:04,666 [INFO] Label accuracies statistics:
2024-10-10 20:49:04,666 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.25, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.25, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.25, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.25, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.5, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.25, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 20:49:05,207 [INFO] [1] TRAIN  loss: 5.428362008598116 acc: 0.006255792400370714
2024-10-10 20:49:05,207 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.428362008598116}
2024-10-10 20:49:05,207 [INFO] [1] VALIDATION loss: 5.165361051206236 VALIDATION  acc: 0.015151515151515152
2024-10-10 20:49:05,207 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.165361051206236}
2024-10-10 20:49:05,207 [INFO] 
2024-10-10 20:50:43,775 [INFO] Step[50/144]: training loss : 5.133375749588013 TRAIN  loss dict:  {'classification_loss': 5.133375749588013}
2024-10-10 20:51:46,162 [INFO] Step[100/144]: training loss : 4.865037612915039 TRAIN  loss dict:  {'classification_loss': 4.865037612915039}
2024-10-10 20:53:58,728 [INFO] Label accuracies statistics:
2024-10-10 20:53:58,728 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.25, 4: 0.25, 5: 0.0, 6: 0.25, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.25, 24: 0.0, 25: 0.0, 26: 0.5, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.5, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.25, 40: 0.25, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.25, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.0, 62: 0.5, 63: 0.0, 64: 0.75, 65: 0.25, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.5, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.5, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.25, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.25, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.0, 106: 0.0, 107: 0.25, 108: 0.25, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.25, 120: 0.0, 121: 0.0, 122: 0.75, 123: 0.5, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.5, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.5, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.5, 152: 0.25, 153: 0.25, 154: 0.0, 155: 0.25, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.0, 161: 0.0, 162: 0.5, 163: 0.0, 164: 0.0, 165: 0.25, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.5, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 20:53:59,520 [INFO] [2] TRAIN  loss: 4.903768360614777 acc: 0.028730305838739572
2024-10-10 20:53:59,520 [INFO] [2] TRAIN  loss dict: {'classification_loss': 4.903768360614777}
2024-10-10 20:53:59,520 [INFO] [2] VALIDATION loss: 4.520978733345315 VALIDATION  acc: 0.07828282828282829
2024-10-10 20:53:59,520 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.520978733345315}
2024-10-10 20:53:59,520 [INFO] 
2024-10-10 20:55:37,006 [INFO] Step[50/144]: training loss : 4.303955774307251 TRAIN  loss dict:  {'classification_loss': 4.303955774307251}
2024-10-10 20:56:43,182 [INFO] Step[100/144]: training loss : 4.12918071269989 TRAIN  loss dict:  {'classification_loss': 4.12918071269989}
2024-10-10 20:58:54,820 [INFO] Label accuracies statistics:
2024-10-10 20:58:54,820 [INFO] {0: 0.0, 1: 0.3333333333333333, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.5, 10: 0.25, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.0, 24: 0.25, 25: 0.25, 26: 0.5, 27: 0.0, 28: 0.0, 29: 0.75, 30: 0.0, 31: 0.25, 32: 0.25, 33: 0.5, 34: 0.25, 35: 0.0, 36: 0.0, 37: 0.5, 38: 0.0, 39: 0.75, 40: 0.25, 41: 0.0, 42: 0.75, 43: 0.25, 44: 0.0, 45: 0.25, 46: 0.0, 47: 0.25, 48: 0.5, 49: 0.0, 50: 0.25, 51: 0.5, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.5, 62: 0.5, 63: 0.25, 64: 0.25, 65: 0.25, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.25, 73: 0.25, 74: 0.0, 75: 1.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.25, 80: 0.25, 81: 0.25, 82: 0.5, 83: 0.0, 84: 0.0, 85: 0.5, 86: 0.0, 87: 0.25, 88: 0.0, 89: 0.0, 90: 0.25, 91: 0.75, 92: 0.5, 93: 0.5, 94: 0.5, 95: 0.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.0, 102: 0.75, 103: 0.25, 104: 0.5, 105: 1.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.75, 113: 0.25, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.5, 119: 0.0, 120: 0.25, 121: 0.0, 122: 0.5, 123: 0.0, 124: 0.75, 125: 0.25, 126: 0.0, 127: 0.0, 128: 0.75, 129: 0.75, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.25, 134: 1.0, 135: 0.25, 136: 0.25, 137: 0.5, 138: 0.0, 139: 0.25, 140: 0.25, 141: 0.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.25, 147: 0.0, 148: 0.75, 149: 0.5, 150: 0.0, 151: 0.75, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.25, 165: 0.0, 166: 0.25, 167: 0.0, 168: 0.5, 169: 0.0, 170: 0.75, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.75, 175: 0.0, 176: 0.0, 177: 0.75, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.5, 186: 0.0, 187: 0.25, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.25, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 20:58:55,563 [INFO] [3] TRAIN  loss: 4.109114012784428 acc: 0.11051899907321594
2024-10-10 20:58:55,563 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.109114012784428}
2024-10-10 20:58:55,563 [INFO] [3] VALIDATION loss: 3.622937696951407 VALIDATION  acc: 0.20707070707070707
2024-10-10 20:58:55,563 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 3.622937696951407}
2024-10-10 20:58:55,564 [INFO] 
2024-10-10 21:00:34,172 [INFO] Step[50/144]: training loss : 3.471701855659485 TRAIN  loss dict:  {'classification_loss': 3.471701855659485}
2024-10-10 21:01:38,787 [INFO] Step[100/144]: training loss : 3.2863347244262697 TRAIN  loss dict:  {'classification_loss': 3.2863347244262697}
2024-10-10 21:03:50,505 [INFO] Label accuracies statistics:
2024-10-10 21:03:50,506 [INFO] {0: 0.0, 1: 0.6666666666666666, 2: 0.0, 3: 0.5, 4: 0.5, 5: 0.0, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.0, 14: 0.25, 15: 0.3333333333333333, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.5, 23: 0.25, 24: 0.5, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.25, 29: 1.0, 30: 0.0, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.5, 38: 0.25, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.25, 43: 0.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.75, 50: 0.25, 51: 0.75, 52: 0.0, 53: 0.25, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.5, 62: 0.5, 63: 0.25, 64: 0.25, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.5, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.25, 77: 0.0, 78: 0.75, 79: 0.0, 80: 1.0, 81: 0.5, 82: 0.25, 83: 0.0, 84: 0.25, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.25, 90: 0.0, 91: 0.75, 92: 0.5, 93: 0.5, 94: 0.75, 95: 0.5, 96: 0.0, 97: 0.25, 98: 0.25, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.5, 103: 0.0, 104: 0.0, 105: 1.0, 106: 0.0, 107: 0.75, 108: 0.5, 109: 0.25, 110: 0.25, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.75, 115: 0.25, 116: 0.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 1.0, 121: 0.0, 122: 0.5, 123: 0.0, 124: 0.5, 125: 0.25, 126: 0.75, 127: 0.25, 128: 1.0, 129: 1.0, 130: 0.0, 131: 0.25, 132: 0.5, 133: 0.0, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.0, 139: 0.25, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.25, 147: 0.0, 148: 0.25, 149: 0.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.5, 155: 0.25, 156: 0.0, 157: 0.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.0, 161: 0.5, 162: 0.75, 163: 0.0, 164: 0.25, 165: 0.0, 166: 0.0, 167: 0.25, 168: 0.0, 169: 0.0, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.25, 174: 0.5, 175: 0.0, 176: 0.5, 177: 0.75, 178: 0.5, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.5, 188: 0.0, 189: 0.5, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.0, 194: 0.5, 195: 0.0, 196: 0.0, 197: 0.25, 198: 0.0}

2024-10-10 21:03:51,246 [INFO] [4] TRAIN  loss: 3.2884128474526935 acc: 0.2277571825764597
2024-10-10 21:03:51,247 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.2884128474526935}
2024-10-10 21:03:51,247 [INFO] [4] VALIDATION loss: 2.9456539154052734 VALIDATION  acc: 0.3005050505050505
2024-10-10 21:03:51,247 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 2.9456539154052734}
2024-10-10 21:03:51,247 [INFO] 
2024-10-10 21:05:29,745 [INFO] Step[50/144]: training loss : 2.7237408113479615 TRAIN  loss dict:  {'classification_loss': 2.7237408113479615}
2024-10-10 21:06:33,689 [INFO] Step[100/144]: training loss : 2.5372410869598387 TRAIN  loss dict:  {'classification_loss': 2.5372410869598387}
2024-10-10 21:08:46,049 [INFO] Label accuracies statistics:
2024-10-10 21:08:46,049 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.25, 4: 0.25, 5: 0.25, 6: 0.25, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.0, 22: 0.5, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.5, 27: 0.0, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.0, 36: 0.25, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.75, 50: 0.25, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.5, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.5, 62: 0.5, 63: 0.0, 64: 0.25, 65: 0.5, 66: 0.25, 67: 0.25, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.0, 72: 0.5, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.5, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.0, 85: 0.5, 86: 0.25, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.5, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.2, 100: 0.25, 101: 0.5, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.25, 108: 0.75, 109: 0.25, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.75, 115: 0.0, 116: 0.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.75, 126: 0.25, 127: 0.25, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.5, 132: 0.0, 133: 0.25, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.0, 139: 1.0, 140: 0.0, 141: 0.5, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.25, 146: 0.25, 147: 0.5, 148: 0.75, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 0.5, 155: 0.5, 156: 0.25, 157: 0.0, 158: 0.6666666666666666, 159: 0.25, 160: 0.0, 161: 0.5, 162: 0.25, 163: 0.5, 164: 0.25, 165: 0.0, 166: 0.25, 167: 0.0, 168: 0.0, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.0, 173: 0.5, 174: 0.75, 175: 0.0, 176: 0.25, 177: 0.0, 178: 0.5, 179: 0.3333333333333333, 180: 0.25, 181: 0.5, 182: 0.0, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.25, 187: 0.75, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.25, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.25, 197: 0.5, 198: 0.0}

2024-10-10 21:08:46,816 [INFO] [5] TRAIN  loss: 2.5695094101958804 acc: 0.37812789620018533
2024-10-10 21:08:46,816 [INFO] [5] TRAIN  loss dict: {'classification_loss': 2.5695094101958804}
2024-10-10 21:08:46,817 [INFO] [5] VALIDATION loss: 2.452699890843144 VALIDATION  acc: 0.4166666666666667
2024-10-10 21:08:46,817 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.452699890843144}
2024-10-10 21:08:46,817 [INFO] 
2024-10-10 21:10:25,927 [INFO] Step[50/144]: training loss : 2.145801532268524 TRAIN  loss dict:  {'classification_loss': 2.145801532268524}
2024-10-10 21:11:30,475 [INFO] Step[100/144]: training loss : 2.012248876094818 TRAIN  loss dict:  {'classification_loss': 2.012248876094818}
2024-10-10 21:13:40,997 [INFO] Label accuracies statistics:
2024-10-10 21:13:40,997 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.0, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.25, 22: 0.5, 23: 0.5, 24: 0.25, 25: 0.5, 26: 0.0, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.25, 37: 0.75, 38: 0.5, 39: 0.25, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.0, 44: 0.5, 45: 0.25, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.75, 50: 0.25, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.0, 55: 0.5, 56: 0.5, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.25, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.5, 73: 0.25, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.5, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.25, 85: 0.25, 86: 0.25, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.75, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.0, 102: 0.75, 103: 0.5, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.5, 110: 0.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.5, 116: 0.0, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.5, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.0, 126: 0.25, 127: 0.75, 128: 0.75, 129: 0.25, 130: 0.25, 131: 0.5, 132: 0.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.0, 139: 0.75, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.25, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.5, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.25, 153: 0.0, 154: 0.75, 155: 0.0, 156: 0.25, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.25, 162: 1.0, 163: 0.0, 164: 0.25, 165: 0.5, 166: 0.25, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.0, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.25, 179: 0.6666666666666666, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.0, 187: 1.0, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.5, 195: 0.0, 196: 0.0, 197: 1.0, 198: 0.0}

2024-10-10 21:13:41,703 [INFO] [6] TRAIN  loss: 2.0394184067845345 acc: 0.4907321594068582
2024-10-10 21:13:41,704 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.0394184067845345}
2024-10-10 21:13:41,704 [INFO] [6] VALIDATION loss: 2.1039662758509317 VALIDATION  acc: 0.4595959595959596
2024-10-10 21:13:41,704 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.1039662758509317}
2024-10-10 21:13:41,704 [INFO] 
2024-10-10 21:15:19,790 [INFO] Step[50/144]: training loss : 1.701306254863739 TRAIN  loss dict:  {'classification_loss': 1.701306254863739}
2024-10-10 21:16:28,893 [INFO] Step[100/144]: training loss : 1.5961842584609984 TRAIN  loss dict:  {'classification_loss': 1.5961842584609984}
2024-10-10 21:18:36,701 [INFO] Label accuracies statistics:
2024-10-10 21:18:36,701 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.0, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.0, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.0, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.75, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.0, 97: 0.25, 98: 0.5, 99: 1.0, 100: 0.5, 101: 0.5, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.5, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 0.75, 125: 0.75, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.25, 130: 0.75, 131: 0.75, 132: 1.0, 133: 0.5, 134: 0.75, 135: 0.75, 136: 0.5, 137: 0.25, 138: 0.25, 139: 0.25, 140: 0.75, 141: 0.25, 142: 0.25, 143: 1.0, 144: 0.5, 145: 0.0, 146: 0.5, 147: 0.75, 148: 0.5, 149: 0.5, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 0.75, 155: 0.5, 156: 0.25, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.5, 162: 0.5, 163: 0.25, 164: 0.5, 165: 0.25, 166: 0.5, 167: 0.5, 168: 0.25, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.25, 194: 0.5, 195: 0.0, 196: 0.5, 197: 0.75, 198: 0.0}

2024-10-10 21:18:37,481 [INFO] [7] TRAIN  loss: 1.6442967885070376 acc: 0.5776181649675626
2024-10-10 21:18:37,481 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.6442967885070376}
2024-10-10 21:18:37,481 [INFO] [7] VALIDATION loss: 1.8022912895237957 VALIDATION  acc: 0.5492424242424242
2024-10-10 21:18:37,481 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.8022912895237957}
2024-10-10 21:18:37,482 [INFO] 
2024-10-10 21:20:15,506 [INFO] Step[50/144]: training loss : 1.3720728433132172 TRAIN  loss dict:  {'classification_loss': 1.3720728433132172}
2024-10-10 21:21:25,435 [INFO] Step[100/144]: training loss : 1.2416870045661925 TRAIN  loss dict:  {'classification_loss': 1.2416870045661925}
2024-10-10 21:23:32,220 [INFO] Label accuracies statistics:
2024-10-10 21:23:32,221 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 1.0, 38: 0.25, 39: 0.5, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.25, 117: 0.25, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.5, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.0, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.5, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.75, 198: 0.0}

2024-10-10 21:23:33,031 [INFO] [8] TRAIN  loss: 1.2991949713064566 acc: 0.6707599629286376
2024-10-10 21:23:33,031 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.2991949713064566}
2024-10-10 21:23:33,031 [INFO] [8] VALIDATION loss: 1.6069284092496943 VALIDATION  acc: 0.6035353535353535
2024-10-10 21:23:33,031 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.6069284092496943}
2024-10-10 21:23:33,031 [INFO] 
2024-10-10 21:25:11,160 [INFO] Step[50/144]: training loss : 1.1116246962547303 TRAIN  loss dict:  {'classification_loss': 1.1116246962547303}
2024-10-10 21:26:23,662 [INFO] Step[100/144]: training loss : 1.1211298859119416 TRAIN  loss dict:  {'classification_loss': 1.1211298859119416}
2024-10-10 21:28:29,640 [INFO] Label accuracies statistics:
2024-10-10 21:28:29,640 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.0, 8: 0.25, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.5, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.25, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.25, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.75, 102: 0.5, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.25, 107: 0.5, 108: 0.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.25, 128: 1.0, 129: 0.5, 130: 0.25, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.0, 143: 0.5, 144: 0.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.25, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.0, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 0.75, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.0, 185: 1.0, 186: 0.0, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 21:28:30,373 [INFO] [9] TRAIN  loss: 1.0986188393500116 acc: 0.7177942539388322
2024-10-10 21:28:30,373 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.0986188393500116}
2024-10-10 21:28:30,373 [INFO] [9] VALIDATION loss: 1.5194071343651525 VALIDATION  acc: 0.5909090909090909
2024-10-10 21:28:30,373 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.5194071343651525}
2024-10-10 21:28:30,374 [INFO] 
2024-10-10 21:30:07,061 [INFO] Step[50/144]: training loss : 0.8984495174884796 TRAIN  loss dict:  {'classification_loss': 0.8984495174884796}
2024-10-10 21:31:19,541 [INFO] Step[100/144]: training loss : 0.9316051805019379 TRAIN  loss dict:  {'classification_loss': 0.9316051805019379}
2024-10-10 21:33:26,122 [INFO] Label accuracies statistics:
2024-10-10 21:33:26,123 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.0, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.5, 63: 0.5, 64: 0.5, 65: 0.5, 66: 0.5, 67: 0.0, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.0, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.5, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.0, 108: 1.0, 109: 0.5, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 0.75, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 1.0, 134: 0.25, 135: 1.0, 136: 0.5, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.0, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.25, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 21:33:26,905 [INFO] [10] TRAIN  loss: 0.9287581640399165 acc: 0.7594995366079703
2024-10-10 21:33:26,905 [INFO] [10] TRAIN  loss dict: {'classification_loss': 0.9287581640399165}
2024-10-10 21:33:26,906 [INFO] [10] VALIDATION loss: 1.374918426628466 VALIDATION  acc: 0.63510101010101
2024-10-10 21:33:26,906 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.374918426628466}
2024-10-10 21:33:26,906 [INFO] 
2024-10-10 21:35:03,024 [INFO] Step[50/144]: training loss : 0.7981240797042847 TRAIN  loss dict:  {'classification_loss': 0.7981240797042847}
2024-10-10 21:36:14,414 [INFO] Step[100/144]: training loss : 0.7890804272890091 TRAIN  loss dict:  {'classification_loss': 0.7890804272890091}
2024-10-10 21:38:20,391 [INFO] Label accuracies statistics:
2024-10-10 21:38:20,391 [INFO] {0: 0.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.25, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.25, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.5, 141: 0.75, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-10 21:38:21,167 [INFO] [11] TRAIN  loss: 0.7646609997997681 acc: 0.8025949953660797
2024-10-10 21:38:21,167 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.7646609997997681}
2024-10-10 21:38:21,167 [INFO] [11] VALIDATION loss: 1.3443350372491059 VALIDATION  acc: 0.6641414141414141
2024-10-10 21:38:21,167 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.3443350372491059}
2024-10-10 21:38:21,167 [INFO] 
2024-10-10 21:39:57,586 [INFO] Step[50/144]: training loss : 0.6254516083002091 TRAIN  loss dict:  {'classification_loss': 0.6254516083002091}
2024-10-10 21:41:09,317 [INFO] Step[100/144]: training loss : 0.6603507643938065 TRAIN  loss dict:  {'classification_loss': 0.6603507643938065}
2024-10-10 21:43:15,274 [INFO] Label accuracies statistics:
2024-10-10 21:43:15,274 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.5, 144: 0.25, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 1.0, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.25, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-10 21:43:16,054 [INFO] [12] TRAIN  loss: 0.644508247781131 acc: 0.8371177015755329
2024-10-10 21:43:16,054 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.644508247781131}
2024-10-10 21:43:16,054 [INFO] [12] VALIDATION loss: 1.2621574175578576 VALIDATION  acc: 0.6767676767676768
2024-10-10 21:43:16,055 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.2621574175578576}
2024-10-10 21:43:16,055 [INFO] 
2024-10-10 21:44:52,508 [INFO] Step[50/144]: training loss : 0.5591064155101776 TRAIN  loss dict:  {'classification_loss': 0.5591064155101776}
2024-10-10 21:46:04,382 [INFO] Step[100/144]: training loss : 0.5420312035083771 TRAIN  loss dict:  {'classification_loss': 0.5420312035083771}
2024-10-10 21:48:10,642 [INFO] Label accuracies statistics:
2024-10-10 21:48:10,642 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.5, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.25, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.5, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 21:48:10,730 [INFO] [13] TRAIN  loss: 0.5585083617932267 acc: 0.8591288229842446
2024-10-10 21:48:10,730 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.5585083617932267}
2024-10-10 21:48:10,730 [INFO] [13] VALIDATION loss: 1.2641183811205405 VALIDATION  acc: 0.6818181818181818
2024-10-10 21:48:10,730 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.2641183811205405}
2024-10-10 21:48:10,730 [INFO] 
2024-10-10 21:49:46,748 [INFO] Step[50/144]: training loss : 0.4924927419424057 TRAIN  loss dict:  {'classification_loss': 0.4924927419424057}
2024-10-10 21:50:59,138 [INFO] Step[100/144]: training loss : 0.4851591384410858 TRAIN  loss dict:  {'classification_loss': 0.4851591384410858}
2024-10-10 21:53:05,784 [INFO] Label accuracies statistics:
2024-10-10 21:53:05,784 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.0, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.25, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 1.0, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.25, 169: 0.5, 170: 0.25, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 21:53:06,532 [INFO] [14] TRAIN  loss: 0.49852834165924126 acc: 0.8725671918443003
2024-10-10 21:53:06,532 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.49852834165924126}
2024-10-10 21:53:06,532 [INFO] [14] VALIDATION loss: 1.20641986032327 VALIDATION  acc: 0.6805555555555556
2024-10-10 21:53:06,532 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.20641986032327}
2024-10-10 21:53:06,532 [INFO] 
2024-10-10 21:54:43,364 [INFO] Step[50/144]: training loss : 0.41546742647886276 TRAIN  loss dict:  {'classification_loss': 0.41546742647886276}
2024-10-10 21:55:53,408 [INFO] Step[100/144]: training loss : 0.42268011957407 TRAIN  loss dict:  {'classification_loss': 0.42268011957407}
2024-10-10 21:58:00,123 [INFO] Label accuracies statistics:
2024-10-10 21:58:00,124 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 1.0, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.25, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.25, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.0, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 1.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.5, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.0}

2024-10-10 21:58:00,207 [INFO] [15] TRAIN  loss: 0.43163218773487544 acc: 0.8906394810009268
2024-10-10 21:58:00,207 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.43163218773487544}
2024-10-10 21:58:00,207 [INFO] [15] VALIDATION loss: 1.2478603880714487 VALIDATION  acc: 0.6767676767676768
2024-10-10 21:58:00,207 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.2478603880714487}
2024-10-10 21:58:00,207 [INFO] 
2024-10-10 21:59:37,570 [INFO] Step[50/144]: training loss : 0.36100534290075303 TRAIN  loss dict:  {'classification_loss': 0.36100534290075303}
2024-10-10 22:00:48,201 [INFO] Step[100/144]: training loss : 0.36729151517152786 TRAIN  loss dict:  {'classification_loss': 0.36729151517152786}
2024-10-10 22:02:55,935 [INFO] Label accuracies statistics:
2024-10-10 22:02:55,935 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.0, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.25, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.0, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.0, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 22:02:56,018 [INFO] [16] TRAIN  loss: 0.3764233594346378 acc: 0.9061631139944393
2024-10-10 22:02:56,018 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.3764233594346378}
2024-10-10 22:02:56,018 [INFO] [16] VALIDATION loss: 1.245994531446033 VALIDATION  acc: 0.6818181818181818
2024-10-10 22:02:56,018 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.245994531446033}
2024-10-10 22:02:56,019 [INFO] 
2024-10-10 22:04:33,368 [INFO] Step[50/144]: training loss : 0.30535786241292956 TRAIN  loss dict:  {'classification_loss': 0.30535786241292956}
2024-10-10 22:05:43,509 [INFO] Step[100/144]: training loss : 0.31727524995803835 TRAIN  loss dict:  {'classification_loss': 0.31727524995803835}
2024-10-10 22:07:50,055 [INFO] Label accuracies statistics:
2024-10-10 22:07:50,055 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.0, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.0}

2024-10-10 22:07:50,833 [INFO] [17] TRAIN  loss: 0.32897780432055396 acc: 0.9209916589434661
2024-10-10 22:07:50,833 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.32897780432055396}
2024-10-10 22:07:50,834 [INFO] [17] VALIDATION loss: 1.1440617624256346 VALIDATION  acc: 0.6994949494949495
2024-10-10 22:07:50,834 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.1440617624256346}
2024-10-10 22:07:50,834 [INFO] 
2024-10-10 22:09:26,878 [INFO] Step[50/144]: training loss : 0.27571012794971467 TRAIN  loss dict:  {'classification_loss': 0.27571012794971467}
2024-10-10 22:10:38,380 [INFO] Step[100/144]: training loss : 0.29645977780222893 TRAIN  loss dict:  {'classification_loss': 0.29645977780222893}
2024-10-10 22:12:44,732 [INFO] Label accuracies statistics:
2024-10-10 22:12:44,732 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.25, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.5, 141: 0.75, 142: 0.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.0, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 22:12:44,824 [INFO] [18] TRAIN  loss: 0.2914191984778477 acc: 0.9286376274328082
2024-10-10 22:12:44,825 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.2914191984778477}
2024-10-10 22:12:44,825 [INFO] [18] VALIDATION loss: 1.1762367749103793 VALIDATION  acc: 0.702020202020202
2024-10-10 22:12:44,825 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.1762367749103793}
2024-10-10 22:12:44,825 [INFO] 
2024-10-10 22:14:23,690 [INFO] Step[50/144]: training loss : 0.26540841698646545 TRAIN  loss dict:  {'classification_loss': 0.26540841698646545}
2024-10-10 22:15:33,276 [INFO] Step[100/144]: training loss : 0.2782803004980087 TRAIN  loss dict:  {'classification_loss': 0.2782803004980087}
2024-10-10 22:17:40,179 [INFO] Label accuracies statistics:
2024-10-10 22:17:40,179 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.5, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.5, 43: 1.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.5, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.0, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.75, 198: 0.0}

2024-10-10 22:17:40,286 [INFO] [19] TRAIN  loss: 0.29180134025712806 acc: 0.9260889712696941
2024-10-10 22:17:40,286 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.29180134025712806}
2024-10-10 22:17:40,286 [INFO] [19] VALIDATION loss: 1.204281591154911 VALIDATION  acc: 0.6906565656565656
2024-10-10 22:17:40,287 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.204281591154911}
2024-10-10 22:17:40,287 [INFO] 
2024-10-10 22:19:17,955 [INFO] Step[50/144]: training loss : 0.2560351657867432 TRAIN  loss dict:  {'classification_loss': 0.2560351657867432}
2024-10-10 22:20:29,570 [INFO] Step[100/144]: training loss : 0.24483863815665244 TRAIN  loss dict:  {'classification_loss': 0.24483863815665244}
2024-10-10 22:22:36,379 [INFO] Label accuracies statistics:
2024-10-10 22:22:36,380 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.0, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.25, 59: 0.25, 60: 0.25, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.0, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.5, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 22:22:36,454 [INFO] [20] TRAIN  loss: 0.25175950821075177 acc: 0.9413809082483782
2024-10-10 22:22:36,454 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.25175950821075177}
2024-10-10 22:22:36,454 [INFO] [20] VALIDATION loss: 1.1782998982127066 VALIDATION  acc: 0.6906565656565656
2024-10-10 22:22:36,454 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.1782998982127066}
2024-10-10 22:22:36,454 [INFO] 
2024-10-10 22:24:14,062 [INFO] Step[50/144]: training loss : 0.21186179891228676 TRAIN  loss dict:  {'classification_loss': 0.21186179891228676}
2024-10-10 22:25:25,700 [INFO] Step[100/144]: training loss : 0.21433043494820594 TRAIN  loss dict:  {'classification_loss': 0.21433043494820594}
2024-10-10 22:27:31,668 [INFO] Label accuracies statistics:
2024-10-10 22:27:31,668 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.25, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.25, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.5, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 22:27:31,753 [INFO] [21] TRAIN  loss: 0.2107621431350708 acc: 0.9497219647822057
2024-10-10 22:27:31,753 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.2107621431350708}
2024-10-10 22:27:31,753 [INFO] [21] VALIDATION loss: 1.2348148585469634 VALIDATION  acc: 0.696969696969697
2024-10-10 22:27:31,754 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.2348148585469634}
2024-10-10 22:27:31,754 [INFO] 
2024-10-10 22:29:09,069 [INFO] Step[50/144]: training loss : 0.17225367069244385 TRAIN  loss dict:  {'classification_loss': 0.17225367069244385}
2024-10-10 22:30:21,241 [INFO] Step[100/144]: training loss : 0.18826141007244587 TRAIN  loss dict:  {'classification_loss': 0.18826141007244587}
2024-10-10 22:32:27,874 [INFO] Label accuracies statistics:
2024-10-10 22:32:27,874 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.5, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.0, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.75, 135: 0.75, 136: 0.75, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.25, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 22:32:28,657 [INFO] [22] TRAIN  loss: 0.18501938080104688 acc: 0.955746061167748
2024-10-10 22:32:28,657 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.18501938080104688}
2024-10-10 22:32:28,657 [INFO] [22] VALIDATION loss: 1.1113188840724804 VALIDATION  acc: 0.7121212121212122
2024-10-10 22:32:28,657 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.1113188840724804}
2024-10-10 22:32:28,657 [INFO] 
2024-10-10 22:34:06,222 [INFO] Step[50/144]: training loss : 0.14427044078707696 TRAIN  loss dict:  {'classification_loss': 0.14427044078707696}
2024-10-10 22:35:18,840 [INFO] Step[100/144]: training loss : 0.16687735736370088 TRAIN  loss dict:  {'classification_loss': 0.16687735736370088}
2024-10-10 22:37:25,423 [INFO] Label accuracies statistics:
2024-10-10 22:37:25,423 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.0, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.0, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 22:37:25,500 [INFO] [23] TRAIN  loss: 0.16149016513696146 acc: 0.9640871177015755
2024-10-10 22:37:25,500 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.16149016513696146}
2024-10-10 22:37:25,500 [INFO] [23] VALIDATION loss: 1.1793777225194153 VALIDATION  acc: 0.7171717171717171
2024-10-10 22:37:25,500 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.1793777225194153}
2024-10-10 22:37:25,501 [INFO] 
2024-10-10 22:39:01,925 [INFO] Step[50/144]: training loss : 0.15948729395866393 TRAIN  loss dict:  {'classification_loss': 0.15948729395866393}
2024-10-10 22:40:14,513 [INFO] Step[100/144]: training loss : 0.18892280012369156 TRAIN  loss dict:  {'classification_loss': 0.18892280012369156}
2024-10-10 22:42:21,437 [INFO] Label accuracies statistics:
2024-10-10 22:42:21,437 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.0, 72: 1.0, 73: 0.75, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.5, 103: 0.5, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.5, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 22:42:21,526 [INFO] [24] TRAIN  loss: 0.16603035334911612 acc: 0.9608433734939759
2024-10-10 22:42:21,526 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.16603035334911612}
2024-10-10 22:42:21,526 [INFO] [24] VALIDATION loss: 1.2145513536201582 VALIDATION  acc: 0.6982323232323232
2024-10-10 22:42:21,526 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.2145513536201582}
2024-10-10 22:42:21,526 [INFO] 
2024-10-10 22:43:57,528 [INFO] Step[50/144]: training loss : 0.13660080350935458 TRAIN  loss dict:  {'classification_loss': 0.13660080350935458}
2024-10-10 22:45:08,572 [INFO] Step[100/144]: training loss : 0.14974033288657665 TRAIN  loss dict:  {'classification_loss': 0.14974033288657665}
2024-10-10 22:47:15,764 [INFO] Label accuracies statistics:
2024-10-10 22:47:15,764 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 1.0, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 22:47:15,842 [INFO] [25] TRAIN  loss: 0.14794253180217412 acc: 0.9640871177015755
2024-10-10 22:47:15,842 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.14794253180217412}
2024-10-10 22:47:15,842 [INFO] [25] VALIDATION loss: 1.1221244317237977 VALIDATION  acc: 0.7335858585858586
2024-10-10 22:47:15,842 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.1221244317237977}
2024-10-10 22:47:15,842 [INFO] 
2024-10-10 22:48:52,655 [INFO] Step[50/144]: training loss : 0.13927415609359742 TRAIN  loss dict:  {'classification_loss': 0.13927415609359742}
2024-10-10 22:50:03,996 [INFO] Step[100/144]: training loss : 0.13740225315093993 TRAIN  loss dict:  {'classification_loss': 0.13740225315093993}
2024-10-10 22:52:10,533 [INFO] Label accuracies statistics:
2024-10-10 22:52:10,534 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 22:52:11,288 [INFO] [26] TRAIN  loss: 0.1390161025079174 acc: 0.9670991658943466
2024-10-10 22:52:11,288 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.1390161025079174}
2024-10-10 22:52:11,288 [INFO] [26] VALIDATION loss: 1.0971863736157064 VALIDATION  acc: 0.7222222222222222
2024-10-10 22:52:11,288 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.0971863736157064}
2024-10-10 22:52:11,288 [INFO] 
2024-10-10 22:53:49,067 [INFO] Step[50/144]: training loss : 0.1128486005589366 TRAIN  loss dict:  {'classification_loss': 0.1128486005589366}
2024-10-10 22:55:00,156 [INFO] Step[100/144]: training loss : 0.14410519398748875 TRAIN  loss dict:  {'classification_loss': 0.14410519398748875}
2024-10-10 22:57:06,966 [INFO] Label accuracies statistics:
2024-10-10 22:57:06,967 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.5, 130: 0.5, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.0, 157: 0.5, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.0}

2024-10-10 22:57:07,065 [INFO] [27] TRAIN  loss: 0.13439972516304502 acc: 0.9652455977757183
2024-10-10 22:57:07,065 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.13439972516304502}
2024-10-10 22:57:07,065 [INFO] [27] VALIDATION loss: 1.167816771125352 VALIDATION  acc: 0.7171717171717171
2024-10-10 22:57:07,065 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.167816771125352}
2024-10-10 22:57:07,065 [INFO] 
2024-10-10 22:58:42,146 [INFO] Step[50/144]: training loss : 0.12876110561192036 TRAIN  loss dict:  {'classification_loss': 0.12876110561192036}
2024-10-10 22:59:52,868 [INFO] Step[100/144]: training loss : 0.12272153086960316 TRAIN  loss dict:  {'classification_loss': 0.12272153086960316}
2024-10-10 23:01:59,596 [INFO] Label accuracies statistics:
2024-10-10 23:01:59,596 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.5, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 23:01:59,697 [INFO] [28] TRAIN  loss: 0.12571815374152115 acc: 0.9691844300278035
2024-10-10 23:01:59,697 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.12571815374152115}
2024-10-10 23:01:59,697 [INFO] [28] VALIDATION loss: 1.11970638456168 VALIDATION  acc: 0.7411616161616161
2024-10-10 23:01:59,697 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.11970638456168}
2024-10-10 23:01:59,697 [INFO] 
2024-10-10 23:03:36,455 [INFO] Step[50/144]: training loss : 0.11418952994048595 TRAIN  loss dict:  {'classification_loss': 0.11418952994048595}
2024-10-10 23:04:51,831 [INFO] Step[100/144]: training loss : 0.13225479625165462 TRAIN  loss dict:  {'classification_loss': 0.13225479625165462}
2024-10-10 23:06:58,351 [INFO] Label accuracies statistics:
2024-10-10 23:06:58,351 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.5, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.5, 198: 0.5}

2024-10-10 23:06:58,441 [INFO] [29] TRAIN  loss: 0.12577565787877473 acc: 0.9691844300278035
2024-10-10 23:06:58,441 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.12577565787877473}
2024-10-10 23:06:58,441 [INFO] [29] VALIDATION loss: 1.2451062889562712 VALIDATION  acc: 0.7159090909090909
2024-10-10 23:06:58,441 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.2451062889562712}
2024-10-10 23:06:58,441 [INFO] 
2024-10-10 23:08:35,060 [INFO] Step[50/144]: training loss : 0.10753939628601074 TRAIN  loss dict:  {'classification_loss': 0.10753939628601074}
2024-10-10 23:09:46,050 [INFO] Step[100/144]: training loss : 0.10847758732736111 TRAIN  loss dict:  {'classification_loss': 0.10847758732736111}
2024-10-10 23:11:53,391 [INFO] Label accuracies statistics:
2024-10-10 23:11:53,392 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.0, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.25, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.5, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.25, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 23:11:53,476 [INFO] [30] TRAIN  loss: 0.11410009558312595 acc: 0.9726598702502317
2024-10-10 23:11:53,476 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.11410009558312595}
2024-10-10 23:11:53,476 [INFO] [30] VALIDATION loss: 1.2010240080179992 VALIDATION  acc: 0.7121212121212122
2024-10-10 23:11:53,476 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.2010240080179992}
2024-10-10 23:11:53,476 [INFO] 
2024-10-10 23:13:29,159 [INFO] Step[50/144]: training loss : 0.09221194874495268 TRAIN  loss dict:  {'classification_loss': 0.09221194874495268}
2024-10-10 23:14:40,012 [INFO] Step[100/144]: training loss : 0.0987008522450924 TRAIN  loss dict:  {'classification_loss': 0.0987008522450924}
2024-10-10 23:16:46,875 [INFO] Label accuracies statistics:
2024-10-10 23:16:46,875 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 1.0, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.25, 138: 0.75, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.5}

2024-10-10 23:16:46,958 [INFO] [31] TRAIN  loss: 0.09544606715078569 acc: 0.9749768303985171
2024-10-10 23:16:46,958 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.09544606715078569}
2024-10-10 23:16:46,958 [INFO] [31] VALIDATION loss: 1.1767549859704796 VALIDATION  acc: 0.726010101010101
2024-10-10 23:16:46,958 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.1767549859704796}
2024-10-10 23:16:46,959 [INFO] 
2024-10-10 23:18:23,054 [INFO] Step[50/144]: training loss : 0.06975177340209485 TRAIN  loss dict:  {'classification_loss': 0.06975177340209485}
2024-10-10 23:19:34,796 [INFO] Step[100/144]: training loss : 0.09422819439321756 TRAIN  loss dict:  {'classification_loss': 0.09422819439321756}
2024-10-10 23:21:41,837 [INFO] Label accuracies statistics:
2024-10-10 23:21:41,837 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 23:21:41,933 [INFO] [32] TRAIN  loss: 0.08476354139727643 acc: 0.9784522706209453
2024-10-10 23:21:41,933 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.08476354139727643}
2024-10-10 23:21:41,934 [INFO] [32] VALIDATION loss: 1.1366895936705448 VALIDATION  acc: 0.7449494949494949
2024-10-10 23:21:41,934 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.1366895936705448}
2024-10-10 23:21:41,934 [INFO] 
2024-10-10 23:23:17,380 [INFO] Step[50/144]: training loss : 0.08020611755549907 TRAIN  loss dict:  {'classification_loss': 0.08020611755549907}
2024-10-10 23:24:29,077 [INFO] Step[100/144]: training loss : 0.08420479889959097 TRAIN  loss dict:  {'classification_loss': 0.08420479889959097}
2024-10-10 23:26:35,459 [INFO] Label accuracies statistics:
2024-10-10 23:26:35,459 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 1.0, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 23:26:35,547 [INFO] [33] TRAIN  loss: 0.08314961228623158 acc: 0.9833178869323448
2024-10-10 23:26:35,547 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.08314961228623158}
2024-10-10 23:26:35,547 [INFO] [33] VALIDATION loss: 1.124694896241029 VALIDATION  acc: 0.7285353535353535
2024-10-10 23:26:35,547 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 1.124694896241029}
2024-10-10 23:26:35,547 [INFO] 
2024-10-10 23:28:13,706 [INFO] Step[50/144]: training loss : 0.08152349960058927 TRAIN  loss dict:  {'classification_loss': 0.08152349960058927}
2024-10-10 23:29:25,743 [INFO] Step[100/144]: training loss : 0.07065858293324709 TRAIN  loss dict:  {'classification_loss': 0.07065858293324709}
2024-10-10 23:31:32,785 [INFO] Label accuracies statistics:
2024-10-10 23:31:32,785 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 23:31:32,862 [INFO] [34] TRAIN  loss: 0.07856759666982624 acc: 0.9800741427247451
2024-10-10 23:31:32,862 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.07856759666982624}
2024-10-10 23:31:32,862 [INFO] [34] VALIDATION loss: 1.1754403467531558 VALIDATION  acc: 0.7121212121212122
2024-10-10 23:31:32,862 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.1754403467531558}
2024-10-10 23:31:32,863 [INFO] 
2024-10-10 23:33:08,851 [INFO] Step[50/144]: training loss : 0.06391363987699152 TRAIN  loss dict:  {'classification_loss': 0.06391363987699152}
2024-10-10 23:34:20,686 [INFO] Step[100/144]: training loss : 0.07797521635890008 TRAIN  loss dict:  {'classification_loss': 0.07797521635890008}
2024-10-10 23:36:28,374 [INFO] Label accuracies statistics:
2024-10-10 23:36:28,374 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 23:36:29,115 [INFO] [35] TRAIN  loss: 0.07373635503851499 acc: 0.9842446709916589
2024-10-10 23:36:29,115 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.07373635503851499}
2024-10-10 23:36:29,116 [INFO] [35] VALIDATION loss: 1.0839497847137627 VALIDATION  acc: 0.73989898989899
2024-10-10 23:36:29,116 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.0839497847137627}
2024-10-10 23:36:29,116 [INFO] 
2024-10-10 23:38:06,145 [INFO] Step[50/144]: training loss : 0.05561017472296953 TRAIN  loss dict:  {'classification_loss': 0.05561017472296953}
2024-10-10 23:39:18,460 [INFO] Step[100/144]: training loss : 0.05313460245728493 TRAIN  loss dict:  {'classification_loss': 0.05313460245728493}
2024-10-10 23:41:26,839 [INFO] Label accuracies statistics:
2024-10-10 23:41:26,840 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.5, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 23:41:26,936 [INFO] [36] TRAIN  loss: 0.06050725229498413 acc: 0.9895736793327155
2024-10-10 23:41:26,936 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.06050725229498413}
2024-10-10 23:41:26,937 [INFO] [36] VALIDATION loss: 1.0977531850889877 VALIDATION  acc: 0.7474747474747475
2024-10-10 23:41:26,937 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.0977531850889877}
2024-10-10 23:41:26,937 [INFO] 
2024-10-10 23:43:03,890 [INFO] Step[50/144]: training loss : 0.06600985810160637 TRAIN  loss dict:  {'classification_loss': 0.06600985810160637}
2024-10-10 23:44:15,131 [INFO] Step[100/144]: training loss : 0.06884178109467029 TRAIN  loss dict:  {'classification_loss': 0.06884178109467029}
2024-10-10 23:46:21,900 [INFO] Label accuracies statistics:
2024-10-10 23:46:21,900 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.5, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 23:46:21,984 [INFO] [37] TRAIN  loss: 0.06903255666192207 acc: 0.9854031510658017
2024-10-10 23:46:21,984 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.06903255666192207}
2024-10-10 23:46:21,984 [INFO] [37] VALIDATION loss: 1.1231510030726592 VALIDATION  acc: 0.7310606060606061
2024-10-10 23:46:21,984 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.1231510030726592}
2024-10-10 23:46:21,984 [INFO] 
2024-10-10 23:47:58,482 [INFO] Step[50/144]: training loss : 0.055423417612910274 TRAIN  loss dict:  {'classification_loss': 0.055423417612910274}
2024-10-10 23:49:08,295 [INFO] Step[100/144]: training loss : 0.07291723538190126 TRAIN  loss dict:  {'classification_loss': 0.07291723538190126}
2024-10-10 23:51:16,425 [INFO] Label accuracies statistics:
2024-10-10 23:51:16,425 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 23:51:16,512 [INFO] [38] TRAIN  loss: 0.06030192524324068 acc: 0.9870250231696015
2024-10-10 23:51:16,512 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.06030192524324068}
2024-10-10 23:51:16,512 [INFO] [38] VALIDATION loss: 1.1357598917351828 VALIDATION  acc: 0.7323232323232324
2024-10-10 23:51:16,512 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.1357598917351828}
2024-10-10 23:51:16,512 [INFO] 
2024-10-10 23:52:53,517 [INFO] Step[50/144]: training loss : 0.050002510268241165 TRAIN  loss dict:  {'classification_loss': 0.050002510268241165}
2024-10-10 23:54:03,441 [INFO] Step[100/144]: training loss : 0.06593175359070301 TRAIN  loss dict:  {'classification_loss': 0.06593175359070301}
2024-10-10 23:56:10,256 [INFO] Label accuracies statistics:
2024-10-10 23:56:10,256 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.25, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.25, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-10 23:56:10,337 [INFO] [39] TRAIN  loss: 0.05677279952215031 acc: 0.9891102873030584
2024-10-10 23:56:10,337 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.05677279952215031}
2024-10-10 23:56:10,338 [INFO] [39] VALIDATION loss: 1.1416164417233732 VALIDATION  acc: 0.726010101010101
2024-10-10 23:56:10,338 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.1416164417233732}
2024-10-10 23:56:10,338 [INFO] 
2024-10-10 23:57:45,219 [INFO] Step[50/144]: training loss : 0.0478480327129364 TRAIN  loss dict:  {'classification_loss': 0.0478480327129364}
2024-10-10 23:58:56,003 [INFO] Step[100/144]: training loss : 0.061091107856482266 TRAIN  loss dict:  {'classification_loss': 0.061091107856482266}
2024-10-11 00:01:03,610 [INFO] Label accuracies statistics:
2024-10-11 00:01:03,611 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.5, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 00:01:03,705 [INFO] [40] TRAIN  loss: 0.056273678544029176 acc: 0.9854031510658017
2024-10-11 00:01:03,705 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.056273678544029176}
2024-10-11 00:01:03,705 [INFO] [40] VALIDATION loss: 1.268885489139292 VALIDATION  acc: 0.696969696969697
2024-10-11 00:01:03,705 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.268885489139292}
2024-10-11 00:01:03,705 [INFO] 
2024-10-11 00:02:40,397 [INFO] Step[50/144]: training loss : 0.049387756399810315 TRAIN  loss dict:  {'classification_loss': 0.049387756399810315}
2024-10-11 00:03:52,534 [INFO] Step[100/144]: training loss : 0.05069457668811083 TRAIN  loss dict:  {'classification_loss': 0.05069457668811083}
2024-10-11 00:05:59,920 [INFO] Label accuracies statistics:
2024-10-11 00:05:59,920 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-11 00:06:00,004 [INFO] [41] TRAIN  loss: 0.051912167077211455 acc: 0.986793327154773
2024-10-11 00:06:00,004 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.051912167077211455}
2024-10-11 00:06:00,005 [INFO] [41] VALIDATION loss: 1.1685375325657703 VALIDATION  acc: 0.7310606060606061
2024-10-11 00:06:00,005 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.1685375325657703}
2024-10-11 00:06:00,005 [INFO] 
2024-10-11 00:07:37,177 [INFO] Step[50/144]: training loss : 0.04979585241526365 TRAIN  loss dict:  {'classification_loss': 0.04979585241526365}
2024-10-11 00:08:49,132 [INFO] Step[100/144]: training loss : 0.05100740878842771 TRAIN  loss dict:  {'classification_loss': 0.05100740878842771}
2024-10-11 00:10:57,176 [INFO] Label accuracies statistics:
2024-10-11 00:10:57,177 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.75, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.5, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.25, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-11 00:10:57,271 [INFO] [42] TRAIN  loss: 0.04736850076652546 acc: 0.9905004633920297
2024-10-11 00:10:57,271 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.04736850076652546}
2024-10-11 00:10:57,271 [INFO] [42] VALIDATION loss: 1.1517733039541378 VALIDATION  acc: 0.7323232323232324
2024-10-11 00:10:57,271 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.1517733039541378}
2024-10-11 00:10:57,271 [INFO] 
2024-10-11 00:12:35,853 [INFO] Step[50/144]: training loss : 0.045696037113666536 TRAIN  loss dict:  {'classification_loss': 0.045696037113666536}
2024-10-11 00:13:45,289 [INFO] Step[100/144]: training loss : 0.04624619379639625 TRAIN  loss dict:  {'classification_loss': 0.04624619379639625}
2024-10-11 00:15:52,439 [INFO] Label accuracies statistics:
2024-10-11 00:15:52,440 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-11 00:15:52,539 [INFO] [43] TRAIN  loss: 0.04758648698528608 acc: 0.9895736793327155
2024-10-11 00:15:52,539 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.04758648698528608}
2024-10-11 00:15:52,539 [INFO] [43] VALIDATION loss: 1.1731934595025248 VALIDATION  acc: 0.7373737373737373
2024-10-11 00:15:52,540 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.1731934595025248}
2024-10-11 00:15:52,540 [INFO] 
2024-10-11 00:17:29,465 [INFO] Step[50/144]: training loss : 0.03980946539901197 TRAIN  loss dict:  {'classification_loss': 0.03980946539901197}
2024-10-11 00:18:42,257 [INFO] Step[100/144]: training loss : 0.04539421379566193 TRAIN  loss dict:  {'classification_loss': 0.04539421379566193}
2024-10-11 00:20:49,781 [INFO] Label accuracies statistics:
2024-10-11 00:20:49,781 [INFO] {0: 0.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.75, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 00:20:49,865 [INFO] [44] TRAIN  loss: 0.039865086427501716 acc: 0.992354031510658
2024-10-11 00:20:49,865 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.039865086427501716}
2024-10-11 00:20:49,865 [INFO] [44] VALIDATION loss: 1.1804089285433292 VALIDATION  acc: 0.7373737373737373
2024-10-11 00:20:49,866 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.1804089285433292}
2024-10-11 00:20:49,866 [INFO] 
2024-10-11 00:22:26,863 [INFO] Step[50/144]: training loss : 0.03910521634854376 TRAIN  loss dict:  {'classification_loss': 0.03910521634854376}
2024-10-11 00:23:39,542 [INFO] Step[100/144]: training loss : 0.03821375316008926 TRAIN  loss dict:  {'classification_loss': 0.03821375316008926}
2024-10-11 00:25:47,593 [INFO] Label accuracies statistics:
2024-10-11 00:25:47,594 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-11 00:25:48,282 [INFO] [45] TRAIN  loss: 0.039360666288606204 acc: 0.9914272474513438
2024-10-11 00:25:48,283 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.039360666288606204}
2024-10-11 00:25:48,283 [INFO] [45] VALIDATION loss: 1.0659740934907287 VALIDATION  acc: 0.7588383838383839
2024-10-11 00:25:48,283 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.0659740934907287}
2024-10-11 00:25:48,283 [INFO] 
2024-10-11 00:27:25,363 [INFO] Step[50/144]: training loss : 0.034601501561701296 TRAIN  loss dict:  {'classification_loss': 0.034601501561701296}
2024-10-11 00:28:38,153 [INFO] Step[100/144]: training loss : 0.040864432295784354 TRAIN  loss dict:  {'classification_loss': 0.040864432295784354}
2024-10-11 00:30:45,375 [INFO] Label accuracies statistics:
2024-10-11 00:30:45,375 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-11 00:30:45,456 [INFO] [46] TRAIN  loss: 0.040631959793649405 acc: 0.9914272474513438
2024-10-11 00:30:45,456 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.040631959793649405}
2024-10-11 00:30:45,456 [INFO] [46] VALIDATION loss: 1.0954379470053095 VALIDATION  acc: 0.7386363636363636
2024-10-11 00:30:45,456 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.0954379470053095}
2024-10-11 00:30:45,457 [INFO] 
2024-10-11 00:32:22,986 [INFO] Step[50/144]: training loss : 0.044942858861759305 TRAIN  loss dict:  {'classification_loss': 0.044942858861759305}
2024-10-11 00:33:33,992 [INFO] Step[100/144]: training loss : 0.037034669732674955 TRAIN  loss dict:  {'classification_loss': 0.037034669732674955}
2024-10-11 00:35:42,496 [INFO] Label accuracies statistics:
2024-10-11 00:35:42,497 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 00:35:42,567 [INFO] [47] TRAIN  loss: 0.043527818685914904 acc: 0.9893419833178869
2024-10-11 00:35:42,567 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.043527818685914904}
2024-10-11 00:35:42,568 [INFO] [47] VALIDATION loss: 1.103347009461787 VALIDATION  acc: 0.7424242424242424
2024-10-11 00:35:42,568 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.103347009461787}
2024-10-11 00:35:42,568 [INFO] 
2024-10-11 00:37:20,394 [INFO] Step[50/144]: training loss : 0.04426207970827818 TRAIN  loss dict:  {'classification_loss': 0.04426207970827818}
2024-10-11 00:38:30,652 [INFO] Step[100/144]: training loss : 0.03491315147839487 TRAIN  loss dict:  {'classification_loss': 0.03491315147839487}
2024-10-11 00:40:38,417 [INFO] Label accuracies statistics:
2024-10-11 00:40:38,417 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-11 00:40:38,533 [INFO] [48] TRAIN  loss: 0.03829710354006642 acc: 0.9911955514365153
2024-10-11 00:40:38,533 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.03829710354006642}
2024-10-11 00:40:38,533 [INFO] [48] VALIDATION loss: 1.1889491417548723 VALIDATION  acc: 0.7297979797979798
2024-10-11 00:40:38,533 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.1889491417548723}
2024-10-11 00:40:38,533 [INFO] 
2024-10-11 00:42:15,374 [INFO] Step[50/144]: training loss : 0.037967891972512005 TRAIN  loss dict:  {'classification_loss': 0.037967891972512005}
2024-10-11 00:43:26,438 [INFO] Step[100/144]: training loss : 0.033361733434721826 TRAIN  loss dict:  {'classification_loss': 0.033361733434721826}
2024-10-11 00:45:33,829 [INFO] Label accuracies statistics:
2024-10-11 00:45:33,829 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.25, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 1.0, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 00:45:33,927 [INFO] [49] TRAIN  loss: 0.03768311425099253 acc: 0.9907321594068582
2024-10-11 00:45:33,927 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.03768311425099253}
2024-10-11 00:45:33,927 [INFO] [49] VALIDATION loss: 1.1311321991185348 VALIDATION  acc: 0.75
2024-10-11 00:45:33,927 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.1311321991185348}
2024-10-11 00:45:33,927 [INFO] 
2024-10-11 00:47:10,910 [INFO] Step[50/144]: training loss : 0.04474024557508528 TRAIN  loss dict:  {'classification_loss': 0.04474024557508528}
2024-10-11 00:48:22,496 [INFO] Step[100/144]: training loss : 0.0358175097592175 TRAIN  loss dict:  {'classification_loss': 0.0358175097592175}
2024-10-11 00:50:30,619 [INFO] Label accuracies statistics:
2024-10-11 00:50:30,620 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.5, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-11 00:50:30,702 [INFO] [50] TRAIN  loss: 0.041419775040897854 acc: 0.9895736793327155
2024-10-11 00:50:30,703 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.041419775040897854}
2024-10-11 00:50:30,703 [INFO] [50] VALIDATION loss: 1.153292842278326 VALIDATION  acc: 0.7512626262626263
2024-10-11 00:50:30,703 [INFO] [50] VALIDATION  loss dict: {'classification_loss': 1.153292842278326}
2024-10-11 00:50:30,703 [INFO] 
2024-10-11 00:52:08,320 [INFO] Step[50/144]: training loss : 0.02978220486547798 TRAIN  loss dict:  {'classification_loss': 0.02978220486547798}
2024-10-11 00:53:21,053 [INFO] Step[100/144]: training loss : 0.02959450242109597 TRAIN  loss dict:  {'classification_loss': 0.02959450242109597}
2024-10-11 00:55:28,588 [INFO] Label accuracies statistics:
2024-10-11 00:55:28,588 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.5, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 00:55:28,689 [INFO] [51] TRAIN  loss: 0.029257061863770813 acc: 0.9928174235403151
2024-10-11 00:55:28,689 [INFO] [51] TRAIN  loss dict: {'classification_loss': 0.029257061863770813}
2024-10-11 00:55:28,689 [INFO] [51] VALIDATION loss: 1.1332234821489289 VALIDATION  acc: 0.75
2024-10-11 00:55:28,689 [INFO] [51] VALIDATION  loss dict: {'classification_loss': 1.1332234821489289}
2024-10-11 00:55:28,689 [INFO] 
2024-10-11 00:57:06,239 [INFO] Step[50/144]: training loss : 0.033117846306413415 TRAIN  loss dict:  {'classification_loss': 0.033117846306413415}
2024-10-11 00:58:18,033 [INFO] Step[100/144]: training loss : 0.02979472029954195 TRAIN  loss dict:  {'classification_loss': 0.02979472029954195}
2024-10-11 01:00:26,343 [INFO] Label accuracies statistics:
2024-10-11 01:00:26,343 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-11 01:00:26,430 [INFO] [52] TRAIN  loss: 0.027422331097315893 acc: 0.9960611677479148
2024-10-11 01:00:26,430 [INFO] [52] TRAIN  loss dict: {'classification_loss': 0.027422331097315893}
2024-10-11 01:00:26,430 [INFO] [52] VALIDATION loss: 1.0802787337797108 VALIDATION  acc: 0.7588383838383839
2024-10-11 01:00:26,430 [INFO] [52] VALIDATION  loss dict: {'classification_loss': 1.0802787337797108}
2024-10-11 01:00:26,430 [INFO] 
2024-10-11 01:02:02,825 [INFO] Step[50/144]: training loss : 0.030400920379906892 TRAIN  loss dict:  {'classification_loss': 0.030400920379906892}
2024-10-11 01:03:15,978 [INFO] Step[100/144]: training loss : 0.02389653604477644 TRAIN  loss dict:  {'classification_loss': 0.02389653604477644}
2024-10-11 01:05:23,397 [INFO] Label accuracies statistics:
2024-10-11 01:05:23,397 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 01:05:23,484 [INFO] [53] TRAIN  loss: 0.027474033313208364 acc: 0.9942075996292864
2024-10-11 01:05:23,484 [INFO] [53] TRAIN  loss dict: {'classification_loss': 0.027474033313208364}
2024-10-11 01:05:23,484 [INFO] [53] VALIDATION loss: 1.0948605218350336 VALIDATION  acc: 0.7474747474747475
2024-10-11 01:05:23,484 [INFO] [53] VALIDATION  loss dict: {'classification_loss': 1.0948605218350336}
2024-10-11 01:05:23,484 [INFO] 
2024-10-11 01:07:00,387 [INFO] Step[50/144]: training loss : 0.023100812337361276 TRAIN  loss dict:  {'classification_loss': 0.023100812337361276}
2024-10-11 01:08:11,159 [INFO] Step[100/144]: training loss : 0.033781589725986126 TRAIN  loss dict:  {'classification_loss': 0.033781589725986126}
2024-10-11 01:10:18,335 [INFO] Label accuracies statistics:
2024-10-11 01:10:18,335 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 01:10:18,433 [INFO] [54] TRAIN  loss: 0.028221547977106336 acc: 0.9932808155699722
2024-10-11 01:10:18,433 [INFO] [54] TRAIN  loss dict: {'classification_loss': 0.028221547977106336}
2024-10-11 01:10:18,433 [INFO] [54] VALIDATION loss: 1.099340149546387 VALIDATION  acc: 0.7638888888888888
2024-10-11 01:10:18,433 [INFO] [54] VALIDATION  loss dict: {'classification_loss': 1.099340149546387}
2024-10-11 01:10:18,433 [INFO] 
2024-10-11 01:11:55,463 [INFO] Step[50/144]: training loss : 0.027292276527732612 TRAIN  loss dict:  {'classification_loss': 0.027292276527732612}
2024-10-11 01:13:08,285 [INFO] Step[100/144]: training loss : 0.02742693821899593 TRAIN  loss dict:  {'classification_loss': 0.02742693821899593}
2024-10-11 01:15:15,346 [INFO] Label accuracies statistics:
2024-10-11 01:15:15,347 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.25, 64: 1.0, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.0, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 01:15:15,434 [INFO] [55] TRAIN  loss: 0.02749182852858212 acc: 0.9932808155699722
2024-10-11 01:15:15,434 [INFO] [55] TRAIN  loss dict: {'classification_loss': 0.02749182852858212}
2024-10-11 01:15:15,434 [INFO] [55] VALIDATION loss: 1.1170533334629402 VALIDATION  acc: 0.7462121212121212
2024-10-11 01:15:15,434 [INFO] [55] VALIDATION  loss dict: {'classification_loss': 1.1170533334629402}
2024-10-11 01:15:15,434 [INFO] 
2024-10-11 01:16:52,124 [INFO] Step[50/144]: training loss : 0.02775727903470397 TRAIN  loss dict:  {'classification_loss': 0.02775727903470397}
2024-10-11 01:18:04,232 [INFO] Step[100/144]: training loss : 0.01987385394051671 TRAIN  loss dict:  {'classification_loss': 0.01987385394051671}
2024-10-11 01:20:13,417 [INFO] Label accuracies statistics:
2024-10-11 01:20:13,417 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.5, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-11 01:20:13,504 [INFO] [56] TRAIN  loss: 0.023220693265708785 acc: 0.9955977757182577
2024-10-11 01:20:13,504 [INFO] [56] TRAIN  loss dict: {'classification_loss': 0.023220693265708785}
2024-10-11 01:20:13,504 [INFO] [56] VALIDATION loss: 1.1256722490544673 VALIDATION  acc: 0.7449494949494949
2024-10-11 01:20:13,504 [INFO] [56] VALIDATION  loss dict: {'classification_loss': 1.1256722490544673}
2024-10-11 01:20:13,504 [INFO] 
2024-10-11 01:21:49,751 [INFO] Step[50/144]: training loss : 0.02359351552091539 TRAIN  loss dict:  {'classification_loss': 0.02359351552091539}
2024-10-11 01:23:03,776 [INFO] Step[100/144]: training loss : 0.02278506207279861 TRAIN  loss dict:  {'classification_loss': 0.02278506207279861}
2024-10-11 01:25:10,384 [INFO] Label accuracies statistics:
2024-10-11 01:25:10,385 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.25, 197: 0.5, 198: 0.75}

2024-10-11 01:25:10,462 [INFO] [57] TRAIN  loss: 0.024238674274076603 acc: 0.9939759036144579
2024-10-11 01:25:10,462 [INFO] [57] TRAIN  loss dict: {'classification_loss': 0.024238674274076603}
2024-10-11 01:25:10,462 [INFO] [57] VALIDATION loss: 1.116252112650761 VALIDATION  acc: 0.75
2024-10-11 01:25:10,462 [INFO] [57] VALIDATION  loss dict: {'classification_loss': 1.116252112650761}
2024-10-11 01:25:10,462 [INFO] 
2024-10-11 01:26:47,114 [INFO] Step[50/144]: training loss : 0.026127738705836238 TRAIN  loss dict:  {'classification_loss': 0.026127738705836238}
2024-10-11 01:27:58,075 [INFO] Step[100/144]: training loss : 0.021541032949462535 TRAIN  loss dict:  {'classification_loss': 0.021541032949462535}
2024-10-11 01:30:05,773 [INFO] Label accuracies statistics:
2024-10-11 01:30:05,773 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.5, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.0, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 01:30:05,859 [INFO] [58] TRAIN  loss: 0.02385220627345714 acc: 0.9958294717330862
2024-10-11 01:30:05,859 [INFO] [58] TRAIN  loss dict: {'classification_loss': 0.02385220627345714}
2024-10-11 01:30:05,859 [INFO] [58] VALIDATION loss: 1.1618910001383886 VALIDATION  acc: 0.7424242424242424
2024-10-11 01:30:05,859 [INFO] [58] VALIDATION  loss dict: {'classification_loss': 1.1618910001383886}
2024-10-11 01:30:05,860 [INFO] 
2024-10-11 01:31:43,418 [INFO] Step[50/144]: training loss : 0.022611342072486877 TRAIN  loss dict:  {'classification_loss': 0.022611342072486877}
2024-10-11 01:32:53,311 [INFO] Step[100/144]: training loss : 0.024488626387901603 TRAIN  loss dict:  {'classification_loss': 0.024488626387901603}
2024-10-11 01:35:00,842 [INFO] Label accuracies statistics:
2024-10-11 01:35:00,842 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.0, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-11 01:35:00,937 [INFO] [59] TRAIN  loss: 0.026367403167468082 acc: 0.9942075996292864
2024-10-11 01:35:00,937 [INFO] [59] TRAIN  loss dict: {'classification_loss': 0.026367403167468082}
2024-10-11 01:35:00,937 [INFO] [59] VALIDATION loss: 1.1419464285588927 VALIDATION  acc: 0.73989898989899
2024-10-11 01:35:00,937 [INFO] [59] VALIDATION  loss dict: {'classification_loss': 1.1419464285588927}
2024-10-11 01:35:00,937 [INFO] 
2024-10-11 01:36:39,970 [INFO] Step[50/144]: training loss : 0.01616882157046348 TRAIN  loss dict:  {'classification_loss': 0.01616882157046348}
2024-10-11 01:37:51,378 [INFO] Step[100/144]: training loss : 0.02912876145914197 TRAIN  loss dict:  {'classification_loss': 0.02912876145914197}
2024-10-11 01:39:58,333 [INFO] Label accuracies statistics:
2024-10-11 01:39:58,333 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-11 01:39:58,412 [INFO] [60] TRAIN  loss: 0.02250828619030977 acc: 0.9962928637627433
2024-10-11 01:39:58,412 [INFO] [60] TRAIN  loss dict: {'classification_loss': 0.02250828619030977}
2024-10-11 01:39:58,412 [INFO] [60] VALIDATION loss: 1.0942423678934574 VALIDATION  acc: 0.7462121212121212
2024-10-11 01:39:58,412 [INFO] [60] VALIDATION  loss dict: {'classification_loss': 1.0942423678934574}
2024-10-11 01:39:58,412 [INFO] 
2024-10-11 01:39:58,412 [INFO] 

***Stop training***


2024-10-11 01:39:58,413 [INFO] 
Testing checkpointed models starting...

2024-10-11 01:41:01,084 [INFO] Label accuracies statistics:
2024-10-11 01:41:01,085 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.0, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.25, 16: 1.0, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 1.0, 23: 1.0, 24: 1.0, 25: 1.0, 26: 1.0, 27: 0.25, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.25, 42: 0.75, 43: 1.0, 44: 1.0, 45: 0.5, 46: 0.75, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 1.0, 52: 0.75, 53: 1.0, 54: 1.0, 55: 1.0, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.25, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 1.0, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.75, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 1.0, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.25, 102: 0.5, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 0.75, 109: 1.0, 110: 0.5, 111: 0.75, 112: 1.0, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.25, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.5, 174: 0.75, 175: 0.5, 176: 0.75, 177: 0.25, 178: 0.75, 179: 0.5, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.25, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-11 01:41:01,159 [INFO] 
Testing accuracy: 0.7623261694058154
