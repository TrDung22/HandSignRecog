2024-10-09 17:04:24,124 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 512 gcn features vsl for one view (1024 + 512 attention)...


2024-10-09 17:04:52,771 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 512 gcn features vsl for one view (1024 + 512 attention)...


2024-10-09 17:06:32,092 [INFO] Step[50/144]: training loss : 5.85501880645752 TRAIN  loss dict:  {'classification_loss': 5.85501880645752}
2024-10-09 17:07:35,328 [INFO] Step[100/144]: training loss : 5.5375277709960935 TRAIN  loss dict:  {'classification_loss': 5.5375277709960935}
2024-10-09 17:09:48,382 [INFO] Label accuracies statistics:
2024-10-09 17:09:48,382 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.75, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 1.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-09 17:09:49,132 [INFO] [1] TRAIN  loss: 5.609477069642809 acc: 0.004865616311399444
2024-10-09 17:09:49,132 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.609477069642809}
2024-10-09 17:09:49,132 [INFO] [1] VALIDATION loss: 5.314296899018465 VALIDATION  acc: 0.010101010101010102
2024-10-09 17:09:49,132 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.314296899018465}
2024-10-09 17:09:49,133 [INFO] 
2024-10-09 17:11:32,772 [INFO] Step[50/144]: training loss : 5.253231115341187 TRAIN  loss dict:  {'classification_loss': 5.253231115341187}
2024-10-09 17:12:39,246 [INFO] Step[100/144]: training loss : 4.993254375457764 TRAIN  loss dict:  {'classification_loss': 4.993254375457764}
2024-10-09 17:14:46,638 [INFO] Label accuracies statistics:
2024-10-09 17:14:46,638 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.25, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.25, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.25, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.25, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.5, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.75, 150: 0.0, 151: 0.5, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.5, 198: 0.0}

2024-10-09 17:14:47,790 [INFO] [2] TRAIN  loss: 5.049190385474099 acc: 0.013901760889712697
2024-10-09 17:14:47,790 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.049190385474099}
2024-10-09 17:14:47,790 [INFO] [2] VALIDATION loss: 4.934315610814978 VALIDATION  acc: 0.03156565656565657
2024-10-09 17:14:47,790 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.934315610814978}
2024-10-09 17:14:47,790 [INFO] 
2024-10-09 17:16:21,986 [INFO] Step[50/144]: training loss : 4.628098106384277 TRAIN  loss dict:  {'classification_loss': 4.628098106384277}
2024-10-09 17:17:30,742 [INFO] Step[100/144]: training loss : 4.432463231086731 TRAIN  loss dict:  {'classification_loss': 4.432463231086731}
2024-10-09 17:19:39,912 [INFO] Label accuracies statistics:
2024-10-09 17:19:39,912 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.75, 4: 0.0, 5: 0.25, 6: 1.0, 7: 0.0, 8: 0.25, 9: 0.5, 10: 0.5, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.25, 23: 0.75, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.75, 29: 0.5, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.25, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.25, 44: 0.0, 45: 0.25, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.25, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.0, 62: 0.25, 63: 0.25, 64: 0.0, 65: 1.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.0, 93: 0.25, 94: 0.25, 95: 0.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.6, 100: 0.0, 101: 0.0, 102: 0.25, 103: 0.0, 104: 0.0, 105: 0.25, 106: 0.25, 107: 0.75, 108: 0.75, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.25, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.25, 135: 0.25, 136: 0.25, 137: 0.0, 138: 0.25, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.5, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.5, 152: 0.25, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.25, 188: 0.0, 189: 0.5, 190: 0.0, 191: 0.0, 192: 0.25, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-09 17:19:40,957 [INFO] [3] TRAIN  loss: 4.455932516190741 acc: 0.049351251158480075
2024-10-09 17:19:40,958 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.455932516190741}
2024-10-09 17:19:40,958 [INFO] [3] VALIDATION loss: 4.2031275519618285 VALIDATION  acc: 0.09848484848484848
2024-10-09 17:19:40,958 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.2031275519618285}
2024-10-09 17:19:40,958 [INFO] 
2024-10-09 17:21:15,794 [INFO] Step[50/144]: training loss : 3.842776727676392 TRAIN  loss dict:  {'classification_loss': 3.842776727676392}
2024-10-09 17:22:24,408 [INFO] Step[100/144]: training loss : 3.6455331945419314 TRAIN  loss dict:  {'classification_loss': 3.6455331945419314}
2024-10-09 17:24:33,002 [INFO] Label accuracies statistics:
2024-10-09 17:24:33,002 [INFO] {0: 0.0, 1: 1.0, 2: 0.0, 3: 0.0, 4: 0.5, 5: 0.0, 6: 0.5, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.25, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.25, 26: 1.0, 27: 0.0, 28: 0.0, 29: 0.75, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.25, 34: 0.75, 35: 0.0, 36: 0.0, 37: 0.0, 38: 1.0, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.25, 47: 0.0, 48: 0.5, 49: 0.25, 50: 0.25, 51: 0.0, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.25, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.75, 66: 0.0, 67: 0.75, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.0, 73: 0.25, 74: 0.5, 75: 0.75, 76: 0.0, 77: 0.25, 78: 0.5, 79: 0.0, 80: 0.5, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.25, 91: 0.75, 92: 0.0, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.25, 97: 0.25, 98: 0.25, 99: 0.6, 100: 0.0, 101: 0.25, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.25, 106: 1.0, 107: 0.0, 108: 0.0, 109: 0.25, 110: 0.0, 111: 0.5, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.25, 116: 0.25, 117: 0.25, 118: 0.75, 119: 0.0, 120: 0.25, 121: 0.0, 122: 0.75, 123: 0.0, 124: 0.25, 125: 0.25, 126: 0.0, 127: 0.25, 128: 0.75, 129: 0.5, 130: 0.0, 131: 0.25, 132: 0.75, 133: 0.75, 134: 0.0, 135: 0.5, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.75, 147: 0.25, 148: 0.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.25, 154: 0.5, 155: 0.0, 156: 1.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.5, 163: 0.0, 164: 0.0, 165: 0.25, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.25, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.75, 174: 0.75, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.25, 184: 0.0, 185: 0.75, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.25, 198: 0.0}

2024-10-09 17:24:34,105 [INFO] [4] TRAIN  loss: 3.6912254757351346 acc: 0.13021316033364227
2024-10-09 17:24:34,105 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.6912254757351346}
2024-10-09 17:24:34,105 [INFO] [4] VALIDATION loss: 3.380969285964966 VALIDATION  acc: 0.20075757575757575
2024-10-09 17:24:34,105 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.380969285964966}
2024-10-09 17:24:34,105 [INFO] 
2024-10-09 17:26:08,322 [INFO] Step[50/144]: training loss : 3.0485650587081907 TRAIN  loss dict:  {'classification_loss': 3.0485650587081907}
2024-10-09 17:27:19,601 [INFO] Step[100/144]: training loss : 2.9586488676071165 TRAIN  loss dict:  {'classification_loss': 2.9586488676071165}
2024-10-09 17:29:29,826 [INFO] Label accuracies statistics:
2024-10-09 17:29:29,826 [INFO] {0: 0.6666666666666666, 1: 0.3333333333333333, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.25, 7: 0.0, 8: 0.0, 9: 0.5, 10: 0.25, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.75, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.0, 23: 0.75, 24: 0.0, 25: 0.25, 26: 1.0, 27: 0.5, 28: 0.25, 29: 1.0, 30: 0.0, 31: 0.0, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.5, 38: 0.5, 39: 0.0, 40: 0.0, 41: 0.5, 42: 0.0, 43: 0.5, 44: 0.5, 45: 0.0, 46: 0.75, 47: 0.5, 48: 0.5, 49: 0.5, 50: 0.0, 51: 0.25, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.25, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.25, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.0, 65: 0.25, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.25, 73: 1.0, 74: 0.0, 75: 0.75, 76: 0.25, 77: 0.25, 78: 1.0, 79: 0.0, 80: 0.25, 81: 0.5, 82: 0.0, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.0, 87: 0.75, 88: 0.0, 89: 0.0, 90: 0.25, 91: 0.5, 92: 0.75, 93: 0.5, 94: 0.0, 95: 0.25, 96: 0.5, 97: 0.0, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.5, 103: 0.0, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.0, 113: 0.0, 114: 0.25, 115: 0.0, 116: 0.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.0, 121: 0.0, 122: 0.75, 123: 0.5, 124: 0.25, 125: 0.75, 126: 0.0, 127: 0.75, 128: 0.75, 129: 0.5, 130: 0.25, 131: 0.0, 132: 0.0, 133: 0.25, 134: 1.0, 135: 0.75, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.5, 140: 0.75, 141: 0.0, 142: 0.25, 143: 0.25, 144: 1.0, 145: 0.25, 146: 0.0, 147: 0.5, 148: 0.0, 149: 0.75, 150: 0.25, 151: 0.5, 152: 0.5, 153: 0.75, 154: 0.25, 155: 0.5, 156: 0.5, 157: 0.0, 158: 0.0, 159: 0.75, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.5, 165: 0.25, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.75, 174: 0.25, 175: 0.0, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.0, 185: 0.5, 186: 0.0, 187: 0.25, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.0, 196: 0.25, 197: 0.25, 198: 0.0}

2024-10-09 17:29:30,886 [INFO] [5] TRAIN  loss: 2.957317754626274 acc: 0.24258572752548657
2024-10-09 17:29:30,886 [INFO] [5] TRAIN  loss dict: {'classification_loss': 2.957317754626274}
2024-10-09 17:29:30,886 [INFO] [5] VALIDATION loss: 2.9087974495357938 VALIDATION  acc: 0.31186868686868685
2024-10-09 17:29:30,886 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.9087974495357938}
2024-10-09 17:29:30,886 [INFO] 
2024-10-09 17:31:04,145 [INFO] Step[50/144]: training loss : 2.4141049575805664 TRAIN  loss dict:  {'classification_loss': 2.4141049575805664}
2024-10-09 17:32:12,501 [INFO] Step[100/144]: training loss : 2.345701427459717 TRAIN  loss dict:  {'classification_loss': 2.345701427459717}
2024-10-09 17:34:18,904 [INFO] Label accuracies statistics:
2024-10-09 17:34:18,904 [INFO] {0: 0.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.5, 19: 0.0, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.25, 25: 0.25, 26: 0.25, 27: 0.25, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.25, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.0, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.0, 53: 0.25, 54: 0.25, 55: 0.25, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.75, 62: 0.25, 63: 0.25, 64: 1.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.25, 70: 0.25, 71: 0.25, 72: 0.5, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.25, 77: 0.0, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.25, 82: 0.5, 83: 0.25, 84: 0.0, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.25, 90: 0.25, 91: 0.5, 92: 0.5, 93: 0.75, 94: 0.25, 95: 0.5, 96: 0.25, 97: 0.25, 98: 0.0, 99: 0.6, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.25, 104: 0.0, 105: 0.75, 106: 0.5, 107: 0.0, 108: 0.25, 109: 1.0, 110: 0.25, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.0, 115: 0.5, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.25, 121: 0.0, 122: 1.0, 123: 0.5, 124: 0.75, 125: 1.0, 126: 0.25, 127: 0.25, 128: 0.75, 129: 0.75, 130: 0.5, 131: 0.75, 132: 0.75, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.0, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.5, 145: 0.0, 146: 0.5, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.75, 151: 0.75, 152: 0.25, 153: 0.0, 154: 1.0, 155: 0.5, 156: 0.25, 157: 0.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.25, 161: 0.5, 162: 0.75, 163: 0.0, 164: 0.0, 165: 1.0, 166: 0.0, 167: 0.0, 168: 0.5, 169: 0.25, 170: 0.0, 171: 0.0, 172: 0.25, 173: 0.75, 174: 0.75, 175: 0.5, 176: 0.25, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.5, 181: 0.5, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.75, 189: 0.0, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.0, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-09 17:34:20,030 [INFO] [6] TRAIN  loss: 2.37823194762071 acc: 0.36886005560704355
2024-10-09 17:34:20,030 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.37823194762071}
2024-10-09 17:34:20,030 [INFO] [6] VALIDATION loss: 2.380862028510482 VALIDATION  acc: 0.4128787878787879
2024-10-09 17:34:20,030 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.380862028510482}
2024-10-09 17:34:20,030 [INFO] 
2024-10-09 17:35:55,245 [INFO] Step[50/144]: training loss : 1.9805839276313781 TRAIN  loss dict:  {'classification_loss': 1.9805839276313781}
2024-10-09 17:37:07,676 [INFO] Step[100/144]: training loss : 1.9029049897193908 TRAIN  loss dict:  {'classification_loss': 1.9029049897193908}
2024-10-09 17:38:56,203 [INFO] Label accuracies statistics:
2024-10-09 17:38:56,203 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.25, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.5, 19: 0.0, 20: 0.0, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.25, 25: 0.0, 26: 0.75, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.0, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.5, 35: 0.25, 36: 0.5, 37: 0.5, 38: 0.0, 39: 0.0, 40: 0.25, 41: 0.0, 42: 1.0, 43: 0.0, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.0, 62: 0.5, 63: 0.25, 64: 0.0, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.5, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.5, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.25, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.5, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.5, 87: 0.25, 88: 0.0, 89: 0.25, 90: 0.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.5, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.0, 115: 0.75, 116: 0.25, 117: 0.25, 118: 0.75, 119: 0.25, 120: 0.5, 121: 0.0, 122: 0.5, 123: 0.5, 124: 0.5, 125: 0.25, 126: 1.0, 127: 0.75, 128: 0.5, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.75, 138: 0.0, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.5, 143: 0.0, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.5, 148: 0.5, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.0, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.0, 169: 0.25, 170: 0.25, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.25, 177: 0.25, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.0, 184: 0.25, 185: 0.75, 186: 0.25, 187: 0.5, 188: 0.5, 189: 0.5, 190: 0.0, 191: 0.25, 192: 1.0, 193: 0.0, 194: 1.0, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-09 17:38:57,107 [INFO] [7] TRAIN  loss: 1.9378194817238383 acc: 0.46825764596848934
2024-10-09 17:38:57,107 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.9378194817238383}
2024-10-09 17:38:57,107 [INFO] [7] VALIDATION loss: 2.1120690548861467 VALIDATION  acc: 0.47095959595959597
2024-10-09 17:38:57,107 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 2.1120690548861467}
2024-10-09 17:38:57,107 [INFO] 
2024-10-09 17:40:15,153 [INFO] Step[50/144]: training loss : 1.6094933128356934 TRAIN  loss dict:  {'classification_loss': 1.6094933128356934}
2024-10-09 17:41:10,457 [INFO] Step[100/144]: training loss : 1.5685487699508667 TRAIN  loss dict:  {'classification_loss': 1.5685487699508667}
2024-10-09 17:42:48,148 [INFO] Label accuracies statistics:
2024-10-09 17:42:48,148 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.0, 8: 0.25, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.5, 23: 0.75, 24: 0.75, 25: 1.0, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.25, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.25, 41: 0.25, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.25, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.75, 72: 0.5, 73: 0.5, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.25, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.0, 85: 0.25, 86: 0.75, 87: 1.0, 88: 0.0, 89: 0.75, 90: 0.0, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.5, 103: 1.0, 104: 0.0, 105: 0.5, 106: 0.5, 107: 0.0, 108: 0.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.25, 127: 0.0, 128: 1.0, 129: 0.5, 130: 0.5, 131: 0.75, 132: 0.0, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.25, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.5, 141: 0.25, 142: 0.0, 143: 0.25, 144: 0.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.0, 151: 0.75, 152: 0.25, 153: 0.0, 154: 0.75, 155: 0.25, 156: 0.25, 157: 0.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.0, 164: 0.25, 165: 0.5, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.25, 171: 0.0, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.25, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.25, 183: 0.0, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.75, 193: 1.0, 194: 0.75, 195: 0.5, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-09 17:42:49,054 [INFO] [8] TRAIN  loss: 1.5931310090753767 acc: 0.541241890639481
2024-10-09 17:42:49,054 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.5931310090753767}
2024-10-09 17:42:49,054 [INFO] [8] VALIDATION loss: 1.976796759499444 VALIDATION  acc: 0.5025252525252525
2024-10-09 17:42:49,054 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.976796759499444}
2024-10-09 17:42:49,054 [INFO] 
2024-10-09 17:44:06,333 [INFO] Step[50/144]: training loss : 1.3397236788272857 TRAIN  loss dict:  {'classification_loss': 1.3397236788272857}
2024-10-09 17:45:01,598 [INFO] Step[100/144]: training loss : 1.287554292678833 TRAIN  loss dict:  {'classification_loss': 1.287554292678833}
2024-10-09 17:46:39,519 [INFO] Label accuracies statistics:
2024-10-09 17:46:39,520 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.0, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.0, 21: 0.25, 22: 0.25, 23: 0.75, 24: 0.25, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.0, 31: 0.25, 32: 0.25, 33: 0.5, 34: 0.25, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.0, 70: 0.5, 71: 0.25, 72: 0.75, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.4, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 0.25, 105: 1.0, 106: 0.25, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.0, 123: 0.5, 124: 0.75, 125: 0.5, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.0, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.25, 145: 0.25, 146: 0.5, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.5, 156: 0.25, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.5, 163: 0.25, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.5, 189: 0.25, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-09 17:46:40,416 [INFO] [9] TRAIN  loss: 1.3072506400446098 acc: 0.6355421686746988
2024-10-09 17:46:40,416 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.3072506400446098}
2024-10-09 17:46:40,416 [INFO] [9] VALIDATION loss: 1.7631949716144137 VALIDATION  acc: 0.5265151515151515
2024-10-09 17:46:40,416 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.7631949716144137}
2024-10-09 17:46:40,416 [INFO] 
2024-10-09 17:47:58,500 [INFO] Step[50/144]: training loss : 1.101626271009445 TRAIN  loss dict:  {'classification_loss': 1.101626271009445}
2024-10-09 17:48:53,883 [INFO] Step[100/144]: training loss : 1.1129069900512696 TRAIN  loss dict:  {'classification_loss': 1.1129069900512696}
2024-10-09 17:50:56,308 [INFO] Label accuracies statistics:
2024-10-09 17:50:56,309 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.5, 23: 0.5, 24: 0.75, 25: 0.0, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.5, 43: 0.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.5, 82: 0.5, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.25, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.25, 130: 0.5, 131: 0.0, 132: 0.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.25, 137: 0.25, 138: 0.0, 139: 0.75, 140: 0.25, 141: 1.0, 142: 0.25, 143: 0.0, 144: 0.25, 145: 0.25, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.25, 156: 0.25, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.25, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.25, 187: 0.75, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-09 17:50:57,412 [INFO] [10] TRAIN  loss: 1.113788814180427 acc: 0.688368860055607
2024-10-09 17:50:57,412 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.113788814180427}
2024-10-09 17:50:57,412 [INFO] [10] VALIDATION loss: 1.5758003393809001 VALIDATION  acc: 0.5757575757575758
2024-10-09 17:50:57,412 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.5758003393809001}
2024-10-09 17:50:57,412 [INFO] 
2024-10-09 17:52:35,764 [INFO] Step[50/144]: training loss : 0.8941380405426025 TRAIN  loss dict:  {'classification_loss': 0.8941380405426025}
2024-10-09 17:53:37,296 [INFO] Step[100/144]: training loss : 0.8607225555181504 TRAIN  loss dict:  {'classification_loss': 0.8607225555181504}
2024-10-09 17:55:50,725 [INFO] Label accuracies statistics:
2024-10-09 17:55:50,725 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.75, 34: 0.5, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.0, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.5, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.25, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.5, 103: 0.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.25, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.5, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 0.75, 188: 0.0, 189: 0.5, 190: 0.25, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.0, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-09 17:55:51,812 [INFO] [11] TRAIN  loss: 0.8853515843964286 acc: 0.754633920296571
2024-10-09 17:55:51,812 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.8853515843964286}
2024-10-09 17:55:51,812 [INFO] [11] VALIDATION loss: 1.400836831993527 VALIDATION  acc: 0.6275252525252525
2024-10-09 17:55:51,812 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.400836831993527}
2024-10-09 17:55:51,812 [INFO] 
2024-10-09 17:57:28,982 [INFO] Step[50/144]: training loss : 0.7364506375789642 TRAIN  loss dict:  {'classification_loss': 0.7364506375789642}
2024-10-09 17:58:32,515 [INFO] Step[100/144]: training loss : 0.7538159954547882 TRAIN  loss dict:  {'classification_loss': 0.7538159954547882}
2024-10-09 18:00:48,308 [INFO] Label accuracies statistics:
2024-10-09 18:00:48,308 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.0, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 1.0, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.5, 30: 0.25, 31: 0.25, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.25, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 0.75, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 0.25, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.75, 116: 0.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.5, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.5, 128: 0.75, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 0.5, 135: 1.0, 136: 0.5, 137: 1.0, 138: 0.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.25, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.25, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 1.0, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.25, 183: 0.25, 184: 0.5, 185: 1.0, 186: 0.5, 187: 0.75, 188: 0.0, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 18:00:48,384 [INFO] [12] TRAIN  loss: 0.7530445872495571 acc: 0.7970342910101946
2024-10-09 18:00:48,384 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.7530445872495571}
2024-10-09 18:00:48,384 [INFO] [12] VALIDATION loss: 1.4274259695300349 VALIDATION  acc: 0.6275252525252525
2024-10-09 18:00:48,384 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.4274259695300349}
2024-10-09 18:00:48,385 [INFO] 
2024-10-09 18:02:26,683 [INFO] Step[50/144]: training loss : 0.635327889919281 TRAIN  loss dict:  {'classification_loss': 0.635327889919281}
2024-10-09 18:03:32,031 [INFO] Step[100/144]: training loss : 0.6354972213506699 TRAIN  loss dict:  {'classification_loss': 0.6354972213506699}
2024-10-09 18:05:44,719 [INFO] Label accuracies statistics:
2024-10-09 18:05:44,719 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.0, 67: 0.75, 68: 0.25, 69: 0.0, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.5, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 0.5, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 0.25, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.25, 143: 0.0, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.5, 152: 0.5, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.0, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.25, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 0.75, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-09 18:05:44,805 [INFO] [13] TRAIN  loss: 0.6520829618804984 acc: 0.8204355885078777
2024-10-09 18:05:44,805 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.6520829618804984}
2024-10-09 18:05:44,805 [INFO] [13] VALIDATION loss: 1.408357529728501 VALIDATION  acc: 0.6401515151515151
2024-10-09 18:05:44,805 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.408357529728501}
2024-10-09 18:05:44,805 [INFO] 
2024-10-09 18:07:24,041 [INFO] Step[50/144]: training loss : 0.5523875209689141 TRAIN  loss dict:  {'classification_loss': 0.5523875209689141}
2024-10-09 18:08:30,489 [INFO] Step[100/144]: training loss : 0.566791117489338 TRAIN  loss dict:  {'classification_loss': 0.566791117489338}
2024-10-09 18:10:41,275 [INFO] Label accuracies statistics:
2024-10-09 18:10:41,275 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.25, 84: 0.0, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.0, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.5, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.5, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-09 18:10:42,392 [INFO] [14] TRAIN  loss: 0.5883802332811885 acc: 0.8313253012048193
2024-10-09 18:10:42,392 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.5883802332811885}
2024-10-09 18:10:42,392 [INFO] [14] VALIDATION loss: 1.3827719699453425 VALIDATION  acc: 0.6616161616161617
2024-10-09 18:10:42,392 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.3827719699453425}
2024-10-09 18:10:42,392 [INFO] 
2024-10-09 18:12:21,331 [INFO] Step[50/144]: training loss : 0.49734881192445757 TRAIN  loss dict:  {'classification_loss': 0.49734881192445757}
2024-10-09 18:13:33,167 [INFO] Step[100/144]: training loss : 0.4972741663455963 TRAIN  loss dict:  {'classification_loss': 0.4972741663455963}
2024-10-09 18:15:39,805 [INFO] Label accuracies statistics:
2024-10-09 18:15:39,805 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.25, 127: 1.0, 128: 0.75, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.25, 144: 0.5, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.25, 194: 0.75, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.0}

2024-10-09 18:15:40,908 [INFO] [15] TRAIN  loss: 0.5095183939362565 acc: 0.8591288229842446
2024-10-09 18:15:40,908 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.5095183939362565}
2024-10-09 18:15:40,908 [INFO] [15] VALIDATION loss: 1.283750206232071 VALIDATION  acc: 0.6502525252525253
2024-10-09 18:15:40,908 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.283750206232071}
2024-10-09 18:15:40,908 [INFO] 
2024-10-09 18:17:17,482 [INFO] Step[50/144]: training loss : 0.41164169073104856 TRAIN  loss dict:  {'classification_loss': 0.41164169073104856}
2024-10-09 18:18:29,991 [INFO] Step[100/144]: training loss : 0.45552045702934263 TRAIN  loss dict:  {'classification_loss': 0.45552045702934263}
2024-10-09 18:20:36,721 [INFO] Label accuracies statistics:
2024-10-09 18:20:36,721 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.25, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.75, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.5, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 0.25, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.5, 114: 0.0, 115: 0.5, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.25, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.5, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 0.75, 195: 0.25, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-09 18:20:36,819 [INFO] [16] TRAIN  loss: 0.43643924138612217 acc: 0.8774328081556997
2024-10-09 18:20:36,820 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.43643924138612217}
2024-10-09 18:20:36,820 [INFO] [16] VALIDATION loss: 1.335589488071424 VALIDATION  acc: 0.6565656565656566
2024-10-09 18:20:36,820 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.335589488071424}
2024-10-09 18:20:36,820 [INFO] 
2024-10-09 18:22:14,237 [INFO] Step[50/144]: training loss : 0.3814727309346199 TRAIN  loss dict:  {'classification_loss': 0.3814727309346199}
2024-10-09 18:23:26,168 [INFO] Step[100/144]: training loss : 0.44494125962257386 TRAIN  loss dict:  {'classification_loss': 0.44494125962257386}
2024-10-09 18:25:33,699 [INFO] Label accuracies statistics:
2024-10-09 18:25:33,699 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.25, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 1.0, 69: 0.75, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.25, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.0, 139: 1.0, 140: 0.5, 141: 0.75, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.0, 168: 1.0, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-09 18:25:34,805 [INFO] [17] TRAIN  loss: 0.4201938820381959 acc: 0.8783595922150139
2024-10-09 18:25:34,805 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.4201938820381959}
2024-10-09 18:25:34,806 [INFO] [17] VALIDATION loss: 1.2090408189429178 VALIDATION  acc: 0.7058080808080808
2024-10-09 18:25:34,806 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.2090408189429178}
2024-10-09 18:25:34,806 [INFO] 
2024-10-09 18:27:11,052 [INFO] Step[50/144]: training loss : 0.32317401200532914 TRAIN  loss dict:  {'classification_loss': 0.32317401200532914}
2024-10-09 18:28:21,277 [INFO] Step[100/144]: training loss : 0.4040317988395691 TRAIN  loss dict:  {'classification_loss': 0.4040317988395691}
2024-10-09 18:30:31,504 [INFO] Label accuracies statistics:
2024-10-09 18:30:31,504 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 0.5, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 0.75, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.25, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.5, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.5, 117: 1.0, 118: 0.75, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.25, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-09 18:30:31,604 [INFO] [18] TRAIN  loss: 0.36855273554101586 acc: 0.8943466172381835
2024-10-09 18:30:31,604 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.36855273554101586}
2024-10-09 18:30:31,605 [INFO] [18] VALIDATION loss: 1.3241308486020122 VALIDATION  acc: 0.6654040404040404
2024-10-09 18:30:31,605 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.3241308486020122}
2024-10-09 18:30:31,605 [INFO] 
2024-10-09 18:32:06,764 [INFO] Step[50/144]: training loss : 0.27957297205924986 TRAIN  loss dict:  {'classification_loss': 0.27957297205924986}
2024-10-09 18:33:18,848 [INFO] Step[100/144]: training loss : 0.34703502207994463 TRAIN  loss dict:  {'classification_loss': 0.34703502207994463}
2024-10-09 18:35:25,857 [INFO] Label accuracies statistics:
2024-10-09 18:35:25,857 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.25, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.75, 115: 0.25, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.25, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.0}

2024-10-09 18:35:25,943 [INFO] [19] TRAIN  loss: 0.3241966688591573 acc: 0.9077849860982391
2024-10-09 18:35:25,943 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.3241966688591573}
2024-10-09 18:35:25,943 [INFO] [19] VALIDATION loss: 1.2538254812911704 VALIDATION  acc: 0.6691919191919192
2024-10-09 18:35:25,943 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.2538254812911704}
2024-10-09 18:35:25,943 [INFO] 
2024-10-09 18:37:01,917 [INFO] Step[50/144]: training loss : 0.28978367388248444 TRAIN  loss dict:  {'classification_loss': 0.28978367388248444}
2024-10-09 18:38:13,361 [INFO] Step[100/144]: training loss : 0.34566347792744634 TRAIN  loss dict:  {'classification_loss': 0.34566347792744634}
2024-10-09 18:40:21,432 [INFO] Label accuracies statistics:
2024-10-09 18:40:21,432 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.0, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.0, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.25, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.25, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.25}

2024-10-09 18:40:21,519 [INFO] [20] TRAIN  loss: 0.32465352133537334 acc: 0.9089434661723819
2024-10-09 18:40:21,519 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.32465352133537334}
2024-10-09 18:40:21,519 [INFO] [20] VALIDATION loss: 1.2134597798188527 VALIDATION  acc: 0.6944444444444444
2024-10-09 18:40:21,519 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.2134597798188527}
2024-10-09 18:40:21,519 [INFO] 
2024-10-09 18:41:57,667 [INFO] Step[50/144]: training loss : 0.25284095406532286 TRAIN  loss dict:  {'classification_loss': 0.25284095406532286}
2024-10-09 18:43:08,098 [INFO] Step[100/144]: training loss : 0.23658152893185616 TRAIN  loss dict:  {'classification_loss': 0.23658152893185616}
2024-10-09 18:45:16,245 [INFO] Label accuracies statistics:
2024-10-09 18:45:16,245 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.5, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.75, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-09 18:45:17,368 [INFO] [21] TRAIN  loss: 0.24701849655765626 acc: 0.9341983317886933
2024-10-09 18:45:17,368 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.24701849655765626}
2024-10-09 18:45:17,369 [INFO] [21] VALIDATION loss: 1.1980612956815295 VALIDATION  acc: 0.7032828282828283
2024-10-09 18:45:17,369 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.1980612956815295}
2024-10-09 18:45:17,369 [INFO] 
2024-10-09 18:46:55,473 [INFO] Step[50/144]: training loss : 0.2005260157585144 TRAIN  loss dict:  {'classification_loss': 0.2005260157585144}
2024-10-09 18:48:07,010 [INFO] Step[100/144]: training loss : 0.20351105988025664 TRAIN  loss dict:  {'classification_loss': 0.20351105988025664}
2024-10-09 18:50:14,929 [INFO] Label accuracies statistics:
2024-10-09 18:50:14,929 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.5, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.25, 165: 0.25, 166: 0.75, 167: 0.0, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-09 18:50:16,011 [INFO] [22] TRAIN  loss: 0.21025842911977735 acc: 0.9425393883225208
2024-10-09 18:50:16,011 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.21025842911977735}
2024-10-09 18:50:16,011 [INFO] [22] VALIDATION loss: 1.1833360875370327 VALIDATION  acc: 0.6957070707070707
2024-10-09 18:50:16,011 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.1833360875370327}
2024-10-09 18:50:16,011 [INFO] 
2024-10-09 18:51:50,464 [INFO] Step[50/144]: training loss : 0.18969522714614867 TRAIN  loss dict:  {'classification_loss': 0.18969522714614867}
2024-10-09 18:53:01,749 [INFO] Step[100/144]: training loss : 0.19643400549888612 TRAIN  loss dict:  {'classification_loss': 0.19643400549888612}
2024-10-09 18:55:10,788 [INFO] Label accuracies statistics:
2024-10-09 18:55:10,788 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.0, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-09 18:55:10,874 [INFO] [23] TRAIN  loss: 0.2015458771234585 acc: 0.946014828544949
2024-10-09 18:55:10,874 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.2015458771234585}
2024-10-09 18:55:10,874 [INFO] [23] VALIDATION loss: 1.1936592641803954 VALIDATION  acc: 0.6982323232323232
2024-10-09 18:55:10,874 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.1936592641803954}
2024-10-09 18:55:10,874 [INFO] 
2024-10-09 18:56:47,630 [INFO] Step[50/144]: training loss : 0.2007019554078579 TRAIN  loss dict:  {'classification_loss': 0.2007019554078579}
2024-10-09 18:58:00,726 [INFO] Step[100/144]: training loss : 0.18758827626705168 TRAIN  loss dict:  {'classification_loss': 0.18758827626705168}
2024-10-09 19:00:08,629 [INFO] Label accuracies statistics:
2024-10-09 19:00:08,629 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 1.0, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.25, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.25, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.0, 168: 1.0, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 19:00:08,713 [INFO] [24] TRAIN  loss: 0.18944522469407982 acc: 0.9446246524559777
2024-10-09 19:00:08,713 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.18944522469407982}
2024-10-09 19:00:08,713 [INFO] [24] VALIDATION loss: 1.2714030146598816 VALIDATION  acc: 0.6957070707070707
2024-10-09 19:00:08,713 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.2714030146598816}
2024-10-09 19:00:08,713 [INFO] 
2024-10-09 19:01:45,764 [INFO] Step[50/144]: training loss : 0.17103999748826026 TRAIN  loss dict:  {'classification_loss': 0.17103999748826026}
2024-10-09 19:02:55,755 [INFO] Step[100/144]: training loss : 0.175653417930007 TRAIN  loss dict:  {'classification_loss': 0.175653417930007}
2024-10-09 19:05:03,650 [INFO] Label accuracies statistics:
2024-10-09 19:05:03,650 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.25, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.5, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 1.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.0, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 1.0, 114: 0.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.25, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.5, 144: 0.5, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.5, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 1.0, 178: 0.5, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-09 19:05:03,730 [INFO] [25] TRAIN  loss: 0.17270934242858654 acc: 0.9545875810936052
2024-10-09 19:05:03,730 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.17270934242858654}
2024-10-09 19:05:03,730 [INFO] [25] VALIDATION loss: 1.2173947863004826 VALIDATION  acc: 0.702020202020202
2024-10-09 19:05:03,730 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.2173947863004826}
2024-10-09 19:05:03,730 [INFO] 
2024-10-09 19:06:39,747 [INFO] Step[50/144]: training loss : 0.17272866435348988 TRAIN  loss dict:  {'classification_loss': 0.17272866435348988}
2024-10-09 19:07:50,993 [INFO] Step[100/144]: training loss : 0.14545791644603015 TRAIN  loss dict:  {'classification_loss': 0.14545791644603015}
2024-10-09 19:09:58,889 [INFO] Label accuracies statistics:
2024-10-09 19:09:58,889 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 1.0, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.25, 145: 0.25, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-09 19:09:58,966 [INFO] [26] TRAIN  loss: 0.16387747686045864 acc: 0.9508804448563485
2024-10-09 19:09:58,966 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.16387747686045864}
2024-10-09 19:09:58,966 [INFO] [26] VALIDATION loss: 1.213294310150323 VALIDATION  acc: 0.6893939393939394
2024-10-09 19:09:58,966 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.213294310150323}
2024-10-09 19:09:58,966 [INFO] 
2024-10-09 19:11:33,646 [INFO] Step[50/144]: training loss : 0.15745000444352628 TRAIN  loss dict:  {'classification_loss': 0.15745000444352628}
2024-10-09 19:12:45,855 [INFO] Step[100/144]: training loss : 0.15652390129864216 TRAIN  loss dict:  {'classification_loss': 0.15652390129864216}
2024-10-09 19:14:53,705 [INFO] Label accuracies statistics:
2024-10-09 19:14:53,705 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.25, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 19:14:54,768 [INFO] [27] TRAIN  loss: 0.1592826255493694 acc: 0.9548192771084337
2024-10-09 19:14:54,768 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.1592826255493694}
2024-10-09 19:14:54,769 [INFO] [27] VALIDATION loss: 1.1667143382408 VALIDATION  acc: 0.7032828282828283
2024-10-09 19:14:54,769 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.1667143382408}
2024-10-09 19:14:54,769 [INFO] 
2024-10-09 19:16:30,585 [INFO] Step[50/144]: training loss : 0.13201170202344656 TRAIN  loss dict:  {'classification_loss': 0.13201170202344656}
2024-10-09 19:17:43,209 [INFO] Step[100/144]: training loss : 0.15805019848048688 TRAIN  loss dict:  {'classification_loss': 0.15805019848048688}
2024-10-09 19:19:51,359 [INFO] Label accuracies statistics:
2024-10-09 19:19:51,360 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 1.0, 154: 0.75, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-09 19:19:51,446 [INFO] [28] TRAIN  loss: 0.1468162944721472 acc: 0.9573679332715477
2024-10-09 19:19:51,446 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.1468162944721472}
2024-10-09 19:19:51,446 [INFO] [28] VALIDATION loss: 1.169542021635506 VALIDATION  acc: 0.7247474747474747
2024-10-09 19:19:51,446 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.169542021635506}
2024-10-09 19:19:51,446 [INFO] 
2024-10-09 19:21:25,776 [INFO] Step[50/144]: training loss : 0.12287162706255912 TRAIN  loss dict:  {'classification_loss': 0.12287162706255912}
2024-10-09 19:22:37,091 [INFO] Step[100/144]: training loss : 0.12070334110409021 TRAIN  loss dict:  {'classification_loss': 0.12070334110409021}
2024-10-09 19:24:45,881 [INFO] Label accuracies statistics:
2024-10-09 19:24:45,881 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 1.0, 26: 0.5, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.25, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.5, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-09 19:24:46,963 [INFO] [29] TRAIN  loss: 0.13008131185132596 acc: 0.9654772937905468
2024-10-09 19:24:46,963 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.13008131185132596}
2024-10-09 19:24:46,963 [INFO] [29] VALIDATION loss: 1.0799009954487835 VALIDATION  acc: 0.7095959595959596
2024-10-09 19:24:46,963 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.0799009954487835}
2024-10-09 19:24:46,963 [INFO] 
2024-10-09 19:26:24,646 [INFO] Step[50/144]: training loss : 0.10559871025383473 TRAIN  loss dict:  {'classification_loss': 0.10559871025383473}
2024-10-09 19:27:33,091 [INFO] Step[100/144]: training loss : 0.12587293080985545 TRAIN  loss dict:  {'classification_loss': 0.12587293080985545}
2024-10-09 19:29:41,413 [INFO] Label accuracies statistics:
2024-10-09 19:29:41,414 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.0, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.25, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-09 19:29:41,502 [INFO] [30] TRAIN  loss: 0.12237652124733561 acc: 0.968952734012975
2024-10-09 19:29:41,502 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.12237652124733561}
2024-10-09 19:29:41,502 [INFO] [30] VALIDATION loss: 1.2364357207660321 VALIDATION  acc: 0.6994949494949495
2024-10-09 19:29:41,502 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.2364357207660321}
2024-10-09 19:29:41,503 [INFO] 
2024-10-09 19:31:17,325 [INFO] Step[50/144]: training loss : 0.11001442898064852 TRAIN  loss dict:  {'classification_loss': 0.11001442898064852}
2024-10-09 19:32:26,798 [INFO] Step[100/144]: training loss : 0.10185419246554375 TRAIN  loss dict:  {'classification_loss': 0.10185419246554375}
2024-10-09 19:34:35,649 [INFO] Label accuracies statistics:
2024-10-09 19:34:35,650 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.25, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.25, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.5, 198: 0.5}

2024-10-09 19:34:35,741 [INFO] [31] TRAIN  loss: 0.10649172054965877 acc: 0.9731232622798888
2024-10-09 19:34:35,741 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.10649172054965877}
2024-10-09 19:34:35,742 [INFO] [31] VALIDATION loss: 1.181088857628681 VALIDATION  acc: 0.7234848484848485
2024-10-09 19:34:35,742 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.181088857628681}
2024-10-09 19:34:35,742 [INFO] 
2024-10-09 19:36:13,488 [INFO] Step[50/144]: training loss : 0.09886044517159462 TRAIN  loss dict:  {'classification_loss': 0.09886044517159462}
2024-10-09 19:37:22,635 [INFO] Step[100/144]: training loss : 0.09109639771282672 TRAIN  loss dict:  {'classification_loss': 0.09109639771282672}
2024-10-09 19:39:29,967 [INFO] Label accuracies statistics:
2024-10-09 19:39:29,967 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.0, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-09 19:39:30,061 [INFO] [32] TRAIN  loss: 0.09711365297617805 acc: 0.9763670064874884
2024-10-09 19:39:30,061 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.09711365297617805}
2024-10-09 19:39:30,061 [INFO] [32] VALIDATION loss: 1.164539717413761 VALIDATION  acc: 0.7209595959595959
2024-10-09 19:39:30,061 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.164539717413761}
2024-10-09 19:39:30,062 [INFO] 
2024-10-09 19:41:05,142 [INFO] Step[50/144]: training loss : 0.09565360073000193 TRAIN  loss dict:  {'classification_loss': 0.09565360073000193}
2024-10-09 19:42:16,127 [INFO] Step[100/144]: training loss : 0.08096048187464476 TRAIN  loss dict:  {'classification_loss': 0.08096048187464476}
2024-10-09 19:44:24,753 [INFO] Label accuracies statistics:
2024-10-09 19:44:24,753 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.5, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-09 19:44:24,840 [INFO] [33] TRAIN  loss: 0.09593360159002866 acc: 0.9763670064874884
2024-10-09 19:44:24,840 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.09593360159002866}
2024-10-09 19:44:24,840 [INFO] [33] VALIDATION loss: 1.1141285101572673 VALIDATION  acc: 0.7171717171717171
2024-10-09 19:44:24,841 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 1.1141285101572673}
2024-10-09 19:44:24,841 [INFO] 
2024-10-09 19:46:00,694 [INFO] Step[50/144]: training loss : 0.08825812678784133 TRAIN  loss dict:  {'classification_loss': 0.08825812678784133}
2024-10-09 19:47:10,644 [INFO] Step[100/144]: training loss : 0.0961472393758595 TRAIN  loss dict:  {'classification_loss': 0.0961472393758595}
2024-10-09 19:49:19,685 [INFO] Label accuracies statistics:
2024-10-09 19:49:19,685 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.25, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-09 19:49:19,768 [INFO] [34] TRAIN  loss: 0.09339034062577412 acc: 0.9754402224281742
2024-10-09 19:49:19,768 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.09339034062577412}
2024-10-09 19:49:19,768 [INFO] [34] VALIDATION loss: 1.1563675155242283 VALIDATION  acc: 0.7247474747474747
2024-10-09 19:49:19,768 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.1563675155242283}
2024-10-09 19:49:19,769 [INFO] 
2024-10-09 19:50:57,036 [INFO] Step[50/144]: training loss : 0.08348754841834306 TRAIN  loss dict:  {'classification_loss': 0.08348754841834306}
2024-10-09 19:52:05,899 [INFO] Step[100/144]: training loss : 0.08385758992284537 TRAIN  loss dict:  {'classification_loss': 0.08385758992284537}
2024-10-09 19:54:15,168 [INFO] Label accuracies statistics:
2024-10-09 19:54:15,168 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.25, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.5, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 19:54:15,259 [INFO] [35] TRAIN  loss: 0.08270270800373207 acc: 0.9761353104726599
2024-10-09 19:54:15,259 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.08270270800373207}
2024-10-09 19:54:15,259 [INFO] [35] VALIDATION loss: 1.228915591482763 VALIDATION  acc: 0.7222222222222222
2024-10-09 19:54:15,259 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.228915591482763}
2024-10-09 19:54:15,259 [INFO] 
2024-10-09 19:55:51,397 [INFO] Step[50/144]: training loss : 0.07231253458186984 TRAIN  loss dict:  {'classification_loss': 0.07231253458186984}
2024-10-09 19:57:00,935 [INFO] Step[100/144]: training loss : 0.09880184818059207 TRAIN  loss dict:  {'classification_loss': 0.09880184818059207}
2024-10-09 19:59:09,365 [INFO] Label accuracies statistics:
2024-10-09 19:59:09,365 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.5, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-09 19:59:09,450 [INFO] [36] TRAIN  loss: 0.08167656608081113 acc: 0.977062094531974
2024-10-09 19:59:09,450 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.08167656608081113}
2024-10-09 19:59:09,450 [INFO] [36] VALIDATION loss: 1.200771261834436 VALIDATION  acc: 0.7209595959595959
2024-10-09 19:59:09,450 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.200771261834436}
2024-10-09 19:59:09,450 [INFO] 
2024-10-09 20:00:46,270 [INFO] Step[50/144]: training loss : 0.08148313276469707 TRAIN  loss dict:  {'classification_loss': 0.08148313276469707}
2024-10-09 20:01:54,871 [INFO] Step[100/144]: training loss : 0.07306081756949424 TRAIN  loss dict:  {'classification_loss': 0.07306081756949424}
2024-10-09 20:04:04,861 [INFO] Label accuracies statistics:
2024-10-09 20:04:04,861 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.5}

2024-10-09 20:04:04,962 [INFO] [37] TRAIN  loss: 0.07544691749434504 acc: 0.9807692307692307
2024-10-09 20:04:04,962 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.07544691749434504}
2024-10-09 20:04:04,962 [INFO] [37] VALIDATION loss: 1.2147516718617193 VALIDATION  acc: 0.7070707070707071
2024-10-09 20:04:04,962 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.2147516718617193}
2024-10-09 20:04:04,963 [INFO] 
2024-10-09 20:05:41,458 [INFO] Step[50/144]: training loss : 0.07220262846909463 TRAIN  loss dict:  {'classification_loss': 0.07220262846909463}
2024-10-09 20:06:49,698 [INFO] Step[100/144]: training loss : 0.07092888528481125 TRAIN  loss dict:  {'classification_loss': 0.07092888528481125}
2024-10-09 20:08:57,642 [INFO] Label accuracies statistics:
2024-10-09 20:08:57,642 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-09 20:08:57,750 [INFO] [38] TRAIN  loss: 0.07466681807677054 acc: 0.9805375347544022
2024-10-09 20:08:57,750 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.07466681807677054}
2024-10-09 20:08:57,750 [INFO] [38] VALIDATION loss: 1.1833912873709644 VALIDATION  acc: 0.7323232323232324
2024-10-09 20:08:57,750 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.1833912873709644}
2024-10-09 20:08:57,750 [INFO] 
2024-10-09 20:10:34,170 [INFO] Step[50/144]: training loss : 0.06057231979444623 TRAIN  loss dict:  {'classification_loss': 0.06057231979444623}
2024-10-09 20:11:42,892 [INFO] Step[100/144]: training loss : 0.07993651242926716 TRAIN  loss dict:  {'classification_loss': 0.07993651242926716}
2024-10-09 20:13:51,063 [INFO] Label accuracies statistics:
2024-10-09 20:13:51,063 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-09 20:13:51,152 [INFO] [39] TRAIN  loss: 0.07646815897250134 acc: 0.9810009267840594
2024-10-09 20:13:51,152 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.07646815897250134}
2024-10-09 20:13:51,153 [INFO] [39] VALIDATION loss: 1.231631984313329 VALIDATION  acc: 0.7297979797979798
2024-10-09 20:13:51,153 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.231631984313329}
2024-10-09 20:13:51,153 [INFO] 
2024-10-09 20:15:28,371 [INFO] Step[50/144]: training loss : 0.0774365975894034 TRAIN  loss dict:  {'classification_loss': 0.0774365975894034}
2024-10-09 20:16:36,091 [INFO] Step[100/144]: training loss : 0.08101583670824766 TRAIN  loss dict:  {'classification_loss': 0.08101583670824766}
2024-10-09 20:18:45,896 [INFO] Label accuracies statistics:
2024-10-09 20:18:45,896 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.0, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.25, 197: 0.5, 198: 0.25}

2024-10-09 20:18:45,982 [INFO] [40] TRAIN  loss: 0.07904908616587313 acc: 0.9779888785912882
2024-10-09 20:18:45,982 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.07904908616587313}
2024-10-09 20:18:45,983 [INFO] [40] VALIDATION loss: 1.1902078221793528 VALIDATION  acc: 0.7222222222222222
2024-10-09 20:18:45,983 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.1902078221793528}
2024-10-09 20:18:45,983 [INFO] 
2024-10-09 20:20:21,010 [INFO] Step[50/144]: training loss : 0.06624477559700609 TRAIN  loss dict:  {'classification_loss': 0.06624477559700609}
2024-10-09 20:21:29,409 [INFO] Step[100/144]: training loss : 0.0641015420295298 TRAIN  loss dict:  {'classification_loss': 0.0641015420295298}
2024-10-09 20:23:39,371 [INFO] Label accuracies statistics:
2024-10-09 20:23:39,371 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-09 20:23:39,457 [INFO] [41] TRAIN  loss: 0.06431624033979864 acc: 0.9826227988878591
2024-10-09 20:23:39,457 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.06431624033979864}
2024-10-09 20:23:39,457 [INFO] [41] VALIDATION loss: 1.1286101435069684 VALIDATION  acc: 0.7411616161616161
2024-10-09 20:23:39,457 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.1286101435069684}
2024-10-09 20:23:39,458 [INFO] 
2024-10-09 20:25:16,277 [INFO] Step[50/144]: training loss : 0.059988207146525384 TRAIN  loss dict:  {'classification_loss': 0.059988207146525384}
2024-10-09 20:26:24,532 [INFO] Step[100/144]: training loss : 0.0495535197481513 TRAIN  loss dict:  {'classification_loss': 0.0495535197481513}
2024-10-09 20:28:35,388 [INFO] Label accuracies statistics:
2024-10-09 20:28:35,388 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.0, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.75}

2024-10-09 20:28:35,481 [INFO] [42] TRAIN  loss: 0.05392776447762218 acc: 0.9870250231696015
2024-10-09 20:28:35,481 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.05392776447762218}
2024-10-09 20:28:35,481 [INFO] [42] VALIDATION loss: 1.1876311401526134 VALIDATION  acc: 0.73989898989899
2024-10-09 20:28:35,481 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.1876311401526134}
2024-10-09 20:28:35,481 [INFO] 
2024-10-09 20:30:11,846 [INFO] Step[50/144]: training loss : 0.05228825671598315 TRAIN  loss dict:  {'classification_loss': 0.05228825671598315}
2024-10-09 20:31:20,452 [INFO] Step[100/144]: training loss : 0.05304942976683378 TRAIN  loss dict:  {'classification_loss': 0.05304942976683378}
2024-10-09 20:33:27,563 [INFO] Label accuracies statistics:
2024-10-09 20:33:27,563 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.5, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.0, 143: 0.5, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.5, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-09 20:33:27,657 [INFO] [43] TRAIN  loss: 0.052474514277289726 acc: 0.9865616311399444
2024-10-09 20:33:27,657 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.052474514277289726}
2024-10-09 20:33:27,657 [INFO] [43] VALIDATION loss: 1.1791969432874962 VALIDATION  acc: 0.7146464646464646
2024-10-09 20:33:27,657 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.1791969432874962}
2024-10-09 20:33:27,657 [INFO] 
2024-10-09 20:35:02,279 [INFO] Step[50/144]: training loss : 0.04896597439423203 TRAIN  loss dict:  {'classification_loss': 0.04896597439423203}
2024-10-09 20:36:11,799 [INFO] Step[100/144]: training loss : 0.04975146792829037 TRAIN  loss dict:  {'classification_loss': 0.04975146792829037}
2024-10-09 20:38:20,913 [INFO] Label accuracies statistics:
2024-10-09 20:38:20,913 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.5, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-09 20:38:21,015 [INFO] [44] TRAIN  loss: 0.051013738091569394 acc: 0.9870250231696015
2024-10-09 20:38:21,015 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.051013738091569394}
2024-10-09 20:38:21,015 [INFO] [44] VALIDATION loss: 1.2322075736743432 VALIDATION  acc: 0.7335858585858586
2024-10-09 20:38:21,015 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.2322075736743432}
2024-10-09 20:38:21,016 [INFO] 
2024-10-09 20:38:21,016 [INFO] 

***Stop training***


2024-10-09 20:38:21,017 [INFO] 
Testing checkpointed models starting...

2024-10-09 20:39:21,648 [INFO] Label accuracies statistics:
2024-10-09 20:39:21,648 [INFO] {0: 1.0, 1: 0.75, 2: 1.0, 3: 0.75, 4: 0.0, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.75, 15: 0.0, 16: 1.0, 17: 0.3333333333333333, 18: 0.75, 19: 1.0, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 1.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.5, 53: 1.0, 54: 0.75, 55: 1.0, 56: 0.25, 57: 1.0, 58: 0.75, 59: 0.0, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 1.0, 71: 0.25, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 1.0, 85: 0.5, 86: 0.5, 87: 1.0, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 0.75, 96: 0.25, 97: 0.5, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.5, 104: 0.75, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.25, 109: 0.5, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.25, 115: 0.75, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.25, 130: 0.75, 131: 0.5, 132: 0.75, 133: 0.75, 134: 0.25, 135: 1.0, 136: 0.25, 137: 1.0, 138: 0.0, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.25, 145: 1.0, 146: 0.75, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.0, 164: 0.25, 165: 1.0, 166: 0.25, 167: 0.75, 168: 0.75, 169: 0.25, 170: 0.75, 171: 0.75, 172: 1.0, 173: 0.75, 174: 0.75, 175: 0.5, 176: 1.0, 177: 0.5, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.25, 183: 0.5, 184: 0.0, 185: 1.0, 186: 1.0, 187: 0.75, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.0, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-09 20:39:21,715 [INFO] 
Testing accuracy: 0.7104930467762326
