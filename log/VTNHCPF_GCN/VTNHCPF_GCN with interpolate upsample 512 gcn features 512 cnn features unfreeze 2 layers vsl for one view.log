2024-10-10 13:14:21,439 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample 512 gcn features 512 cnn features unfreeze 2 layers vsl for one view...


2024-10-10 13:15:50,066 [INFO] Step[50/144]: training loss : 5.501416997909546 TRAIN  loss dict:  {'classification_loss': 5.501416997909546}
2024-10-10 13:16:50,744 [INFO] Step[100/144]: training loss : 5.427559251785278 TRAIN  loss dict:  {'classification_loss': 5.427559251785278}
2024-10-10 13:18:41,220 [INFO] Label accuracies statistics:
2024-10-10 13:18:41,221 [INFO] {0: 0.0, 1: 0.0, 2: 0.25, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.25, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.25, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 13:18:41,612 [INFO] [1] TRAIN  loss: 5.434450281990899 acc: 0.006719184430027804
2024-10-10 13:18:41,612 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.434450281990899}
2024-10-10 13:18:41,612 [INFO] [1] VALIDATION loss: 5.262183154070819 VALIDATION  acc: 0.010101010101010102
2024-10-10 13:18:41,612 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.262183154070819}
2024-10-10 13:18:41,612 [INFO] 
2024-10-10 13:20:05,612 [INFO] Step[50/144]: training loss : 5.245606842041016 TRAIN  loss dict:  {'classification_loss': 5.245606842041016}
2024-10-10 13:21:06,828 [INFO] Step[100/144]: training loss : 5.128396034240723 TRAIN  loss dict:  {'classification_loss': 5.128396034240723}
2024-10-10 13:22:51,875 [INFO] Label accuracies statistics:
2024-10-10 13:22:51,875 [INFO] {0: 0.0, 1: 0.0, 2: 0.25, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.75, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.5, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.25, 92: 0.0, 93: 0.25, 94: 0.25, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.25, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.25, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.25, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.5, 135: 0.5, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.25, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.25, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 13:22:52,469 [INFO] [2] TRAIN  loss: 5.11238600148095 acc: 0.012974976830398516
2024-10-10 13:22:52,469 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.11238600148095}
2024-10-10 13:22:52,469 [INFO] [2] VALIDATION loss: 4.92989589549877 VALIDATION  acc: 0.027777777777777776
2024-10-10 13:22:52,469 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.92989589549877}
2024-10-10 13:22:52,469 [INFO] 
2024-10-10 13:24:16,948 [INFO] Step[50/144]: training loss : 4.751087255477906 TRAIN  loss dict:  {'classification_loss': 4.751087255477906}
2024-10-10 13:25:18,674 [INFO] Step[100/144]: training loss : 4.621161193847656 TRAIN  loss dict:  {'classification_loss': 4.621161193847656}
2024-10-10 13:27:04,146 [INFO] Label accuracies statistics:
2024-10-10 13:27:04,146 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.25, 22: 0.0, 23: 0.75, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.25, 35: 0.25, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.5, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.75, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.25, 52: 0.0, 53: 0.0, 54: 0.25, 55: 0.25, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.25, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.25, 74: 0.0, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.0, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.25, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.25, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.25, 102: 0.0, 103: 0.25, 104: 0.25, 105: 0.0, 106: 0.0, 107: 0.25, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.5, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.75, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.25, 125: 0.5, 126: 0.0, 127: 0.25, 128: 0.5, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.75, 135: 0.75, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.25, 142: 0.0, 143: 0.5, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.25, 150: 0.0, 151: 0.5, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.0, 161: 0.25, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.5, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.5, 178: 0.25, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.25, 186: 0.0, 187: 0.25, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 13:27:04,717 [INFO] [3] TRAIN  loss: 4.63456850581699 acc: 0.03707136237256719
2024-10-10 13:27:04,717 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.63456850581699}
2024-10-10 13:27:04,718 [INFO] [3] VALIDATION loss: 4.387802830448857 VALIDATION  acc: 0.08964646464646464
2024-10-10 13:27:04,718 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.387802830448857}
2024-10-10 13:27:04,718 [INFO] 
2024-10-10 13:28:29,298 [INFO] Step[50/144]: training loss : 4.220982003211975 TRAIN  loss dict:  {'classification_loss': 4.220982003211975}
2024-10-10 13:29:31,482 [INFO] Step[100/144]: training loss : 4.0386480045318605 TRAIN  loss dict:  {'classification_loss': 4.0386480045318605}
2024-10-10 13:31:17,178 [INFO] Label accuracies statistics:
2024-10-10 13:31:17,179 [INFO] {0: 0.0, 1: 0.6666666666666666, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.5, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.25, 18: 0.25, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.25, 24: 0.25, 25: 0.0, 26: 0.25, 27: 0.0, 28: 0.25, 29: 0.0, 30: 0.25, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.25, 38: 0.0, 39: 0.5, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.25, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.25, 53: 0.25, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.25, 65: 0.75, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.25, 72: 0.0, 73: 0.25, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.25, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.75, 107: 0.25, 108: 0.0, 109: 0.25, 110: 0.25, 111: 0.5, 112: 0.0, 113: 0.0, 114: 0.5, 115: 0.0, 116: 0.0, 117: 0.25, 118: 0.25, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.5, 124: 0.25, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.75, 129: 0.0, 130: 0.0, 131: 0.75, 132: 0.0, 133: 0.0, 134: 0.75, 135: 0.75, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.25, 140: 0.0, 141: 0.25, 142: 0.5, 143: 0.5, 144: 0.25, 145: 0.0, 146: 0.5, 147: 0.25, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.25, 175: 0.0, 176: 0.0, 177: 0.5, 178: 0.5, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.5, 186: 0.0, 187: 0.5, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.0, 192: 0.25, 193: 0.0, 194: 0.25, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 13:31:17,775 [INFO] [4] TRAIN  loss: 4.041767529315418 acc: 0.10125115848007414
2024-10-10 13:31:17,776 [INFO] [4] TRAIN  loss dict: {'classification_loss': 4.041767529315418}
2024-10-10 13:31:17,776 [INFO] [4] VALIDATION loss: 3.8167974242457636 VALIDATION  acc: 0.1414141414141414
2024-10-10 13:31:17,776 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.8167974242457636}
2024-10-10 13:31:17,776 [INFO] 
2024-10-10 13:32:42,775 [INFO] Step[50/144]: training loss : 3.5732579755783083 TRAIN  loss dict:  {'classification_loss': 3.5732579755783083}
2024-10-10 13:33:44,583 [INFO] Step[100/144]: training loss : 3.3654711198806764 TRAIN  loss dict:  {'classification_loss': 3.3654711198806764}
2024-10-10 13:35:29,357 [INFO] Label accuracies statistics:
2024-10-10 13:35:29,357 [INFO] {0: 0.3333333333333333, 1: 0.0, 2: 0.25, 3: 0.25, 4: 0.0, 5: 0.25, 6: 0.5, 7: 0.0, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.5, 19: 0.0, 20: 0.0, 21: 0.5, 22: 0.5, 23: 0.25, 24: 0.0, 25: 0.0, 26: 0.25, 27: 0.0, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.0, 32: 0.25, 33: 0.0, 34: 0.25, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.75, 39: 0.5, 40: 0.5, 41: 0.0, 42: 0.75, 43: 0.0, 44: 0.25, 45: 0.5, 46: 0.75, 47: 1.0, 48: 0.25, 49: 0.0, 50: 0.5, 51: 0.75, 52: 0.0, 53: 0.5, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.0, 62: 0.75, 63: 0.0, 64: 0.5, 65: 0.5, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.5, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.5, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.25, 93: 0.75, 94: 0.25, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.25, 102: 0.5, 103: 0.0, 104: 0.25, 105: 0.75, 106: 0.5, 107: 0.25, 108: 0.25, 109: 0.25, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.25, 115: 0.0, 116: 0.0, 117: 0.25, 118: 0.25, 119: 0.0, 120: 0.0, 121: 0.25, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.75, 126: 0.0, 127: 0.0, 128: 0.75, 129: 0.25, 130: 0.0, 131: 0.25, 132: 0.25, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.5, 139: 0.5, 140: 0.0, 141: 0.75, 142: 0.25, 143: 0.0, 144: 0.75, 145: 0.0, 146: 0.75, 147: 0.25, 148: 0.5, 149: 0.5, 150: 0.0, 151: 0.75, 152: 0.5, 153: 0.0, 154: 0.75, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.5, 160: 0.0, 161: 0.25, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.25, 166: 0.0, 167: 0.5, 168: 0.75, 169: 0.5, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.25, 179: 0.3333333333333333, 180: 0.5, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.25, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.5, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.5, 198: 0.0}

2024-10-10 13:35:29,926 [INFO] [5] TRAIN  loss: 3.4213891194926367 acc: 0.18697868396663578
2024-10-10 13:35:29,927 [INFO] [5] TRAIN  loss dict: {'classification_loss': 3.4213891194926367}
2024-10-10 13:35:29,927 [INFO] [5] VALIDATION loss: 3.1987027945341886 VALIDATION  acc: 0.2398989898989899
2024-10-10 13:35:29,927 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 3.1987027945341886}
2024-10-10 13:35:29,927 [INFO] 
2024-10-10 13:36:53,840 [INFO] Step[50/144]: training loss : 2.897871356010437 TRAIN  loss dict:  {'classification_loss': 2.897871356010437}
2024-10-10 13:37:55,361 [INFO] Step[100/144]: training loss : 2.781020441055298 TRAIN  loss dict:  {'classification_loss': 2.781020441055298}
2024-10-10 13:39:40,571 [INFO] Label accuracies statistics:
2024-10-10 13:39:40,571 [INFO] {0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.0, 3: 0.5, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.75, 24: 0.5, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.25, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.75, 38: 0.0, 39: 0.5, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.0, 50: 0.25, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.25, 55: 0.5, 56: 0.0, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.25, 61: 0.25, 62: 0.5, 63: 0.25, 64: 1.0, 65: 0.5, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.25, 77: 0.0, 78: 0.5, 79: 0.0, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.25, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.5, 95: 0.5, 96: 0.0, 97: 0.0, 98: 0.5, 99: 0.8, 100: 0.25, 101: 0.25, 102: 0.75, 103: 0.0, 104: 0.25, 105: 0.75, 106: 0.5, 107: 0.25, 108: 0.25, 109: 0.25, 110: 0.25, 111: 0.5, 112: 0.0, 113: 0.0, 114: 0.0, 115: 1.0, 116: 0.0, 117: 0.75, 118: 0.75, 119: 0.5, 120: 0.0, 121: 0.0, 122: 1.0, 123: 0.25, 124: 0.75, 125: 0.5, 126: 0.75, 127: 0.25, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.5, 132: 0.5, 133: 0.25, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.5, 139: 0.0, 140: 0.5, 141: 0.5, 142: 0.25, 143: 0.25, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.0, 151: 0.75, 152: 0.0, 153: 0.75, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.75, 160: 0.0, 161: 0.25, 162: 0.0, 163: 0.0, 164: 0.25, 165: 0.75, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.0, 170: 0.75, 171: 0.25, 172: 0.25, 173: 0.0, 174: 0.25, 175: 0.5, 176: 0.25, 177: 0.75, 178: 0.5, 179: 0.3333333333333333, 180: 0.25, 181: 0.25, 182: 0.0, 183: 0.0, 184: 0.25, 185: 0.75, 186: 0.0, 187: 0.75, 188: 0.25, 189: 0.5, 190: 0.0, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.25, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-10 13:39:41,155 [INFO] [6] TRAIN  loss: 2.782888645927111 acc: 0.31394810009267843
2024-10-10 13:39:41,155 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.782888645927111}
2024-10-10 13:39:41,156 [INFO] [6] VALIDATION loss: 2.639996193073414 VALIDATION  acc: 0.36237373737373735
2024-10-10 13:39:41,156 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.639996193073414}
2024-10-10 13:39:41,156 [INFO] 
2024-10-10 13:41:06,120 [INFO] Step[50/144]: training loss : 2.3016441917419432 TRAIN  loss dict:  {'classification_loss': 2.3016441917419432}
2024-10-10 13:42:08,181 [INFO] Step[100/144]: training loss : 2.3160478138923644 TRAIN  loss dict:  {'classification_loss': 2.3160478138923644}
2024-10-10 13:43:53,733 [INFO] Label accuracies statistics:
2024-10-10 13:43:53,733 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.0, 6: 0.5, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.25, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.25, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.25, 26: 0.5, 27: 0.25, 28: 0.25, 29: 0.5, 30: 0.0, 31: 0.0, 32: 0.75, 33: 0.25, 34: 0.25, 35: 0.25, 36: 0.25, 37: 0.25, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.25, 44: 0.75, 45: 0.5, 46: 0.25, 47: 0.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.25, 55: 0.5, 56: 0.25, 57: 0.25, 58: 0.5, 59: 0.0, 60: 0.25, 61: 0.25, 62: 0.25, 63: 0.5, 64: 0.0, 65: 0.25, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.5, 72: 0.5, 73: 0.25, 74: 0.0, 75: 0.75, 76: 0.5, 77: 0.0, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.0, 84: 0.75, 85: 0.0, 86: 0.5, 87: 0.25, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.5, 101: 0.25, 102: 0.25, 103: 0.0, 104: 0.25, 105: 0.5, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.5, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.0, 114: 0.5, 115: 0.75, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.0, 120: 0.25, 121: 0.0, 122: 0.5, 123: 0.25, 124: 1.0, 125: 0.75, 126: 0.25, 127: 0.5, 128: 0.5, 129: 0.25, 130: 0.75, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.0, 139: 0.5, 140: 0.75, 141: 0.5, 142: 0.25, 143: 1.0, 144: 0.25, 145: 0.0, 146: 0.0, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 0.5, 152: 0.0, 153: 0.0, 154: 0.5, 155: 0.25, 156: 0.0, 157: 0.0, 158: 0.3333333333333333, 159: 0.25, 160: 0.25, 161: 0.5, 162: 0.5, 163: 0.5, 164: 0.0, 165: 0.75, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.25, 173: 0.5, 174: 0.5, 175: 0.25, 176: 0.25, 177: 0.75, 178: 0.5, 179: 0.3333333333333333, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.5, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.25, 194: 0.75, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-10 13:43:54,335 [INFO] [7] TRAIN  loss: 2.282864207194911 acc: 0.41682113067655235
2024-10-10 13:43:54,335 [INFO] [7] TRAIN  loss dict: {'classification_loss': 2.282864207194911}
2024-10-10 13:43:54,335 [INFO] [7] VALIDATION loss: 2.4464213406598128 VALIDATION  acc: 0.38762626262626265
2024-10-10 13:43:54,335 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 2.4464213406598128}
2024-10-10 13:43:54,336 [INFO] 
2024-10-10 13:45:18,478 [INFO] Step[50/144]: training loss : 1.9742567181587218 TRAIN  loss dict:  {'classification_loss': 1.9742567181587218}
2024-10-10 13:46:20,382 [INFO] Step[100/144]: training loss : 1.8860187196731568 TRAIN  loss dict:  {'classification_loss': 1.8860187196731568}
2024-10-10 13:48:05,551 [INFO] Label accuracies statistics:
2024-10-10 13:48:05,551 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.25, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.25, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.25, 26: 0.25, 27: 0.25, 28: 0.25, 29: 0.25, 30: 0.25, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.0, 36: 0.25, 37: 0.5, 38: 1.0, 39: 1.0, 40: 0.25, 41: 0.0, 42: 0.25, 43: 0.25, 44: 0.5, 45: 0.25, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.25, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.25, 55: 0.0, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.0, 67: 0.75, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.25, 72: 0.5, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.0, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.0, 91: 0.75, 92: 0.75, 93: 0.5, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.25, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.25, 111: 0.5, 112: 0.25, 113: 0.5, 114: 0.0, 115: 0.25, 116: 0.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.25, 127: 0.25, 128: 0.75, 129: 0.25, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.5, 134: 0.0, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.0, 139: 0.25, 140: 0.25, 141: 0.75, 142: 0.75, 143: 0.0, 144: 0.75, 145: 0.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.25, 157: 0.0, 158: 0.0, 159: 0.75, 160: 0.0, 161: 0.25, 162: 0.25, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.25, 167: 0.0, 168: 0.25, 169: 0.75, 170: 0.25, 171: 0.5, 172: 0.0, 173: 0.5, 174: 1.0, 175: 0.25, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.25, 184: 0.0, 185: 0.75, 186: 0.5, 187: 0.5, 188: 0.0, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.25, 195: 0.5, 196: 0.0, 197: 0.5, 198: 0.75}

2024-10-10 13:48:06,107 [INFO] [8] TRAIN  loss: 1.8939524417122204 acc: 0.5187673772011121
2024-10-10 13:48:06,107 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.8939524417122204}
2024-10-10 13:48:06,108 [INFO] [8] VALIDATION loss: 2.0876368107619108 VALIDATION  acc: 0.4659090909090909
2024-10-10 13:48:06,108 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 2.0876368107619108}
2024-10-10 13:48:06,108 [INFO] 
2024-10-10 13:49:51,069 [INFO] Step[50/144]: training loss : 1.6143007850646973 TRAIN  loss dict:  {'classification_loss': 1.6143007850646973}
2024-10-10 13:50:52,358 [INFO] Step[100/144]: training loss : 1.5883615970611573 TRAIN  loss dict:  {'classification_loss': 1.5883615970611573}
2024-10-10 13:52:37,402 [INFO] Label accuracies statistics:
2024-10-10 13:52:37,402 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.0, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.25, 26: 0.25, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.25, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.25, 55: 0.0, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.25, 72: 0.75, 73: 0.5, 74: 0.25, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.0, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 0.5, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 0.75, 105: 0.5, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.25, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.25, 114: 0.0, 115: 0.75, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.25, 121: 0.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.5, 128: 0.75, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.5, 135: 0.75, 136: 0.25, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.75, 143: 0.25, 144: 0.75, 145: 0.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.25, 158: 0.0, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.0, 172: 0.0, 173: 0.25, 174: 0.75, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.25, 181: 0.75, 182: 0.0, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.25, 196: 0.5, 197: 0.5, 198: 0.0}

2024-10-10 13:52:37,987 [INFO] [9] TRAIN  loss: 1.5991281726294093 acc: 0.5887395736793327
2024-10-10 13:52:37,987 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.5991281726294093}
2024-10-10 13:52:37,987 [INFO] [9] VALIDATION loss: 1.9217603471544054 VALIDATION  acc: 0.5126262626262627
2024-10-10 13:52:37,987 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.9217603471544054}
2024-10-10 13:52:37,988 [INFO] 
2024-10-10 13:54:04,748 [INFO] Step[50/144]: training loss : 1.3180629336833953 TRAIN  loss dict:  {'classification_loss': 1.3180629336833953}
2024-10-10 13:55:06,263 [INFO] Step[100/144]: training loss : 1.3166260874271394 TRAIN  loss dict:  {'classification_loss': 1.3166260874271394}
2024-10-10 13:56:50,808 [INFO] Label accuracies statistics:
2024-10-10 13:56:50,808 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.25, 15: 0.0, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.25, 27: 0.0, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.25, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.0, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.25, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.0, 70: 0.0, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.5, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.0, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.0, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.25, 127: 0.25, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.0, 138: 0.5, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.0, 143: 0.5, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.0, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.5, 163: 0.5, 164: 0.25, 165: 1.0, 166: 1.0, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.0, 196: 0.75, 197: 0.5, 198: 0.25}

2024-10-10 13:56:51,411 [INFO] [10] TRAIN  loss: 1.3347694670988455 acc: 0.6475903614457831
2024-10-10 13:56:51,411 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.3347694670988455}
2024-10-10 13:56:51,411 [INFO] [10] VALIDATION loss: 1.7182362719818398 VALIDATION  acc: 0.5757575757575758
2024-10-10 13:56:51,411 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.7182362719818398}
2024-10-10 13:56:51,412 [INFO] 
2024-10-10 13:58:38,478 [INFO] Step[50/144]: training loss : 1.1467873001098632 TRAIN  loss dict:  {'classification_loss': 1.1467873001098632}
2024-10-10 13:59:39,916 [INFO] Step[100/144]: training loss : 1.1418707239627839 TRAIN  loss dict:  {'classification_loss': 1.1418707239627839}
2024-10-10 14:01:24,049 [INFO] Label accuracies statistics:
2024-10-10 14:01:24,049 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.0, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.0, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.25, 61: 0.5, 62: 0.5, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.5, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.5, 139: 0.25, 140: 0.5, 141: 0.25, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.25, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.25, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.25, 196: 0.75, 197: 0.5, 198: 0.0}

2024-10-10 14:01:24,603 [INFO] [11] TRAIN  loss: 1.1244112472567294 acc: 0.7115384615384616
2024-10-10 14:01:24,603 [INFO] [11] TRAIN  loss dict: {'classification_loss': 1.1244112472567294}
2024-10-10 14:01:24,603 [INFO] [11] VALIDATION loss: 1.5694822514498676 VALIDATION  acc: 0.6060606060606061
2024-10-10 14:01:24,603 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.5694822514498676}
2024-10-10 14:01:24,603 [INFO] 
2024-10-10 14:02:55,202 [INFO] Step[50/144]: training loss : 0.9693231332302094 TRAIN  loss dict:  {'classification_loss': 0.9693231332302094}
2024-10-10 14:03:56,576 [INFO] Step[100/144]: training loss : 0.9761809861660004 TRAIN  loss dict:  {'classification_loss': 0.9761809861660004}
2024-10-10 14:05:41,698 [INFO] Label accuracies statistics:
2024-10-10 14:05:41,698 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.5, 18: 1.0, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.0, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.25, 32: 0.75, 33: 0.25, 34: 0.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.25, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.25, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.0, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.25, 85: 0.75, 86: 0.75, 87: 0.25, 88: 0.0, 89: 0.75, 90: 0.25, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.5, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.0, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.25, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.0, 138: 0.5, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.5, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 1.0, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.25, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.0, 191: 0.25, 192: 1.0, 193: 0.5, 194: 0.25, 195: 1.0, 196: 0.5, 197: 0.25, 198: 0.25}

2024-10-10 14:05:42,310 [INFO] [12] TRAIN  loss: 0.9695045782460107 acc: 0.7523169601482854
2024-10-10 14:05:42,310 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.9695045782460107}
2024-10-10 14:05:42,310 [INFO] [12] VALIDATION loss: 1.4567281912874293 VALIDATION  acc: 0.6212121212121212
2024-10-10 14:05:42,310 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.4567281912874293}
2024-10-10 14:05:42,310 [INFO] 
2024-10-10 14:07:16,071 [INFO] Step[50/144]: training loss : 0.84968376994133 TRAIN  loss dict:  {'classification_loss': 0.84968376994133}
2024-10-10 14:08:17,409 [INFO] Step[100/144]: training loss : 0.8341907674074173 TRAIN  loss dict:  {'classification_loss': 0.8341907674074173}
2024-10-10 14:10:01,915 [INFO] Label accuracies statistics:
2024-10-10 14:10:01,915 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.75, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.5, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.25, 43: 0.25, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.25, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.5, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.5, 99: 0.8, 100: 0.75, 101: 0.25, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 0.5, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.0, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.5, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.5, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.0, 154: 1.0, 155: 0.25, 156: 0.5, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.25, 173: 0.5, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.5, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 14:10:01,985 [INFO] [13] TRAIN  loss: 0.8524115278075138 acc: 0.7782669138090825
2024-10-10 14:10:01,985 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.8524115278075138}
2024-10-10 14:10:01,985 [INFO] [13] VALIDATION loss: 1.5029705851166337 VALIDATION  acc: 0.6047979797979798
2024-10-10 14:10:01,985 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.5029705851166337}
2024-10-10 14:10:01,985 [INFO] 
2024-10-10 14:11:36,035 [INFO] Step[50/144]: training loss : 0.7172112554311753 TRAIN  loss dict:  {'classification_loss': 0.7172112554311753}
2024-10-10 14:12:37,608 [INFO] Step[100/144]: training loss : 0.7811455976963043 TRAIN  loss dict:  {'classification_loss': 0.7811455976963043}
2024-10-10 14:14:22,494 [INFO] Label accuracies statistics:
2024-10-10 14:14:22,495 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.25, 123: 0.5, 124: 1.0, 125: 0.75, 126: 0.25, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.5, 139: 0.5, 140: 0.5, 141: 0.5, 142: 0.25, 143: 0.5, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.25, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.25, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.0, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.0, 191: 0.25, 192: 0.75, 193: 0.75, 194: 0.5, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 14:14:23,076 [INFO] [14] TRAIN  loss: 0.7506100734074911 acc: 0.7995829471733086
2024-10-10 14:14:23,076 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.7506100734074911}
2024-10-10 14:14:23,077 [INFO] [14] VALIDATION loss: 1.3285006472357996 VALIDATION  acc: 0.6515151515151515
2024-10-10 14:14:23,077 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.3285006472357996}
2024-10-10 14:14:23,077 [INFO] 
2024-10-10 14:15:52,696 [INFO] Step[50/144]: training loss : 0.6325483679771423 TRAIN  loss dict:  {'classification_loss': 0.6325483679771423}
2024-10-10 14:16:54,121 [INFO] Step[100/144]: training loss : 0.6751571369171142 TRAIN  loss dict:  {'classification_loss': 0.6751571369171142}
2024-10-10 14:18:39,287 [INFO] Label accuracies statistics:
2024-10-10 14:18:39,287 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.25, 27: 0.25, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.5, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.0, 141: 0.75, 142: 0.75, 143: 0.0, 144: 0.5, 145: 0.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.25, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.5, 169: 0.25, 170: 0.25, 171: 0.5, 172: 0.5, 173: 0.25, 174: 1.0, 175: 0.25, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.5, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.0}

2024-10-10 14:18:39,357 [INFO] [15] TRAIN  loss: 0.6705371793359518 acc: 0.82483781278962
2024-10-10 14:18:39,357 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.6705371793359518}
2024-10-10 14:18:39,357 [INFO] [15] VALIDATION loss: 1.401137731693409 VALIDATION  acc: 0.6325757575757576
2024-10-10 14:18:39,357 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.401137731693409}
2024-10-10 14:18:39,357 [INFO] 
2024-10-10 14:20:03,312 [INFO] Step[50/144]: training loss : 0.5772824674844742 TRAIN  loss dict:  {'classification_loss': 0.5772824674844742}
2024-10-10 14:21:05,011 [INFO] Step[100/144]: training loss : 0.5892181277275086 TRAIN  loss dict:  {'classification_loss': 0.5892181277275086}
2024-10-10 14:22:50,165 [INFO] Label accuracies statistics:
2024-10-10 14:22:50,165 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.0, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.0, 67: 0.75, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.0, 84: 0.25, 85: 1.0, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.5, 90: 0.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.25, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 0.75, 188: 1.0, 189: 0.5, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-10 14:22:50,750 [INFO] [16] TRAIN  loss: 0.5992915369570255 acc: 0.8394346617238183
2024-10-10 14:22:50,750 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.5992915369570255}
2024-10-10 14:22:50,750 [INFO] [16] VALIDATION loss: 1.2801595606185772 VALIDATION  acc: 0.6590909090909091
2024-10-10 14:22:50,750 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.2801595606185772}
2024-10-10 14:22:50,751 [INFO] 
2024-10-10 14:24:14,907 [INFO] Step[50/144]: training loss : 0.5305856931209564 TRAIN  loss dict:  {'classification_loss': 0.5305856931209564}
2024-10-10 14:25:16,465 [INFO] Step[100/144]: training loss : 0.5419376176595688 TRAIN  loss dict:  {'classification_loss': 0.5419376176595688}
2024-10-10 14:27:01,373 [INFO] Label accuracies statistics:
2024-10-10 14:27:01,373 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.5, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.5, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.5, 28: 1.0, 29: 0.5, 30: 0.25, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.0, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.75, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.5, 139: 0.75, 140: 0.5, 141: 0.25, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.0, 197: 0.75, 198: 0.25}

2024-10-10 14:27:01,442 [INFO] [17] TRAIN  loss: 0.5460855039871402 acc: 0.852873030583874
2024-10-10 14:27:01,442 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.5460855039871402}
2024-10-10 14:27:01,442 [INFO] [17] VALIDATION loss: 1.2821513988353588 VALIDATION  acc: 0.6464646464646465
2024-10-10 14:27:01,442 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.2821513988353588}
2024-10-10 14:27:01,442 [INFO] 
2024-10-10 14:28:25,331 [INFO] Step[50/144]: training loss : 0.4589190936088562 TRAIN  loss dict:  {'classification_loss': 0.4589190936088562}
2024-10-10 14:29:26,367 [INFO] Step[100/144]: training loss : 0.5077638787031173 TRAIN  loss dict:  {'classification_loss': 0.5077638787031173}
2024-10-10 14:31:11,087 [INFO] Label accuracies statistics:
2024-10-10 14:31:11,087 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 0.5, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.5, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.5, 141: 0.5, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.25, 165: 0.75, 166: 1.0, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-10 14:31:11,656 [INFO] [18] TRAIN  loss: 0.48259908002283836 acc: 0.870713623725672
2024-10-10 14:31:11,656 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.48259908002283836}
2024-10-10 14:31:11,656 [INFO] [18] VALIDATION loss: 1.2656010025077395 VALIDATION  acc: 0.6654040404040404
2024-10-10 14:31:11,656 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.2656010025077395}
2024-10-10 14:31:11,656 [INFO] 
2024-10-10 14:32:36,756 [INFO] Step[50/144]: training loss : 0.4024071389436722 TRAIN  loss dict:  {'classification_loss': 0.4024071389436722}
2024-10-10 14:33:38,394 [INFO] Step[100/144]: training loss : 0.4340593728423119 TRAIN  loss dict:  {'classification_loss': 0.4340593728423119}
2024-10-10 14:35:23,327 [INFO] Label accuracies statistics:
2024-10-10 14:35:23,327 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.0, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.5, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.75, 99: 0.6, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.75, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.25, 174: 1.0, 175: 0.25, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 14:35:23,932 [INFO] [19] TRAIN  loss: 0.42242495581093764 acc: 0.8894810009267841
2024-10-10 14:35:23,932 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.42242495581093764}
2024-10-10 14:35:23,933 [INFO] [19] VALIDATION loss: 1.263244997572016 VALIDATION  acc: 0.6755050505050505
2024-10-10 14:35:23,933 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.263244997572016}
2024-10-10 14:35:23,933 [INFO] 
2024-10-10 14:36:58,650 [INFO] Step[50/144]: training loss : 0.38875015914440153 TRAIN  loss dict:  {'classification_loss': 0.38875015914440153}
2024-10-10 14:38:00,546 [INFO] Step[100/144]: training loss : 0.4069363170862198 TRAIN  loss dict:  {'classification_loss': 0.4069363170862198}
2024-10-10 14:39:45,213 [INFO] Label accuracies statistics:
2024-10-10 14:39:45,213 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.5, 28: 1.0, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.5, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 14:39:45,800 [INFO] [20] TRAIN  loss: 0.4004385055353244 acc: 0.8913345690454124
2024-10-10 14:39:45,800 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.4004385055353244}
2024-10-10 14:39:45,800 [INFO] [20] VALIDATION loss: 1.2353090930868078 VALIDATION  acc: 0.672979797979798
2024-10-10 14:39:45,800 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.2353090930868078}
2024-10-10 14:39:45,801 [INFO] 
2024-10-10 14:41:10,857 [INFO] Step[50/144]: training loss : 0.313160679936409 TRAIN  loss dict:  {'classification_loss': 0.313160679936409}
2024-10-10 14:42:12,219 [INFO] Step[100/144]: training loss : 0.3378181958198547 TRAIN  loss dict:  {'classification_loss': 0.3378181958198547}
2024-10-10 14:43:57,048 [INFO] Label accuracies statistics:
2024-10-10 14:43:57,048 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.25, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.25, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-10 14:43:57,117 [INFO] [21] TRAIN  loss: 0.333988674191965 acc: 0.9154309545875811
2024-10-10 14:43:57,118 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.333988674191965}
2024-10-10 14:43:57,118 [INFO] [21] VALIDATION loss: 1.2453593203315028 VALIDATION  acc: 0.6717171717171717
2024-10-10 14:43:57,118 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.2453593203315028}
2024-10-10 14:43:57,118 [INFO] 
2024-10-10 14:45:31,496 [INFO] Step[50/144]: training loss : 0.2955227738618851 TRAIN  loss dict:  {'classification_loss': 0.2955227738618851}
2024-10-10 14:46:33,206 [INFO] Step[100/144]: training loss : 0.3166816356778145 TRAIN  loss dict:  {'classification_loss': 0.3166816356778145}
2024-10-10 14:48:18,024 [INFO] Label accuracies statistics:
2024-10-10 14:48:18,024 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.5, 140: 0.75, 141: 0.5, 142: 0.75, 143: 0.25, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.25, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 14:48:18,577 [INFO] [22] TRAIN  loss: 0.3097377513638801 acc: 0.9189063948100092
2024-10-10 14:48:18,577 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.3097377513638801}
2024-10-10 14:48:18,577 [INFO] [22] VALIDATION loss: 1.1386630380595173 VALIDATION  acc: 0.6957070707070707
2024-10-10 14:48:18,577 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.1386630380595173}
2024-10-10 14:48:18,578 [INFO] 
2024-10-10 14:49:48,081 [INFO] Step[50/144]: training loss : 0.268737271130085 TRAIN  loss dict:  {'classification_loss': 0.268737271130085}
2024-10-10 14:50:49,427 [INFO] Step[100/144]: training loss : 0.2865104728937149 TRAIN  loss dict:  {'classification_loss': 0.2865104728937149}
2024-10-10 14:52:34,332 [INFO] Label accuracies statistics:
2024-10-10 14:52:34,332 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.75, 78: 0.75, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.25, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.5, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.5, 145: 0.25, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-10 14:52:34,402 [INFO] [23] TRAIN  loss: 0.27325043165021473 acc: 0.9323447636700649
2024-10-10 14:52:34,402 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.27325043165021473}
2024-10-10 14:52:34,403 [INFO] [23] VALIDATION loss: 1.2021268010139465 VALIDATION  acc: 0.6868686868686869
2024-10-10 14:52:34,403 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.2021268010139465}
2024-10-10 14:52:34,403 [INFO] 
2024-10-10 14:53:58,735 [INFO] Step[50/144]: training loss : 0.24826711311936378 TRAIN  loss dict:  {'classification_loss': 0.24826711311936378}
2024-10-10 14:55:00,415 [INFO] Step[100/144]: training loss : 0.28523498237133027 TRAIN  loss dict:  {'classification_loss': 0.28523498237133027}
2024-10-10 14:56:45,514 [INFO] Label accuracies statistics:
2024-10-10 14:56:45,514 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 1.0, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.25, 28: 1.0, 29: 0.5, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.0, 67: 0.5, 68: 0.25, 69: 0.0, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.5, 87: 0.5, 88: 0.75, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.0, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 14:56:45,584 [INFO] [24] TRAIN  loss: 0.2671233980088598 acc: 0.9337349397590361
2024-10-10 14:56:45,584 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.2671233980088598}
2024-10-10 14:56:45,584 [INFO] [24] VALIDATION loss: 1.21027525541959 VALIDATION  acc: 0.6856060606060606
2024-10-10 14:56:45,584 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.21027525541959}
2024-10-10 14:56:45,584 [INFO] 
2024-10-10 14:58:10,135 [INFO] Step[50/144]: training loss : 0.2100529134273529 TRAIN  loss dict:  {'classification_loss': 0.2100529134273529}
2024-10-10 14:59:12,246 [INFO] Step[100/144]: training loss : 0.23938032254576683 TRAIN  loss dict:  {'classification_loss': 0.23938032254576683}
2024-10-10 15:00:57,441 [INFO] Label accuracies statistics:
2024-10-10 15:00:57,441 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.25, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.75, 70: 0.25, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.0, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.25, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.5, 141: 0.5, 142: 0.25, 143: 0.0, 144: 0.5, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 0.75, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 15:00:57,512 [INFO] [25] TRAIN  loss: 0.23046622078658807 acc: 0.9439295644114921
2024-10-10 15:00:57,512 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.23046622078658807}
2024-10-10 15:00:57,512 [INFO] [25] VALIDATION loss: 1.2426418590324897 VALIDATION  acc: 0.6767676767676768
2024-10-10 15:00:57,512 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.2426418590324897}
2024-10-10 15:00:57,512 [INFO] 
2024-10-10 15:02:23,353 [INFO] Step[50/144]: training loss : 0.21466443747282027 TRAIN  loss dict:  {'classification_loss': 0.21466443747282027}
2024-10-10 15:03:25,716 [INFO] Step[100/144]: training loss : 0.232670638859272 TRAIN  loss dict:  {'classification_loss': 0.232670638859272}
2024-10-10 15:05:11,465 [INFO] Label accuracies statistics:
2024-10-10 15:05:11,465 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.0, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.0, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 15:05:12,055 [INFO] [26] TRAIN  loss: 0.21597947620062363 acc: 0.9457831325301205
2024-10-10 15:05:12,055 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.21597947620062363}
2024-10-10 15:05:12,055 [INFO] [26] VALIDATION loss: 1.128884435803802 VALIDATION  acc: 0.696969696969697
2024-10-10 15:05:12,055 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.128884435803802}
2024-10-10 15:05:12,055 [INFO] 
2024-10-10 15:06:37,594 [INFO] Step[50/144]: training loss : 0.1890178807079792 TRAIN  loss dict:  {'classification_loss': 0.1890178807079792}
2024-10-10 15:07:40,137 [INFO] Step[100/144]: training loss : 0.2068644195795059 TRAIN  loss dict:  {'classification_loss': 0.2068644195795059}
2024-10-10 15:09:25,962 [INFO] Label accuracies statistics:
2024-10-10 15:09:25,962 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.75, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.25, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.5, 145: 1.0, 146: 0.5, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.75, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 15:09:26,032 [INFO] [27] TRAIN  loss: 0.21076155660880935 acc: 0.9455514365152919
2024-10-10 15:09:26,032 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.21076155660880935}
2024-10-10 15:09:26,033 [INFO] [27] VALIDATION loss: 1.2012720764787108 VALIDATION  acc: 0.6843434343434344
2024-10-10 15:09:26,033 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.2012720764787108}
2024-10-10 15:09:26,033 [INFO] 
2024-10-10 15:10:52,298 [INFO] Step[50/144]: training loss : 0.17996901586651803 TRAIN  loss dict:  {'classification_loss': 0.17996901586651803}
2024-10-10 15:11:55,091 [INFO] Step[100/144]: training loss : 0.1801567180454731 TRAIN  loss dict:  {'classification_loss': 0.1801567180454731}
2024-10-10 15:13:41,725 [INFO] Label accuracies statistics:
2024-10-10 15:13:41,726 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.25, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.25, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.25, 170: 0.5, 171: 0.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.0, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 15:13:41,796 [INFO] [28] TRAIN  loss: 0.18217721201168993 acc: 0.9555143651529193
2024-10-10 15:13:41,796 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.18217721201168993}
2024-10-10 15:13:41,796 [INFO] [28] VALIDATION loss: 1.236693717815258 VALIDATION  acc: 0.6792929292929293
2024-10-10 15:13:41,796 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.236693717815258}
2024-10-10 15:13:41,796 [INFO] 
2024-10-10 15:15:07,736 [INFO] Step[50/144]: training loss : 0.16001522541046143 TRAIN  loss dict:  {'classification_loss': 0.16001522541046143}
2024-10-10 15:16:10,464 [INFO] Step[100/144]: training loss : 0.17653667084872723 TRAIN  loss dict:  {'classification_loss': 0.17653667084872723}
2024-10-10 15:17:56,521 [INFO] Label accuracies statistics:
2024-10-10 15:17:56,521 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.0, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.0, 113: 0.75, 114: 0.25, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 0.5, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.25, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 15:17:56,590 [INFO] [29] TRAIN  loss: 0.17385890425389838 acc: 0.9566728452270621
2024-10-10 15:17:56,590 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.17385890425389838}
2024-10-10 15:17:56,590 [INFO] [29] VALIDATION loss: 1.168104949924681 VALIDATION  acc: 0.6931818181818182
2024-10-10 15:17:56,590 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.168104949924681}
2024-10-10 15:17:56,591 [INFO] 
2024-10-10 15:19:26,749 [INFO] Step[50/144]: training loss : 0.17082641512155533 TRAIN  loss dict:  {'classification_loss': 0.17082641512155533}
2024-10-10 15:20:29,384 [INFO] Step[100/144]: training loss : 0.17077773869037627 TRAIN  loss dict:  {'classification_loss': 0.17077773869037627}
2024-10-10 15:22:15,526 [INFO] Label accuracies statistics:
2024-10-10 15:22:15,526 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.25, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 0.75, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.25, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 15:22:15,596 [INFO] [30] TRAIN  loss: 0.1677410891538279 acc: 0.9566728452270621
2024-10-10 15:22:15,596 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.1677410891538279}
2024-10-10 15:22:15,596 [INFO] [30] VALIDATION loss: 1.1744422540068626 VALIDATION  acc: 0.7171717171717171
2024-10-10 15:22:15,596 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.1744422540068626}
2024-10-10 15:22:15,596 [INFO] 
2024-10-10 15:23:46,785 [INFO] Step[50/144]: training loss : 0.14905600912868977 TRAIN  loss dict:  {'classification_loss': 0.14905600912868977}
2024-10-10 15:24:50,070 [INFO] Step[100/144]: training loss : 0.1337632817029953 TRAIN  loss dict:  {'classification_loss': 0.1337632817029953}
2024-10-10 15:26:36,759 [INFO] Label accuracies statistics:
2024-10-10 15:26:36,759 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.25, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.75, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.5, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 15:26:36,830 [INFO] [31] TRAIN  loss: 0.1413293389810456 acc: 0.9684893419833179
2024-10-10 15:26:36,830 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.1413293389810456}
2024-10-10 15:26:36,830 [INFO] [31] VALIDATION loss: 1.134503405403208 VALIDATION  acc: 0.7095959595959596
2024-10-10 15:26:36,830 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.134503405403208}
2024-10-10 15:26:36,830 [INFO] 
2024-10-10 15:28:03,971 [INFO] Step[50/144]: training loss : 0.11410729125142098 TRAIN  loss dict:  {'classification_loss': 0.11410729125142098}
2024-10-10 15:29:00,389 [INFO] Step[100/144]: training loss : 0.13572387143969536 TRAIN  loss dict:  {'classification_loss': 0.13572387143969536}
2024-10-10 15:30:38,565 [INFO] Label accuracies statistics:
2024-10-10 15:30:38,565 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.25, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.5, 171: 1.0, 172: 0.5, 173: 0.25, 174: 1.0, 175: 0.75, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 15:30:39,160 [INFO] [32] TRAIN  loss: 0.1309379486936248 acc: 0.9691844300278035
2024-10-10 15:30:39,160 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.1309379486936248}
2024-10-10 15:30:39,160 [INFO] [32] VALIDATION loss: 1.1140816940201654 VALIDATION  acc: 0.7285353535353535
2024-10-10 15:30:39,160 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.1140816940201654}
2024-10-10 15:30:39,161 [INFO] 
2024-10-10 15:31:57,517 [INFO] Step[50/144]: training loss : 0.12006495170295238 TRAIN  loss dict:  {'classification_loss': 0.12006495170295238}
2024-10-10 15:32:53,183 [INFO] Step[100/144]: training loss : 0.13654793202877044 TRAIN  loss dict:  {'classification_loss': 0.13654793202877044}
2024-10-10 15:34:30,625 [INFO] Label accuracies statistics:
2024-10-10 15:34:30,625 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.25, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 1.0, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 15:34:31,205 [INFO] [33] TRAIN  loss: 0.1315727846748713 acc: 0.9682576459684893
2024-10-10 15:34:31,205 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.1315727846748713}
2024-10-10 15:34:31,206 [INFO] [33] VALIDATION loss: 1.1104583638133827 VALIDATION  acc: 0.7070707070707071
2024-10-10 15:34:31,206 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 1.1104583638133827}
2024-10-10 15:34:31,206 [INFO] 
2024-10-10 15:35:50,234 [INFO] Step[50/144]: training loss : 0.11948966324329376 TRAIN  loss dict:  {'classification_loss': 0.11948966324329376}
2024-10-10 15:36:45,844 [INFO] Step[100/144]: training loss : 0.1390781419724226 TRAIN  loss dict:  {'classification_loss': 0.1390781419724226}
2024-10-10 15:38:23,330 [INFO] Label accuracies statistics:
2024-10-10 15:38:23,330 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 15:38:23,913 [INFO] [34] TRAIN  loss: 0.12794503631691137 acc: 0.9715013901760889
2024-10-10 15:38:23,913 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.12794503631691137}
2024-10-10 15:38:23,913 [INFO] [34] VALIDATION loss: 1.104940535293685 VALIDATION  acc: 0.7121212121212122
2024-10-10 15:38:23,913 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.104940535293685}
2024-10-10 15:38:23,913 [INFO] 
2024-10-10 15:39:42,574 [INFO] Step[50/144]: training loss : 0.09725264798849821 TRAIN  loss dict:  {'classification_loss': 0.09725264798849821}
2024-10-10 15:40:38,126 [INFO] Step[100/144]: training loss : 0.1119327162951231 TRAIN  loss dict:  {'classification_loss': 0.1119327162951231}
2024-10-10 15:42:15,394 [INFO] Label accuracies statistics:
2024-10-10 15:42:15,395 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.25, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.0, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.25, 144: 0.5, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 15:42:15,464 [INFO] [35] TRAIN  loss: 0.1007398626792969 acc: 0.9789156626506024
2024-10-10 15:42:15,464 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.1007398626792969}
2024-10-10 15:42:15,464 [INFO] [35] VALIDATION loss: 1.1157712194102782 VALIDATION  acc: 0.7159090909090909
2024-10-10 15:42:15,464 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.1157712194102782}
2024-10-10 15:42:15,464 [INFO] 
2024-10-10 15:43:34,721 [INFO] Step[50/144]: training loss : 0.10565196488052607 TRAIN  loss dict:  {'classification_loss': 0.10565196488052607}
2024-10-10 15:44:30,426 [INFO] Step[100/144]: training loss : 0.10189113073050976 TRAIN  loss dict:  {'classification_loss': 0.10189113073050976}
2024-10-10 15:46:08,479 [INFO] Label accuracies statistics:
2024-10-10 15:46:08,479 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 15:46:09,034 [INFO] [36] TRAIN  loss: 0.10872490270735903 acc: 0.9759036144578314
2024-10-10 15:46:09,034 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.10872490270735903}
2024-10-10 15:46:09,034 [INFO] [36] VALIDATION loss: 1.0767774879932404 VALIDATION  acc: 0.7348484848484849
2024-10-10 15:46:09,034 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.0767774879932404}
2024-10-10 15:46:09,034 [INFO] 
2024-10-10 15:47:28,278 [INFO] Step[50/144]: training loss : 0.1044046650826931 TRAIN  loss dict:  {'classification_loss': 0.1044046650826931}
2024-10-10 15:48:23,706 [INFO] Step[100/144]: training loss : 0.08963101267814637 TRAIN  loss dict:  {'classification_loss': 0.08963101267814637}
2024-10-10 15:50:00,427 [INFO] Label accuracies statistics:
2024-10-10 15:50:00,427 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.25, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.25, 143: 0.25, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.0, 172: 0.75, 173: 0.25, 174: 1.0, 175: 0.25, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 15:50:00,495 [INFO] [37] TRAIN  loss: 0.09602683908047362 acc: 0.9798424467099166
2024-10-10 15:50:00,495 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.09602683908047362}
2024-10-10 15:50:00,495 [INFO] [37] VALIDATION loss: 1.1848158714947876 VALIDATION  acc: 0.7070707070707071
2024-10-10 15:50:00,495 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.1848158714947876}
2024-10-10 15:50:00,495 [INFO] 
2024-10-10 15:51:19,503 [INFO] Step[50/144]: training loss : 0.1061824394762516 TRAIN  loss dict:  {'classification_loss': 0.1061824394762516}
2024-10-10 15:52:14,961 [INFO] Step[100/144]: training loss : 0.09813094113022089 TRAIN  loss dict:  {'classification_loss': 0.09813094113022089}
2024-10-10 15:53:52,641 [INFO] Label accuracies statistics:
2024-10-10 15:53:52,641 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 1.0, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 1.0, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.75, 166: 1.0, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 1.0, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 15:53:52,708 [INFO] [38] TRAIN  loss: 0.1011737745332842 acc: 0.976598702502317
2024-10-10 15:53:52,709 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.1011737745332842}
2024-10-10 15:53:52,709 [INFO] [38] VALIDATION loss: 1.1265537689129512 VALIDATION  acc: 0.7171717171717171
2024-10-10 15:53:52,709 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.1265537689129512}
2024-10-10 15:53:52,709 [INFO] 
2024-10-10 15:55:10,724 [INFO] Step[50/144]: training loss : 0.0798574634641409 TRAIN  loss dict:  {'classification_loss': 0.0798574634641409}
2024-10-10 15:56:06,188 [INFO] Step[100/144]: training loss : 0.08860796093940734 TRAIN  loss dict:  {'classification_loss': 0.08860796093940734}
2024-10-10 15:57:43,678 [INFO] Label accuracies statistics:
2024-10-10 15:57:43,678 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.25, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.0, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.25, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 1.0, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.0, 172: 0.75, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 15:57:43,747 [INFO] [39] TRAIN  loss: 0.08982208841997716 acc: 0.9784522706209453
2024-10-10 15:57:43,747 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.08982208841997716}
2024-10-10 15:57:43,747 [INFO] [39] VALIDATION loss: 1.2891775703540556 VALIDATION  acc: 0.6868686868686869
2024-10-10 15:57:43,747 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.2891775703540556}
2024-10-10 15:57:43,747 [INFO] 
2024-10-10 15:59:23,169 [INFO] Step[50/144]: training loss : 0.08565177775919437 TRAIN  loss dict:  {'classification_loss': 0.08565177775919437}
2024-10-10 16:00:19,518 [INFO] Step[100/144]: training loss : 0.0833447377383709 TRAIN  loss dict:  {'classification_loss': 0.0833447377383709}
2024-10-10 16:01:58,138 [INFO] Label accuracies statistics:
2024-10-10 16:01:58,138 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 0.75, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 16:01:58,206 [INFO] [40] TRAIN  loss: 0.08942199975717813 acc: 0.9800741427247451
2024-10-10 16:01:58,206 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.08942199975717813}
2024-10-10 16:01:58,206 [INFO] [40] VALIDATION loss: 1.1241456003928627 VALIDATION  acc: 0.7146464646464646
2024-10-10 16:01:58,206 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.1241456003928627}
2024-10-10 16:01:58,207 [INFO] 
2024-10-10 16:03:22,528 [INFO] Step[50/144]: training loss : 0.07594982765614987 TRAIN  loss dict:  {'classification_loss': 0.07594982765614987}
2024-10-10 16:04:20,391 [INFO] Step[100/144]: training loss : 0.0766840486228466 TRAIN  loss dict:  {'classification_loss': 0.0766840486228466}
2024-10-10 16:06:03,067 [INFO] Label accuracies statistics:
2024-10-10 16:06:03,067 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.25, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 0.75, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.5, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-10 16:06:03,136 [INFO] [41] TRAIN  loss: 0.07541319852720739 acc: 0.9830861909175163
2024-10-10 16:06:03,136 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.07541319852720739}
2024-10-10 16:06:03,136 [INFO] [41] VALIDATION loss: 1.1584515877895885 VALIDATION  acc: 0.7171717171717171
2024-10-10 16:06:03,136 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.1584515877895885}
2024-10-10 16:06:03,136 [INFO] 
2024-10-10 16:07:28,299 [INFO] Step[50/144]: training loss : 0.060595905557274815 TRAIN  loss dict:  {'classification_loss': 0.060595905557274815}
2024-10-10 16:08:30,791 [INFO] Step[100/144]: training loss : 0.0765562328696251 TRAIN  loss dict:  {'classification_loss': 0.0765562328696251}
2024-10-10 16:10:16,181 [INFO] Label accuracies statistics:
2024-10-10 16:10:16,182 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-10 16:10:16,251 [INFO] [42] TRAIN  loss: 0.06965147772441721 acc: 0.9844763670064874
2024-10-10 16:10:16,251 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.06965147772441721}
2024-10-10 16:10:16,251 [INFO] [42] VALIDATION loss: 1.154402098308007 VALIDATION  acc: 0.7297979797979798
2024-10-10 16:10:16,251 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.154402098308007}
2024-10-10 16:10:16,251 [INFO] 
2024-10-10 16:11:41,466 [INFO] Step[50/144]: training loss : 0.062318230047822 TRAIN  loss dict:  {'classification_loss': 0.062318230047822}
2024-10-10 16:12:43,198 [INFO] Step[100/144]: training loss : 0.06752261716872454 TRAIN  loss dict:  {'classification_loss': 0.06752261716872454}
2024-10-10 16:14:28,436 [INFO] Label accuracies statistics:
2024-10-10 16:14:28,436 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 16:14:28,505 [INFO] [43] TRAIN  loss: 0.07278535610789226 acc: 0.9830861909175163
2024-10-10 16:14:28,506 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.07278535610789226}
2024-10-10 16:14:28,506 [INFO] [43] VALIDATION loss: 1.1144563001063135 VALIDATION  acc: 0.7272727272727273
2024-10-10 16:14:28,506 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.1144563001063135}
2024-10-10 16:14:28,506 [INFO] 
2024-10-10 16:15:51,955 [INFO] Step[50/144]: training loss : 0.05756641544401646 TRAIN  loss dict:  {'classification_loss': 0.05756641544401646}
2024-10-10 16:16:54,394 [INFO] Step[100/144]: training loss : 0.07298161778599024 TRAIN  loss dict:  {'classification_loss': 0.07298161778599024}
2024-10-10 16:18:40,033 [INFO] Label accuracies statistics:
2024-10-10 16:18:40,033 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.25, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.25, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 16:18:40,109 [INFO] [44] TRAIN  loss: 0.06414544111531642 acc: 0.9844763670064874
2024-10-10 16:18:40,109 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.06414544111531642}
2024-10-10 16:18:40,109 [INFO] [44] VALIDATION loss: 1.1320642216338053 VALIDATION  acc: 0.7348484848484849
2024-10-10 16:18:40,109 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.1320642216338053}
2024-10-10 16:18:40,109 [INFO] 
2024-10-10 16:20:05,701 [INFO] Step[50/144]: training loss : 0.05416843635961413 TRAIN  loss dict:  {'classification_loss': 0.05416843635961413}
2024-10-10 16:21:06,339 [INFO] Step[100/144]: training loss : 0.05370290640741587 TRAIN  loss dict:  {'classification_loss': 0.05370290640741587}
2024-10-10 16:22:52,059 [INFO] Label accuracies statistics:
2024-10-10 16:22:52,059 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.75, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 16:22:52,131 [INFO] [45] TRAIN  loss: 0.061078643730272435 acc: 0.98725671918443
2024-10-10 16:22:52,131 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.061078643730272435}
2024-10-10 16:22:52,131 [INFO] [45] VALIDATION loss: 1.1326514421789735 VALIDATION  acc: 0.7272727272727273
2024-10-10 16:22:52,131 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.1326514421789735}
2024-10-10 16:22:52,131 [INFO] 
2024-10-10 16:24:17,851 [INFO] Step[50/144]: training loss : 0.061903098970651625 TRAIN  loss dict:  {'classification_loss': 0.061903098970651625}
2024-10-10 16:25:18,883 [INFO] Step[100/144]: training loss : 0.05896332954987884 TRAIN  loss dict:  {'classification_loss': 0.05896332954987884}
2024-10-10 16:27:02,714 [INFO] Label accuracies statistics:
2024-10-10 16:27:02,714 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.0, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 16:27:02,785 [INFO] [46] TRAIN  loss: 0.06348805501410323 acc: 0.9856348470806302
2024-10-10 16:27:02,785 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.06348805501410323}
2024-10-10 16:27:02,785 [INFO] [46] VALIDATION loss: 1.159810624188847 VALIDATION  acc: 0.7209595959595959
2024-10-10 16:27:02,785 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.159810624188847}
2024-10-10 16:27:02,785 [INFO] 
2024-10-10 16:28:25,777 [INFO] Step[50/144]: training loss : 0.06716925932094454 TRAIN  loss dict:  {'classification_loss': 0.06716925932094454}
2024-10-10 16:29:25,614 [INFO] Step[100/144]: training loss : 0.06593552906066179 TRAIN  loss dict:  {'classification_loss': 0.06593552906066179}
2024-10-10 16:31:04,382 [INFO] Label accuracies statistics:
2024-10-10 16:31:04,382 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.5, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.25, 168: 1.0, 169: 0.5, 170: 0.75, 171: 0.0, 172: 0.75, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 16:31:04,451 [INFO] [47] TRAIN  loss: 0.0684991279267706 acc: 0.9842446709916589
2024-10-10 16:31:04,451 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.0684991279267706}
2024-10-10 16:31:04,451 [INFO] [47] VALIDATION loss: 1.1151778921484947 VALIDATION  acc: 0.7146464646464646
2024-10-10 16:31:04,451 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.1151778921484947}
2024-10-10 16:31:04,451 [INFO] 
2024-10-10 16:32:25,707 [INFO] Step[50/144]: training loss : 0.0578227099403739 TRAIN  loss dict:  {'classification_loss': 0.0578227099403739}
2024-10-10 16:33:22,275 [INFO] Step[100/144]: training loss : 0.049729886669665574 TRAIN  loss dict:  {'classification_loss': 0.049729886669665574}
2024-10-10 16:35:01,466 [INFO] Label accuracies statistics:
2024-10-10 16:35:01,466 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.25, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 16:35:01,535 [INFO] [48] TRAIN  loss: 0.05540731575779824 acc: 0.986793327154773
2024-10-10 16:35:01,535 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.05540731575779824}
2024-10-10 16:35:01,535 [INFO] [48] VALIDATION loss: 1.1558271279489551 VALIDATION  acc: 0.7335858585858586
2024-10-10 16:35:01,535 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.1558271279489551}
2024-10-10 16:35:01,535 [INFO] 
2024-10-10 16:36:20,024 [INFO] Step[50/144]: training loss : 0.06462820993736386 TRAIN  loss dict:  {'classification_loss': 0.06462820993736386}
2024-10-10 16:37:16,750 [INFO] Step[100/144]: training loss : 0.058145942240953444 TRAIN  loss dict:  {'classification_loss': 0.058145942240953444}
2024-10-10 16:38:55,718 [INFO] Label accuracies statistics:
2024-10-10 16:38:55,718 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 1.0, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 16:38:55,789 [INFO] [49] TRAIN  loss: 0.06056588796976333 acc: 0.9860982391102873
2024-10-10 16:38:55,790 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.06056588796976333}
2024-10-10 16:38:55,790 [INFO] [49] VALIDATION loss: 1.0854541021916602 VALIDATION  acc: 0.7361111111111112
2024-10-10 16:38:55,790 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.0854541021916602}
2024-10-10 16:38:55,790 [INFO] 
2024-10-10 16:40:29,807 [INFO] Step[50/144]: training loss : 0.04588680043816566 TRAIN  loss dict:  {'classification_loss': 0.04588680043816566}
2024-10-10 16:41:25,800 [INFO] Step[100/144]: training loss : 0.048835230711847546 TRAIN  loss dict:  {'classification_loss': 0.048835230711847546}
2024-10-10 16:43:04,610 [INFO] Label accuracies statistics:
2024-10-10 16:43:04,610 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.25, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-10 16:43:05,182 [INFO] [50] TRAIN  loss: 0.047894064847949065 acc: 0.9909638554216867
2024-10-10 16:43:05,182 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.047894064847949065}
2024-10-10 16:43:05,183 [INFO] [50] VALIDATION loss: 1.0537566773041531 VALIDATION  acc: 0.7348484848484849
2024-10-10 16:43:05,183 [INFO] [50] VALIDATION  loss dict: {'classification_loss': 1.0537566773041531}
2024-10-10 16:43:05,183 [INFO] 
2024-10-10 16:44:35,153 [INFO] Step[50/144]: training loss : 0.03709002416580916 TRAIN  loss dict:  {'classification_loss': 0.03709002416580916}
2024-10-10 16:45:32,313 [INFO] Step[100/144]: training loss : 0.04589254772290587 TRAIN  loss dict:  {'classification_loss': 0.04589254772290587}
2024-10-10 16:47:38,155 [INFO] Label accuracies statistics:
2024-10-10 16:47:38,155 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 16:47:38,237 [INFO] [51] TRAIN  loss: 0.04040790582722467 acc: 0.9925857275254866
2024-10-10 16:47:38,238 [INFO] [51] TRAIN  loss dict: {'classification_loss': 0.04040790582722467}
2024-10-10 16:47:38,238 [INFO] [51] VALIDATION loss: 1.0828361378775702 VALIDATION  acc: 0.7297979797979798
2024-10-10 16:47:38,238 [INFO] [51] VALIDATION  loss dict: {'classification_loss': 1.0828361378775702}
2024-10-10 16:47:38,238 [INFO] 
2024-10-10 16:49:22,022 [INFO] Step[50/144]: training loss : 0.044539502244442704 TRAIN  loss dict:  {'classification_loss': 0.044539502244442704}
2024-10-10 16:50:33,028 [INFO] Step[100/144]: training loss : 0.0479898707382381 TRAIN  loss dict:  {'classification_loss': 0.0479898707382381}
2024-10-10 16:52:37,782 [INFO] Label accuracies statistics:
2024-10-10 16:52:37,782 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.75, 89: 0.5, 90: 1.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.75, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 16:52:37,863 [INFO] [52] TRAIN  loss: 0.04508704793341975 acc: 0.9900370713623726
2024-10-10 16:52:37,863 [INFO] [52] TRAIN  loss dict: {'classification_loss': 0.04508704793341975}
2024-10-10 16:52:37,863 [INFO] [52] VALIDATION loss: 1.1180443471228634 VALIDATION  acc: 0.7361111111111112
2024-10-10 16:52:37,863 [INFO] [52] VALIDATION  loss dict: {'classification_loss': 1.1180443471228634}
2024-10-10 16:52:37,863 [INFO] 
2024-10-10 16:54:20,071 [INFO] Step[50/144]: training loss : 0.03907296339049935 TRAIN  loss dict:  {'classification_loss': 0.03907296339049935}
2024-10-10 16:55:24,260 [INFO] Step[100/144]: training loss : 0.04489968441426754 TRAIN  loss dict:  {'classification_loss': 0.04489968441426754}
2024-10-10 16:57:36,706 [INFO] Label accuracies statistics:
2024-10-10 16:57:36,706 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.5, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.75, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 16:57:36,786 [INFO] [53] TRAIN  loss: 0.04146213515842748 acc: 0.9930491195551436
2024-10-10 16:57:36,786 [INFO] [53] TRAIN  loss dict: {'classification_loss': 0.04146213515842748}
2024-10-10 16:57:36,786 [INFO] [53] VALIDATION loss: 1.1231868267059326 VALIDATION  acc: 0.7247474747474747
2024-10-10 16:57:36,786 [INFO] [53] VALIDATION  loss dict: {'classification_loss': 1.1231868267059326}
2024-10-10 16:57:36,786 [INFO] 
2024-10-10 16:59:15,069 [INFO] Step[50/144]: training loss : 0.03397831974551082 TRAIN  loss dict:  {'classification_loss': 0.03397831974551082}
2024-10-10 17:00:19,630 [INFO] Step[100/144]: training loss : 0.035036682542413475 TRAIN  loss dict:  {'classification_loss': 0.035036682542413475}
2024-10-10 17:02:32,175 [INFO] Label accuracies statistics:
2024-10-10 17:02:32,175 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.5, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 17:02:32,272 [INFO] [54] TRAIN  loss: 0.035139440804616444 acc: 0.9935125115848007
2024-10-10 17:02:32,272 [INFO] [54] TRAIN  loss dict: {'classification_loss': 0.035139440804616444}
2024-10-10 17:02:32,272 [INFO] [54] VALIDATION loss: 1.153262184139479 VALIDATION  acc: 0.7285353535353535
2024-10-10 17:02:32,272 [INFO] [54] VALIDATION  loss dict: {'classification_loss': 1.153262184139479}
2024-10-10 17:02:32,272 [INFO] 
2024-10-10 17:04:12,014 [INFO] Step[50/144]: training loss : 0.04505972340703011 TRAIN  loss dict:  {'classification_loss': 0.04505972340703011}
2024-10-10 17:05:19,604 [INFO] Step[100/144]: training loss : 0.039593708999454975 TRAIN  loss dict:  {'classification_loss': 0.039593708999454975}
2024-10-10 17:07:29,492 [INFO] Label accuracies statistics:
2024-10-10 17:07:29,493 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.75, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 17:07:29,605 [INFO] [55] TRAIN  loss: 0.042838889041579224 acc: 0.9916589434661723
2024-10-10 17:07:29,605 [INFO] [55] TRAIN  loss dict: {'classification_loss': 0.042838889041579224}
2024-10-10 17:07:29,605 [INFO] [55] VALIDATION loss: 1.0855260587952755 VALIDATION  acc: 0.7361111111111112
2024-10-10 17:07:29,605 [INFO] [55] VALIDATION  loss dict: {'classification_loss': 1.0855260587952755}
2024-10-10 17:07:29,605 [INFO] 
2024-10-10 17:09:07,633 [INFO] Step[50/144]: training loss : 0.036788664609193805 TRAIN  loss dict:  {'classification_loss': 0.036788664609193805}
2024-10-10 17:10:12,253 [INFO] Step[100/144]: training loss : 0.03132702597416937 TRAIN  loss dict:  {'classification_loss': 0.03132702597416937}
2024-10-10 17:12:25,755 [INFO] Label accuracies statistics:
2024-10-10 17:12:25,755 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 1.0, 99: 1.0, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 17:12:25,843 [INFO] [56] TRAIN  loss: 0.0375070955132186 acc: 0.9939759036144579
2024-10-10 17:12:25,843 [INFO] [56] TRAIN  loss dict: {'classification_loss': 0.0375070955132186}
2024-10-10 17:12:25,843 [INFO] [56] VALIDATION loss: 1.0543996182580788 VALIDATION  acc: 0.7411616161616161
2024-10-10 17:12:25,843 [INFO] [56] VALIDATION  loss dict: {'classification_loss': 1.0543996182580788}
2024-10-10 17:12:25,844 [INFO] 
2024-10-10 17:14:03,903 [INFO] Step[50/144]: training loss : 0.03226013329811394 TRAIN  loss dict:  {'classification_loss': 0.03226013329811394}
2024-10-10 17:15:10,351 [INFO] Step[100/144]: training loss : 0.03746693043038249 TRAIN  loss dict:  {'classification_loss': 0.03746693043038249}
2024-10-10 17:17:21,188 [INFO] Label accuracies statistics:
2024-10-10 17:17:21,188 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.0, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-10 17:17:21,264 [INFO] [57] TRAIN  loss: 0.036871217569569126 acc: 0.9902687673772012
2024-10-10 17:17:21,264 [INFO] [57] TRAIN  loss dict: {'classification_loss': 0.036871217569569126}
2024-10-10 17:17:21,265 [INFO] [57] VALIDATION loss: 1.1191327417338337 VALIDATION  acc: 0.7373737373737373
2024-10-10 17:17:21,265 [INFO] [57] VALIDATION  loss dict: {'classification_loss': 1.1191327417338337}
2024-10-10 17:17:21,265 [INFO] 
2024-10-10 17:18:59,363 [INFO] Step[50/144]: training loss : 0.0324014828260988 TRAIN  loss dict:  {'classification_loss': 0.0324014828260988}
2024-10-10 17:20:07,135 [INFO] Step[100/144]: training loss : 0.03791988542769104 TRAIN  loss dict:  {'classification_loss': 0.03791988542769104}
2024-10-10 17:22:15,645 [INFO] Label accuracies statistics:
2024-10-10 17:22:15,645 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.0, 69: 0.75, 70: 0.25, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 17:22:15,726 [INFO] [58] TRAIN  loss: 0.03499497518350836 acc: 0.9921223354958295
2024-10-10 17:22:15,727 [INFO] [58] TRAIN  loss dict: {'classification_loss': 0.03499497518350836}
2024-10-10 17:22:15,727 [INFO] [58] VALIDATION loss: 1.1641593248479896 VALIDATION  acc: 0.726010101010101
2024-10-10 17:22:15,727 [INFO] [58] VALIDATION  loss dict: {'classification_loss': 1.1641593248479896}
2024-10-10 17:22:15,727 [INFO] 
2024-10-10 17:23:54,322 [INFO] Step[50/144]: training loss : 0.03421881519258022 TRAIN  loss dict:  {'classification_loss': 0.03421881519258022}
2024-10-10 17:25:03,820 [INFO] Step[100/144]: training loss : 0.03960832122713327 TRAIN  loss dict:  {'classification_loss': 0.03960832122713327}
2024-10-10 17:27:12,073 [INFO] Label accuracies statistics:
2024-10-10 17:27:12,074 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.25, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 17:27:12,158 [INFO] [59] TRAIN  loss: 0.03648183368366315 acc: 0.9928174235403151
2024-10-10 17:27:12,158 [INFO] [59] TRAIN  loss dict: {'classification_loss': 0.03648183368366315}
2024-10-10 17:27:12,158 [INFO] [59] VALIDATION loss: 1.1141995926973995 VALIDATION  acc: 0.7449494949494949
2024-10-10 17:27:12,158 [INFO] [59] VALIDATION  loss dict: {'classification_loss': 1.1141995926973995}
2024-10-10 17:27:12,158 [INFO] 
2024-10-10 17:28:50,149 [INFO] Step[50/144]: training loss : 0.035052317157387734 TRAIN  loss dict:  {'classification_loss': 0.035052317157387734}
2024-10-10 17:30:00,935 [INFO] Step[100/144]: training loss : 0.03171957055106759 TRAIN  loss dict:  {'classification_loss': 0.03171957055106759}
2024-10-10 17:32:07,833 [INFO] Label accuracies statistics:
2024-10-10 17:32:07,833 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.75, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 17:32:07,915 [INFO] [60] TRAIN  loss: 0.034328614387454257 acc: 0.9932808155699722
2024-10-10 17:32:07,915 [INFO] [60] TRAIN  loss dict: {'classification_loss': 0.034328614387454257}
2024-10-10 17:32:07,915 [INFO] [60] VALIDATION loss: 1.1103894139329593 VALIDATION  acc: 0.7348484848484849
2024-10-10 17:32:07,915 [INFO] [60] VALIDATION  loss dict: {'classification_loss': 1.1103894139329593}
2024-10-10 17:32:07,915 [INFO] 
2024-10-10 17:33:44,350 [INFO] Step[50/144]: training loss : 0.02686449366621673 TRAIN  loss dict:  {'classification_loss': 0.02686449366621673}
2024-10-10 17:34:55,272 [INFO] Step[100/144]: training loss : 0.033393987119197846 TRAIN  loss dict:  {'classification_loss': 0.033393987119197846}
2024-10-10 17:37:03,322 [INFO] Label accuracies statistics:
2024-10-10 17:37:03,322 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.0, 69: 0.75, 70: 0.25, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 17:37:03,402 [INFO] [61] TRAIN  loss: 0.03061480653963776 acc: 0.9932808155699722
2024-10-10 17:37:03,402 [INFO] [61] TRAIN  loss dict: {'classification_loss': 0.03061480653963776}
2024-10-10 17:37:03,402 [INFO] [61] VALIDATION loss: 1.0982806608080864 VALIDATION  acc: 0.7361111111111112
2024-10-10 17:37:03,402 [INFO] [61] VALIDATION  loss dict: {'classification_loss': 1.0982806608080864}
2024-10-10 17:37:03,402 [INFO] 
2024-10-10 17:38:40,726 [INFO] Step[50/144]: training loss : 0.030203410759568214 TRAIN  loss dict:  {'classification_loss': 0.030203410759568214}
2024-10-10 17:39:51,712 [INFO] Step[100/144]: training loss : 0.0265290043130517 TRAIN  loss dict:  {'classification_loss': 0.0265290043130517}
2024-10-10 17:42:00,086 [INFO] Label accuracies statistics:
2024-10-10 17:42:00,086 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.0, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.25, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.5, 170: 1.0, 171: 0.75, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 17:42:00,183 [INFO] [62] TRAIN  loss: 0.028372638357622135 acc: 0.994902687673772
2024-10-10 17:42:00,183 [INFO] [62] TRAIN  loss dict: {'classification_loss': 0.028372638357622135}
2024-10-10 17:42:00,183 [INFO] [62] VALIDATION loss: 1.0938055792616472 VALIDATION  acc: 0.73989898989899
2024-10-10 17:42:00,183 [INFO] [62] VALIDATION  loss dict: {'classification_loss': 1.0938055792616472}
2024-10-10 17:42:00,183 [INFO] 
2024-10-10 17:43:36,622 [INFO] Step[50/144]: training loss : 0.02712337645702064 TRAIN  loss dict:  {'classification_loss': 0.02712337645702064}
2024-10-10 17:44:47,767 [INFO] Step[100/144]: training loss : 0.030474742818623782 TRAIN  loss dict:  {'classification_loss': 0.030474742818623782}
2024-10-10 17:46:55,438 [INFO] Label accuracies statistics:
2024-10-10 17:46:55,438 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 1.0, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 1.0, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 17:46:55,528 [INFO] [63] TRAIN  loss: 0.028631871233099244 acc: 0.9937442075996293
2024-10-10 17:46:55,528 [INFO] [63] TRAIN  loss dict: {'classification_loss': 0.028631871233099244}
2024-10-10 17:46:55,528 [INFO] [63] VALIDATION loss: 1.1086497015699193 VALIDATION  acc: 0.7386363636363636
2024-10-10 17:46:55,528 [INFO] [63] VALIDATION  loss dict: {'classification_loss': 1.1086497015699193}
2024-10-10 17:46:55,528 [INFO] 
2024-10-10 17:48:32,883 [INFO] Step[50/144]: training loss : 0.026898791268467902 TRAIN  loss dict:  {'classification_loss': 0.026898791268467902}
2024-10-10 17:49:43,088 [INFO] Step[100/144]: training loss : 0.026816438836976885 TRAIN  loss dict:  {'classification_loss': 0.026816438836976885}
2024-10-10 17:51:50,622 [INFO] Label accuracies statistics:
2024-10-10 17:51:50,622 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 1.0, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.5, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-10 17:51:50,707 [INFO] [64] TRAIN  loss: 0.027852270936515804 acc: 0.9951343836886005
2024-10-10 17:51:50,707 [INFO] [64] TRAIN  loss dict: {'classification_loss': 0.027852270936515804}
2024-10-10 17:51:50,707 [INFO] [64] VALIDATION loss: 1.077956983336696 VALIDATION  acc: 0.7525252525252525
2024-10-10 17:51:50,707 [INFO] [64] VALIDATION  loss dict: {'classification_loss': 1.077956983336696}
2024-10-10 17:51:50,707 [INFO] 
2024-10-10 17:53:28,231 [INFO] Step[50/144]: training loss : 0.020952322455123067 TRAIN  loss dict:  {'classification_loss': 0.020952322455123067}
2024-10-10 17:54:39,426 [INFO] Step[100/144]: training loss : 0.0277041304577142 TRAIN  loss dict:  {'classification_loss': 0.0277041304577142}
2024-10-10 17:56:47,300 [INFO] Label accuracies statistics:
2024-10-10 17:56:47,300 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 1.0, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 17:56:47,378 [INFO] [65] TRAIN  loss: 0.025773002074048337 acc: 0.9942075996292864
2024-10-10 17:56:47,378 [INFO] [65] TRAIN  loss dict: {'classification_loss': 0.025773002074048337}
2024-10-10 17:56:47,378 [INFO] [65] VALIDATION loss: 1.0647759606578835 VALIDATION  acc: 0.7537878787878788
2024-10-10 17:56:47,378 [INFO] [65] VALIDATION  loss dict: {'classification_loss': 1.0647759606578835}
2024-10-10 17:56:47,378 [INFO] 
2024-10-10 17:56:47,378 [INFO] 

***Stop training***


2024-10-10 17:56:47,379 [INFO] 
Testing checkpointed models starting...

2024-10-10 17:57:49,574 [INFO] Label accuracies statistics:
2024-10-10 17:57:49,574 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.5, 14: 1.0, 15: 0.0, 16: 1.0, 17: 1.0, 18: 0.5, 19: 0.25, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 1.0, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.5, 43: 0.75, 44: 0.75, 45: 1.0, 46: 0.5, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 1.0, 52: 0.75, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.0, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.75, 84: 1.0, 85: 0.75, 86: 0.25, 87: 0.5, 88: 0.25, 89: 0.75, 90: 1.0, 91: 0.75, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.25, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.5, 103: 0.5, 104: 0.5, 105: 0.75, 106: 0.75, 107: 0.25, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.5, 114: 0.25, 115: 0.75, 116: 0.5, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.6666666666666666, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.5, 131: 0.75, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 1.0, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.5, 169: 0.25, 170: 1.0, 171: 0.5, 172: 0.5, 173: 0.25, 174: 0.75, 175: 0.25, 176: 0.75, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.25, 184: 0.5, 185: 1.0, 186: 1.0, 187: 0.75, 188: 0.5, 189: 1.0, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.5, 194: 0.75, 195: 0.25, 196: 0.75, 197: 0.5, 198: 1.0}

2024-10-10 17:57:49,644 [INFO] 
Testing accuracy: 0.706700379266751
