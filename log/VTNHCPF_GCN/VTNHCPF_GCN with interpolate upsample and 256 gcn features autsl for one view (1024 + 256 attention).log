2024-10-10 00:26:10,335 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features autsl for one view (1024 + 256 attention)...


2024-10-10 00:26:52,773 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features autsl for one view (1024 + 256 attention)...


2024-10-10 00:28:06,738 [INFO] Step[50/938]: training loss : 5.8127972030639645 TRAIN  loss dict:  {'classification_loss': 5.8127972030639645}
2024-10-10 00:28:58,926 [INFO] Step[100/938]: training loss : 5.579499835968018 TRAIN  loss dict:  {'classification_loss': 5.579499835968018}
2024-10-10 00:29:51,473 [INFO] Step[150/938]: training loss : 5.375479402542115 TRAIN  loss dict:  {'classification_loss': 5.375479402542115}
2024-10-10 00:30:44,311 [INFO] Step[200/938]: training loss : 5.067029209136963 TRAIN  loss dict:  {'classification_loss': 5.067029209136963}
2024-10-10 00:31:36,789 [INFO] Step[250/938]: training loss : 4.5954223728179935 TRAIN  loss dict:  {'classification_loss': 4.5954223728179935}
2024-10-10 00:32:29,445 [INFO] Step[300/938]: training loss : 4.189542622566223 TRAIN  loss dict:  {'classification_loss': 4.189542622566223}
2024-10-10 00:33:21,993 [INFO] Step[350/938]: training loss : 3.7722012424468994 TRAIN  loss dict:  {'classification_loss': 3.7722012424468994}
2024-10-10 00:34:15,007 [INFO] Step[400/938]: training loss : 3.4123400497436522 TRAIN  loss dict:  {'classification_loss': 3.4123400497436522}
2024-10-10 00:35:07,896 [INFO] Step[450/938]: training loss : 3.0873876142501833 TRAIN  loss dict:  {'classification_loss': 3.0873876142501833}
2024-10-10 00:36:00,624 [INFO] Step[500/938]: training loss : 2.77170654296875 TRAIN  loss dict:  {'classification_loss': 2.77170654296875}
2024-10-10 00:36:56,902 [INFO] Step[550/938]: training loss : 2.536208624839783 TRAIN  loss dict:  {'classification_loss': 2.536208624839783}
2024-10-10 00:37:52,882 [INFO] Step[600/938]: training loss : 2.2688494992256163 TRAIN  loss dict:  {'classification_loss': 2.2688494992256163}
2024-10-10 00:38:49,601 [INFO] Step[650/938]: training loss : 2.0121538758277895 TRAIN  loss dict:  {'classification_loss': 2.0121538758277895}
2024-10-10 00:39:43,448 [INFO] Step[700/938]: training loss : 1.8761320328712463 TRAIN  loss dict:  {'classification_loss': 1.8761320328712463}
2024-10-10 00:40:37,016 [INFO] Step[750/938]: training loss : 1.7533530068397523 TRAIN  loss dict:  {'classification_loss': 1.7533530068397523}
2024-10-10 00:41:31,052 [INFO] Step[800/938]: training loss : 1.5849286556243896 TRAIN  loss dict:  {'classification_loss': 1.5849286556243896}
2024-10-10 00:42:24,946 [INFO] Step[850/938]: training loss : 1.4640650701522828 TRAIN  loss dict:  {'classification_loss': 1.4640650701522828}
2024-10-10 00:43:19,119 [INFO] Step[900/938]: training loss : 1.341341758966446 TRAIN  loss dict:  {'classification_loss': 1.341341758966446}
2024-10-10 00:46:03,536 [INFO] Label accuracies statistics:
2024-10-10 00:46:03,537 [INFO] {0: 0.8, 1: 0.8947368421052632, 2: 0.9, 3: 0.9473684210526315, 4: 0.75, 5: 0.75, 6: 0.3076923076923077, 7: 0.6, 8: 0.6, 9: 0.3157894736842105, 10: 0.47368421052631576, 11: 1.0, 12: 0.6842105263157895, 13: 0.2, 14: 0.55, 15: 0.9, 16: 0.55, 17: 0.7222222222222222, 18: 0.7058823529411765, 19: 0.8947368421052632, 20: 0.9473684210526315, 21: 1.0, 22: 0.8, 23: 0.2, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 0.85, 28: 0.95, 29: 0.85, 30: 0.85, 31: 0.7, 32: 1.0, 33: 1.0, 34: 0.9, 35: 0.95, 36: 1.0, 37: 0.6, 38: 0.75, 39: 0.95, 40: 0.9, 41: 0.7, 42: 0.75, 43: 0.75, 44: 0.9473684210526315, 45: 0.5, 46: 0.8, 47: 0.25, 48: 0.6, 49: 0.6842105263157895, 50: 1.0, 51: 0.7222222222222222, 52: 0.16666666666666666, 53: 0.55, 54: 0.85, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 1.0, 58: 0.75, 59: 0.7777777777777778, 60: 0.8, 61: 0.5789473684210527, 62: 0.5789473684210527, 63: 0.6842105263157895, 64: 0.55, 65: 0.2, 66: 1.0, 67: 1.0, 68: 0.7222222222222222, 69: 0.7222222222222222, 70: 0.95, 71: 0.65, 72: 1.0, 73: 0.7368421052631579, 74: 0.95, 75: 0.5, 76: 0.6842105263157895, 77: 1.0, 78: 0.75, 79: 0.8235294117647058, 80: 0.9, 81: 0.6, 82: 0.95, 83: 1.0, 84: 0.85, 85: 1.0, 86: 0.7, 87: 0.8235294117647058, 88: 0.9, 89: 0.7058823529411765, 90: 0.7, 91: 0.6, 92: 0.65, 93: 0.95, 94: 0.5789473684210527, 95: 0.6666666666666666, 96: 0.35294117647058826, 97: 0.55, 98: 0.3684210526315789, 99: 0.65, 100: 0.95, 101: 1.0, 102: 0.9473684210526315, 103: 0.85, 104: 0.7, 105: 1.0, 106: 1.0, 107: 0.55, 108: 1.0, 109: 0.95, 110: 0.9, 111: 0.4, 112: 1.0, 113: 0.75, 114: 0.9, 115: 1.0, 116: 0.85, 117: 0.7894736842105263, 118: 1.0, 119: 0.75, 120: 0.9, 121: 0.95, 122: 0.45, 123: 0.65, 124: 0.9, 125: 0.6, 126: 0.65, 127: 0.25, 128: 0.85, 129: 0.85, 130: 1.0, 131: 0.5, 132: 0.5263157894736842, 133: 1.0, 134: 0.7, 135: 0.75, 136: 0.9, 137: 0.8, 138: 0.65, 139: 0.7, 140: 0.85, 141: 0.85, 142: 0.4, 143: 0.8, 144: 0.85, 145: 0.8421052631578947, 146: 0.95, 147: 0.55, 148: 0.6, 149: 0.8421052631578947, 150: 0.55, 151: 1.0, 152: 1.0, 153: 0.85, 154: 0.25, 155: 0.7, 156: 0.7894736842105263, 157: 0.5, 158: 0.6470588235294118, 159: 1.0, 160: 0.7, 161: 0.8, 162: 0.95, 163: 0.45, 164: 0.05263157894736842, 165: 1.0, 166: 0.4, 167: 0.8, 168: 0.9, 169: 1.0, 170: 0.8421052631578947, 171: 0.8, 172: 0.0, 173: 0.7, 174: 0.95, 175: 0.8888888888888888, 176: 0.9, 177: 0.9, 178: 0.15, 179: 0.85, 180: 1.0, 181: 0.9, 182: 0.4, 183: 0.65, 184: 0.8, 185: 0.65, 186: 0.5, 187: 0.15789473684210525, 188: 0.9, 189: 0.8, 190: 0.4, 191: 1.0, 192: 0.75, 193: 0.9, 194: 0.85, 195: 0.8888888888888888, 196: 0.9, 197: 0.85, 198: 0.85, 199: 0.9, 200: 0.9473684210526315, 201: 1.0, 202: 0.65, 203: 0.9, 204: 0.45, 205: 0.6, 206: 0.3333333333333333, 207: 0.6, 208: 1.0, 209: 0.95, 210: 1.0, 211: 0.6, 212: 0.9411764705882353, 213: 0.65, 214: 0.8, 215: 0.9, 216: 0.9, 217: 0.55, 218: 0.85, 219: 1.0, 220: 0.6, 221: 0.45, 222: 0.7894736842105263, 223: 0.95, 224: 0.4, 225: 0.55}

2024-10-10 00:46:03,990 [INFO] [1] TRAIN  loss: 3.169782449441678 acc: 0.31142471207166217
2024-10-10 00:46:03,990 [INFO] [1] TRAIN  loss dict: {'classification_loss': 3.169782449441678}
2024-10-10 00:46:03,991 [INFO] [1] VALIDATION loss: 0.9977309208463978 VALIDATION  acc: 0.7512449071978271
2024-10-10 00:46:03,991 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 0.9977309208463978}
2024-10-10 00:46:03,991 [INFO] 
2024-10-10 00:47:31,228 [INFO] Step[50/938]: training loss : 1.15100732922554 TRAIN  loss dict:  {'classification_loss': 1.15100732922554}
2024-10-10 00:48:29,015 [INFO] Step[100/938]: training loss : 1.072725465297699 TRAIN  loss dict:  {'classification_loss': 1.072725465297699}
2024-10-10 00:49:26,071 [INFO] Step[150/938]: training loss : 1.0614646410942077 TRAIN  loss dict:  {'classification_loss': 1.0614646410942077}
2024-10-10 00:50:23,046 [INFO] Step[200/938]: training loss : 0.9344378423690796 TRAIN  loss dict:  {'classification_loss': 0.9344378423690796}
2024-10-10 00:51:24,565 [INFO] Step[250/938]: training loss : 0.9675129187107087 TRAIN  loss dict:  {'classification_loss': 0.9675129187107087}
2024-10-10 00:52:22,668 [INFO] Step[300/938]: training loss : 0.917423598766327 TRAIN  loss dict:  {'classification_loss': 0.917423598766327}
2024-10-10 00:53:20,787 [INFO] Step[350/938]: training loss : 0.8752751433849335 TRAIN  loss dict:  {'classification_loss': 0.8752751433849335}
2024-10-10 00:54:18,801 [INFO] Step[400/938]: training loss : 0.8304940366744995 TRAIN  loss dict:  {'classification_loss': 0.8304940366744995}
2024-10-10 00:55:18,767 [INFO] Step[450/938]: training loss : 0.7971407103538514 TRAIN  loss dict:  {'classification_loss': 0.7971407103538514}
2024-10-10 00:56:20,331 [INFO] Step[500/938]: training loss : 0.8023725736141205 TRAIN  loss dict:  {'classification_loss': 0.8023725736141205}
2024-10-10 00:57:19,484 [INFO] Step[550/938]: training loss : 0.7469017308950424 TRAIN  loss dict:  {'classification_loss': 0.7469017308950424}
2024-10-10 00:58:17,644 [INFO] Step[600/938]: training loss : 0.7624573338031769 TRAIN  loss dict:  {'classification_loss': 0.7624573338031769}
2024-10-10 00:59:16,346 [INFO] Step[650/938]: training loss : 0.6821878916025161 TRAIN  loss dict:  {'classification_loss': 0.6821878916025161}
2024-10-10 01:00:19,069 [INFO] Step[700/938]: training loss : 0.7317602467536927 TRAIN  loss dict:  {'classification_loss': 0.7317602467536927}
2024-10-10 01:01:17,994 [INFO] Step[750/938]: training loss : 0.6182116591930389 TRAIN  loss dict:  {'classification_loss': 0.6182116591930389}
2024-10-10 01:02:16,090 [INFO] Step[800/938]: training loss : 0.6093753361701966 TRAIN  loss dict:  {'classification_loss': 0.6093753361701966}
2024-10-10 01:03:14,490 [INFO] Step[850/938]: training loss : 0.5948417717218399 TRAIN  loss dict:  {'classification_loss': 0.5948417717218399}
2024-10-10 01:04:18,227 [INFO] Step[900/938]: training loss : 0.6038121736049652 TRAIN  loss dict:  {'classification_loss': 0.6038121736049652}
2024-10-10 01:07:21,044 [INFO] Label accuracies statistics:
2024-10-10 01:07:21,044 [INFO] {0: 0.8, 1: 0.7368421052631579, 2: 0.75, 3: 0.9473684210526315, 4: 0.85, 5: 0.8, 6: 0.38461538461538464, 7: 0.9, 8: 0.95, 9: 0.3684210526315789, 10: 1.0, 11: 0.75, 12: 0.631578947368421, 13: 0.85, 14: 0.6, 15: 0.9, 16: 0.5, 17: 0.3888888888888889, 18: 0.8235294117647058, 19: 0.6842105263157895, 20: 1.0, 21: 0.9473684210526315, 22: 0.8, 23: 0.5, 24: 0.7368421052631579, 25: 0.9, 26: 0.8947368421052632, 27: 0.95, 28: 0.85, 29: 0.95, 30: 0.85, 31: 0.9, 32: 1.0, 33: 0.95, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.95, 39: 1.0, 40: 0.9, 41: 0.95, 42: 0.95, 43: 0.75, 44: 0.8947368421052632, 45: 0.95, 46: 0.85, 47: 0.2, 48: 0.25, 49: 0.7894736842105263, 50: 1.0, 51: 0.7222222222222222, 52: 0.8333333333333334, 53: 0.85, 54: 0.9, 55: 0.8421052631578947, 56: 0.8947368421052632, 57: 0.9, 58: 1.0, 59: 0.7777777777777778, 60: 0.95, 61: 0.7894736842105263, 62: 0.5789473684210527, 63: 0.9473684210526315, 64: 0.95, 65: 0.85, 66: 1.0, 67: 0.9, 68: 0.5555555555555556, 69: 0.8333333333333334, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8947368421052632, 74: 0.95, 75: 0.55, 76: 0.5789473684210527, 77: 1.0, 78: 0.75, 79: 0.7647058823529411, 80: 1.0, 81: 0.65, 82: 0.85, 83: 0.9, 84: 0.55, 85: 1.0, 86: 0.75, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.6, 91: 0.35, 92: 0.7, 93: 0.75, 94: 0.8947368421052632, 95: 0.9166666666666666, 96: 0.5294117647058824, 97: 0.75, 98: 0.6842105263157895, 99: 0.85, 100: 0.8, 101: 0.95, 102: 0.9473684210526315, 103: 0.8, 104: 0.45, 105: 1.0, 106: 1.0, 107: 0.65, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.6, 112: 1.0, 113: 0.85, 114: 0.95, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 0.9411764705882353, 119: 1.0, 120: 0.85, 121: 0.95, 122: 0.8, 123: 0.85, 124: 0.95, 125: 0.75, 126: 0.7, 127: 0.75, 128: 1.0, 129: 0.8, 130: 1.0, 131: 0.8125, 132: 0.8421052631578947, 133: 1.0, 134: 0.8, 135: 0.85, 136: 1.0, 137: 0.8, 138: 0.75, 139: 0.9, 140: 0.9, 141: 0.9, 142: 0.65, 143: 0.8, 144: 0.8, 145: 0.9473684210526315, 146: 0.9, 147: 0.7, 148: 1.0, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 0.95, 153: 0.9, 154: 0.6, 155: 0.85, 156: 0.7894736842105263, 157: 1.0, 158: 0.4117647058823529, 159: 1.0, 160: 0.95, 161: 0.35, 162: 0.75, 163: 0.8, 164: 0.8947368421052632, 165: 0.7, 166: 0.9, 167: 0.95, 168: 1.0, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.4, 173: 0.8, 174: 0.9, 175: 0.1111111111111111, 176: 1.0, 177: 1.0, 178: 0.8, 179: 0.95, 180: 0.95, 181: 1.0, 182: 0.65, 183: 0.8, 184: 0.9, 185: 0.9, 186: 0.75, 187: 0.5789473684210527, 188: 0.75, 189: 0.9, 190: 0.95, 191: 1.0, 192: 1.0, 193: 0.9, 194: 0.75, 195: 0.5, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.85, 200: 0.9473684210526315, 201: 0.95, 202: 1.0, 203: 0.95, 204: 0.9, 205: 0.9, 206: 0.05555555555555555, 207: 0.65, 208: 1.0, 209: 0.85, 210: 1.0, 211: 0.7, 212: 0.8823529411764706, 213: 0.7, 214: 0.85, 215: 0.9, 216: 0.65, 217: 0.55, 218: 0.85, 219: 1.0, 220: 0.85, 221: 0.6, 222: 0.9473684210526315, 223: 0.95, 224: 0.65, 225: 0.85}

2024-10-10 01:07:21,776 [INFO] [2] TRAIN  loss: 0.8112696831795707 acc: 0.7797525949097114
2024-10-10 01:07:21,776 [INFO] [2] TRAIN  loss dict: {'classification_loss': 0.8112696831795707}
2024-10-10 01:07:21,776 [INFO] [2] VALIDATION loss: 0.6465763761284383 VALIDATION  acc: 0.8291081937528293
2024-10-10 01:07:21,776 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 0.6465763761284383}
2024-10-10 01:07:21,777 [INFO] 
2024-10-10 01:08:47,541 [INFO] Step[50/938]: training loss : 0.5064038693904876 TRAIN  loss dict:  {'classification_loss': 0.5064038693904876}
2024-10-10 01:09:46,448 [INFO] Step[100/938]: training loss : 0.505797089934349 TRAIN  loss dict:  {'classification_loss': 0.505797089934349}
2024-10-10 01:10:44,825 [INFO] Step[150/938]: training loss : 0.44152666091918946 TRAIN  loss dict:  {'classification_loss': 0.44152666091918946}
2024-10-10 01:11:42,965 [INFO] Step[200/938]: training loss : 0.4636909872293472 TRAIN  loss dict:  {'classification_loss': 0.4636909872293472}
2024-10-10 01:12:46,659 [INFO] Step[250/938]: training loss : 0.44588213711977004 TRAIN  loss dict:  {'classification_loss': 0.44588213711977004}
2024-10-10 01:13:46,009 [INFO] Step[300/938]: training loss : 0.4646872082352638 TRAIN  loss dict:  {'classification_loss': 0.4646872082352638}
2024-10-10 01:14:44,541 [INFO] Step[350/938]: training loss : 0.45555351436138153 TRAIN  loss dict:  {'classification_loss': 0.45555351436138153}
2024-10-10 01:15:43,435 [INFO] Step[400/938]: training loss : 0.4784149107336998 TRAIN  loss dict:  {'classification_loss': 0.4784149107336998}
2024-10-10 01:16:47,182 [INFO] Step[450/938]: training loss : 0.4750423201918602 TRAIN  loss dict:  {'classification_loss': 0.4750423201918602}
2024-10-10 01:17:46,828 [INFO] Step[500/938]: training loss : 0.4306542119383812 TRAIN  loss dict:  {'classification_loss': 0.4306542119383812}
2024-10-10 01:18:45,133 [INFO] Step[550/938]: training loss : 0.42847025364637376 TRAIN  loss dict:  {'classification_loss': 0.42847025364637376}
2024-10-10 01:19:44,229 [INFO] Step[600/938]: training loss : 0.4302137416601181 TRAIN  loss dict:  {'classification_loss': 0.4302137416601181}
2024-10-10 01:20:46,136 [INFO] Step[650/938]: training loss : 0.44846081376075747 TRAIN  loss dict:  {'classification_loss': 0.44846081376075747}
2024-10-10 01:21:46,563 [INFO] Step[700/938]: training loss : 0.4037578921020031 TRAIN  loss dict:  {'classification_loss': 0.4037578921020031}
2024-10-10 01:22:45,193 [INFO] Step[750/938]: training loss : 0.3811156052350998 TRAIN  loss dict:  {'classification_loss': 0.3811156052350998}
2024-10-10 01:23:44,202 [INFO] Step[800/938]: training loss : 0.38568340241909027 TRAIN  loss dict:  {'classification_loss': 0.38568340241909027}
2024-10-10 01:24:44,641 [INFO] Step[850/938]: training loss : 0.4143151798844337 TRAIN  loss dict:  {'classification_loss': 0.4143151798844337}
2024-10-10 01:25:47,066 [INFO] Step[900/938]: training loss : 0.4483774158358574 TRAIN  loss dict:  {'classification_loss': 0.4483774158358574}
2024-10-10 01:28:34,204 [INFO] Label accuracies statistics:
2024-10-10 01:28:34,204 [INFO] {0: 0.85, 1: 0.9473684210526315, 2: 0.9, 3: 1.0, 4: 0.9, 5: 0.7, 6: 0.46153846153846156, 7: 0.8, 8: 1.0, 9: 0.7894736842105263, 10: 0.7368421052631579, 11: 0.8, 12: 0.7894736842105263, 13: 0.8, 14: 0.7, 15: 0.9, 16: 0.5, 17: 0.6666666666666666, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 0.8947368421052632, 22: 0.45, 23: 0.75, 24: 0.8947368421052632, 25: 0.95, 26: 0.8947368421052632, 27: 0.65, 28: 0.85, 29: 0.85, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.85, 34: 0.75, 35: 0.95, 36: 0.9473684210526315, 37: 0.6, 38: 0.95, 39: 1.0, 40: 1.0, 41: 0.8, 42: 0.9, 43: 0.7, 44: 0.8421052631578947, 45: 0.75, 46: 0.9, 47: 0.5, 48: 0.75, 49: 0.8947368421052632, 50: 1.0, 51: 0.8333333333333334, 52: 0.5, 53: 0.55, 54: 0.9, 55: 0.5263157894736842, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.7222222222222222, 60: 0.85, 61: 0.7894736842105263, 62: 0.6842105263157895, 63: 0.9473684210526315, 64: 1.0, 65: 0.95, 66: 0.95, 67: 0.95, 68: 0.7222222222222222, 69: 0.5, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.55, 76: 1.0, 77: 1.0, 78: 0.85, 79: 0.8823529411764706, 80: 1.0, 81: 0.85, 82: 0.55, 83: 0.95, 84: 0.8, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.9, 89: 0.5294117647058824, 90: 0.65, 91: 0.9, 92: 0.95, 93: 0.95, 94: 0.8947368421052632, 95: 0.5, 96: 0.5294117647058824, 97: 0.7, 98: 0.5789473684210527, 99: 0.9, 100: 0.35, 101: 0.95, 102: 0.9473684210526315, 103: 0.95, 104: 0.65, 105: 0.95, 106: 1.0, 107: 0.65, 108: 0.9, 109: 1.0, 110: 1.0, 111: 0.6, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 0.95, 117: 1.0, 118: 1.0, 119: 0.95, 120: 1.0, 121: 1.0, 122: 0.55, 123: 0.75, 124: 0.9, 125: 0.85, 126: 0.6, 127: 0.75, 128: 0.85, 129: 0.85, 130: 1.0, 131: 0.875, 132: 0.8421052631578947, 133: 1.0, 134: 0.95, 135: 0.9, 136: 0.9, 137: 0.55, 138: 0.75, 139: 0.65, 140: 0.9, 141: 1.0, 142: 0.75, 143: 0.8, 144: 0.85, 145: 0.9473684210526315, 146: 0.75, 147: 0.5, 148: 0.7, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 0.95, 153: 1.0, 154: 0.45, 155: 0.85, 156: 0.7894736842105263, 157: 0.9, 158: 0.6470588235294118, 159: 1.0, 160: 1.0, 161: 0.75, 162: 0.9, 163: 0.8, 164: 0.8947368421052632, 165: 0.7, 166: 0.7, 167: 0.95, 168: 0.95, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.6, 173: 0.8, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.35, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.45, 184: 1.0, 185: 0.8, 186: 0.95, 187: 0.42105263157894735, 188: 0.85, 189: 0.65, 190: 0.6, 191: 0.95, 192: 0.85, 193: 0.95, 194: 0.9, 195: 0.8333333333333334, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.9, 200: 0.9473684210526315, 201: 1.0, 202: 0.75, 203: 0.45, 204: 0.9, 205: 0.95, 206: 0.2222222222222222, 207: 0.8, 208: 1.0, 209: 0.9, 210: 1.0, 211: 0.75, 212: 0.7647058823529411, 213: 0.8, 214: 0.9, 215: 0.85, 216: 0.9, 217: 0.7, 218: 0.8, 219: 1.0, 220: 1.0, 221: 0.55, 222: 0.9473684210526315, 223: 1.0, 224: 0.65, 225: 0.85}

2024-10-10 01:28:35,144 [INFO] [3] TRAIN  loss: 0.4425233460581506 acc: 0.8713209156832077
2024-10-10 01:28:35,145 [INFO] [3] TRAIN  loss dict: {'classification_loss': 0.4425233460581506}
2024-10-10 01:28:35,145 [INFO] [3] VALIDATION loss: 0.592931604616948 VALIDATION  acc: 0.8356722498868266
2024-10-10 01:28:35,145 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 0.592931604616948}
2024-10-10 01:28:35,145 [INFO] 
2024-10-10 01:30:04,170 [INFO] Step[50/938]: training loss : 0.3314151245355606 TRAIN  loss dict:  {'classification_loss': 0.3314151245355606}
2024-10-10 01:31:02,852 [INFO] Step[100/938]: training loss : 0.31721251636743547 TRAIN  loss dict:  {'classification_loss': 0.31721251636743547}
2024-10-10 01:32:01,143 [INFO] Step[150/938]: training loss : 0.3461013287305832 TRAIN  loss dict:  {'classification_loss': 0.3461013287305832}
2024-10-10 01:33:00,181 [INFO] Step[200/938]: training loss : 0.35335914582014083 TRAIN  loss dict:  {'classification_loss': 0.35335914582014083}
2024-10-10 01:34:03,199 [INFO] Step[250/938]: training loss : 0.32416251197457313 TRAIN  loss dict:  {'classification_loss': 0.32416251197457313}
2024-10-10 01:35:02,703 [INFO] Step[300/938]: training loss : 0.3381842465698719 TRAIN  loss dict:  {'classification_loss': 0.3381842465698719}
2024-10-10 01:36:01,387 [INFO] Step[350/938]: training loss : 0.33817084074020387 TRAIN  loss dict:  {'classification_loss': 0.33817084074020387}
2024-10-10 01:36:59,942 [INFO] Step[400/938]: training loss : 0.300300856679678 TRAIN  loss dict:  {'classification_loss': 0.300300856679678}
2024-10-10 01:38:04,064 [INFO] Step[450/938]: training loss : 0.3484960715472698 TRAIN  loss dict:  {'classification_loss': 0.3484960715472698}
2024-10-10 01:39:03,280 [INFO] Step[500/938]: training loss : 0.31031608670949934 TRAIN  loss dict:  {'classification_loss': 0.31031608670949934}
2024-10-10 01:40:02,064 [INFO] Step[550/938]: training loss : 0.31860960856080056 TRAIN  loss dict:  {'classification_loss': 0.31860960856080056}
2024-10-10 01:41:00,986 [INFO] Step[600/938]: training loss : 0.3280942450463772 TRAIN  loss dict:  {'classification_loss': 0.3280942450463772}
2024-10-10 01:42:04,777 [INFO] Step[650/938]: training loss : 0.3116518339514732 TRAIN  loss dict:  {'classification_loss': 0.3116518339514732}
2024-10-10 01:43:04,341 [INFO] Step[700/938]: training loss : 0.2882685421407223 TRAIN  loss dict:  {'classification_loss': 0.2882685421407223}
2024-10-10 01:44:02,609 [INFO] Step[750/938]: training loss : 0.29853722304105756 TRAIN  loss dict:  {'classification_loss': 0.29853722304105756}
2024-10-10 01:45:02,097 [INFO] Step[800/938]: training loss : 0.3068149318546057 TRAIN  loss dict:  {'classification_loss': 0.3068149318546057}
2024-10-10 01:46:04,926 [INFO] Step[850/938]: training loss : 0.3375497296452522 TRAIN  loss dict:  {'classification_loss': 0.3375497296452522}
2024-10-10 01:47:04,263 [INFO] Step[900/938]: training loss : 0.2856000332534313 TRAIN  loss dict:  {'classification_loss': 0.2856000332534313}
2024-10-10 01:50:10,054 [INFO] Label accuracies statistics:
2024-10-10 01:50:10,055 [INFO] {0: 0.75, 1: 0.7368421052631579, 2: 1.0, 3: 1.0, 4: 0.95, 5: 0.85, 6: 0.38461538461538464, 7: 1.0, 8: 0.95, 9: 0.7368421052631579, 10: 0.8947368421052632, 11: 0.75, 12: 0.6842105263157895, 13: 0.65, 14: 0.8, 15: 1.0, 16: 0.45, 17: 0.6666666666666666, 18: 0.7058823529411765, 19: 0.8421052631578947, 20: 0.9473684210526315, 21: 1.0, 22: 0.65, 23: 0.8, 24: 0.8421052631578947, 25: 1.0, 26: 0.8421052631578947, 27: 0.95, 28: 1.0, 29: 0.95, 30: 0.9, 31: 0.9, 32: 1.0, 33: 1.0, 34: 0.55, 35: 0.95, 36: 0.8947368421052632, 37: 0.6, 38: 0.95, 39: 0.9, 40: 1.0, 41: 0.95, 42: 1.0, 43: 0.95, 44: 0.9473684210526315, 45: 0.95, 46: 1.0, 47: 0.25, 48: 0.95, 49: 0.7368421052631579, 50: 1.0, 51: 0.8333333333333334, 52: 0.9444444444444444, 53: 0.7, 54: 0.9, 55: 0.8421052631578947, 56: 1.0, 57: 0.85, 58: 0.875, 59: 0.8333333333333334, 60: 0.95, 61: 0.7894736842105263, 62: 0.631578947368421, 63: 0.8421052631578947, 64: 1.0, 65: 0.9, 66: 1.0, 67: 0.7, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 1.0, 72: 0.9473684210526315, 73: 0.6842105263157895, 74: 1.0, 75: 0.85, 76: 0.8421052631578947, 77: 1.0, 78: 0.75, 79: 1.0, 80: 0.95, 81: 0.75, 82: 0.9, 83: 0.95, 84: 0.95, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.95, 89: 0.8823529411764706, 90: 0.7, 91: 0.9, 92: 0.75, 93: 0.8, 94: 0.9473684210526315, 95: 0.5833333333333334, 96: 0.47058823529411764, 97: 0.5, 98: 0.631578947368421, 99: 1.0, 100: 0.95, 101: 0.8, 102: 0.9473684210526315, 103: 0.65, 104: 0.65, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.85, 111: 0.55, 112: 1.0, 113: 0.85, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.8421052631578947, 118: 1.0, 119: 0.95, 120: 0.65, 121: 0.95, 122: 0.65, 123: 1.0, 124: 0.9, 125: 0.9, 126: 0.8, 127: 0.85, 128: 0.85, 129: 0.75, 130: 1.0, 131: 0.6875, 132: 0.9473684210526315, 133: 1.0, 134: 0.95, 135: 0.85, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.85, 141: 0.9, 142: 0.55, 143: 0.95, 144: 0.9, 145: 0.8421052631578947, 146: 0.85, 147: 0.55, 148: 0.85, 149: 0.8421052631578947, 150: 0.55, 151: 1.0, 152: 0.9, 153: 0.95, 154: 0.45, 155: 0.85, 156: 0.8421052631578947, 157: 0.95, 158: 0.9411764705882353, 159: 1.0, 160: 1.0, 161: 0.75, 162: 0.95, 163: 0.85, 164: 0.7368421052631579, 165: 0.7, 166: 0.7, 167: 0.9, 168: 1.0, 169: 0.95, 170: 0.8947368421052632, 171: 1.0, 172: 0.45, 173: 0.8, 174: 1.0, 175: 1.0, 176: 1.0, 177: 1.0, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 1.0, 184: 1.0, 185: 0.9, 186: 0.7, 187: 0.47368421052631576, 188: 0.65, 189: 0.95, 190: 0.8, 191: 1.0, 192: 0.85, 193: 1.0, 194: 0.7, 195: 0.7777777777777778, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.95, 203: 0.65, 204: 1.0, 205: 0.8, 206: 0.2777777777777778, 207: 0.6, 208: 1.0, 209: 0.85, 210: 1.0, 211: 0.65, 212: 0.8823529411764706, 213: 0.75, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.75, 218: 0.9, 219: 0.9, 220: 1.0, 221: 0.6, 222: 0.9473684210526315, 223: 1.0, 224: 0.65, 225: 0.85}

2024-10-10 01:50:20,634 [INFO] [4] TRAIN  loss: 0.32006871863516534 acc: 0.9047703682638988
2024-10-10 01:50:20,635 [INFO] [4] TRAIN  loss dict: {'classification_loss': 0.32006871863516534}
2024-10-10 01:50:20,635 [INFO] [4] VALIDATION loss: 0.518705276860478 VALIDATION  acc: 0.854232684472612
2024-10-10 01:50:20,635 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 0.518705276860478}
2024-10-10 01:50:20,635 [INFO] 
2024-10-10 01:51:49,525 [INFO] Step[50/938]: training loss : 0.23918399803340434 TRAIN  loss dict:  {'classification_loss': 0.23918399803340434}
2024-10-10 01:52:48,549 [INFO] Step[100/938]: training loss : 0.2637743018567562 TRAIN  loss dict:  {'classification_loss': 0.2637743018567562}
2024-10-10 01:53:47,433 [INFO] Step[150/938]: training loss : 0.24413499742746353 TRAIN  loss dict:  {'classification_loss': 0.24413499742746353}
2024-10-10 01:54:50,334 [INFO] Step[200/938]: training loss : 0.24296586707234383 TRAIN  loss dict:  {'classification_loss': 0.24296586707234383}
2024-10-10 01:55:49,526 [INFO] Step[250/938]: training loss : 0.23379145227372647 TRAIN  loss dict:  {'classification_loss': 0.23379145227372647}
2024-10-10 01:56:48,136 [INFO] Step[300/938]: training loss : 0.2532104702293873 TRAIN  loss dict:  {'classification_loss': 0.2532104702293873}
2024-10-10 01:57:47,410 [INFO] Step[350/938]: training loss : 0.2360087025910616 TRAIN  loss dict:  {'classification_loss': 0.2360087025910616}
2024-10-10 01:58:48,404 [INFO] Step[400/938]: training loss : 0.22928697988390923 TRAIN  loss dict:  {'classification_loss': 0.22928697988390923}
2024-10-10 01:59:49,800 [INFO] Step[450/938]: training loss : 0.2569666258990765 TRAIN  loss dict:  {'classification_loss': 0.2569666258990765}
2024-10-10 02:00:48,496 [INFO] Step[500/938]: training loss : 0.25631342828273773 TRAIN  loss dict:  {'classification_loss': 0.25631342828273773}
2024-10-10 02:01:47,785 [INFO] Step[550/938]: training loss : 0.2225437704473734 TRAIN  loss dict:  {'classification_loss': 0.2225437704473734}
2024-10-10 02:02:47,523 [INFO] Step[600/938]: training loss : 0.2486079379171133 TRAIN  loss dict:  {'classification_loss': 0.2486079379171133}
2024-10-10 02:03:50,356 [INFO] Step[650/938]: training loss : 0.24477326773107053 TRAIN  loss dict:  {'classification_loss': 0.24477326773107053}
2024-10-10 02:04:50,217 [INFO] Step[700/938]: training loss : 0.245697038769722 TRAIN  loss dict:  {'classification_loss': 0.245697038769722}
2024-10-10 02:05:49,301 [INFO] Step[750/938]: training loss : 0.23922239512205123 TRAIN  loss dict:  {'classification_loss': 0.23922239512205123}
2024-10-10 02:06:48,246 [INFO] Step[800/938]: training loss : 0.24094495192170143 TRAIN  loss dict:  {'classification_loss': 0.24094495192170143}
2024-10-10 02:07:51,666 [INFO] Step[850/938]: training loss : 0.2550140157341957 TRAIN  loss dict:  {'classification_loss': 0.2550140157341957}
2024-10-10 02:08:51,604 [INFO] Step[900/938]: training loss : 0.21847431130707265 TRAIN  loss dict:  {'classification_loss': 0.21847431130707265}
2024-10-10 02:11:45,040 [INFO] Label accuracies statistics:
2024-10-10 02:11:45,040 [INFO] {0: 0.75, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.85, 5: 0.8, 6: 0.46153846153846156, 7: 0.85, 8: 0.85, 9: 0.3684210526315789, 10: 0.8421052631578947, 11: 0.8, 12: 0.5789473684210527, 13: 0.85, 14: 0.85, 15: 0.9, 16: 0.45, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 1.0, 21: 0.8947368421052632, 22: 0.9, 23: 0.9, 24: 0.8947368421052632, 25: 0.9, 26: 0.8947368421052632, 27: 0.9, 28: 0.75, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.9, 34: 0.7, 35: 0.95, 36: 1.0, 37: 0.65, 38: 0.9, 39: 1.0, 40: 0.8, 41: 0.95, 42: 1.0, 43: 1.0, 44: 0.9473684210526315, 45: 0.65, 46: 0.9, 47: 0.5, 48: 0.65, 49: 0.8947368421052632, 50: 1.0, 51: 0.8888888888888888, 52: 0.7222222222222222, 53: 1.0, 54: 1.0, 55: 0.7894736842105263, 56: 1.0, 57: 0.9, 58: 0.4375, 59: 0.8333333333333334, 60: 0.95, 61: 0.6842105263157895, 62: 0.5263157894736842, 63: 0.8421052631578947, 64: 0.95, 65: 0.85, 66: 1.0, 67: 0.7, 68: 0.6666666666666666, 69: 0.9444444444444444, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.7368421052631579, 74: 1.0, 75: 0.7, 76: 0.42105263157894735, 77: 1.0, 78: 0.7, 79: 1.0, 80: 1.0, 81: 0.8, 82: 0.95, 83: 0.95, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.95, 89: 0.8235294117647058, 90: 0.8, 91: 0.4, 92: 0.85, 93: 0.8, 94: 1.0, 95: 0.4166666666666667, 96: 0.6470588235294118, 97: 0.65, 98: 0.47368421052631576, 99: 0.95, 100: 0.95, 101: 0.85, 102: 0.9473684210526315, 103: 0.45, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.7, 108: 1.0, 109: 1.0, 110: 0.9, 111: 0.75, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.65, 123: 0.8, 124: 0.95, 125: 0.8, 126: 0.7, 127: 0.45, 128: 0.95, 129: 0.85, 130: 1.0, 131: 0.8125, 132: 0.8421052631578947, 133: 1.0, 134: 0.7, 135: 0.9, 136: 0.95, 137: 0.85, 138: 0.85, 139: 1.0, 140: 0.65, 141: 1.0, 142: 0.6, 143: 1.0, 144: 0.9, 145: 0.9473684210526315, 146: 0.9, 147: 0.7, 148: 1.0, 149: 0.9473684210526315, 150: 0.7, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.4, 155: 0.95, 156: 0.8421052631578947, 157: 0.5, 158: 1.0, 159: 1.0, 160: 1.0, 161: 0.75, 162: 0.85, 163: 0.9, 164: 0.8947368421052632, 165: 0.7, 166: 0.6, 167: 0.95, 168: 0.9, 169: 1.0, 170: 0.9473684210526315, 171: 1.0, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.7222222222222222, 176: 1.0, 177: 0.9, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.8, 184: 0.75, 185: 0.85, 186: 0.65, 187: 0.9473684210526315, 188: 0.95, 189: 0.95, 190: 0.95, 191: 1.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.8333333333333334, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.75, 203: 0.9, 204: 0.95, 205: 0.85, 206: 0.3333333333333333, 207: 0.7, 208: 1.0, 209: 1.0, 210: 1.0, 211: 0.75, 212: 0.7058823529411765, 213: 0.75, 214: 0.9, 215: 0.9, 216: 0.9, 217: 0.95, 218: 0.8, 219: 1.0, 220: 1.0, 221: 0.45, 222: 1.0, 223: 1.0, 224: 1.0, 225: 0.9}

2024-10-10 02:11:45,828 [INFO] [5] TRAIN  loss: 0.24260941036204411 acc: 0.9280179155410209
2024-10-10 02:11:45,828 [INFO] [5] TRAIN  loss dict: {'classification_loss': 0.24260941036204411}
2024-10-10 02:11:45,828 [INFO] [5] VALIDATION loss: 0.5078833553738691 VALIDATION  acc: 0.8580805794477139
2024-10-10 02:11:45,828 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 0.5078833553738691}
2024-10-10 02:11:45,829 [INFO] 
2024-10-10 02:13:06,636 [INFO] Step[50/938]: training loss : 0.19917754881083966 TRAIN  loss dict:  {'classification_loss': 0.19917754881083966}
2024-10-10 02:14:05,106 [INFO] Step[100/938]: training loss : 0.17149667516350747 TRAIN  loss dict:  {'classification_loss': 0.17149667516350747}
2024-10-10 02:15:03,243 [INFO] Step[150/938]: training loss : 0.17814933005720376 TRAIN  loss dict:  {'classification_loss': 0.17814933005720376}
2024-10-10 02:16:06,866 [INFO] Step[200/938]: training loss : 0.21241982907056808 TRAIN  loss dict:  {'classification_loss': 0.21241982907056808}
2024-10-10 02:17:07,012 [INFO] Step[250/938]: training loss : 0.16589072436094285 TRAIN  loss dict:  {'classification_loss': 0.16589072436094285}
2024-10-10 02:18:05,655 [INFO] Step[300/938]: training loss : 0.21751816168427468 TRAIN  loss dict:  {'classification_loss': 0.21751816168427468}
2024-10-10 02:19:04,579 [INFO] Step[350/938]: training loss : 0.18480715692043304 TRAIN  loss dict:  {'classification_loss': 0.18480715692043304}
2024-10-10 02:20:05,913 [INFO] Step[400/938]: training loss : 0.1778367466107011 TRAIN  loss dict:  {'classification_loss': 0.1778367466107011}
2024-10-10 02:21:05,926 [INFO] Step[450/938]: training loss : 0.21559748835861683 TRAIN  loss dict:  {'classification_loss': 0.21559748835861683}
2024-10-10 02:22:05,608 [INFO] Step[500/938]: training loss : 0.19718328535556792 TRAIN  loss dict:  {'classification_loss': 0.19718328535556792}
2024-10-10 02:23:04,450 [INFO] Step[550/938]: training loss : 0.18212467290461062 TRAIN  loss dict:  {'classification_loss': 0.18212467290461062}
2024-10-10 02:24:03,919 [INFO] Step[600/938]: training loss : 0.19668348230421542 TRAIN  loss dict:  {'classification_loss': 0.19668348230421542}
2024-10-10 02:25:06,981 [INFO] Step[650/938]: training loss : 0.22128151208162308 TRAIN  loss dict:  {'classification_loss': 0.22128151208162308}
2024-10-10 02:26:07,215 [INFO] Step[700/938]: training loss : 0.1831959841400385 TRAIN  loss dict:  {'classification_loss': 0.1831959841400385}
2024-10-10 02:27:06,085 [INFO] Step[750/938]: training loss : 0.19615953061729668 TRAIN  loss dict:  {'classification_loss': 0.19615953061729668}
2024-10-10 02:28:04,699 [INFO] Step[800/938]: training loss : 0.18436685059219599 TRAIN  loss dict:  {'classification_loss': 0.18436685059219599}
2024-10-10 02:29:08,371 [INFO] Step[850/938]: training loss : 0.20280320659279824 TRAIN  loss dict:  {'classification_loss': 0.20280320659279824}
2024-10-10 02:30:08,047 [INFO] Step[900/938]: training loss : 0.17955766774713994 TRAIN  loss dict:  {'classification_loss': 0.17955766774713994}
2024-10-10 02:32:59,919 [INFO] Label accuracies statistics:
2024-10-10 02:32:59,920 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.9, 3: 1.0, 4: 0.85, 5: 0.75, 6: 0.38461538461538464, 7: 0.95, 8: 0.85, 9: 0.8421052631578947, 10: 0.8421052631578947, 11: 1.0, 12: 0.6842105263157895, 13: 1.0, 14: 0.85, 15: 0.9, 16: 0.4, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.7894736842105263, 20: 1.0, 21: 0.9473684210526315, 22: 0.7, 23: 0.9, 24: 0.8947368421052632, 25: 1.0, 26: 0.8947368421052632, 27: 0.9, 28: 0.8, 29: 0.9, 30: 0.9, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.9, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.9, 39: 1.0, 40: 0.85, 41: 1.0, 42: 0.85, 43: 1.0, 44: 0.9473684210526315, 45: 0.85, 46: 0.9, 47: 0.75, 48: 0.5, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.6666666666666666, 53: 0.9, 54: 0.9, 55: 0.8421052631578947, 56: 1.0, 57: 1.0, 58: 0.8125, 59: 0.7777777777777778, 60: 0.8, 61: 0.8947368421052632, 62: 0.5263157894736842, 63: 0.8421052631578947, 64: 1.0, 65: 0.8, 66: 1.0, 67: 0.7, 68: 0.5555555555555556, 69: 1.0, 70: 1.0, 71: 0.95, 72: 0.9473684210526315, 73: 1.0, 74: 1.0, 75: 0.55, 76: 0.7368421052631579, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.75, 83: 0.95, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.7647058823529411, 90: 0.85, 91: 0.9, 92: 0.85, 93: 0.95, 94: 0.9473684210526315, 95: 0.5, 96: 0.5882352941176471, 97: 0.75, 98: 0.42105263157894735, 99: 0.8, 100: 0.95, 101: 0.95, 102: 1.0, 103: 0.75, 104: 0.6, 105: 1.0, 106: 0.8, 107: 0.8, 108: 1.0, 109: 1.0, 110: 0.95, 111: 0.7, 112: 1.0, 113: 0.7, 114: 0.95, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.7, 123: 0.9, 124: 1.0, 125: 0.55, 126: 0.8, 127: 1.0, 128: 0.9, 129: 0.65, 130: 1.0, 131: 0.75, 132: 0.47368421052631576, 133: 1.0, 134: 0.65, 135: 0.85, 136: 0.95, 137: 0.8, 138: 0.65, 139: 0.95, 140: 0.6, 141: 1.0, 142: 0.9, 143: 0.95, 144: 0.9, 145: 0.8947368421052632, 146: 0.95, 147: 0.65, 148: 0.85, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.7, 155: 0.95, 156: 0.7368421052631579, 157: 0.95, 158: 0.7058823529411765, 159: 1.0, 160: 0.95, 161: 0.75, 162: 0.8, 163: 0.75, 164: 0.21052631578947367, 165: 0.5, 166: 0.6, 167: 0.95, 168: 0.9, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.75, 173: 0.9, 174: 1.0, 175: 0.8888888888888888, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.85, 184: 1.0, 185: 0.95, 186: 0.6, 187: 0.9473684210526315, 188: 0.8, 189: 0.95, 190: 0.9, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.95, 195: 0.5, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 0.85, 203: 0.9, 204: 0.9, 205: 1.0, 206: 0.16666666666666666, 207: 0.85, 208: 0.95, 209: 1.0, 210: 1.0, 211: 0.8, 212: 0.6470588235294118, 213: 0.9, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.65, 218: 0.75, 219: 1.0, 220: 1.0, 221: 0.6, 222: 1.0, 223: 0.95, 224: 0.75, 225: 0.75}

2024-10-10 02:33:00,891 [INFO] [6] TRAIN  loss: 0.1919251782323188 acc: 0.9432319067254372
2024-10-10 02:33:00,891 [INFO] [6] TRAIN  loss dict: {'classification_loss': 0.1919251782323188}
2024-10-10 02:33:00,891 [INFO] [6] VALIDATION loss: 0.4925989068028316 VALIDATION  acc: 0.8646446355817112
2024-10-10 02:33:00,892 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 0.4925989068028316}
2024-10-10 02:33:00,892 [INFO] 
2024-10-10 02:34:22,259 [INFO] Step[50/938]: training loss : 0.1522051602229476 TRAIN  loss dict:  {'classification_loss': 0.1522051602229476}
2024-10-10 02:35:21,490 [INFO] Step[100/938]: training loss : 0.1630714475736022 TRAIN  loss dict:  {'classification_loss': 0.1630714475736022}
2024-10-10 02:36:20,524 [INFO] Step[150/938]: training loss : 0.15729336116462947 TRAIN  loss dict:  {'classification_loss': 0.15729336116462947}
2024-10-10 02:37:24,279 [INFO] Step[200/938]: training loss : 0.1689965770766139 TRAIN  loss dict:  {'classification_loss': 0.1689965770766139}
2024-10-10 02:38:24,071 [INFO] Step[250/938]: training loss : 0.17671602830290795 TRAIN  loss dict:  {'classification_loss': 0.17671602830290795}
2024-10-10 02:39:23,789 [INFO] Step[300/938]: training loss : 0.1886337697133422 TRAIN  loss dict:  {'classification_loss': 0.1886337697133422}
2024-10-10 02:40:23,274 [INFO] Step[350/938]: training loss : 0.16183695647865534 TRAIN  loss dict:  {'classification_loss': 0.16183695647865534}
2024-10-10 02:41:26,489 [INFO] Step[400/938]: training loss : 0.17526749990880489 TRAIN  loss dict:  {'classification_loss': 0.17526749990880489}
2024-10-10 02:42:26,572 [INFO] Step[450/938]: training loss : 0.15089051552116872 TRAIN  loss dict:  {'classification_loss': 0.15089051552116872}
2024-10-10 02:43:25,610 [INFO] Step[500/938]: training loss : 0.15516937907785178 TRAIN  loss dict:  {'classification_loss': 0.15516937907785178}
2024-10-10 02:44:25,005 [INFO] Step[550/938]: training loss : 0.14832006070762874 TRAIN  loss dict:  {'classification_loss': 0.14832006070762874}
2024-10-10 02:45:26,655 [INFO] Step[600/938]: training loss : 0.19701462231576441 TRAIN  loss dict:  {'classification_loss': 0.19701462231576441}
2024-10-10 02:46:28,285 [INFO] Step[650/938]: training loss : 0.1552671906352043 TRAIN  loss dict:  {'classification_loss': 0.1552671906352043}
2024-10-10 02:47:27,393 [INFO] Step[700/938]: training loss : 0.14197921693325044 TRAIN  loss dict:  {'classification_loss': 0.14197921693325044}
2024-10-10 02:48:26,850 [INFO] Step[750/938]: training loss : 0.15944675851613282 TRAIN  loss dict:  {'classification_loss': 0.15944675851613282}
2024-10-10 02:49:26,677 [INFO] Step[800/938]: training loss : 0.18160831511020661 TRAIN  loss dict:  {'classification_loss': 0.18160831511020661}
2024-10-10 02:50:30,086 [INFO] Step[850/938]: training loss : 0.15136013604700566 TRAIN  loss dict:  {'classification_loss': 0.15136013604700566}
2024-10-10 02:51:30,714 [INFO] Step[900/938]: training loss : 0.15922700269147755 TRAIN  loss dict:  {'classification_loss': 0.15922700269147755}
2024-10-10 02:54:34,108 [INFO] Label accuracies statistics:
2024-10-10 02:54:34,108 [INFO] {0: 0.6, 1: 1.0, 2: 0.9, 3: 0.9473684210526315, 4: 0.85, 5: 0.9, 6: 0.6923076923076923, 7: 0.7, 8: 0.85, 9: 0.5789473684210527, 10: 0.9473684210526315, 11: 0.95, 12: 0.8421052631578947, 13: 0.6, 14: 0.85, 15: 0.9, 16: 0.6, 17: 0.6111111111111112, 18: 0.7647058823529411, 19: 1.0, 20: 1.0, 21: 1.0, 22: 0.75, 23: 0.9, 24: 0.8947368421052632, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 0.9, 33: 0.9, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.85, 39: 0.9, 40: 1.0, 41: 0.9, 42: 0.9, 43: 0.7, 44: 0.9473684210526315, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.65, 49: 0.6842105263157895, 50: 0.95, 51: 0.7777777777777778, 52: 0.7222222222222222, 53: 0.85, 54: 0.9, 55: 0.9473684210526315, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.8333333333333334, 60: 0.8, 61: 0.7894736842105263, 62: 0.5789473684210527, 63: 0.8421052631578947, 64: 1.0, 65: 0.75, 66: 1.0, 67: 0.95, 68: 0.6666666666666666, 69: 1.0, 70: 1.0, 71: 0.85, 72: 0.8947368421052632, 73: 0.8947368421052632, 74: 1.0, 75: 0.7, 76: 0.7368421052631579, 77: 1.0, 78: 0.8, 79: 0.8823529411764706, 80: 0.95, 81: 0.85, 82: 0.7, 83: 0.9, 84: 0.8, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 0.9, 89: 0.8235294117647058, 90: 0.85, 91: 0.9, 92: 0.9, 93: 0.9, 94: 0.9473684210526315, 95: 0.9166666666666666, 96: 0.5882352941176471, 97: 0.55, 98: 0.21052631578947367, 99: 1.0, 100: 0.9, 101: 0.95, 102: 1.0, 103: 0.8, 104: 0.95, 105: 0.85, 106: 1.0, 107: 1.0, 108: 0.95, 109: 1.0, 110: 0.95, 111: 0.8, 112: 1.0, 113: 0.8, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 0.9, 121: 0.9, 122: 0.5, 123: 0.95, 124: 1.0, 125: 0.85, 126: 0.75, 127: 0.7, 128: 0.95, 129: 0.6, 130: 1.0, 131: 0.75, 132: 0.6842105263157895, 133: 1.0, 134: 0.7, 135: 0.9, 136: 0.95, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.9, 141: 1.0, 142: 0.6, 143: 1.0, 144: 0.9, 145: 0.8947368421052632, 146: 0.9, 147: 0.7, 148: 0.85, 149: 0.8947368421052632, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.85, 154: 0.85, 155: 0.9, 156: 0.7368421052631579, 157: 1.0, 158: 0.8235294117647058, 159: 1.0, 160: 1.0, 161: 0.65, 162: 0.8, 163: 1.0, 164: 0.8947368421052632, 165: 0.9, 166: 0.85, 167: 1.0, 168: 0.95, 169: 1.0, 170: 0.9473684210526315, 171: 1.0, 172: 0.5, 173: 0.85, 174: 1.0, 175: 0.6111111111111112, 176: 0.95, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.85, 184: 1.0, 185: 0.95, 186: 0.85, 187: 0.8421052631578947, 188: 0.8, 189: 0.95, 190: 1.0, 191: 1.0, 192: 0.85, 193: 1.0, 194: 0.9, 195: 0.8888888888888888, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.85, 200: 1.0, 201: 1.0, 202: 1.0, 203: 0.9, 204: 1.0, 205: 0.9, 206: 0.3888888888888889, 207: 0.8, 208: 0.8, 209: 1.0, 210: 1.0, 211: 0.75, 212: 0.8823529411764706, 213: 0.85, 214: 0.9, 215: 0.9, 216: 0.9, 217: 0.8, 218: 0.9, 219: 1.0, 220: 0.95, 221: 0.65, 222: 0.9473684210526315, 223: 0.95, 224: 0.65, 225: 0.85}

2024-10-10 02:54:34,937 [INFO] [7] TRAIN  loss: 0.16405708152455276 acc: 0.9501279681501493
2024-10-10 02:54:34,937 [INFO] [7] TRAIN  loss dict: {'classification_loss': 0.16405708152455276}
2024-10-10 02:54:34,937 [INFO] [7] VALIDATION loss: 0.4817450083918064 VALIDATION  acc: 0.8743775464010864
2024-10-10 02:54:34,937 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 0.4817450083918064}
2024-10-10 02:54:34,937 [INFO] 
2024-10-10 02:55:57,021 [INFO] Step[50/938]: training loss : 0.16224509760737418 TRAIN  loss dict:  {'classification_loss': 0.16224509760737418}
2024-10-10 02:56:55,652 [INFO] Step[100/938]: training loss : 0.14178545031696557 TRAIN  loss dict:  {'classification_loss': 0.14178545031696557}
2024-10-10 02:57:55,313 [INFO] Step[150/938]: training loss : 0.12482160191982984 TRAIN  loss dict:  {'classification_loss': 0.12482160191982984}
2024-10-10 02:58:58,306 [INFO] Step[200/938]: training loss : 0.13355100009590387 TRAIN  loss dict:  {'classification_loss': 0.13355100009590387}
2024-10-10 02:59:57,428 [INFO] Step[250/938]: training loss : 0.1704887519031763 TRAIN  loss dict:  {'classification_loss': 0.1704887519031763}
2024-10-10 03:00:56,094 [INFO] Step[300/938]: training loss : 0.1505288165435195 TRAIN  loss dict:  {'classification_loss': 0.1505288165435195}
2024-10-10 03:01:55,455 [INFO] Step[350/938]: training loss : 0.14772832047194243 TRAIN  loss dict:  {'classification_loss': 0.14772832047194243}
2024-10-10 03:02:59,278 [INFO] Step[400/938]: training loss : 0.1696001199632883 TRAIN  loss dict:  {'classification_loss': 0.1696001199632883}
2024-10-10 03:03:58,714 [INFO] Step[450/938]: training loss : 0.14651099732145667 TRAIN  loss dict:  {'classification_loss': 0.14651099732145667}
2024-10-10 03:04:58,114 [INFO] Step[500/938]: training loss : 0.17881542816758156 TRAIN  loss dict:  {'classification_loss': 0.17881542816758156}
2024-10-10 03:05:56,287 [INFO] Step[550/938]: training loss : 0.13291849944740533 TRAIN  loss dict:  {'classification_loss': 0.13291849944740533}
2024-10-10 03:07:00,590 [INFO] Step[600/938]: training loss : 0.16707451544702054 TRAIN  loss dict:  {'classification_loss': 0.16707451544702054}
2024-10-10 03:08:00,610 [INFO] Step[650/938]: training loss : 0.14588130615651607 TRAIN  loss dict:  {'classification_loss': 0.14588130615651607}
2024-10-10 03:08:59,436 [INFO] Step[700/938]: training loss : 0.1288074566423893 TRAIN  loss dict:  {'classification_loss': 0.1288074566423893}
2024-10-10 03:09:58,720 [INFO] Step[750/938]: training loss : 0.11924830328673125 TRAIN  loss dict:  {'classification_loss': 0.11924830328673125}
2024-10-10 03:11:02,723 [INFO] Step[800/938]: training loss : 0.1402437848970294 TRAIN  loss dict:  {'classification_loss': 0.1402437848970294}
2024-10-10 03:12:02,236 [INFO] Step[850/938]: training loss : 0.14073994919657706 TRAIN  loss dict:  {'classification_loss': 0.14073994919657706}
2024-10-10 03:13:01,562 [INFO] Step[900/938]: training loss : 0.1370885467529297 TRAIN  loss dict:  {'classification_loss': 0.1370885467529297}
2024-10-10 03:15:54,912 [INFO] Label accuracies statistics:
2024-10-10 03:15:54,912 [INFO] {0: 0.85, 1: 0.9473684210526315, 2: 0.9, 3: 0.8947368421052632, 4: 0.9, 5: 0.75, 6: 0.23076923076923078, 7: 1.0, 8: 0.85, 9: 0.6842105263157895, 10: 0.8421052631578947, 11: 0.8, 12: 0.7894736842105263, 13: 0.95, 14: 0.9, 15: 0.9, 16: 0.4, 17: 0.5555555555555556, 18: 0.7647058823529411, 19: 0.8947368421052632, 20: 0.8421052631578947, 21: 1.0, 22: 0.7, 23: 0.6, 24: 0.9473684210526315, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.9, 34: 0.85, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.9, 39: 0.95, 40: 0.7, 41: 0.95, 42: 0.95, 43: 0.85, 44: 0.9473684210526315, 45: 0.8, 46: 0.9, 47: 0.3, 48: 0.5, 49: 0.8421052631578947, 50: 0.95, 51: 0.8888888888888888, 52: 0.7222222222222222, 53: 0.75, 54: 0.95, 55: 0.8421052631578947, 56: 0.9473684210526315, 57: 0.9, 58: 0.6875, 59: 0.7777777777777778, 60: 0.9, 61: 0.7368421052631579, 62: 0.6842105263157895, 63: 0.7368421052631579, 64: 1.0, 65: 0.75, 66: 1.0, 67: 0.85, 68: 0.7222222222222222, 69: 1.0, 70: 0.95, 71: 0.85, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.75, 76: 0.9473684210526315, 77: 1.0, 78: 0.8, 79: 1.0, 80: 1.0, 81: 0.85, 82: 0.85, 83: 0.9, 84: 0.95, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.9, 89: 0.8823529411764706, 90: 0.8, 91: 0.8, 92: 0.85, 93: 1.0, 94: 1.0, 95: 0.5, 96: 0.5294117647058824, 97: 0.6, 98: 0.6842105263157895, 99: 0.95, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.9, 105: 1.0, 106: 1.0, 107: 0.65, 108: 0.85, 109: 1.0, 110: 0.85, 111: 0.55, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 0.9411764705882353, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.65, 123: 0.9, 124: 0.9, 125: 0.9, 126: 0.6, 127: 0.7, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.875, 132: 0.8947368421052632, 133: 1.0, 134: 0.9, 135: 0.85, 136: 1.0, 137: 0.8, 138: 0.75, 139: 0.85, 140: 0.8, 141: 1.0, 142: 0.65, 143: 0.8, 144: 0.75, 145: 0.9473684210526315, 146: 1.0, 147: 0.7, 148: 0.8, 149: 0.8947368421052632, 150: 0.7, 151: 1.0, 152: 0.8, 153: 0.95, 154: 0.75, 155: 0.9, 156: 0.8947368421052632, 157: 0.9, 158: 0.9411764705882353, 159: 1.0, 160: 0.95, 161: 0.8, 162: 1.0, 163: 0.95, 164: 0.7368421052631579, 165: 1.0, 166: 0.6, 167: 0.95, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.9, 172: 0.5, 173: 0.9, 174: 1.0, 175: 0.8888888888888888, 176: 0.95, 177: 1.0, 178: 0.65, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.65, 184: 0.95, 185: 0.85, 186: 0.75, 187: 0.9473684210526315, 188: 0.7, 189: 0.9, 190: 0.9, 191: 1.0, 192: 0.85, 193: 1.0, 194: 0.9, 195: 0.8888888888888888, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8947368421052632, 201: 0.95, 202: 1.0, 203: 0.9, 204: 0.9, 205: 0.9, 206: 0.2222222222222222, 207: 0.85, 208: 1.0, 209: 0.85, 210: 1.0, 211: 0.5, 212: 0.8823529411764706, 213: 0.9, 214: 0.9, 215: 0.85, 216: 0.9, 217: 0.85, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 0.9473684210526315, 223: 1.0, 224: 0.7, 225: 1.0}

2024-10-10 03:15:54,963 [INFO] [8] TRAIN  loss: 0.14688850347417345 acc: 0.9565619223659889
2024-10-10 03:15:54,964 [INFO] [8] TRAIN  loss dict: {'classification_loss': 0.14688850347417345}
2024-10-10 03:15:54,964 [INFO] [8] VALIDATION loss: 0.51352881265779 VALIDATION  acc: 0.8646446355817112
2024-10-10 03:15:54,964 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 0.51352881265779}
2024-10-10 03:15:54,964 [INFO] 
2024-10-10 03:17:16,616 [INFO] Step[50/938]: training loss : 0.11478444945067168 TRAIN  loss dict:  {'classification_loss': 0.11478444945067168}
2024-10-10 03:18:16,081 [INFO] Step[100/938]: training loss : 0.12310354121029377 TRAIN  loss dict:  {'classification_loss': 0.12310354121029377}
2024-10-10 03:19:18,459 [INFO] Step[150/938]: training loss : 0.13525862339884043 TRAIN  loss dict:  {'classification_loss': 0.13525862339884043}
2024-10-10 03:20:19,277 [INFO] Step[200/938]: training loss : 0.13877814749255776 TRAIN  loss dict:  {'classification_loss': 0.13877814749255776}
2024-10-10 03:21:19,235 [INFO] Step[250/938]: training loss : 0.10986669007688761 TRAIN  loss dict:  {'classification_loss': 0.10986669007688761}
2024-10-10 03:22:18,561 [INFO] Step[300/938]: training loss : 0.1423846546560526 TRAIN  loss dict:  {'classification_loss': 0.1423846546560526}
2024-10-10 03:23:18,987 [INFO] Step[350/938]: training loss : 0.13117736980319022 TRAIN  loss dict:  {'classification_loss': 0.13117736980319022}
2024-10-10 03:24:21,558 [INFO] Step[400/938]: training loss : 0.1451110237836838 TRAIN  loss dict:  {'classification_loss': 0.1451110237836838}
2024-10-10 03:25:20,559 [INFO] Step[450/938]: training loss : 0.13237437650561332 TRAIN  loss dict:  {'classification_loss': 0.13237437650561332}
2024-10-10 03:26:19,258 [INFO] Step[500/938]: training loss : 0.11664211809635162 TRAIN  loss dict:  {'classification_loss': 0.11664211809635162}
2024-10-10 03:27:18,835 [INFO] Step[550/938]: training loss : 0.14244770925492048 TRAIN  loss dict:  {'classification_loss': 0.14244770925492048}
2024-10-10 03:28:22,173 [INFO] Step[600/938]: training loss : 0.1309315131418407 TRAIN  loss dict:  {'classification_loss': 0.1309315131418407}
2024-10-10 03:29:22,311 [INFO] Step[650/938]: training loss : 0.12062066696584224 TRAIN  loss dict:  {'classification_loss': 0.12062066696584224}
2024-10-10 03:30:21,311 [INFO] Step[700/938]: training loss : 0.1265263462997973 TRAIN  loss dict:  {'classification_loss': 0.1265263462997973}
2024-10-10 03:31:20,363 [INFO] Step[750/938]: training loss : 0.11615520145744085 TRAIN  loss dict:  {'classification_loss': 0.11615520145744085}
2024-10-10 03:32:24,408 [INFO] Step[800/938]: training loss : 0.13291605517268182 TRAIN  loss dict:  {'classification_loss': 0.13291605517268182}
2024-10-10 03:33:23,875 [INFO] Step[850/938]: training loss : 0.16560885451734067 TRAIN  loss dict:  {'classification_loss': 0.16560885451734067}
2024-10-10 03:34:22,925 [INFO] Step[900/938]: training loss : 0.11757035486400128 TRAIN  loss dict:  {'classification_loss': 0.11757035486400128}
2024-10-10 03:37:15,583 [INFO] Label accuracies statistics:
2024-10-10 03:37:15,583 [INFO] {0: 0.8, 1: 1.0, 2: 0.9, 3: 0.8947368421052632, 4: 0.85, 5: 0.9, 6: 0.7692307692307693, 7: 0.65, 8: 1.0, 9: 0.8421052631578947, 10: 1.0, 11: 0.75, 12: 0.8421052631578947, 13: 0.65, 14: 0.65, 15: 0.9, 16: 0.55, 17: 0.6666666666666666, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 1.0, 21: 1.0, 22: 0.7, 23: 0.9, 24: 0.8947368421052632, 25: 0.9, 26: 0.8947368421052632, 27: 0.6, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.95, 34: 0.7, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.9, 39: 0.95, 40: 0.9, 41: 0.95, 42: 0.95, 43: 0.8, 44: 0.8421052631578947, 45: 0.75, 46: 0.85, 47: 0.7, 48: 0.95, 49: 0.7368421052631579, 50: 0.95, 51: 0.7777777777777778, 52: 0.8888888888888888, 53: 0.7, 54: 0.9, 55: 0.8421052631578947, 56: 1.0, 57: 1.0, 58: 0.875, 59: 0.6666666666666666, 60: 0.8, 61: 0.7894736842105263, 62: 0.631578947368421, 63: 0.9473684210526315, 64: 1.0, 65: 0.8, 66: 1.0, 67: 0.6, 68: 0.7222222222222222, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.85, 76: 0.8421052631578947, 77: 1.0, 78: 0.85, 79: 0.8823529411764706, 80: 1.0, 81: 0.95, 82: 0.7, 83: 0.95, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.9, 89: 0.8823529411764706, 90: 0.75, 91: 0.95, 92: 1.0, 93: 0.95, 94: 0.8947368421052632, 95: 0.3333333333333333, 96: 0.47058823529411764, 97: 0.75, 98: 0.47368421052631576, 99: 0.85, 100: 0.7, 101: 1.0, 102: 0.9473684210526315, 103: 0.8, 104: 0.7, 105: 1.0, 106: 0.9, 107: 0.65, 108: 0.95, 109: 1.0, 110: 0.85, 111: 0.8, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 0.95, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.65, 123: 0.95, 124: 0.9, 125: 0.55, 126: 0.6, 127: 0.85, 128: 0.9, 129: 0.7, 130: 0.95, 131: 0.75, 132: 0.7894736842105263, 133: 1.0, 134: 0.8, 135: 0.75, 136: 0.9, 137: 0.8, 138: 0.85, 139: 0.8, 140: 0.85, 141: 1.0, 142: 0.5, 143: 0.95, 144: 0.75, 145: 0.9473684210526315, 146: 0.95, 147: 0.7, 148: 0.85, 149: 1.0, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.3, 155: 0.9, 156: 0.8421052631578947, 157: 1.0, 158: 0.8235294117647058, 159: 1.0, 160: 1.0, 161: 0.65, 162: 1.0, 163: 0.9, 164: 0.9473684210526315, 165: 0.75, 166: 0.55, 167: 1.0, 168: 1.0, 169: 1.0, 170: 0.9473684210526315, 171: 1.0, 172: 0.95, 173: 0.95, 174: 1.0, 175: 0.7777777777777778, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 0.95, 181: 1.0, 182: 0.9, 183: 0.75, 184: 1.0, 185: 0.95, 186: 0.7, 187: 0.9473684210526315, 188: 0.85, 189: 0.65, 190: 0.85, 191: 1.0, 192: 0.9, 193: 1.0, 194: 0.95, 195: 0.8333333333333334, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.9, 200: 1.0, 201: 1.0, 202: 1.0, 203: 0.95, 204: 1.0, 205: 0.9, 206: 0.2222222222222222, 207: 0.85, 208: 1.0, 209: 1.0, 210: 0.95, 211: 0.9, 212: 0.6470588235294118, 213: 0.85, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.85, 218: 0.8, 219: 1.0, 220: 1.0, 221: 0.6, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.9}

2024-10-10 03:37:15,646 [INFO] [9] TRAIN  loss: 0.1297370161521616 acc: 0.9605076069955922
2024-10-10 03:37:15,646 [INFO] [9] TRAIN  loss dict: {'classification_loss': 0.1297370161521616}
2024-10-10 03:37:15,646 [INFO] [9] VALIDATION loss: 0.5269312070292497 VALIDATION  acc: 0.8693979176097781
2024-10-10 03:37:15,646 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 0.5269312070292497}
2024-10-10 03:37:15,646 [INFO] 
2024-10-10 03:38:37,567 [INFO] Step[50/938]: training loss : 0.1086476724781096 TRAIN  loss dict:  {'classification_loss': 0.1086476724781096}
2024-10-10 03:39:36,789 [INFO] Step[100/938]: training loss : 0.11340616131201386 TRAIN  loss dict:  {'classification_loss': 0.11340616131201386}
2024-10-10 03:40:40,812 [INFO] Step[150/938]: training loss : 0.10503769966773689 TRAIN  loss dict:  {'classification_loss': 0.10503769966773689}
2024-10-10 03:41:40,219 [INFO] Step[200/938]: training loss : 0.10159739717841149 TRAIN  loss dict:  {'classification_loss': 0.10159739717841149}
2024-10-10 03:42:39,136 [INFO] Step[250/938]: training loss : 0.08351372722536325 TRAIN  loss dict:  {'classification_loss': 0.08351372722536325}
2024-10-10 03:43:39,053 [INFO] Step[300/938]: training loss : 0.09664687529206276 TRAIN  loss dict:  {'classification_loss': 0.09664687529206276}
2024-10-10 03:44:41,550 [INFO] Step[350/938]: training loss : 0.11105279300361871 TRAIN  loss dict:  {'classification_loss': 0.11105279300361871}
2024-10-10 03:45:41,935 [INFO] Step[400/938]: training loss : 0.1309954922273755 TRAIN  loss dict:  {'classification_loss': 0.1309954922273755}
2024-10-10 03:46:41,306 [INFO] Step[450/938]: training loss : 0.10771675691008568 TRAIN  loss dict:  {'classification_loss': 0.10771675691008568}
2024-10-10 03:47:40,288 [INFO] Step[500/938]: training loss : 0.12210348034277559 TRAIN  loss dict:  {'classification_loss': 0.12210348034277559}
2024-10-10 03:48:41,275 [INFO] Step[550/938]: training loss : 0.10468107528984547 TRAIN  loss dict:  {'classification_loss': 0.10468107528984547}
2024-10-10 03:49:43,558 [INFO] Step[600/938]: training loss : 0.11833772024139762 TRAIN  loss dict:  {'classification_loss': 0.11833772024139762}
2024-10-10 03:50:43,381 [INFO] Step[650/938]: training loss : 0.13252906212583185 TRAIN  loss dict:  {'classification_loss': 0.13252906212583185}
2024-10-10 03:51:42,582 [INFO] Step[700/938]: training loss : 0.12015500895678997 TRAIN  loss dict:  {'classification_loss': 0.12015500895678997}
2024-10-10 03:52:42,269 [INFO] Step[750/938]: training loss : 0.09946694869548083 TRAIN  loss dict:  {'classification_loss': 0.09946694869548083}
2024-10-10 03:53:45,680 [INFO] Step[800/938]: training loss : 0.12328816216439009 TRAIN  loss dict:  {'classification_loss': 0.12328816216439009}
2024-10-10 03:54:44,947 [INFO] Step[850/938]: training loss : 0.11096917305141688 TRAIN  loss dict:  {'classification_loss': 0.11096917305141688}
2024-10-10 03:55:43,864 [INFO] Step[900/938]: training loss : 0.11754959885030986 TRAIN  loss dict:  {'classification_loss': 0.11754959885030986}
2024-10-10 03:58:40,953 [INFO] Label accuracies statistics:
2024-10-10 03:58:40,953 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.9, 3: 1.0, 4: 0.85, 5: 0.8, 6: 0.7692307692307693, 7: 0.85, 8: 0.85, 9: 0.6842105263157895, 10: 1.0, 11: 1.0, 12: 0.8421052631578947, 13: 0.7, 14: 0.8, 15: 0.9, 16: 0.6, 17: 0.5555555555555556, 18: 0.7647058823529411, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 0.9473684210526315, 22: 0.8, 23: 0.8, 24: 0.7894736842105263, 25: 0.95, 26: 0.8947368421052632, 27: 0.85, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.95, 34: 0.65, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.9, 39: 0.9, 40: 1.0, 41: 1.0, 42: 0.9, 43: 0.85, 44: 0.9473684210526315, 45: 0.75, 46: 0.9, 47: 0.55, 48: 0.75, 49: 0.9473684210526315, 50: 0.95, 51: 0.8333333333333334, 52: 0.8333333333333334, 53: 1.0, 54: 0.85, 55: 0.8947368421052632, 56: 1.0, 57: 1.0, 58: 0.875, 59: 0.6666666666666666, 60: 0.8, 61: 0.6842105263157895, 62: 0.5789473684210527, 63: 0.8947368421052632, 64: 1.0, 65: 0.8, 66: 0.95, 67: 1.0, 68: 0.6111111111111112, 69: 0.9444444444444444, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.85, 76: 0.8421052631578947, 77: 1.0, 78: 0.7, 79: 0.8823529411764706, 80: 1.0, 81: 0.9, 82: 0.75, 83: 0.9, 84: 0.9, 85: 1.0, 86: 0.7, 87: 0.8823529411764706, 88: 0.95, 89: 0.8823529411764706, 90: 0.8, 91: 0.7, 92: 0.95, 93: 1.0, 94: 0.9473684210526315, 95: 0.6666666666666666, 96: 0.5294117647058824, 97: 0.8, 98: 0.21052631578947367, 99: 1.0, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.8, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.7, 108: 1.0, 109: 1.0, 110: 0.85, 111: 0.7, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.55, 123: 0.95, 124: 0.95, 125: 0.55, 126: 0.8, 127: 0.65, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.875, 132: 0.8947368421052632, 133: 1.0, 134: 1.0, 135: 0.65, 136: 0.8, 137: 0.8, 138: 0.85, 139: 1.0, 140: 0.45, 141: 1.0, 142: 0.9, 143: 1.0, 144: 0.75, 145: 0.9473684210526315, 146: 1.0, 147: 0.7, 148: 0.7, 149: 0.8947368421052632, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.6, 155: 0.9, 156: 0.6842105263157895, 157: 0.8, 158: 0.7647058823529411, 159: 1.0, 160: 1.0, 161: 0.9, 162: 0.85, 163: 1.0, 164: 0.9473684210526315, 165: 0.7, 166: 0.6, 167: 0.9, 168: 0.9, 169: 0.9, 170: 1.0, 171: 0.9, 172: 0.7, 173: 0.85, 174: 1.0, 175: 0.7222222222222222, 176: 1.0, 177: 1.0, 178: 0.75, 179: 1.0, 180: 1.0, 181: 0.9, 182: 0.9, 183: 0.9, 184: 1.0, 185: 0.9, 186: 0.65, 187: 0.8421052631578947, 188: 0.75, 189: 0.95, 190: 0.9, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.6666666666666666, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.9, 200: 1.0, 201: 1.0, 202: 1.0, 203: 0.55, 204: 0.9, 205: 0.9, 206: 0.4444444444444444, 207: 0.6, 208: 1.0, 209: 0.9, 210: 1.0, 211: 0.85, 212: 0.7647058823529411, 213: 0.85, 214: 1.0, 215: 0.9, 216: 0.9, 217: 0.75, 218: 0.75, 219: 1.0, 220: 0.9, 221: 0.45, 222: 0.9473684210526315, 223: 0.95, 224: 0.7, 225: 1.0}

2024-10-10 03:58:41,009 [INFO] [10] TRAIN  loss: 0.11095005142212565 acc: 0.966728280961183
2024-10-10 03:58:41,010 [INFO] [10] TRAIN  loss dict: {'classification_loss': 0.11095005142212565}
2024-10-10 03:58:41,010 [INFO] [10] VALIDATION loss: 0.5354387967900776 VALIDATION  acc: 0.8698506111362607
2024-10-10 03:58:41,010 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 0.5354387967900776}
2024-10-10 03:58:41,010 [INFO] 
2024-10-10 04:00:00,946 [INFO] Step[50/938]: training loss : 0.09814430864527822 TRAIN  loss dict:  {'classification_loss': 0.09814430864527822}
2024-10-10 04:01:00,419 [INFO] Step[100/938]: training loss : 0.078678433354944 TRAIN  loss dict:  {'classification_loss': 0.078678433354944}
2024-10-10 04:02:04,226 [INFO] Step[150/938]: training loss : 0.0819505525752902 TRAIN  loss dict:  {'classification_loss': 0.0819505525752902}
2024-10-10 04:03:03,860 [INFO] Step[200/938]: training loss : 0.09047935970127582 TRAIN  loss dict:  {'classification_loss': 0.09047935970127582}
2024-10-10 04:04:02,553 [INFO] Step[250/938]: training loss : 0.08239262718707323 TRAIN  loss dict:  {'classification_loss': 0.08239262718707323}
2024-10-10 04:05:01,262 [INFO] Step[300/938]: training loss : 0.07374647178687155 TRAIN  loss dict:  {'classification_loss': 0.07374647178687155}
2024-10-10 04:06:05,438 [INFO] Step[350/938]: training loss : 0.09250054562464356 TRAIN  loss dict:  {'classification_loss': 0.09250054562464356}
2024-10-10 04:07:05,392 [INFO] Step[400/938]: training loss : 0.1150992794893682 TRAIN  loss dict:  {'classification_loss': 0.1150992794893682}
2024-10-10 04:08:04,298 [INFO] Step[450/938]: training loss : 0.08186401570215822 TRAIN  loss dict:  {'classification_loss': 0.08186401570215822}
2024-10-10 04:09:03,846 [INFO] Step[500/938]: training loss : 0.11588260227814316 TRAIN  loss dict:  {'classification_loss': 0.11588260227814316}
2024-10-10 04:10:06,829 [INFO] Step[550/938]: training loss : 0.10587696728296578 TRAIN  loss dict:  {'classification_loss': 0.10587696728296578}
2024-10-10 04:11:06,649 [INFO] Step[600/938]: training loss : 0.07919168753549456 TRAIN  loss dict:  {'classification_loss': 0.07919168753549456}
2024-10-10 04:12:05,482 [INFO] Step[650/938]: training loss : 0.08172469277866184 TRAIN  loss dict:  {'classification_loss': 0.08172469277866184}
2024-10-10 04:13:04,785 [INFO] Step[700/938]: training loss : 0.06979373855516315 TRAIN  loss dict:  {'classification_loss': 0.06979373855516315}
2024-10-10 04:14:06,018 [INFO] Step[750/938]: training loss : 0.07977086188737303 TRAIN  loss dict:  {'classification_loss': 0.07977086188737303}
2024-10-10 04:15:07,971 [INFO] Step[800/938]: training loss : 0.07663330873474479 TRAIN  loss dict:  {'classification_loss': 0.07663330873474479}
2024-10-10 04:16:07,766 [INFO] Step[850/938]: training loss : 0.08637564711272716 TRAIN  loss dict:  {'classification_loss': 0.08637564711272716}
2024-10-10 04:17:06,978 [INFO] Step[900/938]: training loss : 0.09587303126230835 TRAIN  loss dict:  {'classification_loss': 0.09587303126230835}
2024-10-10 04:20:05,316 [INFO] Label accuracies statistics:
2024-10-10 04:20:05,316 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.9, 3: 0.8421052631578947, 4: 0.95, 5: 0.75, 6: 0.46153846153846156, 7: 0.85, 8: 0.85, 9: 1.0, 10: 0.8947368421052632, 11: 0.9, 12: 0.8947368421052632, 13: 0.9, 14: 0.9, 15: 0.9, 16: 0.2, 17: 0.6111111111111112, 18: 0.8823529411764706, 19: 0.8947368421052632, 20: 0.8421052631578947, 21: 0.9473684210526315, 22: 0.95, 23: 0.7, 24: 0.8947368421052632, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 0.95, 29: 1.0, 30: 0.85, 31: 0.95, 32: 1.0, 33: 1.0, 34: 0.8, 35: 1.0, 36: 0.9473684210526315, 37: 0.6, 38: 0.9, 39: 0.95, 40: 0.95, 41: 0.95, 42: 0.95, 43: 0.9, 44: 0.9473684210526315, 45: 0.75, 46: 0.9, 47: 0.3, 48: 0.7, 49: 0.9473684210526315, 50: 0.95, 51: 0.8333333333333334, 52: 0.7777777777777778, 53: 0.9, 54: 0.9, 55: 0.9473684210526315, 56: 1.0, 57: 1.0, 58: 0.875, 59: 0.6111111111111112, 60: 0.8, 61: 0.8947368421052632, 62: 0.8421052631578947, 63: 0.7894736842105263, 64: 1.0, 65: 0.75, 66: 1.0, 67: 0.95, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8421052631578947, 74: 1.0, 75: 0.8, 76: 1.0, 77: 1.0, 78: 0.75, 79: 0.8235294117647058, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.95, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.9, 89: 0.8823529411764706, 90: 0.85, 91: 0.85, 92: 0.9, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.75, 98: 0.6842105263157895, 99: 0.95, 100: 0.85, 101: 0.95, 102: 0.9473684210526315, 103: 0.85, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.85, 108: 0.95, 109: 1.0, 110: 1.0, 111: 0.4, 112: 1.0, 113: 1.0, 114: 1.0, 115: 0.9411764705882353, 116: 1.0, 117: 0.8421052631578947, 118: 1.0, 119: 1.0, 120: 0.95, 121: 0.95, 122: 0.55, 123: 1.0, 124: 0.95, 125: 0.9, 126: 0.75, 127: 0.65, 128: 0.95, 129: 0.7, 130: 1.0, 131: 0.875, 132: 0.8947368421052632, 133: 1.0, 134: 0.5, 135: 0.9, 136: 0.95, 137: 0.75, 138: 0.85, 139: 1.0, 140: 0.85, 141: 1.0, 142: 0.85, 143: 0.95, 144: 0.75, 145: 0.8947368421052632, 146: 0.85, 147: 0.85, 148: 0.8, 149: 0.8421052631578947, 150: 0.75, 151: 1.0, 152: 0.95, 153: 1.0, 154: 0.95, 155: 0.9, 156: 0.8421052631578947, 157: 0.9, 158: 0.9411764705882353, 159: 1.0, 160: 1.0, 161: 0.9, 162: 0.75, 163: 1.0, 164: 0.9473684210526315, 165: 0.65, 166: 0.75, 167: 1.0, 168: 0.9, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.6111111111111112, 176: 1.0, 177: 1.0, 178: 0.2, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 1.0, 185: 0.95, 186: 0.7, 187: 0.8947368421052632, 188: 1.0, 189: 0.95, 190: 0.8, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.95, 195: 0.7777777777777778, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 0.9473684210526315, 201: 1.0, 202: 0.95, 203: 0.9, 204: 0.95, 205: 0.9, 206: 0.2777777777777778, 207: 0.8, 208: 0.95, 209: 1.0, 210: 1.0, 211: 0.85, 212: 0.8235294117647058, 213: 0.9, 214: 0.8, 215: 0.9, 216: 0.9, 217: 0.65, 218: 0.8, 219: 1.0, 220: 1.0, 221: 0.6, 222: 1.0, 223: 1.0, 224: 1.0, 225: 0.95}

2024-10-10 04:20:05,367 [INFO] [11] TRAIN  loss: 0.08717949443118476 acc: 0.9726645812597754
2024-10-10 04:20:05,367 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.08717949443118476}
2024-10-10 04:20:05,367 [INFO] [11] VALIDATION loss: 0.5010514324908523 VALIDATION  acc: 0.8825260298777727
2024-10-10 04:20:05,367 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 0.5010514324908523}
2024-10-10 04:20:05,367 [INFO] 
2024-10-10 04:21:25,973 [INFO] Step[50/938]: training loss : 0.08798469378612936 TRAIN  loss dict:  {'classification_loss': 0.08798469378612936}
2024-10-10 04:22:25,471 [INFO] Step[100/938]: training loss : 0.08045759106054902 TRAIN  loss dict:  {'classification_loss': 0.08045759106054902}
2024-10-10 04:23:28,432 [INFO] Step[150/938]: training loss : 0.0635389791149646 TRAIN  loss dict:  {'classification_loss': 0.0635389791149646}
2024-10-10 04:24:27,906 [INFO] Step[200/938]: training loss : 0.06804906580597163 TRAIN  loss dict:  {'classification_loss': 0.06804906580597163}
2024-10-10 04:25:26,938 [INFO] Step[250/938]: training loss : 0.06235912595875561 TRAIN  loss dict:  {'classification_loss': 0.06235912595875561}
2024-10-10 04:26:25,996 [INFO] Step[300/938]: training loss : 0.0833158247359097 TRAIN  loss dict:  {'classification_loss': 0.0833158247359097}
2024-10-10 04:27:29,683 [INFO] Step[350/938]: training loss : 0.05832676922902465 TRAIN  loss dict:  {'classification_loss': 0.05832676922902465}
2024-10-10 04:28:29,737 [INFO] Step[400/938]: training loss : 0.09508517069742084 TRAIN  loss dict:  {'classification_loss': 0.09508517069742084}
2024-10-10 04:29:28,435 [INFO] Step[450/938]: training loss : 0.08959605018608272 TRAIN  loss dict:  {'classification_loss': 0.08959605018608272}
2024-10-10 04:30:27,469 [INFO] Step[500/938]: training loss : 0.08115973189473152 TRAIN  loss dict:  {'classification_loss': 0.08115973189473152}
2024-10-10 04:31:31,926 [INFO] Step[550/938]: training loss : 0.05705602861940861 TRAIN  loss dict:  {'classification_loss': 0.05705602861940861}
2024-10-10 04:32:30,788 [INFO] Step[600/938]: training loss : 0.08353294579312205 TRAIN  loss dict:  {'classification_loss': 0.08353294579312205}
2024-10-10 04:33:24,897 [INFO] Step[650/938]: training loss : 0.06349409065209329 TRAIN  loss dict:  {'classification_loss': 0.06349409065209329}
2024-10-10 04:34:18,478 [INFO] Step[700/938]: training loss : 0.0689522645669058 TRAIN  loss dict:  {'classification_loss': 0.0689522645669058}
2024-10-10 04:35:11,903 [INFO] Step[750/938]: training loss : 0.07564968711696565 TRAIN  loss dict:  {'classification_loss': 0.07564968711696565}
2024-10-10 04:36:05,272 [INFO] Step[800/938]: training loss : 0.07608461821917445 TRAIN  loss dict:  {'classification_loss': 0.07608461821917445}
2024-10-10 04:36:58,630 [INFO] Step[850/938]: training loss : 0.08496366656385362 TRAIN  loss dict:  {'classification_loss': 0.08496366656385362}
2024-10-10 04:37:51,975 [INFO] Step[900/938]: training loss : 0.09689220156520605 TRAIN  loss dict:  {'classification_loss': 0.09689220156520605}
2024-10-10 04:40:17,203 [INFO] Label accuracies statistics:
2024-10-10 04:40:17,203 [INFO] {0: 0.9, 1: 0.8947368421052632, 2: 0.9, 3: 0.9473684210526315, 4: 0.85, 5: 0.85, 6: 0.38461538461538464, 7: 0.9, 8: 1.0, 9: 0.7368421052631579, 10: 0.8947368421052632, 11: 0.9, 12: 0.8421052631578947, 13: 0.75, 14: 0.95, 15: 0.9, 16: 0.45, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 1.0, 21: 1.0, 22: 0.85, 23: 0.9, 24: 0.8947368421052632, 25: 1.0, 26: 0.8421052631578947, 27: 0.95, 28: 0.9, 29: 1.0, 30: 0.85, 31: 0.95, 32: 1.0, 33: 0.95, 34: 0.85, 35: 0.95, 36: 1.0, 37: 0.6, 38: 0.9, 39: 1.0, 40: 0.85, 41: 0.95, 42: 1.0, 43: 0.8, 44: 1.0, 45: 0.8, 46: 0.9, 47: 0.25, 48: 0.75, 49: 0.8947368421052632, 50: 0.95, 51: 0.8888888888888888, 52: 0.7777777777777778, 53: 0.95, 54: 0.95, 55: 0.8947368421052632, 56: 1.0, 57: 0.95, 58: 0.75, 59: 0.7777777777777778, 60: 0.9, 61: 0.6842105263157895, 62: 0.5789473684210527, 63: 0.8421052631578947, 64: 1.0, 65: 0.85, 66: 1.0, 67: 0.95, 68: 0.8888888888888888, 69: 0.7222222222222222, 70: 0.95, 71: 0.95, 72: 0.9473684210526315, 73: 0.7894736842105263, 74: 1.0, 75: 0.75, 76: 0.8421052631578947, 77: 1.0, 78: 0.75, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 0.9, 84: 0.85, 85: 1.0, 86: 0.7, 87: 0.7058823529411765, 88: 0.95, 89: 0.8823529411764706, 90: 0.6, 91: 0.85, 92: 0.9, 93: 0.85, 94: 0.9473684210526315, 95: 1.0, 96: 0.5294117647058824, 97: 0.75, 98: 0.47368421052631576, 99: 1.0, 100: 0.85, 101: 1.0, 102: 0.9473684210526315, 103: 0.7, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.65, 108: 0.85, 109: 0.9, 110: 0.95, 111: 0.7, 112: 1.0, 113: 1.0, 114: 1.0, 115: 0.9411764705882353, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 0.95, 120: 1.0, 121: 1.0, 122: 0.6, 123: 0.9, 124: 0.95, 125: 0.9, 126: 0.75, 127: 0.4, 128: 0.95, 129: 0.85, 130: 1.0, 131: 0.8125, 132: 1.0, 133: 1.0, 134: 0.6, 135: 0.9, 136: 0.9, 137: 0.75, 138: 0.8, 139: 0.95, 140: 0.7, 141: 0.95, 142: 0.9, 143: 0.9, 144: 0.8, 145: 0.9473684210526315, 146: 0.95, 147: 0.8, 148: 0.8, 149: 0.9473684210526315, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.65, 155: 0.9, 156: 0.7368421052631579, 157: 0.95, 158: 0.7058823529411765, 159: 1.0, 160: 1.0, 161: 0.85, 162: 0.85, 163: 0.85, 164: 0.8421052631578947, 165: 0.25, 166: 0.8, 167: 0.95, 168: 0.9, 169: 1.0, 170: 0.9473684210526315, 171: 1.0, 172: 0.85, 173: 0.95, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.85, 184: 0.95, 185: 0.9, 186: 0.75, 187: 0.6842105263157895, 188: 1.0, 189: 0.95, 190: 0.9, 191: 1.0, 192: 0.95, 193: 0.95, 194: 0.95, 195: 0.8888888888888888, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 1.0, 201: 1.0, 202: 0.9, 203: 0.9, 204: 0.9, 205: 0.9, 206: 0.2777777777777778, 207: 0.8, 208: 0.95, 209: 0.95, 210: 1.0, 211: 1.0, 212: 0.8823529411764706, 213: 0.9, 214: 1.0, 215: 0.9, 216: 0.95, 217: 0.9, 218: 0.8, 219: 1.0, 220: 0.9, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.95, 225: 0.9}

2024-10-10 04:40:17,249 [INFO] [12] TRAIN  loss: 0.07723547691511097 acc: 0.9768590928480023
2024-10-10 04:40:17,249 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.07723547691511097}
2024-10-10 04:40:17,250 [INFO] [12] VALIDATION loss: 0.48836704191588165 VALIDATION  acc: 0.8775464010864644
2024-10-10 04:40:17,250 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 0.48836704191588165}
2024-10-10 04:40:17,250 [INFO] 
2024-10-10 04:41:26,878 [INFO] Step[50/938]: training loss : 0.05527437679469585 TRAIN  loss dict:  {'classification_loss': 0.05527437679469585}
2024-10-10 04:42:20,125 [INFO] Step[100/938]: training loss : 0.05526291413232684 TRAIN  loss dict:  {'classification_loss': 0.05526291413232684}
2024-10-10 04:43:13,347 [INFO] Step[150/938]: training loss : 0.08073906360659748 TRAIN  loss dict:  {'classification_loss': 0.08073906360659748}
2024-10-10 04:44:06,573 [INFO] Step[200/938]: training loss : 0.06659980588592589 TRAIN  loss dict:  {'classification_loss': 0.06659980588592589}
2024-10-10 04:44:59,794 [INFO] Step[250/938]: training loss : 0.07885055013932288 TRAIN  loss dict:  {'classification_loss': 0.07885055013932288}
2024-10-10 04:45:52,963 [INFO] Step[300/938]: training loss : 0.06978418457321822 TRAIN  loss dict:  {'classification_loss': 0.06978418457321822}
2024-10-10 04:46:46,174 [INFO] Step[350/938]: training loss : 0.053821156141348185 TRAIN  loss dict:  {'classification_loss': 0.053821156141348185}
2024-10-10 04:47:39,377 [INFO] Step[400/938]: training loss : 0.06119445241056383 TRAIN  loss dict:  {'classification_loss': 0.06119445241056383}
2024-10-10 04:48:32,599 [INFO] Step[450/938]: training loss : 0.06703127672430127 TRAIN  loss dict:  {'classification_loss': 0.06703127672430127}
2024-10-10 04:49:25,745 [INFO] Step[500/938]: training loss : 0.07300341729074716 TRAIN  loss dict:  {'classification_loss': 0.07300341729074716}
2024-10-10 04:50:18,984 [INFO] Step[550/938]: training loss : 0.07771544605493545 TRAIN  loss dict:  {'classification_loss': 0.07771544605493545}
2024-10-10 04:51:12,150 [INFO] Step[600/938]: training loss : 0.07893860965035855 TRAIN  loss dict:  {'classification_loss': 0.07893860965035855}
2024-10-10 04:52:05,386 [INFO] Step[650/938]: training loss : 0.05174607002176344 TRAIN  loss dict:  {'classification_loss': 0.05174607002176344}
2024-10-10 04:52:58,624 [INFO] Step[700/938]: training loss : 0.07004626241978258 TRAIN  loss dict:  {'classification_loss': 0.07004626241978258}
2024-10-10 04:53:51,843 [INFO] Step[750/938]: training loss : 0.09128113366663455 TRAIN  loss dict:  {'classification_loss': 0.09128113366663455}
2024-10-10 04:54:45,120 [INFO] Step[800/938]: training loss : 0.0714697481226176 TRAIN  loss dict:  {'classification_loss': 0.0714697481226176}
2024-10-10 04:55:38,343 [INFO] Step[850/938]: training loss : 0.07203372044488787 TRAIN  loss dict:  {'classification_loss': 0.07203372044488787}
2024-10-10 04:56:31,537 [INFO] Step[900/938]: training loss : 0.07220458173193038 TRAIN  loss dict:  {'classification_loss': 0.07220458173193038}
2024-10-10 04:58:56,452 [INFO] Label accuracies statistics:
2024-10-10 04:58:56,452 [INFO] {0: 0.7, 1: 0.8947368421052632, 2: 0.9, 3: 0.9473684210526315, 4: 0.85, 5: 0.85, 6: 0.38461538461538464, 7: 0.85, 8: 1.0, 9: 0.7894736842105263, 10: 1.0, 11: 1.0, 12: 0.8421052631578947, 13: 0.8, 14: 0.75, 15: 0.9, 16: 0.2, 17: 0.7222222222222222, 18: 0.8235294117647058, 19: 1.0, 20: 0.9473684210526315, 21: 1.0, 22: 0.9, 23: 0.9, 24: 0.9473684210526315, 25: 0.9, 26: 0.8947368421052632, 27: 0.9, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.9, 35: 1.0, 36: 1.0, 37: 0.65, 38: 0.9, 39: 0.95, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.8, 44: 0.9473684210526315, 45: 0.85, 46: 0.9, 47: 0.35, 48: 0.65, 49: 1.0, 50: 0.95, 51: 0.9444444444444444, 52: 0.7222222222222222, 53: 1.0, 54: 0.9, 55: 0.7894736842105263, 56: 1.0, 57: 0.95, 58: 0.875, 59: 0.8333333333333334, 60: 0.9, 61: 0.8947368421052632, 62: 0.8947368421052632, 63: 0.8947368421052632, 64: 1.0, 65: 0.8, 66: 1.0, 67: 0.9, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.85, 76: 0.8421052631578947, 77: 1.0, 78: 0.8, 79: 1.0, 80: 0.95, 81: 0.95, 82: 0.9, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.9, 89: 0.8823529411764706, 90: 0.65, 91: 0.85, 92: 0.95, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.5882352941176471, 97: 0.8, 98: 0.2631578947368421, 99: 0.95, 100: 0.95, 101: 0.85, 102: 1.0, 103: 0.85, 104: 0.85, 105: 1.0, 106: 1.0, 107: 0.55, 108: 1.0, 109: 0.95, 110: 1.0, 111: 0.7, 112: 1.0, 113: 1.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.65, 123: 0.9, 124: 0.95, 125: 0.55, 126: 0.65, 127: 0.65, 128: 0.9, 129: 0.65, 130: 1.0, 131: 0.75, 132: 0.8947368421052632, 133: 1.0, 134: 0.8, 135: 0.9, 136: 0.85, 137: 0.75, 138: 0.8, 139: 1.0, 140: 0.7, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.9, 145: 0.8421052631578947, 146: 1.0, 147: 0.6, 148: 1.0, 149: 0.8421052631578947, 150: 0.85, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.7, 155: 0.85, 156: 0.7894736842105263, 157: 0.85, 158: 0.8235294117647058, 159: 1.0, 160: 1.0, 161: 0.8, 162: 0.9, 163: 0.9, 164: 1.0, 165: 0.95, 166: 0.7, 167: 0.95, 168: 0.95, 169: 0.75, 170: 1.0, 171: 0.85, 172: 0.65, 173: 0.8, 174: 1.0, 175: 0.8888888888888888, 176: 0.95, 177: 1.0, 178: 0.6, 179: 1.0, 180: 1.0, 181: 0.95, 182: 0.95, 183: 0.85, 184: 1.0, 185: 0.85, 186: 0.75, 187: 0.8421052631578947, 188: 0.75, 189: 0.95, 190: 1.0, 191: 1.0, 192: 1.0, 193: 0.95, 194: 1.0, 195: 0.6111111111111112, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 0.95, 203: 0.9, 204: 0.95, 205: 0.95, 206: 0.2777777777777778, 207: 0.6, 208: 0.75, 209: 0.95, 210: 1.0, 211: 0.85, 212: 0.7647058823529411, 213: 0.85, 214: 0.85, 215: 0.9, 216: 0.9, 217: 0.95, 218: 0.8, 219: 1.0, 220: 1.0, 221: 0.6, 222: 0.9473684210526315, 223: 1.0, 224: 0.7, 225: 1.0}

2024-10-10 04:58:56,498 [INFO] [13] TRAIN  loss: 0.06924597292851561 acc: 0.9791696288923646
2024-10-10 04:58:56,498 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.06924597292851561}
2024-10-10 04:58:56,498 [INFO] [13] VALIDATION loss: 0.495497604813175 VALIDATION  acc: 0.8836577636939792
2024-10-10 04:58:56,498 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 0.495497604813175}
2024-10-10 04:58:56,498 [INFO] 
2024-10-10 05:00:06,224 [INFO] Step[50/938]: training loss : 0.0640282532805577 TRAIN  loss dict:  {'classification_loss': 0.0640282532805577}
2024-10-10 05:00:59,392 [INFO] Step[100/938]: training loss : 0.061688768109306694 TRAIN  loss dict:  {'classification_loss': 0.061688768109306694}
2024-10-10 05:01:52,542 [INFO] Step[150/938]: training loss : 0.05411302917636931 TRAIN  loss dict:  {'classification_loss': 0.05411302917636931}
2024-10-10 05:02:45,669 [INFO] Step[200/938]: training loss : 0.05476949658244848 TRAIN  loss dict:  {'classification_loss': 0.05476949658244848}
2024-10-10 05:03:38,816 [INFO] Step[250/938]: training loss : 0.06306280188262463 TRAIN  loss dict:  {'classification_loss': 0.06306280188262463}
2024-10-10 05:04:31,960 [INFO] Step[300/938]: training loss : 0.06817908933386206 TRAIN  loss dict:  {'classification_loss': 0.06817908933386206}
2024-10-10 05:05:25,087 [INFO] Step[350/938]: training loss : 0.06632044623605907 TRAIN  loss dict:  {'classification_loss': 0.06632044623605907}
2024-10-10 05:06:18,286 [INFO] Step[400/938]: training loss : 0.07526353124994785 TRAIN  loss dict:  {'classification_loss': 0.07526353124994785}
2024-10-10 05:07:11,435 [INFO] Step[450/938]: training loss : 0.07215555076021701 TRAIN  loss dict:  {'classification_loss': 0.07215555076021701}
2024-10-10 05:08:04,623 [INFO] Step[500/938]: training loss : 0.08308496370911599 TRAIN  loss dict:  {'classification_loss': 0.08308496370911599}
2024-10-10 05:08:57,797 [INFO] Step[550/938]: training loss : 0.062494276510551575 TRAIN  loss dict:  {'classification_loss': 0.062494276510551575}
2024-10-10 05:09:50,939 [INFO] Step[600/938]: training loss : 0.057590546989813446 TRAIN  loss dict:  {'classification_loss': 0.057590546989813446}
2024-10-10 05:10:44,084 [INFO] Step[650/938]: training loss : 0.06446837287396193 TRAIN  loss dict:  {'classification_loss': 0.06446837287396193}
2024-10-10 05:11:37,254 [INFO] Step[700/938]: training loss : 0.0714009968098253 TRAIN  loss dict:  {'classification_loss': 0.0714009968098253}
2024-10-10 05:12:30,523 [INFO] Step[750/938]: training loss : 0.06359368064440787 TRAIN  loss dict:  {'classification_loss': 0.06359368064440787}
2024-10-10 05:13:23,624 [INFO] Step[800/938]: training loss : 0.055858066324144605 TRAIN  loss dict:  {'classification_loss': 0.055858066324144605}
2024-10-10 05:14:16,807 [INFO] Step[850/938]: training loss : 0.05431154037825763 TRAIN  loss dict:  {'classification_loss': 0.05431154037825763}
2024-10-10 05:15:09,872 [INFO] Step[900/938]: training loss : 0.06356176706496626 TRAIN  loss dict:  {'classification_loss': 0.06356176706496626}
2024-10-10 05:17:34,726 [INFO] Label accuracies statistics:
2024-10-10 05:17:34,726 [INFO] {0: 0.75, 1: 1.0, 2: 0.9, 3: 0.9473684210526315, 4: 0.85, 5: 0.8, 6: 0.46153846153846156, 7: 0.95, 8: 1.0, 9: 0.5789473684210527, 10: 0.7894736842105263, 11: 0.9, 12: 0.6842105263157895, 13: 0.85, 14: 0.7, 15: 0.9, 16: 0.3, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 1.0, 21: 1.0, 22: 0.85, 23: 0.75, 24: 0.9473684210526315, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 0.95, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.95, 34: 0.9, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.9, 39: 0.95, 40: 0.95, 41: 1.0, 42: 0.85, 43: 0.9, 44: 0.9473684210526315, 45: 0.7, 46: 0.9, 47: 0.55, 48: 0.85, 49: 0.9473684210526315, 50: 1.0, 51: 0.9444444444444444, 52: 0.6111111111111112, 53: 0.95, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 1.0, 58: 0.8125, 59: 0.7777777777777778, 60: 0.95, 61: 0.7368421052631579, 62: 0.6842105263157895, 63: 0.7368421052631579, 64: 0.95, 65: 0.9, 66: 1.0, 67: 0.7, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.7894736842105263, 74: 1.0, 75: 0.8, 76: 0.7368421052631579, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 0.95, 84: 0.95, 85: 1.0, 86: 0.7, 87: 0.8823529411764706, 88: 0.95, 89: 0.8823529411764706, 90: 0.8, 91: 0.95, 92: 0.8, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.7058823529411765, 97: 0.6, 98: 0.6842105263157895, 99: 1.0, 100: 0.95, 101: 0.9, 102: 1.0, 103: 0.65, 104: 0.75, 105: 0.95, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.6, 112: 1.0, 113: 0.95, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.95, 120: 0.95, 121: 1.0, 122: 0.55, 123: 0.9, 124: 0.9, 125: 0.85, 126: 0.85, 127: 0.55, 128: 0.95, 129: 0.7, 130: 1.0, 131: 0.6875, 132: 0.7894736842105263, 133: 1.0, 134: 0.45, 135: 0.75, 136: 0.9, 137: 0.85, 138: 0.85, 139: 1.0, 140: 0.9, 141: 0.9, 142: 1.0, 143: 0.9, 144: 1.0, 145: 0.8421052631578947, 146: 0.9, 147: 0.75, 148: 1.0, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 0.95, 153: 1.0, 154: 0.8, 155: 0.85, 156: 0.7894736842105263, 157: 0.95, 158: 0.47058823529411764, 159: 1.0, 160: 1.0, 161: 0.85, 162: 1.0, 163: 1.0, 164: 1.0, 165: 0.8, 166: 0.85, 167: 0.9, 168: 1.0, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.65, 173: 0.85, 174: 1.0, 175: 0.6111111111111112, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.95, 184: 0.95, 185: 0.9, 186: 0.6, 187: 0.8421052631578947, 188: 0.95, 189: 0.9, 190: 0.8, 191: 1.0, 192: 1.0, 193: 0.95, 194: 0.95, 195: 0.6666666666666666, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 1.0, 203: 0.85, 204: 0.95, 205: 0.9, 206: 0.3333333333333333, 207: 0.7, 208: 0.95, 209: 0.9, 210: 1.0, 211: 0.85, 212: 0.8235294117647058, 213: 0.85, 214: 1.0, 215: 0.9, 216: 0.9, 217: 0.95, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 1.0}

2024-10-10 05:17:34,773 [INFO] [14] TRAIN  loss: 0.06454982257399486 acc: 0.979809469643111
2024-10-10 05:17:34,773 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.06454982257399486}
2024-10-10 05:17:34,773 [INFO] [14] VALIDATION loss: 0.4819941147296639 VALIDATION  acc: 0.8820733363512901
2024-10-10 05:17:34,773 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 0.4819941147296639}
2024-10-10 05:17:34,773 [INFO] 
2024-10-10 05:18:44,696 [INFO] Step[50/938]: training loss : 0.07123439689166844 TRAIN  loss dict:  {'classification_loss': 0.07123439689166844}
2024-10-10 05:19:37,790 [INFO] Step[100/938]: training loss : 0.05596162274014205 TRAIN  loss dict:  {'classification_loss': 0.05596162274014205}
2024-10-10 05:20:30,995 [INFO] Step[150/938]: training loss : 0.04934812522493303 TRAIN  loss dict:  {'classification_loss': 0.04934812522493303}
2024-10-10 05:21:24,096 [INFO] Step[200/938]: training loss : 0.06083630752982572 TRAIN  loss dict:  {'classification_loss': 0.06083630752982572}
2024-10-10 05:22:17,258 [INFO] Step[250/938]: training loss : 0.06581075785681606 TRAIN  loss dict:  {'classification_loss': 0.06581075785681606}
2024-10-10 05:23:10,381 [INFO] Step[300/938]: training loss : 0.058245759550482036 TRAIN  loss dict:  {'classification_loss': 0.058245759550482036}
2024-10-10 05:24:03,517 [INFO] Step[350/938]: training loss : 0.06894680027849973 TRAIN  loss dict:  {'classification_loss': 0.06894680027849973}
2024-10-10 05:24:56,647 [INFO] Step[400/938]: training loss : 0.05119849204784259 TRAIN  loss dict:  {'classification_loss': 0.05119849204784259}
2024-10-10 05:25:49,845 [INFO] Step[450/938]: training loss : 0.06668138708919287 TRAIN  loss dict:  {'classification_loss': 0.06668138708919287}
2024-10-10 05:26:42,968 [INFO] Step[500/938]: training loss : 0.06769012068398297 TRAIN  loss dict:  {'classification_loss': 0.06769012068398297}
2024-10-10 05:27:36,138 [INFO] Step[550/938]: training loss : 0.06308867230080067 TRAIN  loss dict:  {'classification_loss': 0.06308867230080067}
2024-10-10 05:28:29,257 [INFO] Step[600/938]: training loss : 0.0705288989841938 TRAIN  loss dict:  {'classification_loss': 0.0705288989841938}
2024-10-10 05:29:22,352 [INFO] Step[650/938]: training loss : 0.05444368367083371 TRAIN  loss dict:  {'classification_loss': 0.05444368367083371}
2024-10-10 05:30:15,472 [INFO] Step[700/938]: training loss : 0.060660684541799126 TRAIN  loss dict:  {'classification_loss': 0.060660684541799126}
2024-10-10 05:31:08,585 [INFO] Step[750/938]: training loss : 0.07971549490466714 TRAIN  loss dict:  {'classification_loss': 0.07971549490466714}
2024-10-10 05:32:01,807 [INFO] Step[800/938]: training loss : 0.09487722666934133 TRAIN  loss dict:  {'classification_loss': 0.09487722666934133}
2024-10-10 05:32:55,021 [INFO] Step[850/938]: training loss : 0.08803934003692121 TRAIN  loss dict:  {'classification_loss': 0.08803934003692121}
2024-10-10 05:33:48,150 [INFO] Step[900/938]: training loss : 0.047831498836167156 TRAIN  loss dict:  {'classification_loss': 0.047831498836167156}
2024-10-10 05:36:13,191 [INFO] Label accuracies statistics:
2024-10-10 05:36:13,191 [INFO] {0: 0.85, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.9, 5: 0.8, 6: 0.3076923076923077, 7: 0.75, 8: 1.0, 9: 0.8947368421052632, 10: 0.7894736842105263, 11: 1.0, 12: 0.5263157894736842, 13: 0.85, 14: 0.9, 15: 0.9, 16: 0.3, 17: 0.7222222222222222, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 0.9473684210526315, 21: 1.0, 22: 0.8, 23: 0.9, 24: 0.8421052631578947, 25: 0.95, 26: 0.8947368421052632, 27: 0.95, 28: 0.95, 29: 0.95, 30: 0.85, 31: 0.95, 32: 1.0, 33: 0.95, 34: 0.65, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.95, 39: 0.95, 40: 1.0, 41: 1.0, 42: 0.95, 43: 1.0, 44: 0.9473684210526315, 45: 0.95, 46: 0.9, 47: 0.2, 48: 0.5, 49: 0.8947368421052632, 50: 1.0, 51: 0.8333333333333334, 52: 0.6666666666666666, 53: 0.9, 54: 1.0, 55: 0.8947368421052632, 56: 1.0, 57: 1.0, 58: 0.6875, 59: 0.7777777777777778, 60: 0.8, 61: 0.7894736842105263, 62: 0.8421052631578947, 63: 0.7368421052631579, 64: 0.9, 65: 0.85, 66: 1.0, 67: 0.95, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.95, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.7, 76: 0.7368421052631579, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.95, 84: 0.85, 85: 1.0, 86: 0.75, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.75, 91: 0.9, 92: 0.85, 93: 0.85, 94: 0.9473684210526315, 95: 1.0, 96: 0.4117647058823529, 97: 0.75, 98: 0.3157894736842105, 99: 0.95, 100: 0.95, 101: 0.85, 102: 1.0, 103: 0.85, 104: 0.95, 105: 1.0, 106: 1.0, 107: 0.55, 108: 1.0, 109: 0.95, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.9, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.55, 123: 0.85, 124: 1.0, 125: 0.9, 126: 0.8, 127: 0.9, 128: 0.9, 129: 0.75, 130: 1.0, 131: 0.6875, 132: 0.9473684210526315, 133: 1.0, 134: 0.4, 135: 0.95, 136: 1.0, 137: 0.8, 138: 0.9, 139: 0.95, 140: 0.95, 141: 0.95, 142: 0.95, 143: 1.0, 144: 1.0, 145: 0.9473684210526315, 146: 1.0, 147: 0.75, 148: 0.8, 149: 1.0, 150: 0.4, 151: 0.95, 152: 1.0, 153: 1.0, 154: 0.7, 155: 0.9, 156: 0.7368421052631579, 157: 0.9, 158: 0.4117647058823529, 159: 1.0, 160: 1.0, 161: 0.85, 162: 0.85, 163: 0.85, 164: 0.8421052631578947, 165: 1.0, 166: 0.8, 167: 0.95, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.85, 173: 0.9, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.7, 179: 0.95, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.85, 184: 1.0, 185: 0.85, 186: 0.95, 187: 0.8947368421052632, 188: 0.9, 189: 0.95, 190: 0.9, 191: 1.0, 192: 1.0, 193: 0.95, 194: 1.0, 195: 0.9444444444444444, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 0.8947368421052632, 201: 1.0, 202: 1.0, 203: 0.9, 204: 0.9, 205: 0.9, 206: 0.2777777777777778, 207: 0.6, 208: 1.0, 209: 0.95, 210: 1.0, 211: 1.0, 212: 0.8235294117647058, 213: 0.85, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.95, 218: 0.8, 219: 1.0, 220: 0.9, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.9, 225: 0.9}

2024-10-10 05:36:13,236 [INFO] [15] TRAIN  loss: 0.0655200866784261 acc: 0.979454002559363
2024-10-10 05:36:13,236 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.0655200866784261}
2024-10-10 05:36:13,237 [INFO] [15] VALIDATION loss: 0.5054528051169237 VALIDATION  acc: 0.8841104572204618
2024-10-10 05:36:13,237 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 0.5054528051169237}
2024-10-10 05:36:13,237 [INFO] 
2024-10-10 05:37:22,807 [INFO] Step[50/938]: training loss : 0.05612794469110668 TRAIN  loss dict:  {'classification_loss': 0.05612794469110668}
2024-10-10 05:38:15,923 [INFO] Step[100/938]: training loss : 0.06364138232544064 TRAIN  loss dict:  {'classification_loss': 0.06364138232544064}
2024-10-10 05:39:09,083 [INFO] Step[150/938]: training loss : 0.05929639687761665 TRAIN  loss dict:  {'classification_loss': 0.05929639687761665}
2024-10-10 05:40:02,279 [INFO] Step[200/938]: training loss : 0.06368420168757438 TRAIN  loss dict:  {'classification_loss': 0.06368420168757438}
2024-10-10 05:40:55,394 [INFO] Step[250/938]: training loss : 0.06298281525261701 TRAIN  loss dict:  {'classification_loss': 0.06298281525261701}
2024-10-10 05:41:48,548 [INFO] Step[300/938]: training loss : 0.0709641233086586 TRAIN  loss dict:  {'classification_loss': 0.0709641233086586}
2024-10-10 05:42:41,688 [INFO] Step[350/938]: training loss : 0.07140853608492762 TRAIN  loss dict:  {'classification_loss': 0.07140853608492762}
2024-10-10 05:43:34,838 [INFO] Step[400/938]: training loss : 0.05689734091050923 TRAIN  loss dict:  {'classification_loss': 0.05689734091050923}
2024-10-10 05:44:28,023 [INFO] Step[450/938]: training loss : 0.06370252306573093 TRAIN  loss dict:  {'classification_loss': 0.06370252306573093}
2024-10-10 05:45:21,146 [INFO] Step[500/938]: training loss : 0.07157066213898361 TRAIN  loss dict:  {'classification_loss': 0.07157066213898361}
2024-10-10 05:46:14,235 [INFO] Step[550/938]: training loss : 0.07486134488601237 TRAIN  loss dict:  {'classification_loss': 0.07486134488601237}
2024-10-10 05:47:07,412 [INFO] Step[600/938]: training loss : 0.07142615301534533 TRAIN  loss dict:  {'classification_loss': 0.07142615301534533}
2024-10-10 05:48:00,569 [INFO] Step[650/938]: training loss : 0.04792457066476345 TRAIN  loss dict:  {'classification_loss': 0.04792457066476345}
2024-10-10 05:48:53,749 [INFO] Step[700/938]: training loss : 0.06102335206698626 TRAIN  loss dict:  {'classification_loss': 0.06102335206698626}
2024-10-10 05:49:46,884 [INFO] Step[750/938]: training loss : 0.06791459391824901 TRAIN  loss dict:  {'classification_loss': 0.06791459391824901}
2024-10-10 05:50:40,010 [INFO] Step[800/938]: training loss : 0.056602842030115424 TRAIN  loss dict:  {'classification_loss': 0.056602842030115424}
2024-10-10 05:51:33,156 [INFO] Step[850/938]: training loss : 0.07016906200908124 TRAIN  loss dict:  {'classification_loss': 0.07016906200908124}
2024-10-10 05:52:26,351 [INFO] Step[900/938]: training loss : 0.06938366454094648 TRAIN  loss dict:  {'classification_loss': 0.06938366454094648}
2024-10-10 05:54:51,091 [INFO] Label accuracies statistics:
2024-10-10 05:54:51,092 [INFO] {0: 0.75, 1: 0.8947368421052632, 2: 0.95, 3: 0.9473684210526315, 4: 0.9, 5: 0.75, 6: 0.46153846153846156, 7: 0.9, 8: 0.95, 9: 0.7894736842105263, 10: 0.7368421052631579, 11: 1.0, 12: 0.9473684210526315, 13: 0.7, 14: 0.9, 15: 0.9, 16: 0.9, 17: 0.7777777777777778, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 0.8947368421052632, 21: 0.8947368421052632, 22: 0.75, 23: 0.9, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 1.0, 29: 1.0, 30: 0.85, 31: 1.0, 32: 0.95, 33: 0.95, 34: 0.9, 35: 1.0, 36: 1.0, 37: 0.7, 38: 0.9, 39: 0.9, 40: 1.0, 41: 1.0, 42: 0.95, 43: 0.85, 44: 0.9473684210526315, 45: 0.8, 46: 0.9, 47: 0.25, 48: 0.65, 49: 0.9473684210526315, 50: 0.95, 51: 0.8888888888888888, 52: 0.8333333333333334, 53: 1.0, 54: 0.95, 55: 0.8947368421052632, 56: 1.0, 57: 1.0, 58: 0.9375, 59: 0.5555555555555556, 60: 0.95, 61: 0.42105263157894735, 62: 0.631578947368421, 63: 0.8947368421052632, 64: 0.95, 65: 0.75, 66: 1.0, 67: 0.9, 68: 0.8888888888888888, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.95, 76: 0.8421052631578947, 77: 1.0, 78: 0.75, 79: 1.0, 80: 1.0, 81: 0.85, 82: 0.8, 83: 0.95, 84: 1.0, 85: 1.0, 86: 0.7, 87: 0.9411764705882353, 88: 1.0, 89: 0.9411764705882353, 90: 0.8, 91: 0.8, 92: 0.95, 93: 1.0, 94: 0.9473684210526315, 95: 0.75, 96: 0.35294117647058826, 97: 0.75, 98: 0.7894736842105263, 99: 0.9, 100: 1.0, 101: 0.9, 102: 0.9473684210526315, 103: 0.8, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.7, 108: 0.8, 109: 1.0, 110: 1.0, 111: 0.55, 112: 1.0, 113: 0.9, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.95, 121: 1.0, 122: 0.75, 123: 1.0, 124: 0.95, 125: 0.85, 126: 0.75, 127: 0.65, 128: 0.95, 129: 0.65, 130: 1.0, 131: 0.8125, 132: 0.8947368421052632, 133: 1.0, 134: 0.75, 135: 0.75, 136: 0.95, 137: 0.85, 138: 0.85, 139: 0.85, 140: 0.9, 141: 1.0, 142: 1.0, 143: 0.8, 144: 0.9, 145: 0.8947368421052632, 146: 0.9, 147: 0.8, 148: 1.0, 149: 0.7894736842105263, 150: 0.8, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.8, 155: 0.85, 156: 0.8421052631578947, 157: 0.95, 158: 0.8823529411764706, 159: 1.0, 160: 0.7, 161: 0.8, 162: 0.85, 163: 1.0, 164: 0.9473684210526315, 165: 0.75, 166: 0.7, 167: 0.95, 168: 0.9, 169: 0.95, 170: 1.0, 171: 1.0, 172: 0.45, 173: 0.85, 174: 0.95, 175: 0.6111111111111112, 176: 0.9, 177: 1.0, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.95, 183: 0.8, 184: 1.0, 185: 0.9, 186: 0.6, 187: 0.8947368421052632, 188: 0.95, 189: 1.0, 190: 1.0, 191: 1.0, 192: 0.9, 193: 1.0, 194: 1.0, 195: 0.8333333333333334, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 1.0, 201: 1.0, 202: 1.0, 203: 0.95, 204: 1.0, 205: 0.8, 206: 0.2222222222222222, 207: 0.65, 208: 0.95, 209: 0.9, 210: 0.9, 211: 0.9, 212: 0.8823529411764706, 213: 0.8, 214: 1.0, 215: 0.9, 216: 0.95, 217: 1.0, 218: 0.8, 219: 1.0, 220: 0.95, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.95, 225: 1.0}

2024-10-10 05:54:51,138 [INFO] [16] TRAIN  loss: 0.06408341050839056 acc: 0.9797383762263614
2024-10-10 05:54:51,138 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.06408341050839056}
2024-10-10 05:54:51,138 [INFO] [16] VALIDATION loss: 0.48477757065336696 VALIDATION  acc: 0.8861475780896333
2024-10-10 05:54:51,138 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 0.48477757065336696}
2024-10-10 05:54:51,138 [INFO] 
2024-10-10 05:56:00,444 [INFO] Step[50/938]: training loss : 0.03973569554742426 TRAIN  loss dict:  {'classification_loss': 0.03973569554742426}
2024-10-10 05:56:53,546 [INFO] Step[100/938]: training loss : 0.055235624215565625 TRAIN  loss dict:  {'classification_loss': 0.055235624215565625}
2024-10-10 05:57:46,751 [INFO] Step[150/938]: training loss : 0.06500795487780124 TRAIN  loss dict:  {'classification_loss': 0.06500795487780124}
2024-10-10 05:58:39,865 [INFO] Step[200/938]: training loss : 0.07679701584391296 TRAIN  loss dict:  {'classification_loss': 0.07679701584391296}
2024-10-10 05:59:32,957 [INFO] Step[250/938]: training loss : 0.04947878768667579 TRAIN  loss dict:  {'classification_loss': 0.04947878768667579}
2024-10-10 06:00:26,100 [INFO] Step[300/938]: training loss : 0.04480927918571979 TRAIN  loss dict:  {'classification_loss': 0.04480927918571979}
2024-10-10 06:01:19,219 [INFO] Step[350/938]: training loss : 0.06285972932353616 TRAIN  loss dict:  {'classification_loss': 0.06285972932353616}
2024-10-10 06:02:12,351 [INFO] Step[400/938]: training loss : 0.07122921677306294 TRAIN  loss dict:  {'classification_loss': 0.07122921677306294}
2024-10-10 06:03:05,556 [INFO] Step[450/938]: training loss : 0.054816584601067 TRAIN  loss dict:  {'classification_loss': 0.054816584601067}
2024-10-10 06:03:58,655 [INFO] Step[500/938]: training loss : 0.05108767350204289 TRAIN  loss dict:  {'classification_loss': 0.05108767350204289}
2024-10-10 06:04:51,884 [INFO] Step[550/938]: training loss : 0.05365629646461457 TRAIN  loss dict:  {'classification_loss': 0.05365629646461457}
2024-10-10 06:05:44,944 [INFO] Step[600/938]: training loss : 0.06890707563608885 TRAIN  loss dict:  {'classification_loss': 0.06890707563608885}
2024-10-10 06:06:38,128 [INFO] Step[650/938]: training loss : 0.07046662323642522 TRAIN  loss dict:  {'classification_loss': 0.07046662323642522}
2024-10-10 06:07:31,271 [INFO] Step[700/938]: training loss : 0.05415848346427083 TRAIN  loss dict:  {'classification_loss': 0.05415848346427083}
2024-10-10 06:08:24,410 [INFO] Step[750/938]: training loss : 0.04970687705092132 TRAIN  loss dict:  {'classification_loss': 0.04970687705092132}
2024-10-10 06:09:17,531 [INFO] Step[800/938]: training loss : 0.059861667905934154 TRAIN  loss dict:  {'classification_loss': 0.059861667905934154}
2024-10-10 06:10:10,646 [INFO] Step[850/938]: training loss : 0.05788535277359188 TRAIN  loss dict:  {'classification_loss': 0.05788535277359188}
2024-10-10 06:11:03,815 [INFO] Step[900/938]: training loss : 0.04875259324675426 TRAIN  loss dict:  {'classification_loss': 0.04875259324675426}
2024-10-10 06:13:28,416 [INFO] Label accuracies statistics:
2024-10-10 06:13:28,416 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.9, 3: 0.9473684210526315, 4: 0.9, 5: 0.7, 6: 0.46153846153846156, 7: 0.85, 8: 1.0, 9: 0.7894736842105263, 10: 0.8947368421052632, 11: 0.9, 12: 0.7894736842105263, 13: 1.0, 14: 0.85, 15: 0.9, 16: 0.3, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 0.9473684210526315, 21: 0.9473684210526315, 22: 0.7, 23: 0.85, 24: 0.7894736842105263, 25: 1.0, 26: 0.8947368421052632, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.9, 31: 1.0, 32: 1.0, 33: 0.9, 34: 0.65, 35: 1.0, 36: 1.0, 37: 0.6, 38: 0.9, 39: 0.95, 40: 0.9, 41: 1.0, 42: 1.0, 43: 0.9, 44: 0.9473684210526315, 45: 0.9, 46: 0.9, 47: 0.3, 48: 0.85, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.8888888888888888, 53: 0.95, 54: 1.0, 55: 0.6842105263157895, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.7777777777777778, 60: 0.85, 61: 0.7368421052631579, 62: 0.631578947368421, 63: 0.9473684210526315, 64: 1.0, 65: 0.75, 66: 1.0, 67: 0.85, 68: 0.7222222222222222, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.8421052631578947, 74: 1.0, 75: 0.6, 76: 0.8947368421052632, 77: 1.0, 78: 0.85, 79: 1.0, 80: 1.0, 81: 0.9, 82: 0.8, 83: 0.9, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.9, 89: 0.9411764705882353, 90: 0.65, 91: 0.7, 92: 0.95, 93: 0.9, 94: 1.0, 95: 0.9166666666666666, 96: 0.4117647058823529, 97: 0.6, 98: 0.47368421052631576, 99: 1.0, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.8, 105: 0.95, 106: 1.0, 107: 0.4, 108: 0.8, 109: 1.0, 110: 1.0, 111: 0.6, 112: 1.0, 113: 1.0, 114: 0.95, 115: 0.8823529411764706, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.95, 122: 0.55, 123: 0.75, 124: 0.9, 125: 0.85, 126: 0.8, 127: 0.65, 128: 0.85, 129: 0.75, 130: 1.0, 131: 0.8125, 132: 0.6842105263157895, 133: 0.9, 134: 0.9, 135: 0.95, 136: 1.0, 137: 0.8, 138: 0.85, 139: 0.9, 140: 0.8, 141: 1.0, 142: 1.0, 143: 0.85, 144: 0.9, 145: 0.9473684210526315, 146: 0.9, 147: 0.65, 148: 0.85, 149: 0.8421052631578947, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.95, 154: 0.9, 155: 0.85, 156: 0.9473684210526315, 157: 0.85, 158: 0.6470588235294118, 159: 1.0, 160: 0.95, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.8421052631578947, 165: 0.7, 166: 0.95, 167: 0.95, 168: 0.95, 169: 1.0, 170: 0.9473684210526315, 171: 1.0, 172: 0.45, 173: 0.75, 174: 0.95, 175: 0.5, 176: 1.0, 177: 1.0, 178: 0.35, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.75, 184: 1.0, 185: 0.9, 186: 0.9, 187: 0.631578947368421, 188: 0.95, 189: 0.95, 190: 0.9, 191: 1.0, 192: 0.8, 193: 1.0, 194: 1.0, 195: 0.6111111111111112, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.9, 200: 1.0, 201: 1.0, 202: 0.95, 203: 0.9, 204: 0.9, 205: 0.85, 206: 0.2777777777777778, 207: 0.85, 208: 1.0, 209: 0.85, 210: 1.0, 211: 0.9, 212: 0.9411764705882353, 213: 0.8, 214: 0.9, 215: 0.9, 216: 0.95, 217: 0.7, 218: 0.9, 219: 1.0, 220: 1.0, 221: 0.6, 222: 1.0, 223: 0.95, 224: 0.8, 225: 0.95}

2024-10-10 06:13:28,462 [INFO] [17] TRAIN  loss: 0.05677914904464763 acc: 0.9822266458125978
2024-10-10 06:13:28,462 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.05677914904464763}
2024-10-10 06:13:28,462 [INFO] [17] VALIDATION loss: 0.5545345667790545 VALIDATION  acc: 0.8730194658216387
2024-10-10 06:13:28,462 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 0.5545345667790545}
2024-10-10 06:13:28,462 [INFO] 
2024-10-10 06:14:38,173 [INFO] Step[50/938]: training loss : 0.04031842617783696 TRAIN  loss dict:  {'classification_loss': 0.04031842617783696}
2024-10-10 06:15:31,216 [INFO] Step[100/938]: training loss : 0.04050586994271725 TRAIN  loss dict:  {'classification_loss': 0.04050586994271725}
2024-10-10 06:16:24,344 [INFO] Step[150/938]: training loss : 0.051567901303060354 TRAIN  loss dict:  {'classification_loss': 0.051567901303060354}
2024-10-10 06:17:17,380 [INFO] Step[200/938]: training loss : 0.06003815685864538 TRAIN  loss dict:  {'classification_loss': 0.06003815685864538}
2024-10-10 06:18:10,530 [INFO] Step[250/938]: training loss : 0.06392883137334138 TRAIN  loss dict:  {'classification_loss': 0.06392883137334138}
2024-10-10 06:19:03,542 [INFO] Step[300/938]: training loss : 0.05372112127486616 TRAIN  loss dict:  {'classification_loss': 0.05372112127486616}
2024-10-10 06:19:56,561 [INFO] Step[350/938]: training loss : 0.05272332843393088 TRAIN  loss dict:  {'classification_loss': 0.05272332843393088}
2024-10-10 06:20:49,561 [INFO] Step[400/938]: training loss : 0.0374885456636548 TRAIN  loss dict:  {'classification_loss': 0.0374885456636548}
2024-10-10 06:21:42,676 [INFO] Step[450/938]: training loss : 0.06806105857249349 TRAIN  loss dict:  {'classification_loss': 0.06806105857249349}
2024-10-10 06:22:35,761 [INFO] Step[500/938]: training loss : 0.057662192340940235 TRAIN  loss dict:  {'classification_loss': 0.057662192340940235}
2024-10-10 06:23:28,867 [INFO] Step[550/938]: training loss : 0.058445676593109966 TRAIN  loss dict:  {'classification_loss': 0.058445676593109966}
2024-10-10 06:24:21,982 [INFO] Step[600/938]: training loss : 0.05485727284103632 TRAIN  loss dict:  {'classification_loss': 0.05485727284103632}
2024-10-10 06:25:15,037 [INFO] Step[650/938]: training loss : 0.04213585597462952 TRAIN  loss dict:  {'classification_loss': 0.04213585597462952}
2024-10-10 06:26:08,127 [INFO] Step[700/938]: training loss : 0.03863496168516576 TRAIN  loss dict:  {'classification_loss': 0.03863496168516576}
2024-10-10 06:27:01,235 [INFO] Step[750/938]: training loss : 0.04767192557454109 TRAIN  loss dict:  {'classification_loss': 0.04767192557454109}
2024-10-10 06:27:54,333 [INFO] Step[800/938]: training loss : 0.04314551952760667 TRAIN  loss dict:  {'classification_loss': 0.04314551952760667}
2024-10-10 06:28:47,435 [INFO] Step[850/938]: training loss : 0.0544782134052366 TRAIN  loss dict:  {'classification_loss': 0.0544782134052366}
2024-10-10 06:29:40,518 [INFO] Step[900/938]: training loss : 0.05004178432747722 TRAIN  loss dict:  {'classification_loss': 0.05004178432747722}
2024-10-10 06:32:05,211 [INFO] Label accuracies statistics:
2024-10-10 06:32:05,211 [INFO] {0: 0.9, 1: 0.9473684210526315, 2: 0.9, 3: 1.0, 4: 0.9, 5: 0.75, 6: 0.3076923076923077, 7: 0.85, 8: 0.95, 9: 0.9473684210526315, 10: 0.8947368421052632, 11: 1.0, 12: 0.7368421052631579, 13: 1.0, 14: 0.9, 15: 0.9, 16: 0.75, 17: 0.8333333333333334, 18: 0.8235294117647058, 19: 1.0, 20: 0.9473684210526315, 21: 1.0, 22: 0.55, 23: 0.9, 24: 0.8947368421052632, 25: 1.0, 26: 0.8421052631578947, 27: 0.95, 28: 1.0, 29: 1.0, 30: 0.85, 31: 1.0, 32: 1.0, 33: 0.9, 34: 0.75, 35: 0.9, 36: 1.0, 37: 0.6, 38: 0.9, 39: 0.95, 40: 1.0, 41: 0.95, 42: 0.9, 43: 1.0, 44: 1.0, 45: 0.85, 46: 0.9, 47: 0.4, 48: 0.7, 49: 0.6842105263157895, 50: 0.95, 51: 0.9444444444444444, 52: 0.8333333333333334, 53: 0.85, 54: 0.9, 55: 0.8947368421052632, 56: 0.9473684210526315, 57: 1.0, 58: 1.0, 59: 1.0, 60: 0.95, 61: 0.6842105263157895, 62: 0.8421052631578947, 63: 0.7894736842105263, 64: 0.95, 65: 0.75, 66: 1.0, 67: 0.9, 68: 0.7777777777777778, 69: 0.8333333333333334, 70: 1.0, 71: 0.95, 72: 0.9473684210526315, 73: 0.8947368421052632, 74: 0.85, 75: 0.8, 76: 1.0, 77: 0.95, 78: 0.8, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.85, 83: 0.9, 84: 0.9, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.95, 89: 0.8823529411764706, 90: 0.75, 91: 0.7, 92: 0.95, 93: 1.0, 94: 0.7368421052631579, 95: 0.5833333333333334, 96: 0.47058823529411764, 97: 0.6, 98: 0.21052631578947367, 99: 1.0, 100: 0.8, 101: 0.95, 102: 1.0, 103: 0.8, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.7, 108: 1.0, 109: 1.0, 110: 0.95, 111: 0.65, 112: 1.0, 113: 0.9, 114: 0.95, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 0.95, 120: 1.0, 121: 1.0, 122: 0.35, 123: 1.0, 124: 0.9, 125: 0.85, 126: 0.85, 127: 0.65, 128: 0.9, 129: 0.75, 130: 1.0, 131: 0.875, 132: 0.9473684210526315, 133: 1.0, 134: 0.6, 135: 0.8, 136: 0.95, 137: 0.75, 138: 0.75, 139: 0.85, 140: 0.85, 141: 1.0, 142: 0.85, 143: 0.9, 144: 1.0, 145: 0.8421052631578947, 146: 0.9, 147: 0.8, 148: 1.0, 149: 0.7894736842105263, 150: 0.7, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.6, 155: 0.85, 156: 0.9473684210526315, 157: 0.95, 158: 1.0, 159: 1.0, 160: 0.95, 161: 0.8, 162: 0.9, 163: 1.0, 164: 0.8421052631578947, 165: 0.7, 166: 0.65, 167: 0.9, 168: 0.95, 169: 1.0, 170: 0.9473684210526315, 171: 0.95, 172: 0.4, 173: 0.85, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.25, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.8, 183: 0.7, 184: 1.0, 185: 0.9, 186: 0.9, 187: 0.6842105263157895, 188: 0.9, 189: 0.95, 190: 0.85, 191: 1.0, 192: 0.85, 193: 1.0, 194: 0.8, 195: 0.8333333333333334, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 0.95, 202: 0.95, 203: 0.9, 204: 0.9, 205: 0.95, 206: 0.3333333333333333, 207: 0.7, 208: 0.85, 209: 1.0, 210: 1.0, 211: 0.85, 212: 0.8823529411764706, 213: 0.8, 214: 0.85, 215: 0.9, 216: 0.9, 217: 0.8, 218: 0.85, 219: 1.0, 220: 0.85, 221: 0.55, 222: 1.0, 223: 1.0, 224: 0.8, 225: 0.9}

2024-10-10 06:32:05,259 [INFO] [18] TRAIN  loss: 0.05086812230302636 acc: 0.9835418740224655
2024-10-10 06:32:05,259 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.05086812230302636}
2024-10-10 06:32:05,259 [INFO] [18] VALIDATION loss: 0.5582256337521185 VALIDATION  acc: 0.8741511996378452
2024-10-10 06:32:05,259 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 0.5582256337521185}
2024-10-10 06:32:05,259 [INFO] 
2024-10-10 06:33:15,031 [INFO] Step[50/938]: training loss : 0.04541320540010929 TRAIN  loss dict:  {'classification_loss': 0.04541320540010929}
2024-10-10 06:34:08,108 [INFO] Step[100/938]: training loss : 0.047407084428705275 TRAIN  loss dict:  {'classification_loss': 0.047407084428705275}
2024-10-10 06:35:01,198 [INFO] Step[150/938]: training loss : 0.05547301592305302 TRAIN  loss dict:  {'classification_loss': 0.05547301592305302}
2024-10-10 06:35:54,332 [INFO] Step[200/938]: training loss : 0.05489519192604348 TRAIN  loss dict:  {'classification_loss': 0.05489519192604348}
2024-10-10 06:36:47,426 [INFO] Step[250/938]: training loss : 0.05317576796282083 TRAIN  loss dict:  {'classification_loss': 0.05317576796282083}
2024-10-10 06:37:40,524 [INFO] Step[300/938]: training loss : 0.04192606702912599 TRAIN  loss dict:  {'classification_loss': 0.04192606702912599}
2024-10-10 06:38:33,582 [INFO] Step[350/938]: training loss : 0.05283654440427199 TRAIN  loss dict:  {'classification_loss': 0.05283654440427199}
2024-10-10 06:39:26,682 [INFO] Step[400/938]: training loss : 0.05596565765328705 TRAIN  loss dict:  {'classification_loss': 0.05596565765328705}
2024-10-10 06:40:19,887 [INFO] Step[450/938]: training loss : 0.05741015503997914 TRAIN  loss dict:  {'classification_loss': 0.05741015503997914}
2024-10-10 06:41:12,995 [INFO] Step[500/938]: training loss : 0.057006325065158306 TRAIN  loss dict:  {'classification_loss': 0.057006325065158306}
2024-10-10 06:42:06,088 [INFO] Step[550/938]: training loss : 0.060920118377543984 TRAIN  loss dict:  {'classification_loss': 0.060920118377543984}
2024-10-10 06:42:59,205 [INFO] Step[600/938]: training loss : 0.04615676885470748 TRAIN  loss dict:  {'classification_loss': 0.04615676885470748}
2024-10-10 06:43:52,303 [INFO] Step[650/938]: training loss : 0.07038332023657859 TRAIN  loss dict:  {'classification_loss': 0.07038332023657859}
2024-10-10 06:44:45,406 [INFO] Step[700/938]: training loss : 0.039807658458594235 TRAIN  loss dict:  {'classification_loss': 0.039807658458594235}
2024-10-10 06:45:38,556 [INFO] Step[750/938]: training loss : 0.045634916665730996 TRAIN  loss dict:  {'classification_loss': 0.045634916665730996}
2024-10-10 06:46:31,665 [INFO] Step[800/938]: training loss : 0.056636322806589305 TRAIN  loss dict:  {'classification_loss': 0.056636322806589305}
2024-10-10 06:47:24,753 [INFO] Step[850/938]: training loss : 0.047144509218633175 TRAIN  loss dict:  {'classification_loss': 0.047144509218633175}
2024-10-10 06:48:17,892 [INFO] Step[900/938]: training loss : 0.04112295635393821 TRAIN  loss dict:  {'classification_loss': 0.04112295635393821}
2024-10-10 06:50:42,345 [INFO] Label accuracies statistics:
2024-10-10 06:50:42,345 [INFO] {0: 0.85, 1: 0.9473684210526315, 2: 0.95, 3: 1.0, 4: 0.85, 5: 0.8, 6: 0.5384615384615384, 7: 0.85, 8: 1.0, 9: 0.6842105263157895, 10: 0.7894736842105263, 11: 1.0, 12: 0.8421052631578947, 13: 1.0, 14: 1.0, 15: 0.9, 16: 0.45, 17: 0.6666666666666666, 18: 0.8235294117647058, 19: 1.0, 20: 0.9473684210526315, 21: 1.0, 22: 0.8, 23: 0.75, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 0.95, 29: 1.0, 30: 0.9, 31: 1.0, 32: 1.0, 33: 0.95, 34: 0.9, 35: 1.0, 36: 0.8947368421052632, 37: 0.6, 38: 0.9, 39: 0.95, 40: 0.85, 41: 1.0, 42: 1.0, 43: 0.85, 44: 0.9473684210526315, 45: 0.85, 46: 0.95, 47: 0.4, 48: 0.7, 49: 0.8947368421052632, 50: 0.95, 51: 0.8888888888888888, 52: 0.7777777777777778, 53: 0.85, 54: 0.9, 55: 0.8421052631578947, 56: 1.0, 57: 1.0, 58: 1.0, 59: 0.8888888888888888, 60: 0.95, 61: 0.6842105263157895, 62: 0.8947368421052632, 63: 0.8947368421052632, 64: 1.0, 65: 0.75, 66: 1.0, 67: 0.85, 68: 0.6111111111111112, 69: 0.8888888888888888, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.9473684210526315, 74: 1.0, 75: 0.8, 76: 0.7894736842105263, 77: 1.0, 78: 0.75, 79: 0.9411764705882353, 80: 1.0, 81: 0.85, 82: 0.75, 83: 0.9, 84: 0.85, 85: 1.0, 86: 0.8, 87: 0.9411764705882353, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 0.8, 92: 0.9, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.35294117647058826, 97: 0.9, 98: 0.47368421052631576, 99: 0.95, 100: 1.0, 101: 0.95, 102: 1.0, 103: 0.9, 104: 0.65, 105: 1.0, 106: 1.0, 107: 0.65, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.7, 112: 1.0, 113: 1.0, 114: 0.95, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 1.0, 120: 0.8, 121: 0.9, 122: 0.45, 123: 0.75, 124: 0.9, 125: 0.85, 126: 0.8, 127: 0.45, 128: 0.85, 129: 0.9, 130: 1.0, 131: 0.8125, 132: 0.6842105263157895, 133: 1.0, 134: 0.7, 135: 0.7, 136: 0.95, 137: 0.8, 138: 0.85, 139: 0.9, 140: 0.9, 141: 1.0, 142: 0.75, 143: 0.9, 144: 1.0, 145: 0.9473684210526315, 146: 1.0, 147: 0.8, 148: 1.0, 149: 0.8421052631578947, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.75, 155: 0.9, 156: 0.8947368421052632, 157: 0.95, 158: 1.0, 159: 1.0, 160: 1.0, 161: 0.8, 162: 0.8, 163: 0.95, 164: 0.8947368421052632, 165: 0.7, 166: 0.55, 167: 0.95, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.4, 173: 0.75, 174: 1.0, 175: 0.7222222222222222, 176: 1.0, 177: 1.0, 178: 0.8, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.8, 184: 0.95, 185: 0.9, 186: 0.8, 187: 0.7894736842105263, 188: 1.0, 189: 1.0, 190: 0.85, 191: 1.0, 192: 0.95, 193: 1.0, 194: 0.8, 195: 0.8888888888888888, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 0.8421052631578947, 201: 1.0, 202: 1.0, 203: 0.9, 204: 1.0, 205: 0.85, 206: 0.4444444444444444, 207: 0.8, 208: 0.8, 209: 1.0, 210: 1.0, 211: 0.95, 212: 0.8823529411764706, 213: 0.9, 214: 0.9, 215: 0.9, 216: 0.9, 217: 0.95, 218: 0.85, 219: 1.0, 220: 1.0, 221: 0.7, 222: 1.0, 223: 1.0, 224: 0.85, 225: 0.9}

2024-10-10 06:50:42,392 [INFO] [19] TRAIN  loss: 0.05153331233689667 acc: 0.984003981231338
2024-10-10 06:50:42,392 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.05153331233689667}
2024-10-10 06:50:42,392 [INFO] [19] VALIDATION loss: 0.49018245202642974 VALIDATION  acc: 0.8836577636939792
2024-10-10 06:50:42,392 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 0.49018245202642974}
2024-10-10 06:50:42,392 [INFO] 
2024-10-10 06:51:52,351 [INFO] Step[50/938]: training loss : 0.043399135498329994 TRAIN  loss dict:  {'classification_loss': 0.043399135498329994}
2024-10-10 06:52:45,399 [INFO] Step[100/938]: training loss : 0.030202418151311576 TRAIN  loss dict:  {'classification_loss': 0.030202418151311576}
2024-10-10 06:53:38,560 [INFO] Step[150/938]: training loss : 0.04872799634700641 TRAIN  loss dict:  {'classification_loss': 0.04872799634700641}
2024-10-10 06:54:31,684 [INFO] Step[200/938]: training loss : 0.040190995971206574 TRAIN  loss dict:  {'classification_loss': 0.040190995971206574}
2024-10-10 06:55:24,806 [INFO] Step[250/938]: training loss : 0.05114164435537532 TRAIN  loss dict:  {'classification_loss': 0.05114164435537532}
2024-10-10 06:56:17,846 [INFO] Step[300/938]: training loss : 0.051636388641782105 TRAIN  loss dict:  {'classification_loss': 0.051636388641782105}
2024-10-10 06:57:10,917 [INFO] Step[350/938]: training loss : 0.04354172112653032 TRAIN  loss dict:  {'classification_loss': 0.04354172112653032}
2024-10-10 06:58:04,029 [INFO] Step[400/938]: training loss : 0.07591786818229593 TRAIN  loss dict:  {'classification_loss': 0.07591786818229593}
2024-10-10 06:58:57,120 [INFO] Step[450/938]: training loss : 0.040509221968241034 TRAIN  loss dict:  {'classification_loss': 0.040509221968241034}
2024-10-10 06:59:50,281 [INFO] Step[500/938]: training loss : 0.0472311655478552 TRAIN  loss dict:  {'classification_loss': 0.0472311655478552}
2024-10-10 07:00:43,320 [INFO] Step[550/938]: training loss : 0.03705250520724803 TRAIN  loss dict:  {'classification_loss': 0.03705250520724803}
2024-10-10 07:01:36,416 [INFO] Step[600/938]: training loss : 0.035017343061044814 TRAIN  loss dict:  {'classification_loss': 0.035017343061044814}
2024-10-10 07:02:29,507 [INFO] Step[650/938]: training loss : 0.04857819909462705 TRAIN  loss dict:  {'classification_loss': 0.04857819909462705}
2024-10-10 07:03:22,623 [INFO] Step[700/938]: training loss : 0.043217390151694415 TRAIN  loss dict:  {'classification_loss': 0.043217390151694415}
2024-10-10 07:04:15,783 [INFO] Step[750/938]: training loss : 0.04126471397001296 TRAIN  loss dict:  {'classification_loss': 0.04126471397001296}
2024-10-10 07:05:08,929 [INFO] Step[800/938]: training loss : 0.058589456654153764 TRAIN  loss dict:  {'classification_loss': 0.058589456654153764}
2024-10-10 07:06:02,023 [INFO] Step[850/938]: training loss : 0.04047717841807753 TRAIN  loss dict:  {'classification_loss': 0.04047717841807753}
2024-10-10 07:06:55,134 [INFO] Step[900/938]: training loss : 0.04627070763614029 TRAIN  loss dict:  {'classification_loss': 0.04627070763614029}
2024-10-10 07:09:19,715 [INFO] Label accuracies statistics:
2024-10-10 07:09:19,715 [INFO] {0: 0.75, 1: 0.6842105263157895, 2: 0.9, 3: 1.0, 4: 0.85, 5: 0.85, 6: 0.23076923076923078, 7: 0.95, 8: 0.9, 9: 0.631578947368421, 10: 0.8421052631578947, 11: 1.0, 12: 0.8947368421052632, 13: 0.9, 14: 0.95, 15: 0.9, 16: 0.3, 17: 0.5555555555555556, 18: 0.8235294117647058, 19: 1.0, 20: 1.0, 21: 0.8947368421052632, 22: 0.75, 23: 0.75, 24: 0.7368421052631579, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 1.0, 29: 1.0, 30: 0.85, 31: 1.0, 32: 0.95, 33: 1.0, 34: 0.55, 35: 0.95, 36: 1.0, 37: 0.95, 38: 0.9, 39: 0.95, 40: 0.95, 41: 1.0, 42: 1.0, 43: 0.85, 44: 0.9473684210526315, 45: 0.95, 46: 0.9, 47: 0.5, 48: 0.7, 49: 0.8947368421052632, 50: 1.0, 51: 0.8888888888888888, 52: 0.7777777777777778, 53: 0.65, 54: 0.8, 55: 0.8421052631578947, 56: 1.0, 57: 1.0, 58: 0.6875, 59: 0.9444444444444444, 60: 0.9, 61: 0.7894736842105263, 62: 0.5263157894736842, 63: 0.7368421052631579, 64: 0.9, 65: 0.9, 66: 1.0, 67: 0.65, 68: 0.8333333333333334, 69: 1.0, 70: 1.0, 71: 0.9, 72: 1.0, 73: 0.8947368421052632, 74: 1.0, 75: 0.6, 76: 0.9473684210526315, 77: 1.0, 78: 0.75, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.75, 83: 0.9, 84: 1.0, 85: 1.0, 86: 0.7, 87: 1.0, 88: 1.0, 89: 0.8823529411764706, 90: 0.8, 91: 1.0, 92: 0.95, 93: 0.9, 94: 1.0, 95: 0.8333333333333334, 96: 0.5882352941176471, 97: 0.8, 98: 0.5263157894736842, 99: 0.95, 100: 0.9, 101: 1.0, 102: 1.0, 103: 0.85, 104: 0.7, 105: 1.0, 106: 1.0, 107: 0.7, 108: 1.0, 109: 1.0, 110: 0.9, 111: 0.55, 112: 1.0, 113: 0.9, 114: 0.95, 115: 0.9411764705882353, 116: 1.0, 117: 0.9473684210526315, 118: 1.0, 119: 1.0, 120: 0.95, 121: 1.0, 122: 0.55, 123: 1.0, 124: 0.9, 125: 0.85, 126: 0.8, 127: 0.8, 128: 1.0, 129: 0.7, 130: 0.9, 131: 0.875, 132: 0.8421052631578947, 133: 1.0, 134: 0.85, 135: 0.7, 136: 1.0, 137: 0.75, 138: 0.9, 139: 0.9, 140: 0.9, 141: 1.0, 142: 0.9, 143: 0.85, 144: 0.9, 145: 0.9473684210526315, 146: 1.0, 147: 0.85, 148: 1.0, 149: 0.8947368421052632, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.8, 155: 0.9, 156: 0.8947368421052632, 157: 1.0, 158: 0.7647058823529411, 159: 1.0, 160: 1.0, 161: 0.8, 162: 0.75, 163: 1.0, 164: 0.6842105263157895, 165: 0.75, 166: 0.85, 167: 0.95, 168: 0.95, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.75, 173: 0.9, 174: 1.0, 175: 0.7222222222222222, 176: 1.0, 177: 1.0, 178: 0.45, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 0.8, 184: 0.9, 185: 0.85, 186: 0.75, 187: 0.8421052631578947, 188: 0.9, 189: 0.75, 190: 1.0, 191: 1.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.7222222222222222, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.95, 200: 1.0, 201: 1.0, 202: 1.0, 203: 0.9, 204: 0.95, 205: 0.85, 206: 0.3888888888888889, 207: 0.65, 208: 0.9, 209: 1.0, 210: 1.0, 211: 0.8, 212: 0.8235294117647058, 213: 1.0, 214: 0.95, 215: 0.9, 216: 0.9, 217: 1.0, 218: 0.9, 219: 1.0, 220: 0.95, 221: 0.65, 222: 1.0, 223: 1.0, 224: 0.75, 225: 0.95}

2024-10-10 07:09:19,761 [INFO] [20] TRAIN  loss: 0.04548512800252373 acc: 0.9850348357742074
2024-10-10 07:09:19,761 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.04548512800252373}
2024-10-10 07:09:19,761 [INFO] [20] VALIDATION loss: 0.5221213561083926 VALIDATION  acc: 0.8836577636939792
2024-10-10 07:09:19,761 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 0.5221213561083926}
2024-10-10 07:09:19,761 [INFO] 
2024-10-10 07:10:29,339 [INFO] Step[50/938]: training loss : 0.04197000260464847 TRAIN  loss dict:  {'classification_loss': 0.04197000260464847}
2024-10-10 07:11:22,400 [INFO] Step[100/938]: training loss : 0.03893500733189285 TRAIN  loss dict:  {'classification_loss': 0.03893500733189285}
2024-10-10 07:12:15,515 [INFO] Step[150/938]: training loss : 0.017053951260168107 TRAIN  loss dict:  {'classification_loss': 0.017053951260168107}
2024-10-10 07:13:08,625 [INFO] Step[200/938]: training loss : 0.027807048538234083 TRAIN  loss dict:  {'classification_loss': 0.027807048538234083}
2024-10-10 07:14:01,666 [INFO] Step[250/938]: training loss : 0.03681134682148695 TRAIN  loss dict:  {'classification_loss': 0.03681134682148695}
2024-10-10 07:14:54,755 [INFO] Step[300/938]: training loss : 0.05024821776663885 TRAIN  loss dict:  {'classification_loss': 0.05024821776663885}
2024-10-10 07:15:47,810 [INFO] Step[350/938]: training loss : 0.03740700517315418 TRAIN  loss dict:  {'classification_loss': 0.03740700517315418}
2024-10-10 07:16:40,840 [INFO] Step[400/938]: training loss : 0.04282905679952819 TRAIN  loss dict:  {'classification_loss': 0.04282905679952819}
2024-10-10 07:17:33,902 [INFO] Step[450/938]: training loss : 0.036357496454147625 TRAIN  loss dict:  {'classification_loss': 0.036357496454147625}
2024-10-10 07:18:27,072 [INFO] Step[500/938]: training loss : 0.031041016303934157 TRAIN  loss dict:  {'classification_loss': 0.031041016303934157}
2024-10-10 07:19:20,116 [INFO] Step[550/938]: training loss : 0.04483071143855341 TRAIN  loss dict:  {'classification_loss': 0.04483071143855341}
2024-10-10 07:20:13,205 [INFO] Step[600/938]: training loss : 0.03546408561989665 TRAIN  loss dict:  {'classification_loss': 0.03546408561989665}
2024-10-10 07:21:06,273 [INFO] Step[650/938]: training loss : 0.02579755916725844 TRAIN  loss dict:  {'classification_loss': 0.02579755916725844}
2024-10-10 07:21:59,427 [INFO] Step[700/938]: training loss : 0.030919946562498808 TRAIN  loss dict:  {'classification_loss': 0.030919946562498808}
2024-10-10 07:22:52,498 [INFO] Step[750/938]: training loss : 0.049533916544169186 TRAIN  loss dict:  {'classification_loss': 0.049533916544169186}
2024-10-10 07:23:45,583 [INFO] Step[800/938]: training loss : 0.034732254749978896 TRAIN  loss dict:  {'classification_loss': 0.034732254749978896}
2024-10-10 07:24:38,694 [INFO] Step[850/938]: training loss : 0.019839052442694082 TRAIN  loss dict:  {'classification_loss': 0.019839052442694082}
2024-10-10 07:25:31,776 [INFO] Step[900/938]: training loss : 0.03271142631303519 TRAIN  loss dict:  {'classification_loss': 0.03271142631303519}
2024-10-10 07:27:56,349 [INFO] Label accuracies statistics:
2024-10-10 07:27:56,349 [INFO] {0: 0.7, 1: 1.0, 2: 0.9, 3: 1.0, 4: 0.95, 5: 0.75, 6: 0.3076923076923077, 7: 0.9, 8: 1.0, 9: 0.6842105263157895, 10: 0.8421052631578947, 11: 0.95, 12: 0.8421052631578947, 13: 0.7, 14: 1.0, 15: 0.9, 16: 0.2, 17: 0.8333333333333334, 18: 0.8235294117647058, 19: 0.8421052631578947, 20: 1.0, 21: 1.0, 22: 0.9, 23: 0.9, 24: 0.6842105263157895, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 1.0, 29: 1.0, 30: 0.9, 31: 1.0, 32: 0.95, 33: 0.95, 34: 0.8, 35: 1.0, 36: 1.0, 37: 0.65, 38: 0.9, 39: 0.9, 40: 1.0, 41: 0.85, 42: 0.85, 43: 0.85, 44: 0.9473684210526315, 45: 0.9, 46: 0.9, 47: 0.4, 48: 0.9, 49: 1.0, 50: 1.0, 51: 0.8888888888888888, 52: 0.7777777777777778, 53: 0.8, 54: 1.0, 55: 0.8421052631578947, 56: 1.0, 57: 1.0, 58: 0.875, 59: 0.7222222222222222, 60: 0.95, 61: 0.7368421052631579, 62: 0.7368421052631579, 63: 0.8947368421052632, 64: 1.0, 65: 0.8, 66: 1.0, 67: 0.9, 68: 0.5, 69: 0.8888888888888888, 70: 1.0, 71: 1.0, 72: 0.9473684210526315, 73: 0.8947368421052632, 74: 1.0, 75: 0.85, 76: 0.8947368421052632, 77: 1.0, 78: 0.75, 79: 1.0, 80: 1.0, 81: 0.95, 82: 0.8, 83: 0.9, 84: 0.85, 85: 1.0, 86: 0.7, 87: 1.0, 88: 0.85, 89: 0.8823529411764706, 90: 0.6, 91: 0.65, 92: 0.95, 93: 1.0, 94: 0.9473684210526315, 95: 1.0, 96: 0.35294117647058826, 97: 0.55, 98: 0.42105263157894735, 99: 0.95, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.8, 104: 0.8, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.9, 109: 0.9, 110: 1.0, 111: 0.8, 112: 1.0, 113: 1.0, 114: 0.95, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 1.0, 121: 0.9, 122: 0.55, 123: 1.0, 124: 0.9, 125: 0.85, 126: 0.6, 127: 0.7, 128: 0.95, 129: 0.8, 130: 1.0, 131: 0.8125, 132: 0.9473684210526315, 133: 1.0, 134: 0.9, 135: 0.7, 136: 0.85, 137: 0.85, 138: 0.85, 139: 1.0, 140: 0.85, 141: 1.0, 142: 0.75, 143: 0.95, 144: 0.95, 145: 0.8947368421052632, 146: 1.0, 147: 0.65, 148: 0.95, 149: 0.8421052631578947, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 0.65, 155: 0.9, 156: 0.8947368421052632, 157: 0.85, 158: 0.7058823529411765, 159: 1.0, 160: 1.0, 161: 1.0, 162: 0.9, 163: 1.0, 164: 0.9473684210526315, 165: 0.7, 166: 0.6, 167: 0.95, 168: 0.9, 169: 1.0, 170: 1.0, 171: 0.95, 172: 0.75, 173: 0.85, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 0.95, 178: 0.7, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.9, 183: 0.7, 184: 1.0, 185: 0.95, 186: 0.8, 187: 0.6842105263157895, 188: 1.0, 189: 0.8, 190: 0.9, 191: 1.0, 192: 1.0, 193: 1.0, 194: 0.9, 195: 0.8333333333333334, 196: 1.0, 197: 0.95, 198: 1.0, 199: 1.0, 200: 0.9473684210526315, 201: 1.0, 202: 1.0, 203: 0.9, 204: 0.9, 205: 0.9, 206: 0.5, 207: 0.8, 208: 1.0, 209: 1.0, 210: 0.95, 211: 0.9, 212: 0.8823529411764706, 213: 0.9, 214: 0.95, 215: 0.9, 216: 0.9, 217: 0.85, 218: 0.85, 219: 1.0, 220: 1.0, 221: 0.6, 222: 1.0, 223: 1.0, 224: 0.95, 225: 0.75}

2024-10-10 07:27:56,397 [INFO] [21] TRAIN  loss: 0.03523688626182484 acc: 0.9896559078629319
2024-10-10 07:27:56,397 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.03523688626182484}
2024-10-10 07:27:56,397 [INFO] [21] VALIDATION loss: 0.5268291171209106 VALIDATION  acc: 0.8841104572204618
2024-10-10 07:27:56,397 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 0.5268291171209106}
2024-10-10 07:27:56,397 [INFO] 
2024-10-10 07:29:06,036 [INFO] Step[50/938]: training loss : 0.03825502371648327 TRAIN  loss dict:  {'classification_loss': 0.03825502371648327}
2024-10-10 07:29:59,129 [INFO] Step[100/938]: training loss : 0.03859816094860435 TRAIN  loss dict:  {'classification_loss': 0.03859816094860435}
2024-10-10 07:30:52,168 [INFO] Step[150/938]: training loss : 0.030824582377681507 TRAIN  loss dict:  {'classification_loss': 0.030824582377681507}
2024-10-10 07:31:45,241 [INFO] Step[200/938]: training loss : 0.03080999632831663 TRAIN  loss dict:  {'classification_loss': 0.03080999632831663}
2024-10-10 07:32:38,356 [INFO] Step[250/938]: training loss : 0.031021463288925587 TRAIN  loss dict:  {'classification_loss': 0.031021463288925587}
2024-10-10 07:33:31,503 [INFO] Step[300/938]: training loss : 0.03932937521429267 TRAIN  loss dict:  {'classification_loss': 0.03932937521429267}
2024-10-10 07:34:24,613 [INFO] Step[350/938]: training loss : 0.03903440269175917 TRAIN  loss dict:  {'classification_loss': 0.03903440269175917}
2024-10-10 07:35:17,692 [INFO] Step[400/938]: training loss : 0.026703144835773854 TRAIN  loss dict:  {'classification_loss': 0.026703144835773854}
2024-10-10 07:36:10,810 [INFO] Step[450/938]: training loss : 0.02665073039359413 TRAIN  loss dict:  {'classification_loss': 0.02665073039359413}
2024-10-10 07:37:03,925 [INFO] Step[500/938]: training loss : 0.030414279235992582 TRAIN  loss dict:  {'classification_loss': 0.030414279235992582}
2024-10-10 07:37:57,040 [INFO] Step[550/938]: training loss : 0.033921607478987426 TRAIN  loss dict:  {'classification_loss': 0.033921607478987426}
2024-10-10 07:38:50,179 [INFO] Step[600/938]: training loss : 0.0292528094118461 TRAIN  loss dict:  {'classification_loss': 0.0292528094118461}
2024-10-10 07:39:43,282 [INFO] Step[650/938]: training loss : 0.039361317796865476 TRAIN  loss dict:  {'classification_loss': 0.039361317796865476}
2024-10-10 07:40:36,371 [INFO] Step[700/938]: training loss : 0.03893357733963057 TRAIN  loss dict:  {'classification_loss': 0.03893357733963057}
2024-10-10 07:41:29,457 [INFO] Step[750/938]: training loss : 0.031514412795659155 TRAIN  loss dict:  {'classification_loss': 0.031514412795659155}
2024-10-10 07:42:22,551 [INFO] Step[800/938]: training loss : 0.03414609301369637 TRAIN  loss dict:  {'classification_loss': 0.03414609301369637}
2024-10-10 07:43:15,632 [INFO] Step[850/938]: training loss : 0.027349640666507184 TRAIN  loss dict:  {'classification_loss': 0.027349640666507184}
2024-10-10 07:44:08,751 [INFO] Step[900/938]: training loss : 0.02660712886136025 TRAIN  loss dict:  {'classification_loss': 0.02660712886136025}
2024-10-10 07:46:33,476 [INFO] Label accuracies statistics:
2024-10-10 07:46:33,476 [INFO] {0: 0.8, 1: 0.9473684210526315, 2: 0.9, 3: 1.0, 4: 0.95, 5: 0.75, 6: 0.38461538461538464, 7: 0.85, 8: 1.0, 9: 1.0, 10: 1.0, 11: 0.95, 12: 0.7894736842105263, 13: 0.9, 14: 1.0, 15: 0.9, 16: 0.2, 17: 0.6111111111111112, 18: 0.8235294117647058, 19: 0.9473684210526315, 20: 1.0, 21: 0.8947368421052632, 22: 0.8, 23: 0.85, 24: 0.8421052631578947, 25: 1.0, 26: 0.8947368421052632, 27: 0.95, 28: 1.0, 29: 1.0, 30: 0.9, 31: 1.0, 32: 1.0, 33: 0.95, 34: 1.0, 35: 1.0, 36: 1.0, 37: 0.75, 38: 0.9, 39: 0.95, 40: 1.0, 41: 0.9, 42: 0.9, 43: 0.8, 44: 1.0, 45: 0.95, 46: 0.9, 47: 0.3, 48: 0.8, 49: 0.8947368421052632, 50: 1.0, 51: 0.8333333333333334, 52: 0.7222222222222222, 53: 0.75, 54: 0.9, 55: 0.8421052631578947, 56: 1.0, 57: 1.0, 58: 0.8125, 59: 0.7222222222222222, 60: 0.95, 61: 0.6842105263157895, 62: 0.6842105263157895, 63: 0.8421052631578947, 64: 0.9, 65: 0.85, 66: 1.0, 67: 1.0, 68: 0.5, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.7894736842105263, 74: 1.0, 75: 0.65, 76: 0.8947368421052632, 77: 1.0, 78: 0.8, 79: 0.9411764705882353, 80: 1.0, 81: 0.95, 82: 0.75, 83: 0.95, 84: 0.75, 85: 1.0, 86: 0.8, 87: 1.0, 88: 0.95, 89: 0.8823529411764706, 90: 0.85, 91: 0.75, 92: 1.0, 93: 0.95, 94: 1.0, 95: 1.0, 96: 0.5294117647058824, 97: 0.55, 98: 0.5263157894736842, 99: 0.85, 100: 0.95, 101: 1.0, 102: 1.0, 103: 0.85, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.7, 108: 1.0, 109: 1.0, 110: 0.95, 111: 0.55, 112: 1.0, 113: 0.9, 114: 0.95, 115: 1.0, 116: 1.0, 117: 0.8947368421052632, 118: 1.0, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.6, 123: 1.0, 124: 0.9, 125: 0.7, 126: 0.55, 127: 0.5, 128: 0.85, 129: 0.8, 130: 1.0, 131: 0.9375, 132: 0.9473684210526315, 133: 1.0, 134: 0.8, 135: 0.9, 136: 0.95, 137: 0.75, 138: 0.9, 139: 1.0, 140: 0.85, 141: 1.0, 142: 0.85, 143: 0.8, 144: 0.8, 145: 0.8947368421052632, 146: 0.9, 147: 0.75, 148: 1.0, 149: 0.8947368421052632, 150: 0.8, 151: 1.0, 152: 1.0, 153: 0.9, 154: 0.8, 155: 1.0, 156: 0.9473684210526315, 157: 0.9, 158: 0.7647058823529411, 159: 1.0, 160: 1.0, 161: 0.8, 162: 0.9, 163: 0.95, 164: 0.8947368421052632, 165: 0.5, 166: 0.75, 167: 0.95, 168: 0.9, 169: 1.0, 170: 1.0, 171: 1.0, 172: 0.8, 173: 0.7, 174: 1.0, 175: 0.8333333333333334, 176: 1.0, 177: 1.0, 178: 0.65, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.85, 183: 0.75, 184: 1.0, 185: 0.95, 186: 0.8, 187: 0.9473684210526315, 188: 1.0, 189: 1.0, 190: 0.85, 191: 0.95, 192: 1.0, 193: 1.0, 194: 0.95, 195: 0.7222222222222222, 196: 1.0, 197: 1.0, 198: 1.0, 199: 1.0, 200: 1.0, 201: 1.0, 202: 1.0, 203: 0.85, 204: 0.95, 205: 0.95, 206: 0.3333333333333333, 207: 0.85, 208: 1.0, 209: 0.95, 210: 0.95, 211: 0.95, 212: 0.8235294117647058, 213: 0.95, 214: 0.85, 215: 0.9, 216: 0.95, 217: 0.85, 218: 0.9, 219: 1.0, 220: 0.95, 221: 0.7, 222: 1.0, 223: 1.0, 224: 1.0, 225: 0.85}

2024-10-10 07:46:33,523 [INFO] [22] TRAIN  loss: 0.033038832736034036 acc: 0.9899758282383051
2024-10-10 07:46:33,523 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.033038832736034036}
2024-10-10 07:46:33,523 [INFO] [22] VALIDATION loss: 0.5395958325660448 VALIDATION  acc: 0.8863739248528746
2024-10-10 07:46:33,523 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 0.5395958325660448}
2024-10-10 07:46:33,523 [INFO] 
2024-10-10 07:46:33,523 [INFO] 

***Stop training***


2024-10-10 07:46:33,524 [INFO] 
Testing checkpointed models starting...

2024-10-10 07:48:05,112 [INFO] Label accuracies statistics:
2024-10-10 07:48:05,112 [INFO] {0: 0.875, 1: 0.75, 2: 0.9411764705882353, 3: 1.0, 4: 1.0, 5: 0.8235294117647058, 6: 0.6470588235294118, 7: 0.5294117647058824, 8: 0.7058823529411765, 9: 0.8823529411764706, 10: 0.6470588235294118, 11: 1.0, 12: 0.9333333333333333, 13: 0.5, 14: 0.9411764705882353, 15: 1.0, 16: 1.0, 17: 0.8125, 18: 0.8235294117647058, 19: 1.0, 20: 0.9375, 21: 0.9411764705882353, 22: 0.8823529411764706, 23: 1.0, 24: 0.75, 25: 0.875, 26: 1.0, 27: 0.7058823529411765, 28: 1.0, 29: 0.9411764705882353, 30: 0.7058823529411765, 31: 1.0, 32: 0.8235294117647058, 33: 0.8235294117647058, 34: 0.8823529411764706, 35: 1.0, 36: 1.0, 37: 0.8823529411764706, 38: 0.7647058823529411, 39: 0.875, 40: 0.5294117647058824, 41: 1.0, 42: 0.7647058823529411, 43: 0.8823529411764706, 44: 0.9411764705882353, 45: 0.8235294117647058, 46: 1.0, 47: 0.9285714285714286, 48: 0.9411764705882353, 49: 0.8235294117647058, 50: 0.8666666666666667, 51: 0.75, 52: 0.2, 53: 0.5882352941176471, 54: 1.0, 55: 1.0, 56: 0.9375, 57: 0.9375, 58: 1.0, 59: 0.8823529411764706, 60: 1.0, 61: 0.8823529411764706, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.9333333333333333, 66: 1.0, 67: 0.8, 68: 0.875, 69: 0.9333333333333333, 70: 1.0, 71: 0.6875, 72: 0.6875, 73: 0.8823529411764706, 74: 1.0, 75: 0.9375, 76: 0.7647058823529411, 77: 1.0, 78: 0.9411764705882353, 79: 0.6363636363636364, 80: 1.0, 81: 0.8823529411764706, 82: 0.9411764705882353, 83: 1.0, 84: 0.7647058823529411, 85: 0.9411764705882353, 86: 0.8823529411764706, 87: 1.0, 88: 1.0, 89: 0.6470588235294118, 90: 0.7647058823529411, 91: 0.8235294117647058, 92: 0.9411764705882353, 93: 0.8823529411764706, 94: 1.0, 95: 1.0, 96: 0.8823529411764706, 97: 0.5882352941176471, 98: 0.75, 99: 0.8235294117647058, 100: 0.5294117647058824, 101: 0.7058823529411765, 102: 0.9411764705882353, 103: 0.6875, 104: 0.8235294117647058, 105: 1.0, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.6470588235294118, 110: 1.0, 111: 0.7647058823529411, 112: 1.0, 113: 0.8235294117647058, 114: 0.9411764705882353, 115: 0.9375, 116: 0.9411764705882353, 117: 0.7857142857142857, 118: 1.0, 119: 1.0, 120: 0.8235294117647058, 121: 0.8823529411764706, 122: 0.5294117647058824, 123: 0.9411764705882353, 124: 0.8823529411764706, 125: 1.0, 126: 0.875, 127: 0.7647058823529411, 128: 0.6470588235294118, 129: 0.6470588235294118, 130: 1.0, 131: 0.35714285714285715, 132: 0.9333333333333333, 133: 1.0, 134: 0.7647058823529411, 135: 0.9411764705882353, 136: 0.875, 137: 0.6470588235294118, 138: 1.0, 139: 0.8823529411764706, 140: 0.9411764705882353, 141: 1.0, 142: 0.6470588235294118, 143: 1.0, 144: 0.47058823529411764, 145: 1.0, 146: 0.9411764705882353, 147: 0.4117647058823529, 148: 0.7058823529411765, 149: 0.9411764705882353, 150: 0.625, 151: 1.0, 152: 1.0, 153: 0.9411764705882353, 154: 0.7058823529411765, 155: 0.9411764705882353, 156: 0.7647058823529411, 157: 1.0, 158: 1.0, 159: 1.0, 160: 1.0, 161: 0.7647058823529411, 162: 0.7058823529411765, 163: 0.7058823529411765, 164: 0.7647058823529411, 165: 0.8823529411764706, 166: 0.5882352941176471, 167: 0.9375, 168: 0.8823529411764706, 169: 0.8823529411764706, 170: 1.0, 171: 1.0, 172: 0.8181818181818182, 173: 0.7058823529411765, 174: 0.8235294117647058, 175: 0.5294117647058824, 176: 0.6, 177: 1.0, 178: 0.9411764705882353, 179: 1.0, 180: 1.0, 181: 0.8823529411764706, 182: 0.8125, 183: 1.0, 184: 1.0, 185: 0.8823529411764706, 186: 0.5625, 187: 0.8823529411764706, 188: 0.8823529411764706, 189: 1.0, 190: 0.8235294117647058, 191: 1.0, 192: 0.7058823529411765, 193: 1.0, 194: 0.9411764705882353, 195: 0.8, 196: 1.0, 197: 1.0, 198: 1.0, 199: 0.6470588235294118, 200: 1.0, 201: 1.0, 202: 0.875, 203: 1.0, 204: 0.7647058823529411, 205: 0.7058823529411765, 206: 0.7857142857142857, 207: 0.7058823529411765, 208: 1.0, 209: 0.7647058823529411, 210: 0.9411764705882353, 211: 0.9285714285714286, 212: 0.8823529411764706, 213: 0.8823529411764706, 214: 0.8235294117647058, 215: 1.0, 216: 0.8823529411764706, 217: 0.5294117647058824, 218: 1.0, 219: 0.9411764705882353, 220: 0.9411764705882353, 221: 0.7058823529411765, 222: 1.0, 223: 0.8823529411764706, 224: 0.8823529411764706, 225: 0.8823529411764706}

2024-10-10 07:48:05,234 [INFO] 
Testing accuracy: 0.8628708901363272
