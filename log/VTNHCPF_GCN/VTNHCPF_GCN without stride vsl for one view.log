2024-10-08 15:59:27,326 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN without stride vsl for one view...


2024-10-08 16:02:37,859 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN without stride vsl for one view...


2024-10-08 16:03:59,383 [INFO] Step[50/144]: training loss : 5.478492231369018 TRAIN  loss dict:  {'classification_loss': 5.478492231369018}
2024-10-08 16:04:53,446 [INFO] Step[100/144]: training loss : 5.4315144729614255 TRAIN  loss dict:  {'classification_loss': 5.4315144729614255}
2024-10-08 16:06:35,085 [INFO] Label accuracies statistics:
2024-10-08 16:06:35,085 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.5, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.25, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.25, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.25, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 16:06:35,465 [INFO] [1] TRAIN  loss: 5.428055581119326 acc: 0.005560704355885079
2024-10-08 16:06:35,465 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.428055581119326}
2024-10-08 16:06:35,465 [INFO] [1] VALIDATION loss: 5.284452456015128 VALIDATION  acc: 0.006313131313131313
2024-10-08 16:06:35,465 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.284452456015128}
2024-10-08 16:06:35,466 [INFO] 
2024-10-08 16:07:52,435 [INFO] Step[50/144]: training loss : 5.287354173660279 TRAIN  loss dict:  {'classification_loss': 5.287354173660279}
2024-10-08 16:08:46,511 [INFO] Step[100/144]: training loss : 5.170060997009277 TRAIN  loss dict:  {'classification_loss': 5.170060997009277}
2024-10-08 16:10:22,090 [INFO] Label accuracies statistics:
2024-10-08 16:10:22,090 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.25, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.5, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.25, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.25, 107: 0.0, 108: 0.5, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.25, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.25, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.75, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.5, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 16:10:22,632 [INFO] [2] TRAIN  loss: 5.162970764769448 acc: 0.012743280815569972
2024-10-08 16:10:22,632 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.162970764769448}
2024-10-08 16:10:22,632 [INFO] [2] VALIDATION loss: 5.011310595053214 VALIDATION  acc: 0.01893939393939394
2024-10-08 16:10:22,632 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 5.011310595053214}
2024-10-08 16:10:22,632 [INFO] 
2024-10-08 16:11:40,477 [INFO] Step[50/144]: training loss : 4.74031816482544 TRAIN  loss dict:  {'classification_loss': 4.74031816482544}
2024-10-08 16:12:34,857 [INFO] Step[100/144]: training loss : 4.598737554550171 TRAIN  loss dict:  {'classification_loss': 4.598737554550171}
2024-10-08 16:14:14,045 [INFO] Label accuracies statistics:
2024-10-08 16:14:14,045 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.5, 8: 0.0, 9: 0.25, 10: 0.25, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.25, 27: 0.0, 28: 0.0, 29: 0.25, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.25, 34: 0.0, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.25, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.25, 92: 0.0, 93: 0.25, 94: 0.5, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.25, 103: 0.0, 104: 0.0, 105: 1.0, 106: 0.0, 107: 0.5, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.5, 126: 0.0, 127: 0.0, 128: 0.25, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 1.0, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.5, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.5, 152: 0.5, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 1.0, 178: 0.25, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.75, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.5, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.25, 195: 0.0, 196: 0.0, 197: 0.25, 198: 0.0}

2024-10-08 16:14:14,615 [INFO] [3] TRAIN  loss: 4.587993439700869 acc: 0.04286376274328082
2024-10-08 16:14:14,616 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.587993439700869}
2024-10-08 16:14:14,616 [INFO] [3] VALIDATION loss: 4.257736771195023 VALIDATION  acc: 0.0946969696969697
2024-10-08 16:14:14,616 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.257736771195023}
2024-10-08 16:14:14,616 [INFO] 
2024-10-08 16:15:30,999 [INFO] Step[50/144]: training loss : 4.0040851354599 TRAIN  loss dict:  {'classification_loss': 4.0040851354599}
2024-10-08 16:16:25,945 [INFO] Step[100/144]: training loss : 3.763725175857544 TRAIN  loss dict:  {'classification_loss': 3.763725175857544}
2024-10-08 16:18:02,313 [INFO] Label accuracies statistics:
2024-10-08 16:18:02,313 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.0, 5: 0.0, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.0, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.0, 21: 0.0, 22: 0.25, 23: 0.75, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.25, 28: 0.0, 29: 0.75, 30: 0.25, 31: 0.0, 32: 0.75, 33: 0.25, 34: 0.75, 35: 0.0, 36: 0.0, 37: 0.25, 38: 0.5, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.25, 45: 0.0, 46: 1.0, 47: 0.25, 48: 1.0, 49: 0.75, 50: 0.25, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.75, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.75, 62: 0.0, 63: 0.25, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.25, 71: 0.0, 72: 0.25, 73: 0.0, 74: 0.25, 75: 0.25, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.5, 93: 0.75, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.25, 105: 0.75, 106: 0.0, 107: 0.0, 108: 0.25, 109: 0.0, 110: 0.25, 111: 0.25, 112: 0.0, 113: 0.25, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.5, 118: 0.5, 119: 0.75, 120: 0.25, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.5, 126: 0.25, 127: 0.0, 128: 0.5, 129: 0.75, 130: 0.0, 131: 0.0, 132: 0.25, 133: 0.0, 134: 0.0, 135: 0.75, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.5, 140: 0.75, 141: 0.5, 142: 0.25, 143: 0.0, 144: 0.0, 145: 0.25, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.75, 150: 0.0, 151: 0.5, 152: 0.75, 153: 1.0, 154: 0.75, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.5, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.25, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.25, 174: 0.25, 175: 0.5, 176: 0.0, 177: 0.5, 178: 0.0, 179: 0.6666666666666666, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.75, 186: 0.0, 187: 0.25, 188: 0.75, 189: 0.0, 190: 0.0, 191: 0.0, 192: 1.0, 193: 0.0, 194: 0.75, 195: 0.25, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 16:18:02,920 [INFO] [4] TRAIN  loss: 3.788791634970241 acc: 0.13994439295644115
2024-10-08 16:18:02,921 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.788791634970241}
2024-10-08 16:18:02,921 [INFO] [4] VALIDATION loss: 3.3740031630904586 VALIDATION  acc: 0.22727272727272727
2024-10-08 16:18:02,921 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.3740031630904586}
2024-10-08 16:18:02,921 [INFO] 
2024-10-08 16:19:34,643 [INFO] Step[50/144]: training loss : 3.1533082342147827 TRAIN  loss dict:  {'classification_loss': 3.1533082342147827}
2024-10-08 16:20:31,361 [INFO] Step[100/144]: training loss : 2.9834563541412353 TRAIN  loss dict:  {'classification_loss': 2.9834563541412353}
2024-10-08 16:22:35,746 [INFO] Label accuracies statistics:
2024-10-08 16:22:35,746 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.0, 8: 0.25, 9: 0.0, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.5, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.25, 24: 0.0, 25: 0.5, 26: 0.25, 27: 0.25, 28: 0.25, 29: 1.0, 30: 0.0, 31: 0.5, 32: 0.25, 33: 0.5, 34: 1.0, 35: 0.25, 36: 0.0, 37: 0.75, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 0.75, 47: 0.25, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.5, 57: 0.75, 58: 0.0, 59: 0.25, 60: 0.25, 61: 1.0, 62: 0.25, 63: 0.25, 64: 0.0, 65: 0.5, 66: 0.25, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.25, 73: 0.25, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.0, 78: 0.75, 79: 0.0, 80: 0.5, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.75, 88: 0.0, 89: 0.25, 90: 0.0, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.6, 100: 0.5, 101: 0.0, 102: 0.75, 103: 0.0, 104: 0.5, 105: 1.0, 106: 0.0, 107: 0.0, 108: 0.5, 109: 0.25, 110: 0.25, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.25, 115: 0.25, 116: 0.0, 117: 0.5, 118: 1.0, 119: 0.0, 120: 0.25, 121: 0.0, 122: 0.75, 123: 0.25, 124: 0.25, 125: 0.25, 126: 0.75, 127: 0.25, 128: 0.75, 129: 0.75, 130: 0.25, 131: 0.25, 132: 0.25, 133: 0.25, 134: 0.5, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.25, 139: 0.5, 140: 0.0, 141: 0.5, 142: 0.75, 143: 0.5, 144: 0.5, 145: 0.25, 146: 0.75, 147: 0.75, 148: 0.25, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 0.25, 155: 0.0, 156: 0.0, 157: 0.25, 158: 0.0, 159: 0.5, 160: 0.0, 161: 0.25, 162: 0.25, 163: 0.0, 164: 0.0, 165: 0.25, 166: 0.0, 167: 0.0, 168: 0.75, 169: 0.25, 170: 0.25, 171: 0.5, 172: 0.0, 173: 0.0, 174: 0.25, 175: 0.25, 176: 0.5, 177: 1.0, 178: 0.5, 179: 0.6666666666666666, 180: 0.5, 181: 0.0, 182: 0.0, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.5, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.0, 194: 0.25, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-08 16:22:36,448 [INFO] [5] TRAIN  loss: 3.006676435470581 acc: 0.2715477293790547
2024-10-08 16:22:36,448 [INFO] [5] TRAIN  loss dict: {'classification_loss': 3.006676435470581}
2024-10-08 16:22:36,448 [INFO] [5] VALIDATION loss: 2.709480572629858 VALIDATION  acc: 0.3522727272727273
2024-10-08 16:22:36,449 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.709480572629858}
2024-10-08 16:22:36,449 [INFO] 
2024-10-08 16:24:11,668 [INFO] Step[50/144]: training loss : 2.467266488075256 TRAIN  loss dict:  {'classification_loss': 2.467266488075256}
2024-10-08 16:25:21,768 [INFO] Step[100/144]: training loss : 2.349311201572418 TRAIN  loss dict:  {'classification_loss': 2.349311201572418}
2024-10-08 16:27:25,121 [INFO] Label accuracies statistics:
2024-10-08 16:27:25,121 [INFO] {0: 0.0, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.5, 18: 0.5, 19: 0.25, 20: 0.0, 21: 0.25, 22: 0.75, 23: 0.25, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.5, 33: 0.5, 34: 0.25, 35: 0.0, 36: 0.25, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 0.75, 47: 0.0, 48: 1.0, 49: 0.25, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.75, 54: 0.0, 55: 0.0, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.5, 63: 0.25, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.5, 73: 0.75, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.25, 78: 0.75, 79: 0.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.75, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.6, 100: 0.75, 101: 0.5, 102: 0.25, 103: 0.5, 104: 0.5, 105: 0.75, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.5, 110: 0.5, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.5, 116: 0.25, 117: 0.75, 118: 0.75, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.5, 125: 0.5, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.0, 130: 0.25, 131: 0.5, 132: 0.25, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 1.0, 146: 0.75, 147: 0.5, 148: 0.75, 149: 0.75, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.25, 157: 0.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.0, 161: 0.5, 162: 0.75, 163: 0.0, 164: 0.25, 165: 0.75, 166: 0.0, 167: 0.25, 168: 0.25, 169: 0.0, 170: 0.25, 171: 0.25, 172: 0.0, 173: 0.75, 174: 0.5, 175: 0.25, 176: 0.0, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.25, 181: 0.5, 182: 0.0, 183: 0.75, 184: 0.0, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.5, 197: 1.0, 198: 0.0}

2024-10-08 16:27:25,781 [INFO] [6] TRAIN  loss: 2.3845424776275954 acc: 0.4040778498609824
2024-10-08 16:27:25,781 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.3845424776275954}
2024-10-08 16:27:25,781 [INFO] [6] VALIDATION loss: 2.2907965933835066 VALIDATION  acc: 0.4393939393939394
2024-10-08 16:27:25,781 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.2907965933835066}
2024-10-08 16:27:25,781 [INFO] 
2024-10-08 16:29:02,829 [INFO] Step[50/144]: training loss : 2.0043135404586794 TRAIN  loss dict:  {'classification_loss': 2.0043135404586794}
2024-10-08 16:30:14,456 [INFO] Step[100/144]: training loss : 1.8464854168891907 TRAIN  loss dict:  {'classification_loss': 1.8464854168891907}
2024-10-08 16:32:20,135 [INFO] Label accuracies statistics:
2024-10-08 16:32:20,136 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.25, 25: 0.5, 26: 0.5, 27: 0.0, 28: 0.5, 29: 0.5, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.5, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.25, 43: 0.25, 44: 0.5, 45: 0.25, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.0, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.0, 54: 0.0, 55: 0.75, 56: 0.25, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.5, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.25, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.25, 85: 0.0, 86: 0.75, 87: 0.25, 88: 0.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.25, 99: 0.6, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.5, 104: 0.5, 105: 0.75, 106: 0.75, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.0, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.5, 130: 0.5, 131: 0.5, 132: 0.0, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.75, 138: 0.25, 139: 1.0, 140: 0.5, 141: 0.0, 142: 0.75, 143: 0.25, 144: 0.25, 145: 0.5, 146: 0.5, 147: 0.75, 148: 1.0, 149: 0.5, 150: 0.0, 151: 0.5, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.0, 157: 0.5, 158: 0.0, 159: 0.75, 160: 0.25, 161: 0.25, 162: 0.75, 163: 0.0, 164: 0.5, 165: 0.0, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.25, 170: 0.5, 171: 0.0, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.5, 178: 0.5, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.0, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.5, 198: 0.0}

2024-10-08 16:32:20,815 [INFO] [7] TRAIN  loss: 1.892038153277503 acc: 0.5236329935125116
2024-10-08 16:32:20,815 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.892038153277503}
2024-10-08 16:32:20,815 [INFO] [7] VALIDATION loss: 1.9410640729798212 VALIDATION  acc: 0.48358585858585856
2024-10-08 16:32:20,815 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.9410640729798212}
2024-10-08 16:32:20,816 [INFO] 
2024-10-08 16:33:59,382 [INFO] Step[50/144]: training loss : 1.565545859336853 TRAIN  loss dict:  {'classification_loss': 1.565545859336853}
2024-10-08 16:35:10,354 [INFO] Step[100/144]: training loss : 1.5001838684082032 TRAIN  loss dict:  {'classification_loss': 1.5001838684082032}
2024-10-08 16:37:16,561 [INFO] Label accuracies statistics:
2024-10-08 16:37:16,561 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.25, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.5, 37: 0.75, 38: 1.0, 39: 0.5, 40: 0.75, 41: 0.25, 42: 0.25, 43: 0.0, 44: 0.75, 45: 0.25, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.0, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.5, 63: 0.5, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.5, 69: 0.25, 70: 0.25, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 0.25, 104: 0.5, 105: 0.5, 106: 0.75, 107: 1.0, 108: 0.75, 109: 0.5, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.0, 122: 0.25, 123: 0.75, 124: 0.75, 125: 0.5, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.5, 131: 1.0, 132: 0.0, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.25, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.0, 144: 0.75, 145: 0.5, 146: 0.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.25, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.75, 165: 0.5, 166: 0.0, 167: 0.0, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.0, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.25, 176: 0.0, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.5, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.25, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.0, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-08 16:37:17,261 [INFO] [8] TRAIN  loss: 1.5229714040954907 acc: 0.6068118628359592
2024-10-08 16:37:17,261 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.5229714040954907}
2024-10-08 16:37:17,262 [INFO] [8] VALIDATION loss: 1.7580986111252397 VALIDATION  acc: 0.5492424242424242
2024-10-08 16:37:17,262 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.7580986111252397}
2024-10-08 16:37:17,262 [INFO] 
2024-10-08 16:38:56,441 [INFO] Step[50/144]: training loss : 1.2474172496795655 TRAIN  loss dict:  {'classification_loss': 1.2474172496795655}
2024-10-08 16:40:08,091 [INFO] Step[100/144]: training loss : 1.2707445478439332 TRAIN  loss dict:  {'classification_loss': 1.2707445478439332}
2024-10-08 16:42:13,148 [INFO] Label accuracies statistics:
2024-10-08 16:42:13,148 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.5, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.5, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.0, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.25, 142: 0.25, 143: 0.0, 144: 0.25, 145: 0.25, 146: 0.5, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.25, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 0.75, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.0, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-08 16:42:13,866 [INFO] [9] TRAIN  loss: 1.269111658549971 acc: 0.6686746987951807
2024-10-08 16:42:13,866 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.269111658549971}
2024-10-08 16:42:13,866 [INFO] [9] VALIDATION loss: 1.4866425516428772 VALIDATION  acc: 0.6186868686868687
2024-10-08 16:42:13,866 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.4866425516428772}
2024-10-08 16:42:13,866 [INFO] 
2024-10-08 16:43:51,162 [INFO] Step[50/144]: training loss : 1.0554290974140168 TRAIN  loss dict:  {'classification_loss': 1.0554290974140168}
2024-10-08 16:45:05,215 [INFO] Step[100/144]: training loss : 1.0641982889175414 TRAIN  loss dict:  {'classification_loss': 1.0641982889175414}
2024-10-08 16:47:09,934 [INFO] Label accuracies statistics:
2024-10-08 16:47:09,935 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.25, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.25, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.5, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.5, 134: 0.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.0, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 0.75, 195: 0.25, 196: 0.5, 197: 1.0, 198: 1.0}

2024-10-08 16:47:10,664 [INFO] [10] TRAIN  loss: 1.0689566793541114 acc: 0.7150139017608897
2024-10-08 16:47:10,664 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.0689566793541114}
2024-10-08 16:47:10,664 [INFO] [10] VALIDATION loss: 1.445039019540504 VALIDATION  acc: 0.6136363636363636
2024-10-08 16:47:10,664 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.445039019540504}
2024-10-08 16:47:10,664 [INFO] 
2024-10-08 16:48:48,599 [INFO] Step[50/144]: training loss : 0.8536875665187835 TRAIN  loss dict:  {'classification_loss': 0.8536875665187835}
2024-10-08 16:50:00,384 [INFO] Step[100/144]: training loss : 0.8562487149238587 TRAIN  loss dict:  {'classification_loss': 0.8562487149238587}
2024-10-08 16:52:06,402 [INFO] Label accuracies statistics:
2024-10-08 16:52:06,402 [INFO] {0: 0.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.25, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 0.5, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.5, 73: 0.75, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 0.75, 125: 0.5, 126: 0.75, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.5, 134: 0.5, 135: 0.75, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.25, 140: 0.5, 141: 0.25, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.25, 171: 0.25, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.0, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 0.25, 197: 0.75, 198: 1.0}

2024-10-08 16:52:07,147 [INFO] [11] TRAIN  loss: 0.8629825731946362 acc: 0.7796570898980537
2024-10-08 16:52:07,148 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.8629825731946362}
2024-10-08 16:52:07,148 [INFO] [11] VALIDATION loss: 1.3694061636924744 VALIDATION  acc: 0.6199494949494949
2024-10-08 16:52:07,148 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.3694061636924744}
2024-10-08 16:52:07,148 [INFO] 
2024-10-08 16:53:44,590 [INFO] Step[50/144]: training loss : 0.7164017033576965 TRAIN  loss dict:  {'classification_loss': 0.7164017033576965}
2024-10-08 16:54:57,263 [INFO] Step[100/144]: training loss : 0.7166137993335724 TRAIN  loss dict:  {'classification_loss': 0.7166137993335724}
2024-10-08 16:57:03,153 [INFO] Label accuracies statistics:
2024-10-08 16:57:03,153 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.0, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.0, 139: 0.5, 140: 1.0, 141: 0.25, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 0.25, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-08 16:57:03,834 [INFO] [12] TRAIN  loss: 0.7170674529754453 acc: 0.8195088044485634
2024-10-08 16:57:03,834 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.7170674529754453}
2024-10-08 16:57:03,834 [INFO] [12] VALIDATION loss: 1.2231313354439206 VALIDATION  acc: 0.6553030303030303
2024-10-08 16:57:03,834 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.2231313354439206}
2024-10-08 16:57:03,834 [INFO] 
2024-10-08 16:58:39,674 [INFO] Step[50/144]: training loss : 0.6333210188150405 TRAIN  loss dict:  {'classification_loss': 0.6333210188150405}
2024-10-08 16:59:51,864 [INFO] Step[100/144]: training loss : 0.6485460370779037 TRAIN  loss dict:  {'classification_loss': 0.6485460370779037}
2024-10-08 17:01:58,374 [INFO] Label accuracies statistics:
2024-10-08 17:01:58,374 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.25, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.25, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 1.0, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 0.5, 142: 1.0, 143: 0.25, 144: 1.0, 145: 0.0, 146: 1.0, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.0, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 17:01:58,458 [INFO] [13] TRAIN  loss: 0.6423252514666982 acc: 0.8357275254865616
2024-10-08 17:01:58,458 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.6423252514666982}
2024-10-08 17:01:58,458 [INFO] [13] VALIDATION loss: 1.2647863648555897 VALIDATION  acc: 0.6578282828282829
2024-10-08 17:01:58,458 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.2647863648555897}
2024-10-08 17:01:58,458 [INFO] 
2024-10-08 17:03:35,611 [INFO] Step[50/144]: training loss : 0.5428980147838592 TRAIN  loss dict:  {'classification_loss': 0.5428980147838592}
2024-10-08 17:04:47,318 [INFO] Step[100/144]: training loss : 0.5472862374782562 TRAIN  loss dict:  {'classification_loss': 0.5472862374782562}
2024-10-08 17:06:53,546 [INFO] Label accuracies statistics:
2024-10-08 17:06:53,546 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.5, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.25, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.0, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.25, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.25, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.5, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.25}

2024-10-08 17:06:53,644 [INFO] [14] TRAIN  loss: 0.5616101752966642 acc: 0.8591288229842446
2024-10-08 17:06:53,644 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.5616101752966642}
2024-10-08 17:06:53,645 [INFO] [14] VALIDATION loss: 1.2407613926463656 VALIDATION  acc: 0.648989898989899
2024-10-08 17:06:53,645 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.2407613926463656}
2024-10-08 17:06:53,645 [INFO] 
2024-10-08 17:08:30,590 [INFO] Step[50/144]: training loss : 0.45168143898248675 TRAIN  loss dict:  {'classification_loss': 0.45168143898248675}
2024-10-08 17:09:42,901 [INFO] Step[100/144]: training loss : 0.4845507934689522 TRAIN  loss dict:  {'classification_loss': 0.4845507934689522}
2024-10-08 17:11:49,719 [INFO] Label accuracies statistics:
2024-10-08 17:11:49,719 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.0, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.5, 109: 1.0, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.5, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-08 17:11:50,416 [INFO] [15] TRAIN  loss: 0.48304016950229806 acc: 0.8714087117701576
2024-10-08 17:11:50,416 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.48304016950229806}
2024-10-08 17:11:50,416 [INFO] [15] VALIDATION loss: 1.1869267429466601 VALIDATION  acc: 0.6691919191919192
2024-10-08 17:11:50,416 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.1869267429466601}
2024-10-08 17:11:50,416 [INFO] 
2024-10-08 17:13:28,675 [INFO] Step[50/144]: training loss : 0.3959745338559151 TRAIN  loss dict:  {'classification_loss': 0.3959745338559151}
2024-10-08 17:14:40,472 [INFO] Step[100/144]: training loss : 0.4264099219441414 TRAIN  loss dict:  {'classification_loss': 0.4264099219441414}
2024-10-08 17:16:46,441 [INFO] Label accuracies statistics:
2024-10-08 17:16:46,441 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.0, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.25, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.5, 124: 0.5, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.25, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.25, 197: 0.5, 198: 0.5}

2024-10-08 17:16:46,520 [INFO] [16] TRAIN  loss: 0.4256957699027326 acc: 0.8936515291936978
2024-10-08 17:16:46,520 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.4256957699027326}
2024-10-08 17:16:46,520 [INFO] [16] VALIDATION loss: 1.1908772709193054 VALIDATION  acc: 0.6679292929292929
2024-10-08 17:16:46,520 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.1908772709193054}
2024-10-08 17:16:46,520 [INFO] 
2024-10-08 17:18:24,773 [INFO] Step[50/144]: training loss : 0.3720256984233856 TRAIN  loss dict:  {'classification_loss': 0.3720256984233856}
2024-10-08 17:19:36,580 [INFO] Step[100/144]: training loss : 0.38035874128341673 TRAIN  loss dict:  {'classification_loss': 0.38035874128341673}
2024-10-08 17:21:43,955 [INFO] Label accuracies statistics:
2024-10-08 17:21:43,955 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.5, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.0, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 17:21:44,036 [INFO] [17] TRAIN  loss: 0.38855915547659 acc: 0.9040778498609824
2024-10-08 17:21:44,036 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.38855915547659}
2024-10-08 17:21:44,036 [INFO] [17] VALIDATION loss: 1.197580740959556 VALIDATION  acc: 0.6931818181818182
2024-10-08 17:21:44,036 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.197580740959556}
2024-10-08 17:21:44,036 [INFO] 
2024-10-08 17:23:20,918 [INFO] Step[50/144]: training loss : 0.2996844667196274 TRAIN  loss dict:  {'classification_loss': 0.2996844667196274}
2024-10-08 17:24:34,571 [INFO] Step[100/144]: training loss : 0.36520198225975037 TRAIN  loss dict:  {'classification_loss': 0.36520198225975037}
2024-10-08 17:26:40,517 [INFO] Label accuracies statistics:
2024-10-08 17:26:40,518 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.75, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.0, 60: 1.0, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.25, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.25, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-08 17:26:41,184 [INFO] [18] TRAIN  loss: 0.34568117734872633 acc: 0.9107970342910102
2024-10-08 17:26:41,184 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.34568117734872633}
2024-10-08 17:26:41,184 [INFO] [18] VALIDATION loss: 1.1565940258679566 VALIDATION  acc: 0.6805555555555556
2024-10-08 17:26:41,185 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.1565940258679566}
2024-10-08 17:26:41,185 [INFO] 
2024-10-08 17:28:18,179 [INFO] Step[50/144]: training loss : 0.3295946729183197 TRAIN  loss dict:  {'classification_loss': 0.3295946729183197}
2024-10-08 17:29:29,481 [INFO] Step[100/144]: training loss : 0.32224714174866675 TRAIN  loss dict:  {'classification_loss': 0.32224714174866675}
2024-10-08 17:31:36,055 [INFO] Label accuracies statistics:
2024-10-08 17:31:36,055 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.5, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.0, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.25, 143: 0.5, 144: 0.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.0, 183: 0.5, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 17:31:36,750 [INFO] [19] TRAIN  loss: 0.3310460412564377 acc: 0.9142724745134384
2024-10-08 17:31:36,750 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.3310460412564377}
2024-10-08 17:31:36,750 [INFO] [19] VALIDATION loss: 1.1294721331861284 VALIDATION  acc: 0.696969696969697
2024-10-08 17:31:36,750 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.1294721331861284}
2024-10-08 17:31:36,750 [INFO] 
2024-10-08 17:33:13,762 [INFO] Step[50/144]: training loss : 0.2718915656208992 TRAIN  loss dict:  {'classification_loss': 0.2718915656208992}
2024-10-08 17:34:25,596 [INFO] Step[100/144]: training loss : 0.30993664368987084 TRAIN  loss dict:  {'classification_loss': 0.30993664368987084}
2024-10-08 17:36:31,471 [INFO] Label accuracies statistics:
2024-10-08 17:36:31,471 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.25, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.5, 112: 1.0, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.0, 145: 0.25, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 17:36:31,549 [INFO] [20] TRAIN  loss: 0.2915755719360378 acc: 0.9265523632993512
2024-10-08 17:36:31,549 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.2915755719360378}
2024-10-08 17:36:31,549 [INFO] [20] VALIDATION loss: 1.1581573406303372 VALIDATION  acc: 0.672979797979798
2024-10-08 17:36:31,549 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.1581573406303372}
2024-10-08 17:36:31,549 [INFO] 
2024-10-08 17:38:08,389 [INFO] Step[50/144]: training loss : 0.2008753699064255 TRAIN  loss dict:  {'classification_loss': 0.2008753699064255}
2024-10-08 17:39:21,261 [INFO] Step[100/144]: training loss : 0.2535497497022152 TRAIN  loss dict:  {'classification_loss': 0.2535497497022152}
2024-10-08 17:41:27,237 [INFO] Label accuracies statistics:
2024-10-08 17:41:27,237 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.0, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.5}

2024-10-08 17:41:27,973 [INFO] [21] TRAIN  loss: 0.2338826173606018 acc: 0.9446246524559777
2024-10-08 17:41:27,973 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.2338826173606018}
2024-10-08 17:41:27,973 [INFO] [21] VALIDATION loss: 1.1148984167310927 VALIDATION  acc: 0.6957070707070707
2024-10-08 17:41:27,973 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.1148984167310927}
2024-10-08 17:41:27,973 [INFO] 
2024-10-08 17:43:04,552 [INFO] Step[50/144]: training loss : 0.19834558218717574 TRAIN  loss dict:  {'classification_loss': 0.19834558218717574}
2024-10-08 17:44:16,349 [INFO] Step[100/144]: training loss : 0.21145708739757538 TRAIN  loss dict:  {'classification_loss': 0.21145708739757538}
2024-10-08 17:46:22,240 [INFO] Label accuracies statistics:
2024-10-08 17:46:22,240 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.0, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-08 17:46:22,324 [INFO] [22] TRAIN  loss: 0.2062296790795194 acc: 0.9525023169601483
2024-10-08 17:46:22,324 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.2062296790795194}
2024-10-08 17:46:22,324 [INFO] [22] VALIDATION loss: 1.1441212942202885 VALIDATION  acc: 0.696969696969697
2024-10-08 17:46:22,324 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.1441212942202885}
2024-10-08 17:46:22,324 [INFO] 
2024-10-08 17:47:58,394 [INFO] Step[50/144]: training loss : 0.18022077903151512 TRAIN  loss dict:  {'classification_loss': 0.18022077903151512}
2024-10-08 17:49:09,059 [INFO] Step[100/144]: training loss : 0.18945204541087152 TRAIN  loss dict:  {'classification_loss': 0.18945204541087152}
2024-10-08 17:51:15,421 [INFO] Label accuracies statistics:
2024-10-08 17:51:15,421 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.25, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 17:51:16,129 [INFO] [23] TRAIN  loss: 0.18602430002970827 acc: 0.9527340129749768
2024-10-08 17:51:16,129 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.18602430002970827}
2024-10-08 17:51:16,130 [INFO] [23] VALIDATION loss: 1.056549162776382 VALIDATION  acc: 0.7121212121212122
2024-10-08 17:51:16,130 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.056549162776382}
2024-10-08 17:51:16,130 [INFO] 
2024-10-08 17:52:53,694 [INFO] Step[50/144]: training loss : 0.17160746842622757 TRAIN  loss dict:  {'classification_loss': 0.17160746842622757}
2024-10-08 17:54:05,763 [INFO] Step[100/144]: training loss : 0.18082849994301797 TRAIN  loss dict:  {'classification_loss': 0.18082849994301797}
2024-10-08 17:56:11,251 [INFO] Label accuracies statistics:
2024-10-08 17:56:11,251 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 17:56:11,930 [INFO] [24] TRAIN  loss: 0.17299532155609793 acc: 0.9608433734939759
2024-10-08 17:56:11,930 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.17299532155609793}
2024-10-08 17:56:11,930 [INFO] [24] VALIDATION loss: 1.0472456771466467 VALIDATION  acc: 0.7209595959595959
2024-10-08 17:56:11,930 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.0472456771466467}
2024-10-08 17:56:11,931 [INFO] 
2024-10-08 17:57:46,583 [INFO] Step[50/144]: training loss : 0.13943983428180218 TRAIN  loss dict:  {'classification_loss': 0.13943983428180218}
2024-10-08 17:58:58,377 [INFO] Step[100/144]: training loss : 0.1717812640964985 TRAIN  loss dict:  {'classification_loss': 0.1717812640964985}
2024-10-08 18:01:05,464 [INFO] Label accuracies statistics:
2024-10-08 18:01:05,464 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-08 18:01:05,551 [INFO] [25] TRAIN  loss: 0.1589650802521242 acc: 0.9640871177015755
2024-10-08 18:01:05,551 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.1589650802521242}
2024-10-08 18:01:05,551 [INFO] [25] VALIDATION loss: 1.0968044146343514 VALIDATION  acc: 0.7108585858585859
2024-10-08 18:01:05,551 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.0968044146343514}
2024-10-08 18:01:05,552 [INFO] 
2024-10-08 18:02:42,493 [INFO] Step[50/144]: training loss : 0.13977184206247328 TRAIN  loss dict:  {'classification_loss': 0.13977184206247328}
2024-10-08 18:03:54,284 [INFO] Step[100/144]: training loss : 0.15749085575342178 TRAIN  loss dict:  {'classification_loss': 0.15749085575342178}
2024-10-08 18:06:00,106 [INFO] Label accuracies statistics:
2024-10-08 18:06:00,106 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.25, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.5, 192: 0.75, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 18:06:00,207 [INFO] [26] TRAIN  loss: 0.15634930312323073 acc: 0.9636237256719185
2024-10-08 18:06:00,207 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.15634930312323073}
2024-10-08 18:06:00,207 [INFO] [26] VALIDATION loss: 1.1036550435754988 VALIDATION  acc: 0.7247474747474747
2024-10-08 18:06:00,207 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.1036550435754988}
2024-10-08 18:06:00,207 [INFO] 
2024-10-08 18:07:37,853 [INFO] Step[50/144]: training loss : 0.14260899052023887 TRAIN  loss dict:  {'classification_loss': 0.14260899052023887}
2024-10-08 18:08:48,957 [INFO] Step[100/144]: training loss : 0.1385605464875698 TRAIN  loss dict:  {'classification_loss': 0.1385605464875698}
2024-10-08 18:10:55,137 [INFO] Label accuracies statistics:
2024-10-08 18:10:55,137 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.0, 120: 0.5, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 18:10:55,216 [INFO] [27] TRAIN  loss: 0.14375657518394291 acc: 0.9666357738646896
2024-10-08 18:10:55,216 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.14375657518394291}
2024-10-08 18:10:55,216 [INFO] [27] VALIDATION loss: 1.0655298608320731 VALIDATION  acc: 0.726010101010101
2024-10-08 18:10:55,216 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.0655298608320731}
2024-10-08 18:10:55,216 [INFO] 
2024-10-08 18:12:32,698 [INFO] Step[50/144]: training loss : 0.12435271359980106 TRAIN  loss dict:  {'classification_loss': 0.12435271359980106}
2024-10-08 18:13:44,190 [INFO] Step[100/144]: training loss : 0.13028344959020616 TRAIN  loss dict:  {'classification_loss': 0.13028344959020616}
2024-10-08 18:15:49,757 [INFO] Label accuracies statistics:
2024-10-08 18:15:49,757 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 1.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 18:15:50,440 [INFO] [28] TRAIN  loss: 0.13357803440238866 acc: 0.9680259499536608
2024-10-08 18:15:50,440 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.13357803440238866}
2024-10-08 18:15:50,440 [INFO] [28] VALIDATION loss: 1.0101311154387616 VALIDATION  acc: 0.7335858585858586
2024-10-08 18:15:50,441 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.0101311154387616}
2024-10-08 18:15:50,441 [INFO] 
2024-10-08 18:17:26,011 [INFO] Step[50/144]: training loss : 0.11485030718147754 TRAIN  loss dict:  {'classification_loss': 0.11485030718147754}
2024-10-08 18:18:37,649 [INFO] Step[100/144]: training loss : 0.1287365373969078 TRAIN  loss dict:  {'classification_loss': 0.1287365373969078}
2024-10-08 18:20:43,152 [INFO] Label accuracies statistics:
2024-10-08 18:20:43,152 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.5, 7: 0.5, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.25, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.25, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 1.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 18:20:43,246 [INFO] [29] TRAIN  loss: 0.1286252933399131 acc: 0.9677942539388322
2024-10-08 18:20:43,247 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.1286252933399131}
2024-10-08 18:20:43,247 [INFO] [29] VALIDATION loss: 1.0768972094412204 VALIDATION  acc: 0.7310606060606061
2024-10-08 18:20:43,247 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.0768972094412204}
2024-10-08 18:20:43,247 [INFO] 
2024-10-08 18:22:19,698 [INFO] Step[50/144]: training loss : 0.11134549811482429 TRAIN  loss dict:  {'classification_loss': 0.11134549811482429}
2024-10-08 18:23:33,896 [INFO] Step[100/144]: training loss : 0.10940258126705885 TRAIN  loss dict:  {'classification_loss': 0.10940258126705885}
2024-10-08 18:25:40,118 [INFO] Label accuracies statistics:
2024-10-08 18:25:40,118 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 18:25:40,212 [INFO] [30] TRAIN  loss: 0.11730483724063055 acc: 0.9728915662650602
2024-10-08 18:25:40,212 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.11730483724063055}
2024-10-08 18:25:40,212 [INFO] [30] VALIDATION loss: 1.0611985883227102 VALIDATION  acc: 0.7373737373737373
2024-10-08 18:25:40,212 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.0611985883227102}
2024-10-08 18:25:40,212 [INFO] 
2024-10-08 18:27:15,385 [INFO] Step[50/144]: training loss : 0.10862360242754221 TRAIN  loss dict:  {'classification_loss': 0.10862360242754221}
2024-10-08 18:28:26,182 [INFO] Step[100/144]: training loss : 0.10103232383728028 TRAIN  loss dict:  {'classification_loss': 0.10103232383728028}
2024-10-08 18:30:31,896 [INFO] Label accuracies statistics:
2024-10-08 18:30:31,896 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.5, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.25, 70: 0.25, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.25, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 18:30:31,977 [INFO] [31] TRAIN  loss: 0.10117338734885885 acc: 0.9791473586654309
2024-10-08 18:30:31,977 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.10117338734885885}
2024-10-08 18:30:31,977 [INFO] [31] VALIDATION loss: 1.0147741136175614 VALIDATION  acc: 0.7234848484848485
2024-10-08 18:30:31,977 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.0147741136175614}
2024-10-08 18:30:31,977 [INFO] 
2024-10-08 18:32:08,289 [INFO] Step[50/144]: training loss : 0.09522474460303783 TRAIN  loss dict:  {'classification_loss': 0.09522474460303783}
2024-10-08 18:33:20,125 [INFO] Step[100/144]: training loss : 0.09188617751002312 TRAIN  loss dict:  {'classification_loss': 0.09188617751002312}
2024-10-08 18:35:25,987 [INFO] Label accuracies statistics:
2024-10-08 18:35:25,987 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.25, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.25, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.75, 154: 0.75, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 18:35:26,737 [INFO] [32] TRAIN  loss: 0.09126167765094174 acc: 0.9798424467099166
2024-10-08 18:35:26,737 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.09126167765094174}
2024-10-08 18:35:26,738 [INFO] [32] VALIDATION loss: 0.9812644244068198 VALIDATION  acc: 0.7436868686868687
2024-10-08 18:35:26,738 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 0.9812644244068198}
2024-10-08 18:35:26,738 [INFO] 
2024-10-08 18:37:02,307 [INFO] Step[50/144]: training loss : 0.07286605063825846 TRAIN  loss dict:  {'classification_loss': 0.07286605063825846}
2024-10-08 18:38:13,961 [INFO] Step[100/144]: training loss : 0.08488734565675259 TRAIN  loss dict:  {'classification_loss': 0.08488734565675259}
2024-10-08 18:40:20,422 [INFO] Label accuracies statistics:
2024-10-08 18:40:20,422 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.25, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.25, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 18:40:21,115 [INFO] [33] TRAIN  loss: 0.08023332218484332 acc: 0.9837812789620018
2024-10-08 18:40:21,115 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.08023332218484332}
2024-10-08 18:40:21,115 [INFO] [33] VALIDATION loss: 0.9714822189675437 VALIDATION  acc: 0.7373737373737373
2024-10-08 18:40:21,115 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 0.9714822189675437}
2024-10-08 18:40:21,115 [INFO] 
2024-10-08 18:41:57,121 [INFO] Step[50/144]: training loss : 0.08348631866276264 TRAIN  loss dict:  {'classification_loss': 0.08348631866276264}
2024-10-08 18:43:08,483 [INFO] Step[100/144]: training loss : 0.07996187599375844 TRAIN  loss dict:  {'classification_loss': 0.07996187599375844}
2024-10-08 18:45:14,055 [INFO] Label accuracies statistics:
2024-10-08 18:45:14,055 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.5, 7: 0.75, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.5, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.25, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 1.0, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 18:45:14,141 [INFO] [34] TRAIN  loss: 0.08332091588656315 acc: 0.9812326227988879
2024-10-08 18:45:14,142 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.08332091588656315}
2024-10-08 18:45:14,142 [INFO] [34] VALIDATION loss: 1.0654736726924225 VALIDATION  acc: 0.7209595959595959
2024-10-08 18:45:14,142 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.0654736726924225}
2024-10-08 18:45:14,142 [INFO] 
2024-10-08 18:46:50,038 [INFO] Step[50/144]: training loss : 0.08003382135182618 TRAIN  loss dict:  {'classification_loss': 0.08003382135182618}
2024-10-08 18:48:01,482 [INFO] Step[100/144]: training loss : 0.07923158280551433 TRAIN  loss dict:  {'classification_loss': 0.07923158280551433}
2024-10-08 18:50:07,050 [INFO] Label accuracies statistics:
2024-10-08 18:50:07,050 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 18:50:07,136 [INFO] [35] TRAIN  loss: 0.0805218607161401 acc: 0.9810009267840594
2024-10-08 18:50:07,136 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.0805218607161401}
2024-10-08 18:50:07,136 [INFO] [35] VALIDATION loss: 1.0527092786850754 VALIDATION  acc: 0.7272727272727273
2024-10-08 18:50:07,137 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.0527092786850754}
2024-10-08 18:50:07,137 [INFO] 
2024-10-08 18:51:42,896 [INFO] Step[50/144]: training loss : 0.06572878252714873 TRAIN  loss dict:  {'classification_loss': 0.06572878252714873}
2024-10-08 18:52:54,816 [INFO] Step[100/144]: training loss : 0.07439984750002622 TRAIN  loss dict:  {'classification_loss': 0.07439984750002622}
2024-10-08 18:55:00,978 [INFO] Label accuracies statistics:
2024-10-08 18:55:00,978 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.0, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 0.75, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-08 18:55:01,064 [INFO] [36] TRAIN  loss: 0.0686387077310226 acc: 0.9865616311399444
2024-10-08 18:55:01,064 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.0686387077310226}
2024-10-08 18:55:01,064 [INFO] [36] VALIDATION loss: 1.0688988124882732 VALIDATION  acc: 0.7310606060606061
2024-10-08 18:55:01,064 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.0688988124882732}
2024-10-08 18:55:01,064 [INFO] 
2024-10-08 18:56:36,673 [INFO] Step[50/144]: training loss : 0.07544663514941931 TRAIN  loss dict:  {'classification_loss': 0.07544663514941931}
2024-10-08 18:57:49,379 [INFO] Step[100/144]: training loss : 0.06788851618766785 TRAIN  loss dict:  {'classification_loss': 0.06788851618766785}
2024-10-08 18:59:54,981 [INFO] Label accuracies statistics:
2024-10-08 18:59:54,981 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.5, 135: 0.75, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.5, 162: 1.0, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 18:59:55,066 [INFO] [37] TRAIN  loss: 0.07808855909388512 acc: 0.9814643188137164
2024-10-08 18:59:55,066 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.07808855909388512}
2024-10-08 18:59:55,066 [INFO] [37] VALIDATION loss: 1.114150065238829 VALIDATION  acc: 0.7133838383838383
2024-10-08 18:59:55,066 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.114150065238829}
2024-10-08 18:59:55,066 [INFO] 
2024-10-08 19:01:30,616 [INFO] Step[50/144]: training loss : 0.06392904842272401 TRAIN  loss dict:  {'classification_loss': 0.06392904842272401}
2024-10-08 19:02:41,729 [INFO] Step[100/144]: training loss : 0.060674909651279446 TRAIN  loss dict:  {'classification_loss': 0.060674909651279446}
2024-10-08 19:04:48,422 [INFO] Label accuracies statistics:
2024-10-08 19:04:48,423 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-08 19:04:48,511 [INFO] [38] TRAIN  loss: 0.061712629310528025 acc: 0.9877201112140871
2024-10-08 19:04:48,511 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.061712629310528025}
2024-10-08 19:04:48,511 [INFO] [38] VALIDATION loss: 1.0760152702116303 VALIDATION  acc: 0.7297979797979798
2024-10-08 19:04:48,511 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.0760152702116303}
2024-10-08 19:04:48,512 [INFO] 
2024-10-08 19:06:23,856 [INFO] Step[50/144]: training loss : 0.06386370861902833 TRAIN  loss dict:  {'classification_loss': 0.06386370861902833}
2024-10-08 19:07:33,880 [INFO] Step[100/144]: training loss : 0.06883461117744445 TRAIN  loss dict:  {'classification_loss': 0.06883461117744445}
2024-10-08 19:09:41,619 [INFO] Label accuracies statistics:
2024-10-08 19:09:41,619 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.25, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 1.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 19:09:41,700 [INFO] [39] TRAIN  loss: 0.06242267910986104 acc: 0.9849397590361446
2024-10-08 19:09:41,700 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.06242267910986104}
2024-10-08 19:09:41,700 [INFO] [39] VALIDATION loss: 1.124532891092477 VALIDATION  acc: 0.7411616161616161
2024-10-08 19:09:41,700 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.124532891092477}
2024-10-08 19:09:41,700 [INFO] 
2024-10-08 19:11:16,457 [INFO] Step[50/144]: training loss : 0.0577709726896137 TRAIN  loss dict:  {'classification_loss': 0.0577709726896137}
2024-10-08 19:12:28,376 [INFO] Step[100/144]: training loss : 0.07972625646740199 TRAIN  loss dict:  {'classification_loss': 0.07972625646740199}
2024-10-08 19:14:34,328 [INFO] Label accuracies statistics:
2024-10-08 19:14:34,328 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 1.0, 141: 0.75, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 19:14:34,421 [INFO] [40] TRAIN  loss: 0.06993532441750479 acc: 0.9833178869323448
2024-10-08 19:14:34,421 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.06993532441750479}
2024-10-08 19:14:34,422 [INFO] [40] VALIDATION loss: 1.1054328359939434 VALIDATION  acc: 0.7310606060606061
2024-10-08 19:14:34,422 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.1054328359939434}
2024-10-08 19:14:34,422 [INFO] 
2024-10-08 19:16:10,853 [INFO] Step[50/144]: training loss : 0.06405615147203207 TRAIN  loss dict:  {'classification_loss': 0.06405615147203207}
2024-10-08 19:17:23,090 [INFO] Step[100/144]: training loss : 0.04920250115916133 TRAIN  loss dict:  {'classification_loss': 0.04920250115916133}
2024-10-08 19:19:42,671 [INFO] Label accuracies statistics:
2024-10-08 19:19:42,671 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 19:19:42,746 [INFO] [41] TRAIN  loss: 0.0585193049434262 acc: 0.986793327154773
2024-10-08 19:19:42,747 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.0585193049434262}
2024-10-08 19:19:42,747 [INFO] [41] VALIDATION loss: 1.002440414632912 VALIDATION  acc: 0.7575757575757576
2024-10-08 19:19:42,747 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.002440414632912}
2024-10-08 19:19:42,747 [INFO] 
2024-10-08 19:21:19,120 [INFO] Step[50/144]: training loss : 0.04275884050875902 TRAIN  loss dict:  {'classification_loss': 0.04275884050875902}
2024-10-08 19:22:29,593 [INFO] Step[100/144]: training loss : 0.043580950405448675 TRAIN  loss dict:  {'classification_loss': 0.043580950405448675}
2024-10-08 19:24:35,755 [INFO] Label accuracies statistics:
2024-10-08 19:24:35,755 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 1.0, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 19:24:35,832 [INFO] [42] TRAIN  loss: 0.043930466092812516 acc: 0.9916589434661723
2024-10-08 19:24:35,832 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.043930466092812516}
2024-10-08 19:24:35,832 [INFO] [42] VALIDATION loss: 1.0017422637384799 VALIDATION  acc: 0.7525252525252525
2024-10-08 19:24:35,832 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.0017422637384799}
2024-10-08 19:24:35,832 [INFO] 
2024-10-08 19:26:10,976 [INFO] Step[50/144]: training loss : 0.04976779984310269 TRAIN  loss dict:  {'classification_loss': 0.04976779984310269}
2024-10-08 19:27:24,040 [INFO] Step[100/144]: training loss : 0.04718520730733872 TRAIN  loss dict:  {'classification_loss': 0.04718520730733872}
2024-10-08 19:29:39,127 [INFO] Label accuracies statistics:
2024-10-08 19:29:39,127 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 19:29:39,219 [INFO] [43] TRAIN  loss: 0.05016067092138757 acc: 0.9863299351251158
2024-10-08 19:29:39,219 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.05016067092138757}
2024-10-08 19:29:39,219 [INFO] [43] VALIDATION loss: 1.0901568084955215 VALIDATION  acc: 0.7196969696969697
2024-10-08 19:29:39,219 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.0901568084955215}
2024-10-08 19:29:39,219 [INFO] 
2024-10-08 19:31:23,924 [INFO] Step[50/144]: training loss : 0.054839310832321644 TRAIN  loss dict:  {'classification_loss': 0.054839310832321644}
2024-10-08 19:32:34,527 [INFO] Step[100/144]: training loss : 0.05298421189188957 TRAIN  loss dict:  {'classification_loss': 0.05298421189188957}
2024-10-08 19:34:48,458 [INFO] Label accuracies statistics:
2024-10-08 19:34:48,458 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.25, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 19:34:48,566 [INFO] [44] TRAIN  loss: 0.05520827424738349 acc: 0.986793327154773
2024-10-08 19:34:48,566 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.05520827424738349}
2024-10-08 19:34:48,566 [INFO] [44] VALIDATION loss: 1.0516475022391036 VALIDATION  acc: 0.7525252525252525
2024-10-08 19:34:48,566 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.0516475022391036}
2024-10-08 19:34:48,566 [INFO] 
2024-10-08 19:36:29,515 [INFO] Step[50/144]: training loss : 0.04177847985178232 TRAIN  loss dict:  {'classification_loss': 0.04177847985178232}
2024-10-08 19:37:40,988 [INFO] Step[100/144]: training loss : 0.04395921958610415 TRAIN  loss dict:  {'classification_loss': 0.04395921958610415}
2024-10-08 19:39:55,251 [INFO] Label accuracies statistics:
2024-10-08 19:39:55,251 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.5, 123: 0.5, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-08 19:39:55,337 [INFO] [45] TRAIN  loss: 0.04427614224065716 acc: 0.9925857275254866
2024-10-08 19:39:55,337 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.04427614224065716}
2024-10-08 19:39:55,338 [INFO] [45] VALIDATION loss: 1.1347513816974781 VALIDATION  acc: 0.7285353535353535
2024-10-08 19:39:55,338 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.1347513816974781}
2024-10-08 19:39:55,338 [INFO] 
2024-10-08 19:41:33,780 [INFO] Step[50/144]: training loss : 0.030971480030566455 TRAIN  loss dict:  {'classification_loss': 0.030971480030566455}
2024-10-08 19:42:47,150 [INFO] Step[100/144]: training loss : 0.05373485312797129 TRAIN  loss dict:  {'classification_loss': 0.05373485312797129}
2024-10-08 19:45:00,098 [INFO] Label accuracies statistics:
2024-10-08 19:45:00,098 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 1.0, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-08 19:45:00,206 [INFO] [46] TRAIN  loss: 0.043244902500494696 acc: 0.9916589434661723
2024-10-08 19:45:00,206 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.043244902500494696}
2024-10-08 19:45:00,207 [INFO] [46] VALIDATION loss: 1.066330486425647 VALIDATION  acc: 0.7285353535353535
2024-10-08 19:45:00,207 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.066330486425647}
2024-10-08 19:45:00,207 [INFO] 
2024-10-08 19:46:39,849 [INFO] Step[50/144]: training loss : 0.027497822139412164 TRAIN  loss dict:  {'classification_loss': 0.027497822139412164}
2024-10-08 19:47:53,226 [INFO] Step[100/144]: training loss : 0.03630065402016044 TRAIN  loss dict:  {'classification_loss': 0.03630065402016044}
2024-10-08 19:50:07,646 [INFO] Label accuracies statistics:
2024-10-08 19:50:07,646 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 1.0, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.25, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-08 19:50:07,730 [INFO] [47] TRAIN  loss: 0.03957403728984193 acc: 0.9916589434661723
2024-10-08 19:50:07,730 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.03957403728984193}
2024-10-08 19:50:07,731 [INFO] [47] VALIDATION loss: 1.0517477169632912 VALIDATION  acc: 0.7361111111111112
2024-10-08 19:50:07,731 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.0517477169632912}
2024-10-08 19:50:07,731 [INFO] 
2024-10-08 19:51:48,601 [INFO] Step[50/144]: training loss : 0.0335306799504906 TRAIN  loss dict:  {'classification_loss': 0.0335306799504906}
2024-10-08 19:53:01,320 [INFO] Step[100/144]: training loss : 0.0362833446264267 TRAIN  loss dict:  {'classification_loss': 0.0362833446264267}
2024-10-08 19:55:16,139 [INFO] Label accuracies statistics:
2024-10-08 19:55:16,139 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.0, 120: 0.5, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-08 19:55:16,230 [INFO] [48] TRAIN  loss: 0.03765828390411722 acc: 0.9911955514365153
2024-10-08 19:55:16,230 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.03765828390411722}
2024-10-08 19:55:16,230 [INFO] [48] VALIDATION loss: 1.0577579333826348 VALIDATION  acc: 0.7449494949494949
2024-10-08 19:55:16,230 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.0577579333826348}
2024-10-08 19:55:16,230 [INFO] 
2024-10-08 19:55:16,230 [INFO] 

***Stop training***


2024-10-08 19:55:16,231 [INFO] 
Testing checkpointed models starting...

2024-10-08 19:56:20,112 [INFO] Label accuracies statistics:
2024-10-08 19:56:20,112 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.0, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.3333333333333333, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 1.0, 38: 0.75, 39: 0.5, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 1.0, 56: 0.5, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.5, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.25, 83: 0.5, 84: 1.0, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.25, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.5, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 0.75, 116: 0.75, 117: 0.5, 118: 0.75, 119: 0.75, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 0.5, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.75, 158: 0.5, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.5, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.5, 167: 1.0, 168: 0.5, 169: 0.25, 170: 1.0, 171: 0.0, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.25, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.75, 187: 0.75, 188: 0.5, 189: 1.0, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.5, 198: 1.0}

2024-10-08 19:56:20,200 [INFO] 
Testing accuracy: 0.7281921618204804
