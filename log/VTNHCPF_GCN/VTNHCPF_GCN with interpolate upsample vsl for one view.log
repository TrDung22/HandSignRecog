2024-10-08 16:12:44,096 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample vsl for one view...


2024-10-08 16:20:06,522 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample vsl for one view...


2024-10-08 16:21:46,805 [INFO] Step[50/144]: training loss : 5.4750430393219 TRAIN  loss dict:  {'classification_loss': 5.4750430393219}
2024-10-08 16:22:52,159 [INFO] Step[100/144]: training loss : 5.414837379455566 TRAIN  loss dict:  {'classification_loss': 5.414837379455566}
2024-10-08 16:25:06,962 [INFO] Label accuracies statistics:
2024-10-08 16:25:06,963 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.5, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.25, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 1.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.25, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 16:25:07,547 [INFO] [1] TRAIN  loss: 5.415513028701146 acc: 0.005329008341056534
2024-10-08 16:25:07,547 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.415513028701146}
2024-10-08 16:25:07,547 [INFO] [1] VALIDATION loss: 5.22213402500859 VALIDATION  acc: 0.010101010101010102
2024-10-08 16:25:07,547 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.22213402500859}
2024-10-08 16:25:07,548 [INFO] 
2024-10-08 16:27:05,183 [INFO] Step[50/144]: training loss : 5.170005712509155 TRAIN  loss dict:  {'classification_loss': 5.170005712509155}
2024-10-08 16:28:11,499 [INFO] Step[100/144]: training loss : 4.976509113311767 TRAIN  loss dict:  {'classification_loss': 4.976509113311767}
2024-10-08 16:30:20,573 [INFO] Label accuracies statistics:
2024-10-08 16:30:20,573 [INFO] {0: 0.0, 1: 0.0, 2: 0.25, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.25, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.25, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.25, 27: 0.0, 28: 0.5, 29: 0.25, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.75, 41: 0.5, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.5, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.25, 81: 0.5, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.5, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.75, 107: 0.0, 108: 0.25, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.25, 113: 0.0, 114: 0.25, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.75, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.5, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.25, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 16:30:21,285 [INFO] [2] TRAIN  loss: 4.992007027069728 acc: 0.017608897126969416
2024-10-08 16:30:21,285 [INFO] [2] TRAIN  loss dict: {'classification_loss': 4.992007027069728}
2024-10-08 16:30:21,285 [INFO] [2] VALIDATION loss: 4.6610878661826805 VALIDATION  acc: 0.050505050505050504
2024-10-08 16:30:21,285 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.6610878661826805}
2024-10-08 16:30:21,285 [INFO] 
2024-10-08 16:32:02,709 [INFO] Step[50/144]: training loss : 4.449882497787476 TRAIN  loss dict:  {'classification_loss': 4.449882497787476}
2024-10-08 16:33:09,730 [INFO] Step[100/144]: training loss : 4.286338381767273 TRAIN  loss dict:  {'classification_loss': 4.286338381767273}
2024-10-08 16:35:18,576 [INFO] Label accuracies statistics:
2024-10-08 16:35:18,576 [INFO] {0: 0.0, 1: 0.0, 2: 0.25, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.25, 23: 0.0, 24: 0.0, 25: 0.25, 26: 0.0, 27: 0.0, 28: 0.75, 29: 0.75, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.25, 37: 0.25, 38: 0.25, 39: 0.75, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.25, 45: 0.5, 46: 0.0, 47: 0.0, 48: 0.25, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.5, 81: 0.75, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.5, 93: 0.0, 94: 0.25, 95: 0.0, 96: 0.25, 97: 0.0, 98: 0.25, 99: 0.4, 100: 0.0, 101: 0.75, 102: 0.5, 103: 0.0, 104: 0.0, 105: 1.0, 106: 0.0, 107: 1.0, 108: 0.0, 109: 0.0, 110: 0.25, 111: 0.25, 112: 0.0, 113: 0.25, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.75, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.5, 123: 0.25, 124: 0.5, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.5, 129: 0.25, 130: 0.25, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.0, 135: 0.25, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.25, 140: 0.0, 141: 0.0, 142: 0.25, 143: 0.25, 144: 0.0, 145: 0.25, 146: 0.5, 147: 0.0, 148: 0.0, 149: 0.25, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.75, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.25, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.75, 184: 0.0, 185: 0.25, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.25, 198: 0.0}

2024-10-08 16:35:19,234 [INFO] [3] TRAIN  loss: 4.267052620649338 acc: 0.0762279888785913
2024-10-08 16:35:19,234 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.267052620649338}
2024-10-08 16:35:19,234 [INFO] [3] VALIDATION loss: 3.8061343740533897 VALIDATION  acc: 0.14772727272727273
2024-10-08 16:35:19,234 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 3.8061343740533897}
2024-10-08 16:35:19,234 [INFO] 
2024-10-08 16:36:59,595 [INFO] Step[50/144]: training loss : 3.630631055831909 TRAIN  loss dict:  {'classification_loss': 3.630631055831909}
2024-10-08 16:38:05,049 [INFO] Step[100/144]: training loss : 3.372589039802551 TRAIN  loss dict:  {'classification_loss': 3.372589039802551}
2024-10-08 16:40:13,205 [INFO] Label accuracies statistics:
2024-10-08 16:40:13,205 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.0, 5: 0.0, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.5, 19: 0.5, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.75, 24: 0.0, 25: 0.25, 26: 0.25, 27: 0.25, 28: 0.0, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.75, 33: 0.5, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.5, 38: 0.25, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.25, 45: 0.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.75, 62: 0.25, 63: 0.5, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.75, 68: 0.5, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 1.0, 76: 0.0, 77: 0.0, 78: 0.5, 79: 0.25, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.5, 93: 0.5, 94: 0.25, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.5, 99: 0.6, 100: 0.5, 101: 0.25, 102: 0.0, 103: 0.0, 104: 0.0, 105: 1.0, 106: 0.0, 107: 0.75, 108: 0.25, 109: 0.0, 110: 0.25, 111: 0.25, 112: 0.0, 113: 0.5, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.5, 118: 0.5, 119: 0.75, 120: 0.0, 121: 0.0, 122: 0.5, 123: 0.25, 124: 0.0, 125: 0.25, 126: 0.25, 127: 0.0, 128: 0.75, 129: 0.75, 130: 0.5, 131: 0.25, 132: 0.25, 133: 0.25, 134: 0.0, 135: 1.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.5, 140: 0.5, 141: 0.25, 142: 0.0, 143: 0.25, 144: 0.0, 145: 0.0, 146: 0.5, 147: 0.0, 148: 0.5, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.75, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.0, 161: 0.25, 162: 0.75, 163: 0.0, 164: 0.25, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.5, 170: 0.25, 171: 0.5, 172: 0.0, 173: 0.5, 174: 1.0, 175: 0.25, 176: 0.0, 177: 0.5, 178: 0.0, 179: 0.3333333333333333, 180: 0.25, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 1.0, 186: 0.0, 187: 1.0, 188: 0.5, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.75, 195: 0.25, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-08 16:40:13,943 [INFO] [4] TRAIN  loss: 3.4151602569553585 acc: 0.19670991658943465
2024-10-08 16:40:13,943 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.4151602569553585}
2024-10-08 16:40:13,944 [INFO] [4] VALIDATION loss: 3.0317440386171692 VALIDATION  acc: 0.2803030303030303
2024-10-08 16:40:13,944 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.0317440386171692}
2024-10-08 16:40:13,944 [INFO] 
2024-10-08 16:41:54,139 [INFO] Step[50/144]: training loss : 2.8363404178619387 TRAIN  loss dict:  {'classification_loss': 2.8363404178619387}
2024-10-08 16:43:00,283 [INFO] Step[100/144]: training loss : 2.690477337837219 TRAIN  loss dict:  {'classification_loss': 2.690477337837219}
2024-10-08 16:45:07,796 [INFO] Label accuracies statistics:
2024-10-08 16:45:07,797 [INFO] {0: 0.6666666666666666, 1: 0.3333333333333333, 2: 0.25, 3: 0.25, 4: 0.5, 5: 0.25, 6: 0.25, 7: 0.0, 8: 0.25, 9: 0.25, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.0, 22: 0.75, 23: 0.25, 24: 0.0, 25: 0.75, 26: 0.5, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.25, 31: 0.0, 32: 0.5, 33: 0.5, 34: 1.0, 35: 0.25, 36: 0.0, 37: 0.5, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.25, 44: 0.75, 45: 0.0, 46: 0.25, 47: 0.25, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.0, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.25, 65: 0.25, 66: 0.5, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.0, 72: 0.5, 73: 0.25, 74: 0.75, 75: 0.75, 76: 0.75, 77: 0.0, 78: 0.75, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.0, 87: 0.5, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.6, 100: 0.25, 101: 0.25, 102: 0.5, 103: 0.25, 104: 0.25, 105: 1.0, 106: 0.0, 107: 0.75, 108: 0.25, 109: 0.5, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.0, 115: 0.0, 116: 0.25, 117: 0.25, 118: 1.0, 119: 0.0, 120: 0.25, 121: 0.0, 122: 0.0, 123: 0.25, 124: 0.5, 125: 0.25, 126: 0.75, 127: 0.25, 128: 0.75, 129: 0.5, 130: 0.75, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.5, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.5, 139: 0.5, 140: 0.0, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.25, 145: 0.25, 146: 0.5, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.0, 153: 0.0, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.5, 160: 0.0, 161: 0.5, 162: 0.75, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.25, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.25, 174: 0.5, 175: 0.25, 176: 0.5, 177: 1.0, 178: 0.75, 179: 1.0, 180: 0.25, 181: 0.0, 182: 0.0, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.0, 187: 1.0, 188: 0.25, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.25, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-08 16:45:08,514 [INFO] [5] TRAIN  loss: 2.7128782404793634 acc: 0.33526413345690453
2024-10-08 16:45:08,514 [INFO] [5] TRAIN  loss dict: {'classification_loss': 2.7128782404793634}
2024-10-08 16:45:08,514 [INFO] [5] VALIDATION loss: 2.5517579272941306 VALIDATION  acc: 0.3648989898989899
2024-10-08 16:45:08,514 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.5517579272941306}
2024-10-08 16:45:08,514 [INFO] 
2024-10-08 16:46:46,332 [INFO] Step[50/144]: training loss : 2.2381858372688295 TRAIN  loss dict:  {'classification_loss': 2.2381858372688295}
2024-10-08 16:47:54,997 [INFO] Step[100/144]: training loss : 2.1184975123405456 TRAIN  loss dict:  {'classification_loss': 2.1184975123405456}
2024-10-08 16:50:01,960 [INFO] Label accuracies statistics:
2024-10-08 16:50:01,960 [INFO] {0: 0.0, 1: 0.3333333333333333, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.5, 18: 0.25, 19: 0.5, 20: 0.0, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.0, 31: 0.0, 32: 0.75, 33: 0.5, 34: 0.5, 35: 0.25, 36: 0.5, 37: 1.0, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 0.75, 47: 0.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.0, 55: 0.0, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.75, 61: 0.5, 62: 0.5, 63: 0.0, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.25, 71: 0.25, 72: 0.75, 73: 0.75, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.25, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.25, 87: 0.25, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.5, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.5, 103: 0.25, 104: 0.5, 105: 0.75, 106: 1.0, 107: 1.0, 108: 1.0, 109: 0.5, 110: 0.75, 111: 0.5, 112: 1.0, 113: 0.25, 114: 0.25, 115: 0.25, 116: 0.75, 117: 0.5, 118: 0.75, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 0.75, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.25, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.25, 134: 0.75, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.5, 139: 1.0, 140: 0.5, 141: 0.25, 142: 0.0, 143: 0.25, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.25, 156: 0.5, 157: 0.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.0, 161: 0.5, 162: 0.5, 163: 0.0, 164: 0.25, 165: 0.25, 166: 0.25, 167: 0.0, 168: 0.25, 169: 0.25, 170: 0.5, 171: 0.25, 172: 0.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.25, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.25, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.0, 196: 0.25, 197: 1.0, 198: 0.0}

2024-10-08 16:50:02,690 [INFO] [6] TRAIN  loss: 2.169870143963231 acc: 0.4483317886932345
2024-10-08 16:50:02,690 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.169870143963231}
2024-10-08 16:50:02,690 [INFO] [6] VALIDATION loss: 2.112355755435096 VALIDATION  acc: 0.48863636363636365
2024-10-08 16:50:02,690 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.112355755435096}
2024-10-08 16:50:02,690 [INFO] 
2024-10-08 16:51:39,098 [INFO] Step[50/144]: training loss : 1.8207575726509093 TRAIN  loss dict:  {'classification_loss': 1.8207575726509093}
2024-10-08 16:52:48,526 [INFO] Step[100/144]: training loss : 1.7015405869483948 TRAIN  loss dict:  {'classification_loss': 1.7015405869483948}
2024-10-08 16:54:56,629 [INFO] Label accuracies statistics:
2024-10-08 16:54:56,629 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.25, 7: 0.25, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.5, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.5, 33: 0.5, 34: 0.5, 35: 0.0, 36: 0.25, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.5, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.25, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.75, 61: 0.75, 62: 0.5, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.0, 71: 0.0, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.0, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.25, 88: 0.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.5, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.0, 117: 0.0, 118: 1.0, 119: 0.25, 120: 0.25, 121: 0.0, 122: 1.0, 123: 0.5, 124: 0.75, 125: 1.0, 126: 0.0, 127: 0.75, 128: 0.75, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.0, 142: 0.75, 143: 0.25, 144: 0.5, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.5, 150: 0.25, 151: 0.5, 152: 0.25, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.25, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.0, 164: 0.5, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.5, 170: 0.75, 171: 0.0, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 0.75, 179: 1.0, 180: 0.25, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.0, 191: 0.25, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.25, 198: 0.0}

2024-10-08 16:54:57,298 [INFO] [7] TRAIN  loss: 1.733596192465888 acc: 0.5537534754402225
2024-10-08 16:54:57,298 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.733596192465888}
2024-10-08 16:54:57,299 [INFO] [7] VALIDATION loss: 1.8368680079778035 VALIDATION  acc: 0.5265151515151515
2024-10-08 16:54:57,299 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.8368680079778035}
2024-10-08 16:54:57,299 [INFO] 
2024-10-08 16:56:33,616 [INFO] Step[50/144]: training loss : 1.4414244043827056 TRAIN  loss dict:  {'classification_loss': 1.4414244043827056}
2024-10-08 16:57:43,764 [INFO] Step[100/144]: training loss : 1.4035274112224578 TRAIN  loss dict:  {'classification_loss': 1.4035274112224578}
2024-10-08 16:59:52,435 [INFO] Label accuracies statistics:
2024-10-08 16:59:52,436 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.5, 10: 0.75, 11: 1.0, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.25, 66: 0.0, 67: 0.25, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.25, 104: 0.5, 105: 0.5, 106: 0.75, 107: 1.0, 108: 0.25, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.0, 122: 0.25, 123: 0.75, 124: 1.0, 125: 0.25, 126: 0.5, 127: 0.5, 128: 0.75, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.25, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.0, 144: 0.75, 145: 0.75, 146: 0.5, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.25, 158: 0.3333333333333333, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.75, 165: 0.25, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.25, 170: 0.5, 171: 0.0, 172: 0.25, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.5, 182: 0.75, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.25, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-08 16:59:53,159 [INFO] [8] TRAIN  loss: 1.41238561934895 acc: 0.6478220574606117
2024-10-08 16:59:53,159 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.41238561934895}
2024-10-08 16:59:53,159 [INFO] [8] VALIDATION loss: 1.5995220277044508 VALIDATION  acc: 0.5833333333333334
2024-10-08 16:59:53,159 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.5995220277044508}
2024-10-08 16:59:53,159 [INFO] 
2024-10-08 17:01:29,083 [INFO] Step[50/144]: training loss : 1.1736515831947327 TRAIN  loss dict:  {'classification_loss': 1.1736515831947327}
2024-10-08 17:02:38,931 [INFO] Step[100/144]: training loss : 1.178615483045578 TRAIN  loss dict:  {'classification_loss': 1.178615483045578}
2024-10-08 17:04:48,317 [INFO] Label accuracies statistics:
2024-10-08 17:04:48,317 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.5, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.25, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.0, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.25, 71: 0.75, 72: 0.5, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.5, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.0, 122: 0.5, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.25, 142: 0.25, 143: 0.25, 144: 0.5, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.25, 166: 1.0, 167: 0.0, 168: 0.25, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 0.75, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-08 17:04:49,043 [INFO] [9] TRAIN  loss: 1.1816226065986686 acc: 0.6978683966635774
2024-10-08 17:04:49,043 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.1816226065986686}
2024-10-08 17:04:49,043 [INFO] [9] VALIDATION loss: 1.4730282282387768 VALIDATION  acc: 0.6111111111111112
2024-10-08 17:04:49,043 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.4730282282387768}
2024-10-08 17:04:49,043 [INFO] 
2024-10-08 17:06:24,942 [INFO] Step[50/144]: training loss : 0.9858632183074951 TRAIN  loss dict:  {'classification_loss': 0.9858632183074951}
2024-10-08 17:07:34,861 [INFO] Step[100/144]: training loss : 0.9991598320007324 TRAIN  loss dict:  {'classification_loss': 0.9991598320007324}
2024-10-08 17:09:42,358 [INFO] Label accuracies statistics:
2024-10-08 17:09:42,358 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.25, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.25, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 1.0, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.25, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.25, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.0, 159: 1.0, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.25, 169: 0.5, 170: 0.5, 171: 0.75, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 0.75, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 17:09:43,085 [INFO] [10] TRAIN  loss: 0.9960522970391644 acc: 0.7360982391102873
2024-10-08 17:09:43,086 [INFO] [10] TRAIN  loss dict: {'classification_loss': 0.9960522970391644}
2024-10-08 17:09:43,086 [INFO] [10] VALIDATION loss: 1.396445518290555 VALIDATION  acc: 0.6401515151515151
2024-10-08 17:09:43,086 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.396445518290555}
2024-10-08 17:09:43,086 [INFO] 
2024-10-08 17:11:19,266 [INFO] Step[50/144]: training loss : 0.8301840317249298 TRAIN  loss dict:  {'classification_loss': 0.8301840317249298}
2024-10-08 17:12:28,298 [INFO] Step[100/144]: training loss : 0.8091793662309646 TRAIN  loss dict:  {'classification_loss': 0.8091793662309646}
2024-10-08 17:14:36,942 [INFO] Label accuracies statistics:
2024-10-08 17:14:36,942 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.25, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.5, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.25, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.0, 123: 0.75, 124: 0.75, 125: 0.5, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.25, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.25, 197: 1.0, 198: 1.0}

2024-10-08 17:14:37,645 [INFO] [11] TRAIN  loss: 0.8263387655218443 acc: 0.7826691380908248
2024-10-08 17:14:37,645 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.8263387655218443}
2024-10-08 17:14:37,645 [INFO] [11] VALIDATION loss: 1.3054533391087144 VALIDATION  acc: 0.648989898989899
2024-10-08 17:14:37,645 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.3054533391087144}
2024-10-08 17:14:37,645 [INFO] 
2024-10-08 17:16:12,242 [INFO] Step[50/144]: training loss : 0.6730455356836319 TRAIN  loss dict:  {'classification_loss': 0.6730455356836319}
2024-10-08 17:17:23,848 [INFO] Step[100/144]: training loss : 0.6834355592727661 TRAIN  loss dict:  {'classification_loss': 0.6834355592727661}
2024-10-08 17:19:32,417 [INFO] Label accuracies statistics:
2024-10-08 17:19:32,417 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.0, 72: 0.25, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.25, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.25, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 0.5, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-08 17:19:33,144 [INFO] [12] TRAIN  loss: 0.6793672179596292 acc: 0.8301668211306765
2024-10-08 17:19:33,144 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.6793672179596292}
2024-10-08 17:19:33,145 [INFO] [12] VALIDATION loss: 1.2993677589628432 VALIDATION  acc: 0.6515151515151515
2024-10-08 17:19:33,145 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.2993677589628432}
2024-10-08 17:19:33,145 [INFO] 
2024-10-08 17:21:09,024 [INFO] Step[50/144]: training loss : 0.581146069765091 TRAIN  loss dict:  {'classification_loss': 0.581146069765091}
2024-10-08 17:22:20,067 [INFO] Step[100/144]: training loss : 0.5992323297262192 TRAIN  loss dict:  {'classification_loss': 0.5992323297262192}
2024-10-08 17:24:28,119 [INFO] Label accuracies statistics:
2024-10-08 17:24:28,119 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.5, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.0, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.25, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.25, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.0, 146: 1.0, 147: 0.75, 148: 0.75, 149: 0.75, 150: 1.0, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.25, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.75, 165: 0.25, 166: 0.5, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.0, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-08 17:24:28,797 [INFO] [13] TRAIN  loss: 0.5937050388505062 acc: 0.8500926784059314
2024-10-08 17:24:28,797 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.5937050388505062}
2024-10-08 17:24:28,797 [INFO] [13] VALIDATION loss: 1.2710563628761857 VALIDATION  acc: 0.6679292929292929
2024-10-08 17:24:28,797 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.2710563628761857}
2024-10-08 17:24:28,798 [INFO] 
2024-10-08 17:26:03,259 [INFO] Step[50/144]: training loss : 0.5118164363503456 TRAIN  loss dict:  {'classification_loss': 0.5118164363503456}
2024-10-08 17:27:15,806 [INFO] Step[100/144]: training loss : 0.527234650850296 TRAIN  loss dict:  {'classification_loss': 0.527234650850296}
2024-10-08 17:29:23,324 [INFO] Label accuracies statistics:
2024-10-08 17:29:23,324 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.5, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 1.0, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.5, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.25, 145: 1.0, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.25, 161: 0.5, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.25, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-08 17:29:24,079 [INFO] [14] TRAIN  loss: 0.5298387485866746 acc: 0.8677015755329008
2024-10-08 17:29:24,079 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.5298387485866746}
2024-10-08 17:29:24,079 [INFO] [14] VALIDATION loss: 1.1748453533207928 VALIDATION  acc: 0.6578282828282829
2024-10-08 17:29:24,079 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.1748453533207928}
2024-10-08 17:29:24,079 [INFO] 
2024-10-08 17:31:00,453 [INFO] Step[50/144]: training loss : 0.43913324296474454 TRAIN  loss dict:  {'classification_loss': 0.43913324296474454}
2024-10-08 17:32:09,525 [INFO] Step[100/144]: training loss : 0.45011839985847474 TRAIN  loss dict:  {'classification_loss': 0.45011839985847474}
2024-10-08 17:34:17,965 [INFO] Label accuracies statistics:
2024-10-08 17:34:17,966 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.5, 37: 0.5, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.5, 145: 1.0, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.5, 198: 0.25}

2024-10-08 17:34:18,688 [INFO] [15] TRAIN  loss: 0.45189844516830313 acc: 0.8846153846153846
2024-10-08 17:34:18,688 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.45189844516830313}
2024-10-08 17:34:18,689 [INFO] [15] VALIDATION loss: 1.1161810435630657 VALIDATION  acc: 0.7007575757575758
2024-10-08 17:34:18,689 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.1161810435630657}
2024-10-08 17:34:18,689 [INFO] 
2024-10-08 17:35:54,338 [INFO] Step[50/144]: training loss : 0.40517143547534945 TRAIN  loss dict:  {'classification_loss': 0.40517143547534945}
2024-10-08 17:37:04,934 [INFO] Step[100/144]: training loss : 0.40467790722846986 TRAIN  loss dict:  {'classification_loss': 0.40467790722846986}
2024-10-08 17:39:12,225 [INFO] Label accuracies statistics:
2024-10-08 17:39:12,225 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.0, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.75, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.75, 122: 0.75, 123: 0.75, 124: 0.5, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 0.5, 140: 1.0, 141: 0.5, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 0.75, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.25, 166: 1.0, 167: 0.25, 168: 0.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.5, 198: 0.75}

2024-10-08 17:39:12,310 [INFO] [16] TRAIN  loss: 0.4215125698182318 acc: 0.8906394810009268
2024-10-08 17:39:12,310 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.4215125698182318}
2024-10-08 17:39:12,310 [INFO] [16] VALIDATION loss: 1.1828810263563085 VALIDATION  acc: 0.6578282828282829
2024-10-08 17:39:12,310 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.1828810263563085}
2024-10-08 17:39:12,311 [INFO] 
2024-10-08 17:40:47,856 [INFO] Step[50/144]: training loss : 0.3804003068804741 TRAIN  loss dict:  {'classification_loss': 0.3804003068804741}
2024-10-08 17:41:56,924 [INFO] Step[100/144]: training loss : 0.3563078185915947 TRAIN  loss dict:  {'classification_loss': 0.3563078185915947}
2024-10-08 17:44:05,208 [INFO] Label accuracies statistics:
2024-10-08 17:44:05,208 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.75, 67: 0.25, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.5, 92: 1.0, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.75, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.0, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.5, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-08 17:44:05,302 [INFO] [17] TRAIN  loss: 0.3816094296053052 acc: 0.9024559777571826
2024-10-08 17:44:05,302 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.3816094296053052}
2024-10-08 17:44:05,303 [INFO] [17] VALIDATION loss: 1.2453076817371227 VALIDATION  acc: 0.6944444444444444
2024-10-08 17:44:05,303 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.2453076817371227}
2024-10-08 17:44:05,303 [INFO] 
2024-10-08 17:45:40,841 [INFO] Step[50/144]: training loss : 0.2989167940616608 TRAIN  loss dict:  {'classification_loss': 0.2989167940616608}
2024-10-08 17:46:52,332 [INFO] Step[100/144]: training loss : 0.37102143168449403 TRAIN  loss dict:  {'classification_loss': 0.37102143168449403}
2024-10-08 17:49:00,229 [INFO] Label accuracies statistics:
2024-10-08 17:49:00,229 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.25, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.5, 198: 0.75}

2024-10-08 17:49:00,313 [INFO] [18] TRAIN  loss: 0.3413164857774973 acc: 0.9107970342910102
2024-10-08 17:49:00,313 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.3413164857774973}
2024-10-08 17:49:00,313 [INFO] [18] VALIDATION loss: 1.124057009264275 VALIDATION  acc: 0.6818181818181818
2024-10-08 17:49:00,313 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.124057009264275}
2024-10-08 17:49:00,313 [INFO] 
2024-10-08 17:50:36,409 [INFO] Step[50/144]: training loss : 0.31205531150102617 TRAIN  loss dict:  {'classification_loss': 0.31205531150102617}
2024-10-08 17:51:46,633 [INFO] Step[100/144]: training loss : 0.2952918536961079 TRAIN  loss dict:  {'classification_loss': 0.2952918536961079}
2024-10-08 17:53:55,683 [INFO] Label accuracies statistics:
2024-10-08 17:53:55,683 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.5, 143: 0.5, 144: 0.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.0, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-08 17:53:56,362 [INFO] [19] TRAIN  loss: 0.30341932943297756 acc: 0.9274791473586654
2024-10-08 17:53:56,362 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.30341932943297756}
2024-10-08 17:53:56,362 [INFO] [19] VALIDATION loss: 1.049166519332815 VALIDATION  acc: 0.7184343434343434
2024-10-08 17:53:56,362 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.049166519332815}
2024-10-08 17:53:56,362 [INFO] 
2024-10-08 17:55:31,191 [INFO] Step[50/144]: training loss : 0.27187076687812806 TRAIN  loss dict:  {'classification_loss': 0.27187076687812806}
2024-10-08 17:56:42,636 [INFO] Step[100/144]: training loss : 0.2691695731878281 TRAIN  loss dict:  {'classification_loss': 0.2691695731878281}
2024-10-08 17:58:50,343 [INFO] Label accuracies statistics:
2024-10-08 17:58:50,343 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.0, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.25, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.25, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.75}

2024-10-08 17:58:50,434 [INFO] [20] TRAIN  loss: 0.2713569681574073 acc: 0.9297961075069509
2024-10-08 17:58:50,434 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.2713569681574073}
2024-10-08 17:58:50,434 [INFO] [20] VALIDATION loss: 1.091613426528595 VALIDATION  acc: 0.6881313131313131
2024-10-08 17:58:50,434 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.091613426528595}
2024-10-08 17:58:50,434 [INFO] 
2024-10-08 18:00:25,109 [INFO] Step[50/144]: training loss : 0.2059568466246128 TRAIN  loss dict:  {'classification_loss': 0.2059568466246128}
2024-10-08 18:01:37,265 [INFO] Step[100/144]: training loss : 0.21859572753310202 TRAIN  loss dict:  {'classification_loss': 0.21859572753310202}
2024-10-08 18:03:44,390 [INFO] Label accuracies statistics:
2024-10-08 18:03:44,390 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 1.0, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.5, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.5, 198: 0.75}

2024-10-08 18:03:45,071 [INFO] [21] TRAIN  loss: 0.2177876671258774 acc: 0.9492585727525487
2024-10-08 18:03:45,071 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.2177876671258774}
2024-10-08 18:03:45,071 [INFO] [21] VALIDATION loss: 1.0128269399757739 VALIDATION  acc: 0.7196969696969697
2024-10-08 18:03:45,072 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.0128269399757739}
2024-10-08 18:03:45,072 [INFO] 
2024-10-08 18:05:20,029 [INFO] Step[50/144]: training loss : 0.1768386769294739 TRAIN  loss dict:  {'classification_loss': 0.1768386769294739}
2024-10-08 18:06:31,577 [INFO] Step[100/144]: training loss : 0.18924308121204375 TRAIN  loss dict:  {'classification_loss': 0.18924308121204375}
2024-10-08 18:08:38,589 [INFO] Label accuracies statistics:
2024-10-08 18:08:38,590 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.25, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 0.5, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.25, 197: 0.5, 198: 0.5}

2024-10-08 18:08:38,682 [INFO] [22] TRAIN  loss: 0.18887012808894119 acc: 0.9529657089898054
2024-10-08 18:08:38,682 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.18887012808894119}
2024-10-08 18:08:38,682 [INFO] [22] VALIDATION loss: 1.044762009271869 VALIDATION  acc: 0.7070707070707071
2024-10-08 18:08:38,682 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.044762009271869}
2024-10-08 18:08:38,682 [INFO] 
2024-10-08 18:10:13,122 [INFO] Step[50/144]: training loss : 0.1750227464735508 TRAIN  loss dict:  {'classification_loss': 0.1750227464735508}
2024-10-08 18:11:23,751 [INFO] Step[100/144]: training loss : 0.19041435286402703 TRAIN  loss dict:  {'classification_loss': 0.19041435286402703}
2024-10-08 18:13:31,067 [INFO] Label accuracies statistics:
2024-10-08 18:13:31,067 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 1.0, 182: 0.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.75, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-08 18:13:31,761 [INFO] [23] TRAIN  loss: 0.18973973926363719 acc: 0.9529657089898054
2024-10-08 18:13:31,761 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.18973973926363719}
2024-10-08 18:13:31,761 [INFO] [23] VALIDATION loss: 1.0007210197272125 VALIDATION  acc: 0.73989898989899
2024-10-08 18:13:31,761 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.0007210197272125}
2024-10-08 18:13:31,762 [INFO] 
2024-10-08 18:15:07,974 [INFO] Step[50/144]: training loss : 0.16516074366867542 TRAIN  loss dict:  {'classification_loss': 0.16516074366867542}
2024-10-08 18:16:18,115 [INFO] Step[100/144]: training loss : 0.17331718303263188 TRAIN  loss dict:  {'classification_loss': 0.17331718303263188}
2024-10-08 18:18:24,921 [INFO] Label accuracies statistics:
2024-10-08 18:18:24,921 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 1.0}

2024-10-08 18:18:25,596 [INFO] [24] TRAIN  loss: 0.17408082727342844 acc: 0.9585264133456904
2024-10-08 18:18:25,596 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.17408082727342844}
2024-10-08 18:18:25,596 [INFO] [24] VALIDATION loss: 0.9570712254003242 VALIDATION  acc: 0.7424242424242424
2024-10-08 18:18:25,596 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 0.9570712254003242}
2024-10-08 18:18:25,596 [INFO] 
2024-10-08 18:19:59,349 [INFO] Step[50/144]: training loss : 0.13456341564655305 TRAIN  loss dict:  {'classification_loss': 0.13456341564655305}
2024-10-08 18:21:10,706 [INFO] Step[100/144]: training loss : 0.15244515903294087 TRAIN  loss dict:  {'classification_loss': 0.15244515903294087}
2024-10-08 18:23:16,671 [INFO] Label accuracies statistics:
2024-10-08 18:23:16,671 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.25, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 0.75, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.75}

2024-10-08 18:23:16,755 [INFO] [25] TRAIN  loss: 0.15109190321527421 acc: 0.9682576459684893
2024-10-08 18:23:16,755 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.15109190321527421}
2024-10-08 18:23:16,755 [INFO] [25] VALIDATION loss: 1.0307578830807298 VALIDATION  acc: 0.7171717171717171
2024-10-08 18:23:16,755 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.0307578830807298}
2024-10-08 18:23:16,756 [INFO] 
2024-10-08 18:24:51,411 [INFO] Step[50/144]: training loss : 0.13982034131884574 TRAIN  loss dict:  {'classification_loss': 0.13982034131884574}
2024-10-08 18:26:02,760 [INFO] Step[100/144]: training loss : 0.15936803825199605 TRAIN  loss dict:  {'classification_loss': 0.15936803825199605}
2024-10-08 18:28:09,140 [INFO] Label accuracies statistics:
2024-10-08 18:28:09,140 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.0, 95: 0.75, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-08 18:28:09,238 [INFO] [26] TRAIN  loss: 0.15236739941044813 acc: 0.9629286376274329
2024-10-08 18:28:09,239 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.15236739941044813}
2024-10-08 18:28:09,239 [INFO] [26] VALIDATION loss: 1.0607015716808814 VALIDATION  acc: 0.7335858585858586
2024-10-08 18:28:09,239 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.0607015716808814}
2024-10-08 18:28:09,239 [INFO] 
2024-10-08 18:29:46,112 [INFO] Step[50/144]: training loss : 0.1359567327797413 TRAIN  loss dict:  {'classification_loss': 0.1359567327797413}
2024-10-08 18:30:56,886 [INFO] Step[100/144]: training loss : 0.1367974515259266 TRAIN  loss dict:  {'classification_loss': 0.1367974515259266}
2024-10-08 18:33:03,702 [INFO] Label accuracies statistics:
2024-10-08 18:33:03,702 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.75, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.25, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 1.0, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.25, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.0, 120: 0.5, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.5, 166: 1.0, 167: 1.0, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.5, 178: 0.75, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.0, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 18:33:03,794 [INFO] [27] TRAIN  loss: 0.14342594304535952 acc: 0.9661723818350324
2024-10-08 18:33:03,794 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.14342594304535952}
2024-10-08 18:33:03,794 [INFO] [27] VALIDATION loss: 1.0570569811043915 VALIDATION  acc: 0.7285353535353535
2024-10-08 18:33:03,794 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.0570569811043915}
2024-10-08 18:33:03,795 [INFO] 
2024-10-08 18:34:38,943 [INFO] Step[50/144]: training loss : 0.10965763308107852 TRAIN  loss dict:  {'classification_loss': 0.10965763308107852}
2024-10-08 18:35:50,636 [INFO] Step[100/144]: training loss : 0.12656745553016663 TRAIN  loss dict:  {'classification_loss': 0.12656745553016663}
2024-10-08 18:37:56,030 [INFO] Label accuracies statistics:
2024-10-08 18:37:56,030 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 1.0, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.25, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-08 18:37:56,134 [INFO] [28] TRAIN  loss: 0.12210513974746896 acc: 0.9698795180722891
2024-10-08 18:37:56,134 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.12210513974746896}
2024-10-08 18:37:56,135 [INFO] [28] VALIDATION loss: 1.0552335690568995 VALIDATION  acc: 0.7196969696969697
2024-10-08 18:37:56,135 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.0552335690568995}
2024-10-08 18:37:56,135 [INFO] 
2024-10-08 18:39:31,700 [INFO] Step[50/144]: training loss : 0.1222723126411438 TRAIN  loss dict:  {'classification_loss': 0.1222723126411438}
2024-10-08 18:40:42,838 [INFO] Step[100/144]: training loss : 0.1276867888867855 TRAIN  loss dict:  {'classification_loss': 0.1276867888867855}
2024-10-08 18:42:50,077 [INFO] Label accuracies statistics:
2024-10-08 18:42:50,077 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.25, 198: 0.25}

2024-10-08 18:42:50,164 [INFO] [29] TRAIN  loss: 0.1266139313682086 acc: 0.968952734012975
2024-10-08 18:42:50,164 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.1266139313682086}
2024-10-08 18:42:50,164 [INFO] [29] VALIDATION loss: 1.103276322837229 VALIDATION  acc: 0.7159090909090909
2024-10-08 18:42:50,165 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.103276322837229}
2024-10-08 18:42:50,165 [INFO] 
2024-10-08 18:44:25,516 [INFO] Step[50/144]: training loss : 0.10991694506257772 TRAIN  loss dict:  {'classification_loss': 0.10991694506257772}
2024-10-08 18:45:38,763 [INFO] Step[100/144]: training loss : 0.10685295760631561 TRAIN  loss dict:  {'classification_loss': 0.10685295760631561}
2024-10-08 18:47:45,057 [INFO] Label accuracies statistics:
2024-10-08 18:47:45,058 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.5, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 0.75, 136: 0.75, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 1.0, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-08 18:47:45,146 [INFO] [30] TRAIN  loss: 0.11840754844403516 acc: 0.9726598702502317
2024-10-08 18:47:45,146 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.11840754844403516}
2024-10-08 18:47:45,146 [INFO] [30] VALIDATION loss: 1.0945609901790265 VALIDATION  acc: 0.7348484848484849
2024-10-08 18:47:45,146 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.0945609901790265}
2024-10-08 18:47:45,146 [INFO] 
2024-10-08 18:49:19,763 [INFO] Step[50/144]: training loss : 0.11489503417164088 TRAIN  loss dict:  {'classification_loss': 0.11489503417164088}
2024-10-08 18:50:32,058 [INFO] Step[100/144]: training loss : 0.09336377251893282 TRAIN  loss dict:  {'classification_loss': 0.09336377251893282}
2024-10-08 18:52:37,626 [INFO] Label accuracies statistics:
2024-10-08 18:52:37,626 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.0, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.75}

2024-10-08 18:52:37,721 [INFO] [31] TRAIN  loss: 0.10416524929718839 acc: 0.9761353104726599
2024-10-08 18:52:37,721 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.10416524929718839}
2024-10-08 18:52:37,722 [INFO] [31] VALIDATION loss: 0.9998536882577119 VALIDATION  acc: 0.7373737373737373
2024-10-08 18:52:37,722 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 0.9998536882577119}
2024-10-08 18:52:37,722 [INFO] 
2024-10-08 18:54:13,395 [INFO] Step[50/144]: training loss : 0.08821093671023846 TRAIN  loss dict:  {'classification_loss': 0.08821093671023846}
2024-10-08 18:55:23,211 [INFO] Step[100/144]: training loss : 0.08720641549676657 TRAIN  loss dict:  {'classification_loss': 0.08720641549676657}
2024-10-08 18:57:30,109 [INFO] Label accuracies statistics:
2024-10-08 18:57:30,109 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.75}

2024-10-08 18:57:30,217 [INFO] [32] TRAIN  loss: 0.08835640041312824 acc: 0.9798424467099166
2024-10-08 18:57:30,217 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.08835640041312824}
2024-10-08 18:57:30,217 [INFO] [32] VALIDATION loss: 1.018403526533533 VALIDATION  acc: 0.7487373737373737
2024-10-08 18:57:30,217 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.018403526533533}
2024-10-08 18:57:30,217 [INFO] 
2024-10-08 18:59:05,285 [INFO] Step[50/144]: training loss : 0.07317999437451363 TRAIN  loss dict:  {'classification_loss': 0.07317999437451363}
2024-10-08 19:00:16,217 [INFO] Step[100/144]: training loss : 0.0856388746201992 TRAIN  loss dict:  {'classification_loss': 0.0856388746201992}
2024-10-08 19:02:22,501 [INFO] Label accuracies statistics:
2024-10-08 19:02:22,502 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-08 19:02:22,596 [INFO] [33] TRAIN  loss: 0.0810661521455687 acc: 0.9823911028730306
2024-10-08 19:02:22,596 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.0810661521455687}
2024-10-08 19:02:22,596 [INFO] [33] VALIDATION loss: 0.9839627709653642 VALIDATION  acc: 0.7525252525252525
2024-10-08 19:02:22,596 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 0.9839627709653642}
2024-10-08 19:02:22,596 [INFO] 
2024-10-08 19:03:58,729 [INFO] Step[50/144]: training loss : 0.06600972037762404 TRAIN  loss dict:  {'classification_loss': 0.06600972037762404}
2024-10-08 19:05:09,649 [INFO] Step[100/144]: training loss : 0.08527463709935545 TRAIN  loss dict:  {'classification_loss': 0.08527463709935545}
2024-10-08 19:07:16,286 [INFO] Label accuracies statistics:
2024-10-08 19:07:16,286 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 19:07:16,961 [INFO] [34] TRAIN  loss: 0.0762603292047667 acc: 0.9837812789620018
2024-10-08 19:07:16,961 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.0762603292047667}
2024-10-08 19:07:16,961 [INFO] [34] VALIDATION loss: 0.9276775891582171 VALIDATION  acc: 0.7651515151515151
2024-10-08 19:07:16,961 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 0.9276775891582171}
2024-10-08 19:07:16,961 [INFO] 
2024-10-08 19:08:52,751 [INFO] Step[50/144]: training loss : 0.07562478225678206 TRAIN  loss dict:  {'classification_loss': 0.07562478225678206}
2024-10-08 19:10:05,169 [INFO] Step[100/144]: training loss : 0.08554892215877771 TRAIN  loss dict:  {'classification_loss': 0.08554892215877771}
2024-10-08 19:12:11,118 [INFO] Label accuracies statistics:
2024-10-08 19:12:11,118 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.5, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.25, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.3333333333333333, 159: 1.0, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-08 19:12:11,198 [INFO] [35] TRAIN  loss: 0.08474969627180447 acc: 0.9798424467099166
2024-10-08 19:12:11,198 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.08474969627180447}
2024-10-08 19:12:11,198 [INFO] [35] VALIDATION loss: 1.0553792432226516 VALIDATION  acc: 0.73989898989899
2024-10-08 19:12:11,198 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.0553792432226516}
2024-10-08 19:12:11,198 [INFO] 
2024-10-08 19:13:46,168 [INFO] Step[50/144]: training loss : 0.06760251658037304 TRAIN  loss dict:  {'classification_loss': 0.06760251658037304}
2024-10-08 19:14:56,992 [INFO] Step[100/144]: training loss : 0.07722412344068288 TRAIN  loss dict:  {'classification_loss': 0.07722412344068288}
2024-10-08 19:17:04,191 [INFO] Label accuracies statistics:
2024-10-08 19:17:04,191 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.25, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 1.0, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 19:17:04,277 [INFO] [36] TRAIN  loss: 0.07130060659902585 acc: 0.9830861909175163
2024-10-08 19:17:04,277 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.07130060659902585}
2024-10-08 19:17:04,277 [INFO] [36] VALIDATION loss: 1.0273312871102933 VALIDATION  acc: 0.7411616161616161
2024-10-08 19:17:04,277 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.0273312871102933}
2024-10-08 19:17:04,277 [INFO] 
2024-10-08 19:18:38,518 [INFO] Step[50/144]: training loss : 0.07103985194116831 TRAIN  loss dict:  {'classification_loss': 0.07103985194116831}
2024-10-08 19:19:44,871 [INFO] Step[100/144]: training loss : 0.06531702063977718 TRAIN  loss dict:  {'classification_loss': 0.06531702063977718}
2024-10-08 19:21:51,065 [INFO] Label accuracies statistics:
2024-10-08 19:21:51,065 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 1.0, 165: 0.5, 166: 1.0, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-08 19:21:51,146 [INFO] [37] TRAIN  loss: 0.06895698784177916 acc: 0.9849397590361446
2024-10-08 19:21:51,146 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.06895698784177916}
2024-10-08 19:21:51,147 [INFO] [37] VALIDATION loss: 0.9840476374935221 VALIDATION  acc: 0.7575757575757576
2024-10-08 19:21:51,147 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 0.9840476374935221}
2024-10-08 19:21:51,147 [INFO] 
2024-10-08 19:23:27,480 [INFO] Step[50/144]: training loss : 0.07060767345130443 TRAIN  loss dict:  {'classification_loss': 0.07060767345130443}
2024-10-08 19:24:38,213 [INFO] Step[100/144]: training loss : 0.07300957217812538 TRAIN  loss dict:  {'classification_loss': 0.07300957217812538}
2024-10-08 19:26:45,841 [INFO] Label accuracies statistics:
2024-10-08 19:26:45,841 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 1.0, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.25}

2024-10-08 19:26:45,923 [INFO] [38] TRAIN  loss: 0.07325312783682926 acc: 0.9828544949026877
2024-10-08 19:26:45,923 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.07325312783682926}
2024-10-08 19:26:45,923 [INFO] [38] VALIDATION loss: 1.0817087441682816 VALIDATION  acc: 0.7348484848484849
2024-10-08 19:26:45,923 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.0817087441682816}
2024-10-08 19:26:45,923 [INFO] 
2024-10-08 19:28:26,805 [INFO] Step[50/144]: training loss : 0.059314912799745795 TRAIN  loss dict:  {'classification_loss': 0.059314912799745795}
2024-10-08 19:29:40,897 [INFO] Step[100/144]: training loss : 0.0669309114664793 TRAIN  loss dict:  {'classification_loss': 0.0669309114664793}
2024-10-08 19:31:50,621 [INFO] Label accuracies statistics:
2024-10-08 19:31:50,622 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 1.0, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-08 19:31:50,704 [INFO] [39] TRAIN  loss: 0.06086205146534161 acc: 0.98725671918443
2024-10-08 19:31:50,704 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.06086205146534161}
2024-10-08 19:31:50,704 [INFO] [39] VALIDATION loss: 1.0392808069785435 VALIDATION  acc: 0.7487373737373737
2024-10-08 19:31:50,704 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.0392808069785435}
2024-10-08 19:31:50,704 [INFO] 
2024-10-08 19:33:31,639 [INFO] Step[50/144]: training loss : 0.05473693741485477 TRAIN  loss dict:  {'classification_loss': 0.05473693741485477}
2024-10-08 19:34:46,857 [INFO] Step[100/144]: training loss : 0.07481567226350308 TRAIN  loss dict:  {'classification_loss': 0.07481567226350308}
2024-10-08 19:36:57,802 [INFO] Label accuracies statistics:
2024-10-08 19:36:57,803 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 1.0, 167: 0.25, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 19:36:57,904 [INFO] [40] TRAIN  loss: 0.06587617381915657 acc: 0.9858665430954587
2024-10-08 19:36:57,904 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.06587617381915657}
2024-10-08 19:36:57,905 [INFO] [40] VALIDATION loss: 1.0011674325775217 VALIDATION  acc: 0.7537878787878788
2024-10-08 19:36:57,905 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.0011674325775217}
2024-10-08 19:36:57,905 [INFO] 
2024-10-08 19:38:39,939 [INFO] Step[50/144]: training loss : 0.04829149654135108 TRAIN  loss dict:  {'classification_loss': 0.04829149654135108}
2024-10-08 19:39:54,538 [INFO] Step[100/144]: training loss : 0.05120267398655415 TRAIN  loss dict:  {'classification_loss': 0.05120267398655415}
2024-10-08 19:42:04,470 [INFO] Label accuracies statistics:
2024-10-08 19:42:04,471 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 19:42:04,556 [INFO] [41] TRAIN  loss: 0.04822943900944665 acc: 0.989805375347544
2024-10-08 19:42:04,556 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.04822943900944665}
2024-10-08 19:42:04,556 [INFO] [41] VALIDATION loss: 0.9359014857974317 VALIDATION  acc: 0.7878787878787878
2024-10-08 19:42:04,556 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 0.9359014857974317}
2024-10-08 19:42:04,556 [INFO] 
2024-10-08 19:43:45,745 [INFO] Step[50/144]: training loss : 0.04536865590140224 TRAIN  loss dict:  {'classification_loss': 0.04536865590140224}
2024-10-08 19:44:59,482 [INFO] Step[100/144]: training loss : 0.04480698905885219 TRAIN  loss dict:  {'classification_loss': 0.04480698905885219}
2024-10-08 19:47:10,896 [INFO] Label accuracies statistics:
2024-10-08 19:47:10,896 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.75, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-08 19:47:10,988 [INFO] [42] TRAIN  loss: 0.046650390315335244 acc: 0.9900370713623726
2024-10-08 19:47:10,988 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.046650390315335244}
2024-10-08 19:47:10,988 [INFO] [42] VALIDATION loss: 0.9914938534299532 VALIDATION  acc: 0.7563131313131313
2024-10-08 19:47:10,988 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 0.9914938534299532}
2024-10-08 19:47:10,988 [INFO] 
2024-10-08 19:48:52,688 [INFO] Step[50/144]: training loss : 0.04328892985358834 TRAIN  loss dict:  {'classification_loss': 0.04328892985358834}
2024-10-08 19:50:07,349 [INFO] Step[100/144]: training loss : 0.06351329639554024 TRAIN  loss dict:  {'classification_loss': 0.06351329639554024}
2024-10-08 19:52:18,953 [INFO] Label accuracies statistics:
2024-10-08 19:52:18,953 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.0, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 19:52:19,048 [INFO] [43] TRAIN  loss: 0.05113348124885104 acc: 0.9884151992585728
2024-10-08 19:52:19,048 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.05113348124885104}
2024-10-08 19:52:19,048 [INFO] [43] VALIDATION loss: 1.1130981813702319 VALIDATION  acc: 0.7285353535353535
2024-10-08 19:52:19,048 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.1130981813702319}
2024-10-08 19:52:19,049 [INFO] 
2024-10-08 19:54:01,745 [INFO] Step[50/144]: training loss : 0.06048851724714041 TRAIN  loss dict:  {'classification_loss': 0.06048851724714041}
2024-10-08 19:55:14,877 [INFO] Step[100/144]: training loss : 0.05454730253666639 TRAIN  loss dict:  {'classification_loss': 0.05454730253666639}
2024-10-08 19:57:06,413 [INFO] Label accuracies statistics:
2024-10-08 19:57:06,413 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 1.0, 6: 1.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 1.0, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 19:57:06,486 [INFO] [44] TRAIN  loss: 0.04884728189143869 acc: 0.9902687673772012
2024-10-08 19:57:06,486 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.04884728189143869}
2024-10-08 19:57:06,486 [INFO] [44] VALIDATION loss: 0.9839028608467844 VALIDATION  acc: 0.7563131313131313
2024-10-08 19:57:06,486 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 0.9839028608467844}
2024-10-08 19:57:06,486 [INFO] 
2024-10-08 19:58:26,548 [INFO] Step[50/144]: training loss : 0.046791107784956695 TRAIN  loss dict:  {'classification_loss': 0.046791107784956695}
2024-10-08 19:59:22,755 [INFO] Step[100/144]: training loss : 0.04243816383183002 TRAIN  loss dict:  {'classification_loss': 0.04243816383183002}
2024-10-08 20:01:02,099 [INFO] Label accuracies statistics:
2024-10-08 20:01:02,100 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-08 20:01:02,172 [INFO] [45] TRAIN  loss: 0.04464043527453517 acc: 0.9902687673772012
2024-10-08 20:01:02,172 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.04464043527453517}
2024-10-08 20:01:02,172 [INFO] [45] VALIDATION loss: 1.0368388720132686 VALIDATION  acc: 0.7563131313131313
2024-10-08 20:01:02,172 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.0368388720132686}
2024-10-08 20:01:02,172 [INFO] 
2024-10-08 20:02:21,429 [INFO] Step[50/144]: training loss : 0.03846034750342369 TRAIN  loss dict:  {'classification_loss': 0.03846034750342369}
2024-10-08 20:03:18,225 [INFO] Step[100/144]: training loss : 0.04226848199032247 TRAIN  loss dict:  {'classification_loss': 0.04226848199032247}
2024-10-08 20:04:58,213 [INFO] Label accuracies statistics:
2024-10-08 20:04:58,213 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 1.0, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.0, 122: 0.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 20:04:58,283 [INFO] [46] TRAIN  loss: 0.044044274147987984 acc: 0.9891102873030584
2024-10-08 20:04:58,283 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.044044274147987984}
2024-10-08 20:04:58,284 [INFO] [46] VALIDATION loss: 1.055222052114981 VALIDATION  acc: 0.7386363636363636
2024-10-08 20:04:58,284 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.055222052114981}
2024-10-08 20:04:58,284 [INFO] 
2024-10-08 20:06:18,531 [INFO] Step[50/144]: training loss : 0.0336903103813529 TRAIN  loss dict:  {'classification_loss': 0.0336903103813529}
2024-10-08 20:07:15,970 [INFO] Step[100/144]: training loss : 0.036563713969662785 TRAIN  loss dict:  {'classification_loss': 0.036563713969662785}
2024-10-08 20:08:56,939 [INFO] Label accuracies statistics:
2024-10-08 20:08:56,939 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-08 20:08:57,010 [INFO] [47] TRAIN  loss: 0.03742130114308869 acc: 0.9939759036144579
2024-10-08 20:08:57,011 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.03742130114308869}
2024-10-08 20:08:57,011 [INFO] [47] VALIDATION loss: 1.015989060824116 VALIDATION  acc: 0.7474747474747475
2024-10-08 20:08:57,011 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.015989060824116}
2024-10-08 20:08:57,011 [INFO] 
2024-10-08 20:10:17,413 [INFO] Step[50/144]: training loss : 0.035595482089556756 TRAIN  loss dict:  {'classification_loss': 0.035595482089556756}
2024-10-08 20:11:14,763 [INFO] Step[100/144]: training loss : 0.03618849794380367 TRAIN  loss dict:  {'classification_loss': 0.03618849794380367}
2024-10-08 20:13:10,915 [INFO] Label accuracies statistics:
2024-10-08 20:13:10,915 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.5, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-08 20:13:10,986 [INFO] [48] TRAIN  loss: 0.042973124863541066 acc: 0.9881835032437442
2024-10-08 20:13:10,986 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.042973124863541066}
2024-10-08 20:13:10,986 [INFO] [48] VALIDATION loss: 1.1369772269218057 VALIDATION  acc: 0.7310606060606061
2024-10-08 20:13:10,986 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.1369772269218057}
2024-10-08 20:13:10,986 [INFO] 
2024-10-08 20:14:31,098 [INFO] Step[50/144]: training loss : 0.030134802497923375 TRAIN  loss dict:  {'classification_loss': 0.030134802497923375}
2024-10-08 20:15:28,306 [INFO] Step[100/144]: training loss : 0.0314210250787437 TRAIN  loss dict:  {'classification_loss': 0.0314210250787437}
2024-10-08 20:17:09,399 [INFO] Label accuracies statistics:
2024-10-08 20:17:09,399 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-08 20:17:09,471 [INFO] [49] TRAIN  loss: 0.0319652580203385 acc: 0.9946709916589435
2024-10-08 20:17:09,471 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.0319652580203385}
2024-10-08 20:17:09,472 [INFO] [49] VALIDATION loss: 1.0676635645881847 VALIDATION  acc: 0.7436868686868687
2024-10-08 20:17:09,472 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.0676635645881847}
2024-10-08 20:17:09,472 [INFO] 
2024-10-08 20:17:09,472 [INFO] 

***Stop training***


2024-10-08 20:17:09,472 [INFO] 
Testing checkpointed models starting...

2024-10-08 20:17:53,554 [INFO] Label accuracies statistics:
2024-10-08 20:17:53,555 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.0, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 1.0, 15: 0.5, 16: 1.0, 17: 1.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.5, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.5, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 1.0, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.25, 84: 1.0, 85: 0.75, 86: 0.5, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.25, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.5, 116: 0.75, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.6666666666666666, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.25, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.25, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.75, 168: 0.75, 169: 0.25, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.5, 174: 1.0, 175: 0.5, 176: 1.0, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.5, 184: 0.0, 185: 1.0, 186: 1.0, 187: 0.75, 188: 0.25, 189: 1.0, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.25, 198: 0.5}

2024-10-08 20:17:53,621 [INFO] 
Testing accuracy: 0.7724399494310998
