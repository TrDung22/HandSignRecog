2024-10-09 12:19:34,939 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 768 gcn features vsl for one view (1024 + 768 attention)...


2024-10-09 12:21:15,741 [INFO] Step[50/144]: training loss : 6.074664535522461 TRAIN  loss dict:  {'classification_loss': 6.074664535522461}
2024-10-09 12:22:17,175 [INFO] Step[100/144]: training loss : 5.518559055328369 TRAIN  loss dict:  {'classification_loss': 5.518559055328369}
2024-10-09 12:24:28,610 [INFO] Label accuracies statistics:
2024-10-09 12:24:28,610 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.5, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 1.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.75, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-09 12:24:29,490 [INFO] [1] TRAIN  loss: 5.695886250999239 acc: 0.0037071362372567192
2024-10-09 12:24:29,490 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.695886250999239}
2024-10-09 12:24:29,490 [INFO] [1] VALIDATION loss: 5.362407737308079 VALIDATION  acc: 0.011363636363636364
2024-10-09 12:24:29,490 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.362407737308079}
2024-10-09 12:24:29,490 [INFO] 
2024-10-09 12:26:08,510 [INFO] Step[50/144]: training loss : 5.252028331756592 TRAIN  loss dict:  {'classification_loss': 5.252028331756592}
2024-10-09 12:27:10,836 [INFO] Step[100/144]: training loss : 5.02182752609253 TRAIN  loss dict:  {'classification_loss': 5.02182752609253}
2024-10-09 12:29:16,139 [INFO] Label accuracies statistics:
2024-10-09 12:29:16,139 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.5, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.5, 39: 0.0, 40: 0.25, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.25, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.5, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.75, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.25, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.25, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-09 12:29:17,490 [INFO] [2] TRAIN  loss: 5.0855113996399774 acc: 0.010194624652455977
2024-10-09 12:29:17,490 [INFO] [2] TRAIN  loss dict: {'classification_loss': 5.0855113996399774}
2024-10-09 12:29:17,490 [INFO] [2] VALIDATION loss: 5.027068491335268 VALIDATION  acc: 0.020202020202020204
2024-10-09 12:29:17,490 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 5.027068491335268}
2024-10-09 12:29:17,490 [INFO] 
2024-10-09 12:30:55,835 [INFO] Step[50/144]: training loss : 4.793629312515259 TRAIN  loss dict:  {'classification_loss': 4.793629312515259}
2024-10-09 12:32:00,899 [INFO] Step[100/144]: training loss : 4.5982286071777345 TRAIN  loss dict:  {'classification_loss': 4.5982286071777345}
2024-10-09 12:34:06,711 [INFO] Label accuracies statistics:
2024-10-09 12:34:06,711 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.75, 4: 0.5, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.25, 29: 0.0, 30: 0.0, 31: 0.25, 32: 0.5, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.75, 46: 0.0, 47: 0.5, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.0, 62: 0.25, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.25, 79: 0.0, 80: 0.5, 81: 0.25, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.75, 93: 0.5, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.4, 100: 0.25, 101: 0.0, 102: 0.5, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.5, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.25, 129: 0.0, 130: 0.5, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.25, 144: 0.25, 145: 0.0, 146: 0.75, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.25, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.5, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.25, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-09 12:34:08,134 [INFO] [3] TRAIN  loss: 4.622528612613678 acc: 0.03313253012048193
2024-10-09 12:34:08,134 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.622528612613678}
2024-10-09 12:34:08,134 [INFO] [3] VALIDATION loss: 4.400435156292385 VALIDATION  acc: 0.06944444444444445
2024-10-09 12:34:08,134 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 4.400435156292385}
2024-10-09 12:34:08,134 [INFO] 
2024-10-09 12:35:46,504 [INFO] Step[50/144]: training loss : 4.104516716003418 TRAIN  loss dict:  {'classification_loss': 4.104516716003418}
2024-10-09 12:36:52,086 [INFO] Step[100/144]: training loss : 3.9566022777557373 TRAIN  loss dict:  {'classification_loss': 3.9566022777557373}
2024-10-09 12:38:59,262 [INFO] Label accuracies statistics:
2024-10-09 12:38:59,262 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.75, 4: 0.5, 5: 0.0, 6: 0.75, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.25, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.25, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.75, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.5, 27: 0.0, 28: 0.25, 29: 0.75, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.75, 34: 0.0, 35: 0.75, 36: 0.0, 37: 0.25, 38: 0.0, 39: 1.0, 40: 0.0, 41: 0.0, 42: 0.25, 43: 0.0, 44: 0.0, 45: 0.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 1.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.5, 73: 0.5, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.5, 79: 0.25, 80: 0.75, 81: 0.25, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.75, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.25, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.25, 102: 1.0, 103: 0.0, 104: 0.0, 105: 0.75, 106: 0.25, 107: 0.0, 108: 0.25, 109: 0.75, 110: 0.0, 111: 0.5, 112: 0.0, 113: 0.0, 114: 0.75, 115: 0.0, 116: 0.0, 117: 0.5, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.25, 126: 0.0, 127: 0.0, 128: 0.25, 129: 0.5, 130: 0.5, 131: 0.0, 132: 0.25, 133: 0.25, 134: 0.0, 135: 0.25, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.5, 142: 0.0, 143: 1.0, 144: 0.0, 145: 0.25, 146: 0.25, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.5, 152: 0.0, 153: 0.25, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.75, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.5, 169: 0.25, 170: 0.25, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.25, 175: 0.25, 176: 0.0, 177: 0.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.0, 181: 0.0, 182: 0.25, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.75, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.25, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.25, 198: 0.25}

2024-10-09 12:39:00,481 [INFO] [4] TRAIN  loss: 3.9139401101403766 acc: 0.10426320667284522
2024-10-09 12:39:00,481 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.9139401101403766}
2024-10-09 12:39:00,481 [INFO] [4] VALIDATION loss: 3.495403422249688 VALIDATION  acc: 0.18181818181818182
2024-10-09 12:39:00,481 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 3.495403422249688}
2024-10-09 12:39:00,482 [INFO] 
2024-10-09 12:40:39,265 [INFO] Step[50/144]: training loss : 3.1951492118835447 TRAIN  loss dict:  {'classification_loss': 3.1951492118835447}
2024-10-09 12:41:44,619 [INFO] Step[100/144]: training loss : 3.086695547103882 TRAIN  loss dict:  {'classification_loss': 3.086695547103882}
2024-10-09 12:43:51,846 [INFO] Label accuracies statistics:
2024-10-09 12:43:51,847 [INFO] {0: 0.3333333333333333, 1: 0.0, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.0, 8: 0.0, 9: 0.25, 10: 0.5, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.5, 23: 0.5, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.5, 28: 0.25, 29: 0.25, 30: 0.25, 31: 0.0, 32: 0.75, 33: 0.0, 34: 0.75, 35: 0.0, 36: 0.0, 37: 0.25, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.25, 43: 0.0, 44: 0.0, 45: 0.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 1.0, 50: 0.25, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.5, 57: 0.0, 58: 0.0, 59: 0.25, 60: 0.25, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.5, 65: 0.0, 66: 0.0, 67: 0.5, 68: 0.25, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.25, 73: 0.25, 74: 0.75, 75: 0.75, 76: 0.5, 77: 0.0, 78: 0.75, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.25, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.5, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 1.0, 93: 0.5, 94: 0.0, 95: 0.75, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.8, 100: 0.5, 101: 0.25, 102: 0.75, 103: 0.0, 104: 0.0, 105: 0.25, 106: 0.75, 107: 0.0, 108: 0.25, 109: 0.75, 110: 0.0, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.25, 115: 0.5, 116: 0.0, 117: 0.5, 118: 0.5, 119: 0.5, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.5, 124: 0.5, 125: 0.5, 126: 0.0, 127: 0.0, 128: 0.75, 129: 0.5, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.0, 135: 0.75, 136: 0.5, 137: 0.0, 138: 0.25, 139: 0.75, 140: 0.0, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.25, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.25, 149: 0.5, 150: 0.5, 151: 0.5, 152: 0.75, 153: 0.5, 154: 0.25, 155: 0.25, 156: 0.5, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.25, 170: 0.5, 171: 0.0, 172: 0.0, 173: 0.25, 174: 1.0, 175: 0.0, 176: 0.0, 177: 0.25, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.5, 182: 0.0, 183: 0.5, 184: 0.0, 185: 1.0, 186: 0.0, 187: 1.0, 188: 0.0, 189: 0.0, 190: 0.25, 191: 0.25, 192: 0.75, 193: 0.75, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.25, 198: 0.0}

2024-10-09 12:43:53,147 [INFO] [5] TRAIN  loss: 3.0834138145049415 acc: 0.22034291010194626
2024-10-09 12:43:53,147 [INFO] [5] TRAIN  loss dict: {'classification_loss': 3.0834138145049415}
2024-10-09 12:43:53,147 [INFO] [5] VALIDATION loss: 2.8963618057745473 VALIDATION  acc: 0.2828282828282828
2024-10-09 12:43:53,147 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.8963618057745473}
2024-10-09 12:43:53,147 [INFO] 
2024-10-09 12:45:30,388 [INFO] Step[50/144]: training loss : 2.5169311952590943 TRAIN  loss dict:  {'classification_loss': 2.5169311952590943}
2024-10-09 12:46:36,013 [INFO] Step[100/144]: training loss : 2.398750314712524 TRAIN  loss dict:  {'classification_loss': 2.398750314712524}
2024-10-09 12:48:46,086 [INFO] Label accuracies statistics:
2024-10-09 12:48:46,086 [INFO] {0: 0.0, 1: 0.3333333333333333, 2: 0.5, 3: 0.5, 4: 0.0, 5: 0.75, 6: 0.25, 7: 0.5, 8: 0.0, 9: 0.25, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.5, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.75, 23: 0.75, 24: 0.0, 25: 0.25, 26: 0.25, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.0, 31: 0.0, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.75, 38: 0.0, 39: 1.0, 40: 0.25, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.25, 45: 0.25, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.25, 57: 0.25, 58: 0.0, 59: 0.0, 60: 0.25, 61: 0.25, 62: 0.5, 63: 0.0, 64: 1.0, 65: 0.5, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.0, 72: 0.5, 73: 0.25, 74: 0.25, 75: 0.75, 76: 0.5, 77: 0.0, 78: 0.75, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.25, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.0, 95: 0.5, 96: 0.25, 97: 0.0, 98: 0.25, 99: 0.8, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.25, 104: 0.0, 105: 1.0, 106: 0.0, 107: 0.0, 108: 0.25, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.0, 113: 0.25, 114: 0.0, 115: 0.25, 116: 0.0, 117: 0.0, 118: 1.0, 119: 0.75, 120: 0.25, 121: 0.0, 122: 0.75, 123: 0.75, 124: 0.5, 125: 0.0, 126: 0.25, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 0.25, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 0.5, 137: 0.25, 138: 0.25, 139: 0.5, 140: 0.0, 141: 0.75, 142: 0.0, 143: 0.75, 144: 0.0, 145: 0.25, 146: 0.75, 147: 0.25, 148: 0.75, 149: 0.5, 150: 0.0, 151: 0.25, 152: 0.0, 153: 0.0, 154: 0.75, 155: 0.0, 156: 0.75, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.5, 161: 0.5, 162: 0.25, 163: 0.25, 164: 0.25, 165: 0.5, 166: 0.5, 167: 0.0, 168: 0.0, 169: 0.75, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.25, 178: 0.75, 179: 0.3333333333333333, 180: 0.0, 181: 0.5, 182: 0.25, 183: 0.0, 184: 0.0, 185: 1.0, 186: 0.0, 187: 1.0, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.25, 192: 0.75, 193: 0.0, 194: 0.5, 195: 0.25, 196: 0.0, 197: 0.75, 198: 0.0}

2024-10-09 12:48:47,448 [INFO] [6] TRAIN  loss: 2.4486791118979454 acc: 0.34406858202038926
2024-10-09 12:48:47,448 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.4486791118979454}
2024-10-09 12:48:47,449 [INFO] [6] VALIDATION loss: 2.504951980378893 VALIDATION  acc: 0.35353535353535354
2024-10-09 12:48:47,449 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.504951980378893}
2024-10-09 12:48:47,449 [INFO] 
2024-10-09 12:50:24,933 [INFO] Step[50/144]: training loss : 2.001482698917389 TRAIN  loss dict:  {'classification_loss': 2.001482698917389}
2024-10-09 12:51:30,167 [INFO] Step[100/144]: training loss : 1.9442870211601258 TRAIN  loss dict:  {'classification_loss': 1.9442870211601258}
2024-10-09 12:53:38,944 [INFO] Label accuracies statistics:
2024-10-09 12:53:38,944 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.0, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.0, 32: 0.75, 33: 0.5, 34: 0.75, 35: 0.25, 36: 0.0, 37: 0.75, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.0, 48: 0.5, 49: 0.75, 50: 0.25, 51: 0.25, 52: 0.25, 53: 0.25, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.0, 62: 0.5, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.0, 71: 0.0, 72: 0.5, 73: 0.5, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.0, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.25, 83: 0.25, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.5, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.0, 97: 0.25, 98: 0.5, 99: 0.6, 100: 0.75, 101: 0.25, 102: 0.75, 103: 0.5, 104: 0.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 0.0, 109: 0.75, 110: 0.75, 111: 0.25, 112: 0.5, 113: 0.25, 114: 0.0, 115: 1.0, 116: 0.0, 117: 0.5, 118: 1.0, 119: 0.0, 120: 0.5, 121: 0.0, 122: 0.75, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.25, 127: 0.0, 128: 0.5, 129: 0.75, 130: 0.25, 131: 0.0, 132: 0.75, 133: 0.25, 134: 0.75, 135: 1.0, 136: 0.25, 137: 0.25, 138: 0.0, 139: 0.5, 140: 0.25, 141: 0.0, 142: 0.5, 143: 0.75, 144: 0.25, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 0.5, 150: 0.0, 151: 0.5, 152: 0.25, 153: 0.0, 154: 0.25, 155: 0.0, 156: 0.25, 157: 0.75, 158: 0.0, 159: 0.25, 160: 0.0, 161: 0.5, 162: 0.25, 163: 0.0, 164: 0.5, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.75, 169: 0.0, 170: 0.25, 171: 0.25, 172: 0.5, 173: 0.5, 174: 0.75, 175: 0.25, 176: 0.25, 177: 0.5, 178: 0.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.0, 187: 0.75, 188: 0.75, 189: 0.25, 190: 0.0, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.0, 196: 0.0, 197: 1.0, 198: 0.0}

2024-10-09 12:53:40,264 [INFO] [7] TRAIN  loss: 1.9799474171466298 acc: 0.456209453197405
2024-10-09 12:53:40,264 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.9799474171466298}
2024-10-09 12:53:40,264 [INFO] [7] VALIDATION loss: 2.1865837618156716 VALIDATION  acc: 0.4116161616161616
2024-10-09 12:53:40,264 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 2.1865837618156716}
2024-10-09 12:53:40,265 [INFO] 
2024-10-09 12:55:20,230 [INFO] Step[50/144]: training loss : 1.596316169500351 TRAIN  loss dict:  {'classification_loss': 1.596316169500351}
2024-10-09 12:56:25,020 [INFO] Step[100/144]: training loss : 1.6030747079849244 TRAIN  loss dict:  {'classification_loss': 1.6030747079849244}
2024-10-09 12:58:32,238 [INFO] Label accuracies statistics:
2024-10-09 12:58:32,238 [INFO] {0: 0.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.0, 6: 0.25, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.0, 11: 0.5, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.0, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.5, 32: 0.5, 33: 0.5, 34: 0.5, 35: 0.0, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.5, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.25, 50: 0.5, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.25, 55: 0.25, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.0, 60: 0.75, 61: 0.5, 62: 0.5, 63: 0.25, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.5, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.25, 78: 0.75, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.5, 99: 0.6, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.0, 111: 0.5, 112: 1.0, 113: 0.25, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.5, 127: 1.0, 128: 0.75, 129: 0.0, 130: 0.75, 131: 0.75, 132: 1.0, 133: 0.5, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.25, 138: 0.0, 139: 0.5, 140: 0.0, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.25, 145: 0.0, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 1.0, 154: 0.5, 155: 0.25, 156: 0.0, 157: 0.0, 158: 0.3333333333333333, 159: 0.25, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.5, 166: 0.5, 167: 0.0, 168: 0.0, 169: 0.75, 170: 0.25, 171: 0.0, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.0, 176: 0.5, 177: 0.0, 178: 0.25, 179: 0.6666666666666666, 180: 0.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.0, 191: 0.25, 192: 0.75, 193: 0.25, 194: 0.75, 195: 0.0, 196: 0.5, 197: 1.0, 198: 0.0}

2024-10-09 12:58:33,555 [INFO] [8] TRAIN  loss: 1.604384519573715 acc: 0.5458758109360519
2024-10-09 12:58:33,556 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.604384519573715}
2024-10-09 12:58:33,556 [INFO] [8] VALIDATION loss: 1.8692687352498372 VALIDATION  acc: 0.494949494949495
2024-10-09 12:58:33,556 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.8692687352498372}
2024-10-09 12:58:33,556 [INFO] 
2024-10-09 13:00:12,998 [INFO] Step[50/144]: training loss : 1.28980961561203 TRAIN  loss dict:  {'classification_loss': 1.28980961561203}
2024-10-09 13:01:18,801 [INFO] Step[100/144]: training loss : 1.3527003359794616 TRAIN  loss dict:  {'classification_loss': 1.3527003359794616}
2024-10-09 13:03:28,054 [INFO] Label accuracies statistics:
2024-10-09 13:03:28,054 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.5, 19: 0.25, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.5, 29: 0.75, 30: 0.0, 31: 0.75, 32: 0.0, 33: 1.0, 34: 0.75, 35: 0.0, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.25, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.25, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.0, 84: 0.0, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.75, 103: 1.0, 104: 0.25, 105: 0.75, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.0, 115: 0.5, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.5, 121: 0.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.5, 130: 0.75, 131: 0.25, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.5, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.25, 141: 0.5, 142: 0.0, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.5, 150: 0.5, 151: 1.0, 152: 0.25, 153: 0.5, 154: 0.5, 155: 0.75, 156: 0.75, 157: 0.25, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.25, 166: 0.75, 167: 0.5, 168: 0.25, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 0.25, 179: 0.0, 180: 0.0, 181: 0.75, 182: 0.0, 183: 0.25, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.5, 198: 0.5}

2024-10-09 13:03:29,409 [INFO] [9] TRAIN  loss: 1.3331928124858274 acc: 0.6269694161260426
2024-10-09 13:03:29,409 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.3331928124858274}
2024-10-09 13:03:29,409 [INFO] [9] VALIDATION loss: 1.5431932210922241 VALIDATION  acc: 0.5795454545454546
2024-10-09 13:03:29,409 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.5431932210922241}
2024-10-09 13:03:29,409 [INFO] 
2024-10-09 13:05:07,193 [INFO] Step[50/144]: training loss : 1.1244124567508698 TRAIN  loss dict:  {'classification_loss': 1.1244124567508698}
2024-10-09 13:06:13,302 [INFO] Step[100/144]: training loss : 1.0982037305831909 TRAIN  loss dict:  {'classification_loss': 1.0982037305831909}
2024-10-09 13:08:21,508 [INFO] Label accuracies statistics:
2024-10-09 13:08:21,508 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.25, 6: 0.25, 7: 0.0, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.25, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.25, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.5, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.0, 131: 1.0, 132: 0.25, 133: 0.5, 134: 0.5, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.0, 139: 0.25, 140: 0.25, 141: 0.75, 142: 0.0, 143: 0.5, 144: 0.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.25, 149: 0.5, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.25, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.25, 167: 0.5, 168: 0.25, 169: 0.75, 170: 0.25, 171: 0.0, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.5, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.0}

2024-10-09 13:08:22,910 [INFO] [10] TRAIN  loss: 1.1085788992544015 acc: 0.6712233549582948
2024-10-09 13:08:22,910 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.1085788992544015}
2024-10-09 13:08:22,910 [INFO] [10] VALIDATION loss: 1.528999458860468 VALIDATION  acc: 0.6047979797979798
2024-10-09 13:08:22,910 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.528999458860468}
2024-10-09 13:08:22,910 [INFO] 
2024-10-09 13:10:01,854 [INFO] Step[50/144]: training loss : 0.8941791993379593 TRAIN  loss dict:  {'classification_loss': 0.8941791993379593}
2024-10-09 13:11:07,233 [INFO] Step[100/144]: training loss : 0.9389842063188553 TRAIN  loss dict:  {'classification_loss': 0.9389842063188553}
2024-10-09 13:13:14,169 [INFO] Label accuracies statistics:
2024-10-09 13:13:14,169 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.75, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.0, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 0.75, 79: 0.0, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.75, 87: 1.0, 88: 0.0, 89: 0.5, 90: 0.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.6, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.25, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.0, 143: 0.25, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.0, 151: 0.75, 152: 0.25, 153: 1.0, 154: 0.25, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.25, 166: 0.5, 167: 0.0, 168: 0.5, 169: 0.75, 170: 0.25, 171: 0.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.25, 187: 0.75, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.0}

2024-10-09 13:13:15,525 [INFO] [11] TRAIN  loss: 0.9155077478951879 acc: 0.7335495829471733
2024-10-09 13:13:15,525 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.9155077478951879}
2024-10-09 13:13:15,525 [INFO] [11] VALIDATION loss: 1.391744644553573 VALIDATION  acc: 0.6035353535353535
2024-10-09 13:13:15,525 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.391744644553573}
2024-10-09 13:13:15,525 [INFO] 
2024-10-09 13:14:53,153 [INFO] Step[50/144]: training loss : 0.7709409826993943 TRAIN  loss dict:  {'classification_loss': 0.7709409826993943}
2024-10-09 13:16:00,263 [INFO] Step[100/144]: training loss : 0.8069099044799805 TRAIN  loss dict:  {'classification_loss': 0.8069099044799805}
2024-10-09 13:18:07,461 [INFO] Label accuracies statistics:
2024-10-09 13:18:07,461 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.0, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.0, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.25, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.25, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.25, 66: 0.25, 67: 0.25, 68: 0.25, 69: 0.25, 70: 0.25, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.25, 75: 0.75, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 0.75, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 1.0, 88: 0.0, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.75, 114: 0.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.0, 121: 0.0, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.75, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 0.5, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.0, 137: 1.0, 138: 0.25, 139: 0.5, 140: 0.5, 141: 0.5, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.0, 157: 0.0, 158: 1.0, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.5, 173: 0.5, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 0.75, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-09 13:18:07,555 [INFO] [12] TRAIN  loss: 0.7767338224997123 acc: 0.7743280815569972
2024-10-09 13:18:07,555 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.7767338224997123}
2024-10-09 13:18:07,555 [INFO] [12] VALIDATION loss: 1.4230341381496854 VALIDATION  acc: 0.6035353535353535
2024-10-09 13:18:07,555 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.4230341381496854}
2024-10-09 13:18:07,555 [INFO] 
2024-10-09 13:19:46,825 [INFO] Step[50/144]: training loss : 0.638219284415245 TRAIN  loss dict:  {'classification_loss': 0.638219284415245}
2024-10-09 13:20:54,039 [INFO] Step[100/144]: training loss : 0.6630989062786102 TRAIN  loss dict:  {'classification_loss': 0.6630989062786102}
2024-10-09 13:23:02,370 [INFO] Label accuracies statistics:
2024-10-09 13:23:02,370 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.0, 67: 0.25, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 0.75, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.5, 141: 0.5, 142: 0.75, 143: 0.75, 144: 0.0, 145: 0.25, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.25, 165: 0.25, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.75, 170: 0.25, 171: 0.0, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-09 13:23:02,459 [INFO] [13] TRAIN  loss: 0.6570274248305294 acc: 0.8046802594995366
2024-10-09 13:23:02,459 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.6570274248305294}
2024-10-09 13:23:02,459 [INFO] [13] VALIDATION loss: 1.4446447822782729 VALIDATION  acc: 0.6275252525252525
2024-10-09 13:23:02,459 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.4446447822782729}
2024-10-09 13:23:02,459 [INFO] 
2024-10-09 13:24:50,436 [INFO] Step[50/144]: training loss : 0.5239287620782852 TRAIN  loss dict:  {'classification_loss': 0.5239287620782852}
2024-10-09 13:25:54,708 [INFO] Step[100/144]: training loss : 0.5950192511081696 TRAIN  loss dict:  {'classification_loss': 0.5950192511081696}
2024-10-09 13:28:00,031 [INFO] Label accuracies statistics:
2024-10-09 13:28:00,031 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.25, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.0, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.0, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.25, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.25, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.5, 132: 1.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.25, 143: 0.75, 144: 1.0, 145: 0.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 1.0, 167: 0.0, 168: 0.25, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.25, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 13:28:01,391 [INFO] [14] TRAIN  loss: 0.578060407191515 acc: 0.830398517145505
2024-10-09 13:28:01,391 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.578060407191515}
2024-10-09 13:28:01,391 [INFO] [14] VALIDATION loss: 1.3190148439672258 VALIDATION  acc: 0.648989898989899
2024-10-09 13:28:01,391 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.3190148439672258}
2024-10-09 13:28:01,391 [INFO] 
2024-10-09 13:29:40,038 [INFO] Step[50/144]: training loss : 0.4569133347272873 TRAIN  loss dict:  {'classification_loss': 0.4569133347272873}
2024-10-09 13:30:45,881 [INFO] Step[100/144]: training loss : 0.5171717071533203 TRAIN  loss dict:  {'classification_loss': 0.5171717071533203}
2024-10-09 13:32:52,582 [INFO] Label accuracies statistics:
2024-10-09 13:32:52,582 [INFO] {0: 1.0, 1: 0.6666666666666666, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.25, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.0, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.0, 36: 0.5, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.5, 49: 0.25, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.0, 70: 0.25, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.25, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.5, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.0, 122: 0.0, 123: 0.25, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.0, 143: 1.0, 144: 0.5, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.0, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.0, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.25, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-09 13:32:52,659 [INFO] [15] TRAIN  loss: 0.5003102951579623 acc: 0.8512511584800742
2024-10-09 13:32:52,659 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.5003102951579623}
2024-10-09 13:32:52,659 [INFO] [15] VALIDATION loss: 1.3661155656532005 VALIDATION  acc: 0.6414141414141414
2024-10-09 13:32:52,659 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.3661155656532005}
2024-10-09 13:32:52,659 [INFO] 
2024-10-09 13:34:32,113 [INFO] Step[50/144]: training loss : 0.4044770473241806 TRAIN  loss dict:  {'classification_loss': 0.4044770473241806}
2024-10-09 13:35:38,681 [INFO] Step[100/144]: training loss : 0.4672246825695038 TRAIN  loss dict:  {'classification_loss': 0.4672246825695038}
2024-10-09 13:37:46,317 [INFO] Label accuracies statistics:
2024-10-09 13:37:46,317 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.0, 15: 0.6666666666666666, 16: 0.25, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 1.0, 29: 0.5, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.0, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.0, 115: 0.75, 116: 0.25, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.25, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.25, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.25, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.5, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.25, 197: 0.75, 198: 1.0}

2024-10-09 13:37:47,668 [INFO] [16] TRAIN  loss: 0.4480958878993988 acc: 0.868628359592215
2024-10-09 13:37:47,668 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.4480958878993988}
2024-10-09 13:37:47,669 [INFO] [16] VALIDATION loss: 1.300417941753511 VALIDATION  acc: 0.6641414141414141
2024-10-09 13:37:47,669 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.300417941753511}
2024-10-09 13:37:47,669 [INFO] 
2024-10-09 13:39:26,139 [INFO] Step[50/144]: training loss : 0.395730262696743 TRAIN  loss dict:  {'classification_loss': 0.395730262696743}
2024-10-09 13:40:30,930 [INFO] Step[100/144]: training loss : 0.3793525743484497 TRAIN  loss dict:  {'classification_loss': 0.3793525743484497}
2024-10-09 13:42:38,568 [INFO] Label accuracies statistics:
2024-10-09 13:42:38,568 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.0, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.25, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 1.0, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.75, 86: 0.5, 87: 0.5, 88: 0.5, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.5, 121: 0.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.25, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 13:42:39,925 [INFO] [17] TRAIN  loss: 0.41788691965242225 acc: 0.8758109360518999
2024-10-09 13:42:39,925 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.41788691965242225}
2024-10-09 13:42:39,925 [INFO] [17] VALIDATION loss: 1.2813800523678462 VALIDATION  acc: 0.6666666666666666
2024-10-09 13:42:39,925 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.2813800523678462}
2024-10-09 13:42:39,926 [INFO] 
2024-10-09 13:44:19,526 [INFO] Step[50/144]: training loss : 0.3699922090768814 TRAIN  loss dict:  {'classification_loss': 0.3699922090768814}
2024-10-09 13:45:24,060 [INFO] Step[100/144]: training loss : 0.4096180012822151 TRAIN  loss dict:  {'classification_loss': 0.4096180012822151}
2024-10-09 13:47:31,387 [INFO] Label accuracies statistics:
2024-10-09 13:47:31,387 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.25, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 0.5, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.25, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.5, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-09 13:47:31,490 [INFO] [18] TRAIN  loss: 0.3880372095025248 acc: 0.8855421686746988
2024-10-09 13:47:31,490 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.3880372095025248}
2024-10-09 13:47:31,491 [INFO] [18] VALIDATION loss: 1.3237092508761972 VALIDATION  acc: 0.6578282828282829
2024-10-09 13:47:31,491 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.3237092508761972}
2024-10-09 13:47:31,491 [INFO] 
2024-10-09 13:49:08,703 [INFO] Step[50/144]: training loss : 0.31782458364963534 TRAIN  loss dict:  {'classification_loss': 0.31782458364963534}
2024-10-09 13:50:13,522 [INFO] Step[100/144]: training loss : 0.36866830110549925 TRAIN  loss dict:  {'classification_loss': 0.36866830110549925}
2024-10-09 13:52:23,727 [INFO] Label accuracies statistics:
2024-10-09 13:52:23,727 [INFO] {0: 0.3333333333333333, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.0, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.25, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.25, 114: 0.25, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.25, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.25, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.0, 181: 0.75, 182: 0.0, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.0, 189: 0.25, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 13:52:23,815 [INFO] [19] TRAIN  loss: 0.35173874865803456 acc: 0.8952734012974977
2024-10-09 13:52:23,815 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.35173874865803456}
2024-10-09 13:52:23,815 [INFO] [19] VALIDATION loss: 1.2820451331359368 VALIDATION  acc: 0.6603535353535354
2024-10-09 13:52:23,815 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.2820451331359368}
2024-10-09 13:52:23,815 [INFO] 
2024-10-09 13:54:03,328 [INFO] Step[50/144]: training loss : 0.3173538838326931 TRAIN  loss dict:  {'classification_loss': 0.3173538838326931}
2024-10-09 13:55:09,349 [INFO] Step[100/144]: training loss : 0.3013899290561676 TRAIN  loss dict:  {'classification_loss': 0.3013899290561676}
2024-10-09 13:57:13,020 [INFO] Label accuracies statistics:
2024-10-09 13:57:13,021 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.25, 85: 0.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.25, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.75, 154: 0.75, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.5, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.25, 167: 0.25, 168: 0.25, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-09 13:57:13,101 [INFO] [20] TRAIN  loss: 0.32159015112039113 acc: 0.9026876737720111
2024-10-09 13:57:13,101 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.32159015112039113}
2024-10-09 13:57:13,101 [INFO] [20] VALIDATION loss: 1.368883561204981 VALIDATION  acc: 0.6767676767676768
2024-10-09 13:57:13,101 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.368883561204981}
2024-10-09 13:57:13,101 [INFO] 
2024-10-09 13:58:53,571 [INFO] Step[50/144]: training loss : 0.27830058947205544 TRAIN  loss dict:  {'classification_loss': 0.27830058947205544}
2024-10-09 13:59:58,193 [INFO] Step[100/144]: training loss : 0.2544099313020706 TRAIN  loss dict:  {'classification_loss': 0.2544099313020706}
2024-10-09 14:02:11,382 [INFO] Label accuracies statistics:
2024-10-09 14:02:11,382 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.25, 33: 1.0, 34: 0.5, 35: 0.75, 36: 0.5, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.25, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 1.0, 124: 0.75, 125: 0.75, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.25, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 0.75, 152: 0.25, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 1.0, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 14:02:12,786 [INFO] [21] TRAIN  loss: 0.2563640200015571 acc: 0.9279425393883225
2024-10-09 14:02:12,786 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.2563640200015571}
2024-10-09 14:02:12,786 [INFO] [21] VALIDATION loss: 1.2631075260815796 VALIDATION  acc: 0.7108585858585859
2024-10-09 14:02:12,786 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.2631075260815796}
2024-10-09 14:02:12,786 [INFO] 
2024-10-09 14:03:50,935 [INFO] Step[50/144]: training loss : 0.20386981412768365 TRAIN  loss dict:  {'classification_loss': 0.20386981412768365}
2024-10-09 14:04:57,062 [INFO] Step[100/144]: training loss : 0.24248060420155526 TRAIN  loss dict:  {'classification_loss': 0.24248060420155526}
2024-10-09 14:07:06,665 [INFO] Label accuracies statistics:
2024-10-09 14:07:06,665 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.25, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.0, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 14:07:07,972 [INFO] [22] TRAIN  loss: 0.22683661565598515 acc: 0.9355885078776645
2024-10-09 14:07:07,972 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.22683661565598515}
2024-10-09 14:07:07,972 [INFO] [22] VALIDATION loss: 1.2594997256442353 VALIDATION  acc: 0.6881313131313131
2024-10-09 14:07:07,972 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 1.2594997256442353}
2024-10-09 14:07:07,972 [INFO] 
2024-10-09 14:08:46,265 [INFO] Step[50/144]: training loss : 0.20966087862849236 TRAIN  loss dict:  {'classification_loss': 0.20966087862849236}
2024-10-09 14:09:53,115 [INFO] Step[100/144]: training loss : 0.20538300886750221 TRAIN  loss dict:  {'classification_loss': 0.20538300886750221}
2024-10-09 14:12:02,858 [INFO] Label accuracies statistics:
2024-10-09 14:12:02,858 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.0, 15: 0.0, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-10-09 14:12:02,946 [INFO] [23] TRAIN  loss: 0.21120516994657615 acc: 0.9402224281742354
2024-10-09 14:12:02,947 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.21120516994657615}
2024-10-09 14:12:02,947 [INFO] [23] VALIDATION loss: 1.2824318243397608 VALIDATION  acc: 0.7108585858585859
2024-10-09 14:12:02,947 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 1.2824318243397608}
2024-10-09 14:12:02,947 [INFO] 
2024-10-09 14:13:43,911 [INFO] Step[50/144]: training loss : 0.18392806068062784 TRAIN  loss dict:  {'classification_loss': 0.18392806068062784}
2024-10-09 14:14:49,360 [INFO] Step[100/144]: training loss : 0.17158820800483227 TRAIN  loss dict:  {'classification_loss': 0.17158820800483227}
2024-10-09 14:16:57,507 [INFO] Label accuracies statistics:
2024-10-09 14:16:57,507 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 1.0, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.25, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.5}

2024-10-09 14:16:57,592 [INFO] [24] TRAIN  loss: 0.18968008207674655 acc: 0.9443929564411492
2024-10-09 14:16:57,592 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.18968008207674655}
2024-10-09 14:16:57,592 [INFO] [24] VALIDATION loss: 1.2765323928108923 VALIDATION  acc: 0.6957070707070707
2024-10-09 14:16:57,593 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 1.2765323928108923}
2024-10-09 14:16:57,593 [INFO] 
2024-10-09 14:18:34,266 [INFO] Step[50/144]: training loss : 0.1808562948554754 TRAIN  loss dict:  {'classification_loss': 0.1808562948554754}
2024-10-09 14:19:39,536 [INFO] Step[100/144]: training loss : 0.16336336337029933 TRAIN  loss dict:  {'classification_loss': 0.16336336337029933}
2024-10-09 14:21:43,055 [INFO] Label accuracies statistics:
2024-10-09 14:21:43,055 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.5, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.25, 165: 0.25, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.25, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.75}

2024-10-09 14:21:44,348 [INFO] [25] TRAIN  loss: 0.1787696769978437 acc: 0.9432344763670065
2024-10-09 14:21:44,348 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.1787696769978437}
2024-10-09 14:21:44,348 [INFO] [25] VALIDATION loss: 1.2496726919241525 VALIDATION  acc: 0.7058080808080808
2024-10-09 14:21:44,348 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 1.2496726919241525}
2024-10-09 14:21:44,348 [INFO] 
2024-10-09 14:23:40,467 [INFO] Step[50/144]: training loss : 0.17037246994674204 TRAIN  loss dict:  {'classification_loss': 0.17037246994674204}
2024-10-09 14:24:44,390 [INFO] Step[100/144]: training loss : 0.16056411806493998 TRAIN  loss dict:  {'classification_loss': 0.16056411806493998}
2024-10-09 14:26:46,910 [INFO] Label accuracies statistics:
2024-10-09 14:26:46,911 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.25, 17: 0.5, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.5, 32: 0.25, 33: 1.0, 34: 1.0, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.75, 114: 0.25, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.75}

2024-10-09 14:26:48,280 [INFO] [26] TRAIN  loss: 0.1710667831486919 acc: 0.9515755329008341
2024-10-09 14:26:48,280 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.1710667831486919}
2024-10-09 14:26:48,280 [INFO] [26] VALIDATION loss: 1.221279733158924 VALIDATION  acc: 0.7058080808080808
2024-10-09 14:26:48,280 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 1.221279733158924}
2024-10-09 14:26:48,280 [INFO] 
2024-10-09 14:28:32,171 [INFO] Step[50/144]: training loss : 0.1557589352875948 TRAIN  loss dict:  {'classification_loss': 0.1557589352875948}
2024-10-09 14:29:37,418 [INFO] Step[100/144]: training loss : 0.1618846680969 TRAIN  loss dict:  {'classification_loss': 0.1618846680969}
2024-10-09 14:31:47,258 [INFO] Label accuracies statistics:
2024-10-09 14:31:47,258 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 1.0, 114: 0.0, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.25, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-09 14:31:48,702 [INFO] [27] TRAIN  loss: 0.16793311361430419 acc: 0.9497219647822057
2024-10-09 14:31:48,703 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.16793311361430419}
2024-10-09 14:31:48,703 [INFO] [27] VALIDATION loss: 1.2037108488104962 VALIDATION  acc: 0.7058080808080808
2024-10-09 14:31:48,703 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.2037108488104962}
2024-10-09 14:31:48,703 [INFO] 
2024-10-09 14:33:28,459 [INFO] Step[50/144]: training loss : 0.13746335815638303 TRAIN  loss dict:  {'classification_loss': 0.13746335815638303}
2024-10-09 14:34:33,923 [INFO] Step[100/144]: training loss : 0.18384221702814102 TRAIN  loss dict:  {'classification_loss': 0.18384221702814102}
2024-10-09 14:36:29,059 [INFO] Label accuracies statistics:
2024-10-09 14:36:29,059 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.5, 8: 0.5, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 1.0, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 0.75, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 1.0, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.5, 181: 1.0, 182: 0.25, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.5}

2024-10-09 14:36:29,152 [INFO] [28] TRAIN  loss: 0.15930741586877653 acc: 0.9548192771084337
2024-10-09 14:36:29,152 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.15930741586877653}
2024-10-09 14:36:29,152 [INFO] [28] VALIDATION loss: 1.2867451504700713 VALIDATION  acc: 0.7032828282828283
2024-10-09 14:36:29,152 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.2867451504700713}
2024-10-09 14:36:29,152 [INFO] 
2024-10-09 14:38:06,390 [INFO] Step[50/144]: training loss : 0.1558103545755148 TRAIN  loss dict:  {'classification_loss': 0.1558103545755148}
2024-10-09 14:39:11,349 [INFO] Step[100/144]: training loss : 0.149053787663579 TRAIN  loss dict:  {'classification_loss': 0.149053787663579}
2024-10-09 14:41:31,049 [INFO] Label accuracies statistics:
2024-10-09 14:41:31,050 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.5, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.5, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.75, 95: 0.75, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 14:41:31,130 [INFO] [29] TRAIN  loss: 0.15636664926488367 acc: 0.9559777571825765
2024-10-09 14:41:31,131 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.15636664926488367}
2024-10-09 14:41:31,131 [INFO] [29] VALIDATION loss: 1.238482076122805 VALIDATION  acc: 0.7045454545454546
2024-10-09 14:41:31,131 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.238482076122805}
2024-10-09 14:41:31,131 [INFO] 
2024-10-09 14:43:07,665 [INFO] Step[50/144]: training loss : 0.13869260266423225 TRAIN  loss dict:  {'classification_loss': 0.13869260266423225}
2024-10-09 14:44:13,764 [INFO] Step[100/144]: training loss : 0.14773023836314678 TRAIN  loss dict:  {'classification_loss': 0.14773023836314678}
2024-10-09 14:46:32,644 [INFO] Label accuracies statistics:
2024-10-09 14:46:32,644 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.0, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.5, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.25, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.5, 121: 0.75, 122: 0.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 0.5, 148: 1.0, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 1.0, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.25, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-09 14:46:32,731 [INFO] [30] TRAIN  loss: 0.1483547931873343 acc: 0.9578313253012049
2024-10-09 14:46:32,732 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.1483547931873343}
2024-10-09 14:46:32,732 [INFO] [30] VALIDATION loss: 1.3350575809125547 VALIDATION  acc: 0.6830808080808081
2024-10-09 14:46:32,732 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.3350575809125547}
2024-10-09 14:46:32,732 [INFO] 
2024-10-09 14:48:09,483 [INFO] Step[50/144]: training loss : 0.1234294842928648 TRAIN  loss dict:  {'classification_loss': 0.1234294842928648}
2024-10-09 14:49:13,709 [INFO] Step[100/144]: training loss : 0.10907288774847984 TRAIN  loss dict:  {'classification_loss': 0.10907288774847984}
2024-10-09 14:51:32,090 [INFO] Label accuracies statistics:
2024-10-09 14:51:32,090 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.5, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.5, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 1.0, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.5, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 1.0, 114: 0.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.5, 198: 0.5}

2024-10-09 14:51:33,391 [INFO] [31] TRAIN  loss: 0.11667175399553445 acc: 0.9657089898053753
2024-10-09 14:51:33,391 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.11667175399553445}
2024-10-09 14:51:33,391 [INFO] [31] VALIDATION loss: 1.196876436471939 VALIDATION  acc: 0.7133838383838383
2024-10-09 14:51:33,391 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.196876436471939}
2024-10-09 14:51:33,391 [INFO] 
2024-10-09 14:53:10,782 [INFO] Step[50/144]: training loss : 0.10192816521972418 TRAIN  loss dict:  {'classification_loss': 0.10192816521972418}
2024-10-09 14:54:17,180 [INFO] Step[100/144]: training loss : 0.10957144249230623 TRAIN  loss dict:  {'classification_loss': 0.10957144249230623}
2024-10-09 14:56:34,886 [INFO] Label accuracies statistics:
2024-10-09 14:56:34,887 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.5, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.25, 144: 0.5, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 0.25, 197: 1.0, 198: 0.75}

2024-10-09 14:56:34,968 [INFO] [32] TRAIN  loss: 0.10280832947076608 acc: 0.9712696941612604
2024-10-09 14:56:34,969 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.10280832947076608}
2024-10-09 14:56:34,969 [INFO] [32] VALIDATION loss: 1.2620432084357296 VALIDATION  acc: 0.6931818181818182
2024-10-09 14:56:34,969 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 1.2620432084357296}
2024-10-09 14:56:34,969 [INFO] 
2024-10-09 14:58:10,223 [INFO] Step[50/144]: training loss : 0.08352666333317757 TRAIN  loss dict:  {'classification_loss': 0.08352666333317757}
2024-10-09 14:59:15,619 [INFO] Step[100/144]: training loss : 0.09126856664195657 TRAIN  loss dict:  {'classification_loss': 0.09126856664195657}
2024-10-09 15:01:34,746 [INFO] Label accuracies statistics:
2024-10-09 15:01:34,746 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.5, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 0.5, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.5}

2024-10-09 15:01:34,817 [INFO] [33] TRAIN  loss: 0.09346508684231797 acc: 0.9756719184430028
2024-10-09 15:01:34,817 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.09346508684231797}
2024-10-09 15:01:34,817 [INFO] [33] VALIDATION loss: 1.2135775983333588 VALIDATION  acc: 0.7159090909090909
2024-10-09 15:01:34,817 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 1.2135775983333588}
2024-10-09 15:01:34,817 [INFO] 
2024-10-09 15:03:10,220 [INFO] Step[50/144]: training loss : 0.0844573698937893 TRAIN  loss dict:  {'classification_loss': 0.0844573698937893}
2024-10-09 15:04:15,311 [INFO] Step[100/144]: training loss : 0.09114224836230278 TRAIN  loss dict:  {'classification_loss': 0.09114224836230278}
2024-10-09 15:06:32,554 [INFO] Label accuracies statistics:
2024-10-09 15:06:32,554 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.25, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.25, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.25, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.5}

2024-10-09 15:06:33,754 [INFO] [34] TRAIN  loss: 0.09436584465826552 acc: 0.9735866543095458
2024-10-09 15:06:33,754 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.09436584465826552}
2024-10-09 15:06:33,754 [INFO] [34] VALIDATION loss: 1.1746610397541966 VALIDATION  acc: 0.7121212121212122
2024-10-09 15:06:33,754 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 1.1746610397541966}
2024-10-09 15:06:33,754 [INFO] 
2024-10-09 15:08:14,990 [INFO] Step[50/144]: training loss : 0.08527002312242984 TRAIN  loss dict:  {'classification_loss': 0.08527002312242984}
2024-10-09 15:09:20,691 [INFO] Step[100/144]: training loss : 0.09471834860742093 TRAIN  loss dict:  {'classification_loss': 0.09471834860742093}
2024-10-09 15:11:39,332 [INFO] Label accuracies statistics:
2024-10-09 15:11:39,333 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.25, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.25, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.5, 150: 0.0, 151: 1.0, 152: 0.5, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-10-09 15:11:39,408 [INFO] [35] TRAIN  loss: 0.09436862981723 acc: 0.9742817423540315
2024-10-09 15:11:39,408 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.09436862981723}
2024-10-09 15:11:39,408 [INFO] [35] VALIDATION loss: 1.3114103724559147 VALIDATION  acc: 0.7121212121212122
2024-10-09 15:11:39,409 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 1.3114103724559147}
2024-10-09 15:11:39,409 [INFO] 
2024-10-09 15:13:14,943 [INFO] Step[50/144]: training loss : 0.09461942154914141 TRAIN  loss dict:  {'classification_loss': 0.09461942154914141}
2024-10-09 15:14:21,115 [INFO] Step[100/144]: training loss : 0.09552756102755666 TRAIN  loss dict:  {'classification_loss': 0.09552756102755666}
2024-10-09 15:16:33,137 [INFO] Label accuracies statistics:
2024-10-09 15:16:33,137 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.25, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.5, 148: 1.0, 149: 0.75, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.75, 169: 1.0, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.25, 197: 0.75, 198: 0.75}

2024-10-09 15:16:33,242 [INFO] [36] TRAIN  loss: 0.10092874028487131 acc: 0.9738183503243745
2024-10-09 15:16:33,242 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.10092874028487131}
2024-10-09 15:16:33,242 [INFO] [36] VALIDATION loss: 1.3458101407245353 VALIDATION  acc: 0.7058080808080808
2024-10-09 15:16:33,242 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 1.3458101407245353}
2024-10-09 15:16:33,242 [INFO] 
2024-10-09 15:18:21,124 [INFO] Step[50/144]: training loss : 0.08236728627234698 TRAIN  loss dict:  {'classification_loss': 0.08236728627234698}
2024-10-09 15:19:24,564 [INFO] Step[100/144]: training loss : 0.07872140426188708 TRAIN  loss dict:  {'classification_loss': 0.07872140426188708}
2024-10-09 15:21:41,822 [INFO] Label accuracies statistics:
2024-10-09 15:21:41,822 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.25, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.5, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 1.0}

2024-10-09 15:21:41,899 [INFO] [37] TRAIN  loss: 0.08789852472384357 acc: 0.9726598702502317
2024-10-09 15:21:41,899 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.08789852472384357}
2024-10-09 15:21:41,899 [INFO] [37] VALIDATION loss: 1.1990975157047312 VALIDATION  acc: 0.7146464646464646
2024-10-09 15:21:41,899 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.1990975157047312}
2024-10-09 15:21:41,899 [INFO] 
2024-10-09 15:23:16,156 [INFO] Step[50/144]: training loss : 0.07470886208117009 TRAIN  loss dict:  {'classification_loss': 0.07470886208117009}
2024-10-09 15:24:20,146 [INFO] Step[100/144]: training loss : 0.07507240487262606 TRAIN  loss dict:  {'classification_loss': 0.07507240487262606}
2024-10-09 15:26:25,660 [INFO] Label accuracies statistics:
2024-10-09 15:26:25,660 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.25, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.5, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.5, 116: 1.0, 117: 0.25, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.25, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-09 15:26:25,772 [INFO] [38] TRAIN  loss: 0.07701041824313709 acc: 0.9777571825764597
2024-10-09 15:26:25,772 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.07701041824313709}
2024-10-09 15:26:25,772 [INFO] [38] VALIDATION loss: 1.323237314130421 VALIDATION  acc: 0.6868686868686869
2024-10-09 15:26:25,772 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 1.323237314130421}
2024-10-09 15:26:25,773 [INFO] 
2024-10-09 15:28:01,066 [INFO] Step[50/144]: training loss : 0.08860604733228683 TRAIN  loss dict:  {'classification_loss': 0.08860604733228683}
2024-10-09 15:29:06,384 [INFO] Step[100/144]: training loss : 0.07654116058722138 TRAIN  loss dict:  {'classification_loss': 0.07654116058722138}
2024-10-09 15:31:05,827 [INFO] Label accuracies statistics:
2024-10-09 15:31:05,827 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.5, 121: 1.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 0.5, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.5, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.5, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 15:31:05,922 [INFO] [39] TRAIN  loss: 0.07880935226502414 acc: 0.9782205746061168
2024-10-09 15:31:05,922 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.07880935226502414}
2024-10-09 15:31:05,922 [INFO] [39] VALIDATION loss: 1.266429087905972 VALIDATION  acc: 0.7184343434343434
2024-10-09 15:31:05,922 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 1.266429087905972}
2024-10-09 15:31:05,923 [INFO] 
2024-10-09 15:32:49,126 [INFO] Step[50/144]: training loss : 0.07982058821246028 TRAIN  loss dict:  {'classification_loss': 0.07982058821246028}
2024-10-09 15:33:54,983 [INFO] Step[100/144]: training loss : 0.08236660238355398 TRAIN  loss dict:  {'classification_loss': 0.08236660238355398}
2024-10-09 15:35:56,406 [INFO] Label accuracies statistics:
2024-10-09 15:35:56,406 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.0, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 15:35:57,818 [INFO] [40] TRAIN  loss: 0.08052802761732084 acc: 0.9786839666357738
2024-10-09 15:35:57,818 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.08052802761732084}
2024-10-09 15:35:57,818 [INFO] [40] VALIDATION loss: 1.1662895345577486 VALIDATION  acc: 0.7361111111111112
2024-10-09 15:35:57,818 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 1.1662895345577486}
2024-10-09 15:35:57,819 [INFO] 
2024-10-09 15:37:42,208 [INFO] Step[50/144]: training loss : 0.06330682575702667 TRAIN  loss dict:  {'classification_loss': 0.06330682575702667}
2024-10-09 15:38:46,860 [INFO] Step[100/144]: training loss : 0.058938488084822896 TRAIN  loss dict:  {'classification_loss': 0.058938488084822896}
2024-10-09 15:40:48,251 [INFO] Label accuracies statistics:
2024-10-09 15:40:48,251 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.5, 19: 0.0, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 1.0, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 0.75, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.0, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 15:40:48,340 [INFO] [41] TRAIN  loss: 0.06081504085321083 acc: 0.9835495829471733
2024-10-09 15:40:48,340 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.06081504085321083}
2024-10-09 15:40:48,340 [INFO] [41] VALIDATION loss: 1.2270504688775097 VALIDATION  acc: 0.7171717171717171
2024-10-09 15:40:48,340 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 1.2270504688775097}
2024-10-09 15:40:48,341 [INFO] 
2024-10-09 15:42:33,056 [INFO] Step[50/144]: training loss : 0.057675264794379476 TRAIN  loss dict:  {'classification_loss': 0.057675264794379476}
2024-10-09 15:43:36,789 [INFO] Step[100/144]: training loss : 0.07970156306400895 TRAIN  loss dict:  {'classification_loss': 0.07970156306400895}
2024-10-09 15:45:38,398 [INFO] Label accuracies statistics:
2024-10-09 15:45:38,398 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.25, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 0.75, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.25, 143: 0.5, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-09 15:45:38,497 [INFO] [42] TRAIN  loss: 0.0628366367406367 acc: 0.9835495829471733
2024-10-09 15:45:38,497 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.0628366367406367}
2024-10-09 15:45:38,497 [INFO] [42] VALIDATION loss: 1.1882246037324269 VALIDATION  acc: 0.7222222222222222
2024-10-09 15:45:38,497 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 1.1882246037324269}
2024-10-09 15:45:38,497 [INFO] 
2024-10-09 15:47:28,549 [INFO] Step[50/144]: training loss : 0.047859841054305435 TRAIN  loss dict:  {'classification_loss': 0.047859841054305435}
2024-10-09 15:48:33,866 [INFO] Step[100/144]: training loss : 0.058204663824290036 TRAIN  loss dict:  {'classification_loss': 0.058204663824290036}
2024-10-09 15:50:34,739 [INFO] Label accuracies statistics:
2024-10-09 15:50:34,739 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.25, 7: 0.25, 8: 0.0, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 0.75, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-09 15:50:34,825 [INFO] [43] TRAIN  loss: 0.0574134531941834 acc: 0.9828544949026877
2024-10-09 15:50:34,825 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.0574134531941834}
2024-10-09 15:50:34,825 [INFO] [43] VALIDATION loss: 1.207743553927651 VALIDATION  acc: 0.7108585858585859
2024-10-09 15:50:34,825 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 1.207743553927651}
2024-10-09 15:50:34,825 [INFO] 
2024-10-09 15:52:20,384 [INFO] Step[50/144]: training loss : 0.06371801597066223 TRAIN  loss dict:  {'classification_loss': 0.06371801597066223}
2024-10-09 15:53:25,954 [INFO] Step[100/144]: training loss : 0.05686547599732876 TRAIN  loss dict:  {'classification_loss': 0.05686547599732876}
2024-10-09 15:55:26,101 [INFO] Label accuracies statistics:
2024-10-09 15:55:26,102 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.25, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.75, 114: 0.25, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 1.0, 182: 0.25, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.75}

2024-10-09 15:55:26,176 [INFO] [44] TRAIN  loss: 0.05876837465459377 acc: 0.9849397590361446
2024-10-09 15:55:26,176 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.05876837465459377}
2024-10-09 15:55:26,176 [INFO] [44] VALIDATION loss: 1.182412760125266 VALIDATION  acc: 0.7196969696969697
2024-10-09 15:55:26,176 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 1.182412760125266}
2024-10-09 15:55:26,176 [INFO] 
2024-10-09 15:57:10,239 [INFO] Step[50/144]: training loss : 0.057907051583752034 TRAIN  loss dict:  {'classification_loss': 0.057907051583752034}
2024-10-09 15:58:16,281 [INFO] Step[100/144]: training loss : 0.04362957548350096 TRAIN  loss dict:  {'classification_loss': 0.04362957548350096}
2024-10-09 16:00:18,277 [INFO] Label accuracies statistics:
2024-10-09 16:00:18,277 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.75, 114: 0.5, 115: 0.25, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.25, 165: 1.0, 166: 0.75, 167: 0.5, 168: 1.0, 169: 1.0, 170: 0.75, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-09 16:00:19,507 [INFO] [45] TRAIN  loss: 0.05322478922122779 acc: 0.9858665430954587
2024-10-09 16:00:19,507 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.05322478922122779}
2024-10-09 16:00:19,507 [INFO] [45] VALIDATION loss: 1.1454818530215158 VALIDATION  acc: 0.7411616161616161
2024-10-09 16:00:19,507 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.1454818530215158}
2024-10-09 16:00:19,507 [INFO] 
2024-10-09 16:02:04,054 [INFO] Step[50/144]: training loss : 0.050450400542467834 TRAIN  loss dict:  {'classification_loss': 0.050450400542467834}
2024-10-09 16:03:07,931 [INFO] Step[100/144]: training loss : 0.04448675855062902 TRAIN  loss dict:  {'classification_loss': 0.04448675855062902}
2024-10-09 16:05:10,268 [INFO] Label accuracies statistics:
2024-10-09 16:05:10,268 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.25, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-09 16:05:10,345 [INFO] [46] TRAIN  loss: 0.05593247201047941 acc: 0.9860982391102873
2024-10-09 16:05:10,345 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.05593247201047941}
2024-10-09 16:05:10,345 [INFO] [46] VALIDATION loss: 1.1660102627895497 VALIDATION  acc: 0.7285353535353535
2024-10-09 16:05:10,345 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 1.1660102627895497}
2024-10-09 16:05:10,345 [INFO] 
2024-10-09 16:06:53,701 [INFO] Step[50/144]: training loss : 0.06111800882034004 TRAIN  loss dict:  {'classification_loss': 0.06111800882034004}
2024-10-09 16:07:56,878 [INFO] Step[100/144]: training loss : 0.056306905196979645 TRAIN  loss dict:  {'classification_loss': 0.056306905196979645}
2024-10-09 16:10:01,102 [INFO] Label accuracies statistics:
2024-10-09 16:10:01,102 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.5, 115: 0.5, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.5, 144: 0.5, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.5, 164: 0.25, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.5, 197: 1.0, 198: 0.75}

2024-10-09 16:10:01,211 [INFO] [47] TRAIN  loss: 0.05775331270544686 acc: 0.9828544949026877
2024-10-09 16:10:01,211 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.05775331270544686}
2024-10-09 16:10:01,212 [INFO] [47] VALIDATION loss: 1.3219310737870358 VALIDATION  acc: 0.7032828282828283
2024-10-09 16:10:01,212 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 1.3219310737870358}
2024-10-09 16:10:01,212 [INFO] 
2024-10-09 16:11:46,061 [INFO] Step[50/144]: training loss : 0.043449209798127414 TRAIN  loss dict:  {'classification_loss': 0.043449209798127414}
2024-10-09 16:12:50,589 [INFO] Step[100/144]: training loss : 0.05369948208332062 TRAIN  loss dict:  {'classification_loss': 0.05369948208332062}
2024-10-09 16:14:54,051 [INFO] Label accuracies statistics:
2024-10-09 16:14:54,051 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.25, 197: 0.75, 198: 0.5}

2024-10-09 16:14:54,131 [INFO] [48] TRAIN  loss: 0.05095488656338097 acc: 0.9891102873030584
2024-10-09 16:14:54,131 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.05095488656338097}
2024-10-09 16:14:54,132 [INFO] [48] VALIDATION loss: 1.214453555919506 VALIDATION  acc: 0.7184343434343434
2024-10-09 16:14:54,132 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 1.214453555919506}
2024-10-09 16:14:54,132 [INFO] 
2024-10-09 16:16:37,767 [INFO] Step[50/144]: training loss : 0.03763160964474082 TRAIN  loss dict:  {'classification_loss': 0.03763160964474082}
2024-10-09 16:17:41,668 [INFO] Step[100/144]: training loss : 0.04431250758469105 TRAIN  loss dict:  {'classification_loss': 0.04431250758469105}
2024-10-09 16:19:45,127 [INFO] Label accuracies statistics:
2024-10-09 16:19:45,127 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.5, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.25, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-09 16:19:45,226 [INFO] [49] TRAIN  loss: 0.04233887048839177 acc: 0.9874884151992586
2024-10-09 16:19:45,226 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.04233887048839177}
2024-10-09 16:19:45,226 [INFO] [49] VALIDATION loss: 1.2198014637386356 VALIDATION  acc: 0.7373737373737373
2024-10-09 16:19:45,226 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.2198014637386356}
2024-10-09 16:19:45,227 [INFO] 
2024-10-09 16:21:28,970 [INFO] Step[50/144]: training loss : 0.03672655995003879 TRAIN  loss dict:  {'classification_loss': 0.03672655995003879}
2024-10-09 16:22:34,111 [INFO] Step[100/144]: training loss : 0.058028534818440676 TRAIN  loss dict:  {'classification_loss': 0.058028534818440676}
2024-10-09 16:24:36,579 [INFO] Label accuracies statistics:
2024-10-09 16:24:36,579 [INFO] {0: 0.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.5, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.25, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.25, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.25, 197: 0.75, 198: 0.5}

2024-10-09 16:24:36,658 [INFO] [50] TRAIN  loss: 0.04362847950607021 acc: 0.9870250231696015
2024-10-09 16:24:36,658 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.04362847950607021}
2024-10-09 16:24:36,658 [INFO] [50] VALIDATION loss: 1.302604721100242 VALIDATION  acc: 0.6994949494949495
2024-10-09 16:24:36,658 [INFO] [50] VALIDATION  loss dict: {'classification_loss': 1.302604721100242}
2024-10-09 16:24:36,659 [INFO] 
2024-10-09 16:26:22,096 [INFO] Step[50/144]: training loss : 0.03867024455685168 TRAIN  loss dict:  {'classification_loss': 0.03867024455685168}
2024-10-09 16:27:26,636 [INFO] Step[100/144]: training loss : 0.037846772065386176 TRAIN  loss dict:  {'classification_loss': 0.037846772065386176}
2024-10-09 16:29:28,707 [INFO] Label accuracies statistics:
2024-10-09 16:29:28,707 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.25, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.75, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 16:29:29,895 [INFO] [51] TRAIN  loss: 0.03972328083990659 acc: 0.9879518072289156
2024-10-09 16:29:29,895 [INFO] [51] TRAIN  loss dict: {'classification_loss': 0.03972328083990659}
2024-10-09 16:29:29,895 [INFO] [51] VALIDATION loss: 1.1376456358918436 VALIDATION  acc: 0.7411616161616161
2024-10-09 16:29:29,895 [INFO] [51] VALIDATION  loss dict: {'classification_loss': 1.1376456358918436}
2024-10-09 16:29:29,895 [INFO] 
2024-10-09 16:31:14,750 [INFO] Step[50/144]: training loss : 0.04160042476840317 TRAIN  loss dict:  {'classification_loss': 0.04160042476840317}
2024-10-09 16:32:18,357 [INFO] Step[100/144]: training loss : 0.031949440268799666 TRAIN  loss dict:  {'classification_loss': 0.031949440268799666}
2024-10-09 16:34:20,476 [INFO] Label accuracies statistics:
2024-10-09 16:34:20,476 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.25, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.5, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.5, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-09 16:34:20,577 [INFO] [52] TRAIN  loss: 0.03606158206821419 acc: 0.9916589434661723
2024-10-09 16:34:20,577 [INFO] [52] TRAIN  loss dict: {'classification_loss': 0.03606158206821419}
2024-10-09 16:34:20,577 [INFO] [52] VALIDATION loss: 1.2259133198746928 VALIDATION  acc: 0.7272727272727273
2024-10-09 16:34:20,578 [INFO] [52] VALIDATION  loss dict: {'classification_loss': 1.2259133198746928}
2024-10-09 16:34:20,578 [INFO] 
2024-10-09 16:36:10,991 [INFO] Step[50/144]: training loss : 0.035433714492246506 TRAIN  loss dict:  {'classification_loss': 0.035433714492246506}
2024-10-09 16:37:07,673 [INFO] Step[100/144]: training loss : 0.03216071947943419 TRAIN  loss dict:  {'classification_loss': 0.03216071947943419}
2024-10-09 16:38:46,355 [INFO] Label accuracies statistics:
2024-10-09 16:38:46,355 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.25, 72: 0.75, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.25, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.5, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 1.0, 144: 0.25, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 16:38:46,425 [INFO] [53] TRAIN  loss: 0.033199458813113675 acc: 0.991890639481001
2024-10-09 16:38:46,425 [INFO] [53] TRAIN  loss dict: {'classification_loss': 0.033199458813113675}
2024-10-09 16:38:46,425 [INFO] [53] VALIDATION loss: 1.255373842186398 VALIDATION  acc: 0.7184343434343434
2024-10-09 16:38:46,425 [INFO] [53] VALIDATION  loss dict: {'classification_loss': 1.255373842186398}
2024-10-09 16:38:46,425 [INFO] 
2024-10-09 16:40:04,918 [INFO] Step[50/144]: training loss : 0.0328408673685044 TRAIN  loss dict:  {'classification_loss': 0.0328408673685044}
2024-10-09 16:41:00,768 [INFO] Step[100/144]: training loss : 0.030286859516054393 TRAIN  loss dict:  {'classification_loss': 0.030286859516054393}
2024-10-09 16:42:39,110 [INFO] Label accuracies statistics:
2024-10-09 16:42:39,110 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.5, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.25, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 0.5, 179: 0.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.25, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.5, 198: 0.5}

2024-10-09 16:42:39,181 [INFO] [54] TRAIN  loss: 0.03464421399662064 acc: 0.991890639481001
2024-10-09 16:42:39,181 [INFO] [54] TRAIN  loss dict: {'classification_loss': 0.03464421399662064}
2024-10-09 16:42:39,181 [INFO] [54] VALIDATION loss: 1.1603386661520712 VALIDATION  acc: 0.7310606060606061
2024-10-09 16:42:39,181 [INFO] [54] VALIDATION  loss dict: {'classification_loss': 1.1603386661520712}
2024-10-09 16:42:39,181 [INFO] 
2024-10-09 16:44:12,077 [INFO] Step[50/144]: training loss : 0.0317201712494716 TRAIN  loss dict:  {'classification_loss': 0.0317201712494716}
2024-10-09 16:45:08,026 [INFO] Step[100/144]: training loss : 0.027586435684934258 TRAIN  loss dict:  {'classification_loss': 0.027586435684934258}
2024-10-09 16:46:46,478 [INFO] Label accuracies statistics:
2024-10-09 16:46:46,478 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.25, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.75, 123: 0.25, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-09 16:46:46,548 [INFO] [55] TRAIN  loss: 0.030698893148736615 acc: 0.9928174235403151
2024-10-09 16:46:46,548 [INFO] [55] TRAIN  loss dict: {'classification_loss': 0.030698893148736615}
2024-10-09 16:46:46,548 [INFO] [55] VALIDATION loss: 1.2928652492938217 VALIDATION  acc: 0.7196969696969697
2024-10-09 16:46:46,548 [INFO] [55] VALIDATION  loss dict: {'classification_loss': 1.2928652492938217}
2024-10-09 16:46:46,548 [INFO] 
2024-10-09 16:48:04,548 [INFO] Step[50/144]: training loss : 0.02710106415208429 TRAIN  loss dict:  {'classification_loss': 0.02710106415208429}
2024-10-09 16:49:00,268 [INFO] Step[100/144]: training loss : 0.026443008305504917 TRAIN  loss dict:  {'classification_loss': 0.026443008305504917}
2024-10-09 16:50:38,866 [INFO] Label accuracies statistics:
2024-10-09 16:50:38,866 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.5, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.0, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 0.5, 197: 0.75, 198: 0.75}

2024-10-09 16:50:38,937 [INFO] [56] TRAIN  loss: 0.027133100826176815 acc: 0.9942075996292864
2024-10-09 16:50:38,937 [INFO] [56] TRAIN  loss dict: {'classification_loss': 0.027133100826176815}
2024-10-09 16:50:38,937 [INFO] [56] VALIDATION loss: 1.2551932152774599 VALIDATION  acc: 0.7234848484848485
2024-10-09 16:50:38,937 [INFO] [56] VALIDATION  loss dict: {'classification_loss': 1.2551932152774599}
2024-10-09 16:50:38,937 [INFO] 
2024-10-09 16:51:57,071 [INFO] Step[50/144]: training loss : 0.022006288971751928 TRAIN  loss dict:  {'classification_loss': 0.022006288971751928}
2024-10-09 16:52:52,955 [INFO] Step[100/144]: training loss : 0.02962555257137865 TRAIN  loss dict:  {'classification_loss': 0.02962555257137865}
2024-10-09 16:54:31,241 [INFO] Label accuracies statistics:
2024-10-09 16:54:31,241 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.75, 114: 0.25, 115: 0.5, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.5, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.25, 197: 0.75, 198: 1.0}

2024-10-09 16:54:31,311 [INFO] [57] TRAIN  loss: 0.02703792088949639 acc: 0.9930491195551436
2024-10-09 16:54:31,311 [INFO] [57] TRAIN  loss dict: {'classification_loss': 0.02703792088949639}
2024-10-09 16:54:31,311 [INFO] [57] VALIDATION loss: 1.2988734129402373 VALIDATION  acc: 0.7196969696969697
2024-10-09 16:54:31,311 [INFO] [57] VALIDATION  loss dict: {'classification_loss': 1.2988734129402373}
2024-10-09 16:54:31,311 [INFO] 
2024-10-09 16:55:49,829 [INFO] Step[50/144]: training loss : 0.032487941440194845 TRAIN  loss dict:  {'classification_loss': 0.032487941440194845}
2024-10-09 16:56:45,511 [INFO] Step[100/144]: training loss : 0.023513488033786417 TRAIN  loss dict:  {'classification_loss': 0.023513488033786417}
2024-10-09 16:58:24,175 [INFO] Label accuracies statistics:
2024-10-09 16:58:24,175 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.25, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-09 16:58:24,246 [INFO] [58] TRAIN  loss: 0.02731325861532241 acc: 0.9935125115848007
2024-10-09 16:58:24,246 [INFO] [58] TRAIN  loss dict: {'classification_loss': 0.02731325861532241}
2024-10-09 16:58:24,246 [INFO] [58] VALIDATION loss: 1.2472572230078556 VALIDATION  acc: 0.7348484848484849
2024-10-09 16:58:24,246 [INFO] [58] VALIDATION  loss dict: {'classification_loss': 1.2472572230078556}
2024-10-09 16:58:24,247 [INFO] 
2024-10-09 16:59:43,067 [INFO] Step[50/144]: training loss : 0.02280461087822914 TRAIN  loss dict:  {'classification_loss': 0.02280461087822914}
2024-10-09 17:00:38,839 [INFO] Step[100/144]: training loss : 0.02652420211583376 TRAIN  loss dict:  {'classification_loss': 0.02652420211583376}
2024-10-09 17:02:17,330 [INFO] Label accuracies statistics:
2024-10-09 17:02:17,330 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.0, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 1.0, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.5, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-09 17:02:17,400 [INFO] [59] TRAIN  loss: 0.028015958313416276 acc: 0.9932808155699722
2024-10-09 17:02:17,400 [INFO] [59] TRAIN  loss dict: {'classification_loss': 0.028015958313416276}
2024-10-09 17:02:17,400 [INFO] [59] VALIDATION loss: 1.2078562262985442 VALIDATION  acc: 0.7297979797979798
2024-10-09 17:02:17,400 [INFO] [59] VALIDATION  loss dict: {'classification_loss': 1.2078562262985442}
2024-10-09 17:02:17,400 [INFO] 
2024-10-09 17:03:41,488 [INFO] Step[50/144]: training loss : 0.026036582798697055 TRAIN  loss dict:  {'classification_loss': 0.026036582798697055}
2024-10-09 17:04:37,978 [INFO] Step[100/144]: training loss : 0.028178485413081943 TRAIN  loss dict:  {'classification_loss': 0.028178485413081943}
2024-10-09 17:06:42,642 [INFO] Label accuracies statistics:
2024-10-09 17:06:42,642 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.0, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 1.0, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.5, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 1.0, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-09 17:06:42,727 [INFO] [60] TRAIN  loss: 0.029074872986206576 acc: 0.9914272474513438
2024-10-09 17:06:42,727 [INFO] [60] TRAIN  loss dict: {'classification_loss': 0.029074872986206576}
2024-10-09 17:06:42,727 [INFO] [60] VALIDATION loss: 1.2320756222362872 VALIDATION  acc: 0.7297979797979798
2024-10-09 17:06:42,728 [INFO] [60] VALIDATION  loss dict: {'classification_loss': 1.2320756222362872}
2024-10-09 17:06:42,728 [INFO] 
2024-10-09 17:08:21,363 [INFO] Step[50/144]: training loss : 0.021035813009366394 TRAIN  loss dict:  {'classification_loss': 0.021035813009366394}
2024-10-09 17:09:24,447 [INFO] Step[100/144]: training loss : 0.02488787319511175 TRAIN  loss dict:  {'classification_loss': 0.02488787319511175}
2024-10-09 17:11:52,886 [INFO] Label accuracies statistics:
2024-10-09 17:11:52,886 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 0.5, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.25, 157: 0.5, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.5, 166: 0.75, 167: 0.75, 168: 1.0, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-09 17:11:52,991 [INFO] [61] TRAIN  loss: 0.023213506708594248 acc: 0.9944392956441149
2024-10-09 17:11:52,991 [INFO] [61] TRAIN  loss dict: {'classification_loss': 0.023213506708594248}
2024-10-09 17:11:52,991 [INFO] [61] VALIDATION loss: 1.26336004336675 VALIDATION  acc: 0.7121212121212122
2024-10-09 17:11:52,991 [INFO] [61] VALIDATION  loss dict: {'classification_loss': 1.26336004336675}
2024-10-09 17:11:52,991 [INFO] 
2024-10-09 17:13:29,432 [INFO] Step[50/144]: training loss : 0.019035564239602537 TRAIN  loss dict:  {'classification_loss': 0.019035564239602537}
2024-10-09 17:14:41,174 [INFO] Step[100/144]: training loss : 0.027628381017129867 TRAIN  loss dict:  {'classification_loss': 0.027628381017129867}
2024-10-09 17:16:48,192 [INFO] Label accuracies statistics:
2024-10-09 17:16:48,193 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 0.5, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.5, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.25, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.75, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-09 17:16:48,278 [INFO] [62] TRAIN  loss: 0.022403114885997236 acc: 0.9937442075996293
2024-10-09 17:16:48,278 [INFO] [62] TRAIN  loss dict: {'classification_loss': 0.022403114885997236}
2024-10-09 17:16:48,279 [INFO] [62] VALIDATION loss: 1.2437297854986455 VALIDATION  acc: 0.7184343434343434
2024-10-09 17:16:48,279 [INFO] [62] VALIDATION  loss dict: {'classification_loss': 1.2437297854986455}
2024-10-09 17:16:48,279 [INFO] 
2024-10-09 17:18:25,251 [INFO] Step[50/144]: training loss : 0.01659280827268958 TRAIN  loss dict:  {'classification_loss': 0.01659280827268958}
2024-10-09 17:19:36,696 [INFO] Step[100/144]: training loss : 0.029249208085238933 TRAIN  loss dict:  {'classification_loss': 0.029249208085238933}
2024-10-09 17:21:44,419 [INFO] Label accuracies statistics:
2024-10-09 17:21:44,420 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.25, 197: 1.0, 198: 0.5}

2024-10-09 17:21:44,504 [INFO] [63] TRAIN  loss: 0.02305874584756869 acc: 0.9939759036144579
2024-10-09 17:21:44,504 [INFO] [63] TRAIN  loss dict: {'classification_loss': 0.02305874584756869}
2024-10-09 17:21:44,505 [INFO] [63] VALIDATION loss: 1.1894602552056313 VALIDATION  acc: 0.7196969696969697
2024-10-09 17:21:44,505 [INFO] [63] VALIDATION  loss dict: {'classification_loss': 1.1894602552056313}
2024-10-09 17:21:44,505 [INFO] 
2024-10-09 17:23:21,049 [INFO] Step[50/144]: training loss : 0.022662873351946472 TRAIN  loss dict:  {'classification_loss': 0.022662873351946472}
2024-10-09 17:24:31,875 [INFO] Step[100/144]: training loss : 0.016806380790658295 TRAIN  loss dict:  {'classification_loss': 0.016806380790658295}
2024-10-09 17:26:39,215 [INFO] Label accuracies statistics:
2024-10-09 17:26:39,215 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-09 17:26:39,303 [INFO] [64] TRAIN  loss: 0.020414717563350376 acc: 0.9944392956441149
2024-10-09 17:26:39,303 [INFO] [64] TRAIN  loss dict: {'classification_loss': 0.020414717563350376}
2024-10-09 17:26:39,303 [INFO] [64] VALIDATION loss: 1.1986551199936204 VALIDATION  acc: 0.7512626262626263
2024-10-09 17:26:39,303 [INFO] [64] VALIDATION  loss dict: {'classification_loss': 1.1986551199936204}
2024-10-09 17:26:39,304 [INFO] 
2024-10-09 17:28:16,760 [INFO] Step[50/144]: training loss : 0.017182700373232364 TRAIN  loss dict:  {'classification_loss': 0.017182700373232364}
2024-10-09 17:29:29,021 [INFO] Step[100/144]: training loss : 0.0162010160041973 TRAIN  loss dict:  {'classification_loss': 0.0162010160041973}
2024-10-09 17:31:37,257 [INFO] Label accuracies statistics:
2024-10-09 17:31:37,257 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 0.75, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 1.0, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.75, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 0.5, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-09 17:31:37,357 [INFO] [65] TRAIN  loss: 0.014735454142889163 acc: 0.9967562557924003
2024-10-09 17:31:37,357 [INFO] [65] TRAIN  loss dict: {'classification_loss': 0.014735454142889163}
2024-10-09 17:31:37,357 [INFO] [65] VALIDATION loss: 1.2392777440448601 VALIDATION  acc: 0.7209595959595959
2024-10-09 17:31:37,357 [INFO] [65] VALIDATION  loss dict: {'classification_loss': 1.2392777440448601}
2024-10-09 17:31:37,357 [INFO] 
2024-10-09 17:33:31,391 [INFO] Step[50/144]: training loss : 0.020620806647930295 TRAIN  loss dict:  {'classification_loss': 0.020620806647930295}
2024-10-09 17:34:43,138 [INFO] Step[100/144]: training loss : 0.018428425977472216 TRAIN  loss dict:  {'classification_loss': 0.018428425977472216}
2024-10-09 17:36:51,908 [INFO] Label accuracies statistics:
2024-10-09 17:36:51,908 [INFO] {0: 0.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 1.0, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.5, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 1.0, 181: 0.75, 182: 0.25, 183: 0.25, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-09 17:36:52,005 [INFO] [66] TRAIN  loss: 0.019287779731611308 acc: 0.9946709916589435
2024-10-09 17:36:52,005 [INFO] [66] TRAIN  loss dict: {'classification_loss': 0.019287779731611308}
2024-10-09 17:36:52,005 [INFO] [66] VALIDATION loss: 1.1764639333166458 VALIDATION  acc: 0.7424242424242424
2024-10-09 17:36:52,005 [INFO] [66] VALIDATION  loss dict: {'classification_loss': 1.1764639333166458}
2024-10-09 17:36:52,005 [INFO] 
2024-10-09 17:36:52,005 [INFO] 

***Stop training***


2024-10-09 17:36:52,006 [INFO] 
Testing checkpointed models starting...

2024-10-09 17:37:53,432 [INFO] Label accuracies statistics:
2024-10-09 17:37:53,433 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.0, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.75, 15: 0.25, 16: 1.0, 17: 0.3333333333333333, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.75, 22: 1.0, 23: 1.0, 24: 0.75, 25: 1.0, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.5, 40: 1.0, 41: 0.75, 42: 0.75, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.25, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.0, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.75, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.25, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.5, 87: 0.5, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.5, 110: 0.5, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.0, 115: 0.25, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 1.0, 121: 0.25, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.25, 128: 1.0, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.25, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.5, 159: 1.0, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.0, 164: 0.5, 165: 1.0, 166: 0.25, 167: 0.75, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 1.0, 174: 0.75, 175: 0.5, 176: 0.75, 177: 1.0, 178: 0.75, 179: 0.5, 180: 0.5, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.0, 185: 1.0, 186: 1.0, 187: 0.75, 188: 0.25, 189: 1.0, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.25, 198: 1.0}

2024-10-09 17:37:53,503 [INFO] 
Testing accuracy: 0.7408343868520859
