2024-10-10 00:32:38,717 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention zc+pose+zk)...


2024-10-10 00:36:09,423 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention zc+pose+zk)...


2024-10-10 00:38:01,052 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention zc+pose+zk)...


2024-10-10 00:41:22,385 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention zc+pose+zk)...


2024-10-10 00:43:07,710 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention zc+pose+zk)...


2024-10-10 00:47:12,557 [INFO] Starting VTNHCPF_GCN/VTNHCPF_GCN with interpolate upsample and 256 gcn features unfreeze 2 layers vsl for one view (1024 + 256 attention zc+pose+zk)...


2024-10-10 00:48:42,015 [INFO] Step[50/144]: training loss : 5.6774475955963135 TRAIN  loss dict:  {'classification_loss': 5.6774475955963135}
2024-10-10 00:49:40,142 [INFO] Step[100/144]: training loss : 5.4504748058319095 TRAIN  loss dict:  {'classification_loss': 5.4504748058319095}
2024-10-10 00:51:33,927 [INFO] Label accuracies statistics:
2024-10-10 00:51:33,927 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.25, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.25, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.75, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.25, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0, 48: 0.25, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.0, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.0, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.5, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.0, 92: 0.0, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0, 101: 0.25, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.0, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.0, 142: 0.0, 143: 0.0, 144: 0.0, 145: 0.75, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.0, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.75, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.25, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 00:51:34,440 [INFO] [1] TRAIN  loss: 5.4839310348033905 acc: 0.006719184430027804
2024-10-10 00:51:34,440 [INFO] [1] TRAIN  loss dict: {'classification_loss': 5.4839310348033905}
2024-10-10 00:51:34,440 [INFO] [1] VALIDATION loss: 5.169116779609963 VALIDATION  acc: 0.021464646464646464
2024-10-10 00:51:34,440 [INFO] [1] VALIDATION  loss dict: {'classification_loss': 5.169116779609963}
2024-10-10 00:51:34,441 [INFO] 
2024-10-10 00:52:59,115 [INFO] Step[50/144]: training loss : 4.980227737426758 TRAIN  loss dict:  {'classification_loss': 4.980227737426758}
2024-10-10 00:53:57,003 [INFO] Step[100/144]: training loss : 4.828276033401489 TRAIN  loss dict:  {'classification_loss': 4.828276033401489}
2024-10-10 00:55:45,574 [INFO] Label accuracies statistics:
2024-10-10 00:55:45,574 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.5, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.25, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.25, 24: 0.0, 25: 0.0, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.0, 34: 0.0, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 0.25, 47: 0.0, 48: 0.0, 49: 0.0, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.25, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0, 67: 0.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.0, 77: 0.0, 78: 0.0, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.0, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.75, 92: 0.25, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.0, 99: 0.2, 100: 0.0, 101: 0.0, 102: 0.0, 103: 0.0, 104: 0.0, 105: 0.0, 106: 0.75, 107: 0.0, 108: 0.25, 109: 0.0, 110: 0.0, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.0, 119: 0.0, 120: 0.0, 121: 0.0, 122: 0.0, 123: 0.0, 124: 0.0, 125: 0.0, 126: 0.0, 127: 0.0, 128: 0.5, 129: 0.0, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.0, 134: 0.0, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.0, 139: 0.0, 140: 0.0, 141: 0.5, 142: 0.0, 143: 1.0, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.0, 150: 0.0, 151: 0.75, 152: 0.0, 153: 0.0, 154: 0.0, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.3333333333333333, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.25, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.5, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.0, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 198: 0.0}

2024-10-10 00:55:46,392 [INFO] [2] TRAIN  loss: 4.837299807204141 acc: 0.02108433734939759
2024-10-10 00:55:46,392 [INFO] [2] TRAIN  loss dict: {'classification_loss': 4.837299807204141}
2024-10-10 00:55:46,393 [INFO] [2] VALIDATION loss: 4.712441479718244 VALIDATION  acc: 0.047979797979797977
2024-10-10 00:55:46,393 [INFO] [2] VALIDATION  loss dict: {'classification_loss': 4.712441479718244}
2024-10-10 00:55:46,393 [INFO] 
2024-10-10 00:57:10,999 [INFO] Step[50/144]: training loss : 4.342820081710816 TRAIN  loss dict:  {'classification_loss': 4.342820081710816}
2024-10-10 00:58:09,100 [INFO] Step[100/144]: training loss : 4.095646743774414 TRAIN  loss dict:  {'classification_loss': 4.095646743774414}
2024-10-10 00:59:57,724 [INFO] Label accuracies statistics:
2024-10-10 00:59:57,724 [INFO] {0: 0.0, 1: 0.0, 2: 0.25, 3: 0.75, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.25, 12: 0.0, 13: 0.5, 14: 0.0, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.5, 19: 0.0, 20: 0.0, 21: 0.25, 22: 0.5, 23: 0.5, 24: 0.0, 25: 0.25, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.5, 30: 0.0, 31: 0.0, 32: 0.0, 33: 0.25, 34: 0.5, 35: 0.0, 36: 0.0, 37: 0.0, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.5, 46: 0.5, 47: 0.0, 48: 0.5, 49: 0.25, 50: 0.0, 51: 0.25, 52: 0.5, 53: 0.0, 54: 0.25, 55: 0.0, 56: 0.0, 57: 0.0, 58: 0.0, 59: 0.0, 60: 0.0, 61: 0.75, 62: 0.5, 63: 0.0, 64: 0.0, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.0, 73: 0.0, 74: 0.0, 75: 0.75, 76: 0.5, 77: 0.0, 78: 0.5, 79: 0.0, 80: 0.25, 81: 0.25, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.25, 86: 0.0, 87: 0.25, 88: 0.0, 89: 0.0, 90: 0.0, 91: 0.5, 92: 0.0, 93: 0.25, 94: 0.0, 95: 0.0, 96: 0.0, 97: 0.0, 98: 0.25, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.25, 103: 0.0, 104: 0.0, 105: 0.25, 106: 1.0, 107: 0.0, 108: 0.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.75, 115: 0.0, 116: 0.0, 117: 0.0, 118: 0.25, 119: 0.25, 120: 0.0, 121: 0.0, 122: 0.5, 123: 0.0, 124: 0.75, 125: 0.0, 126: 0.75, 127: 0.25, 128: 0.0, 129: 0.75, 130: 0.0, 131: 0.0, 132: 0.0, 133: 0.25, 134: 0.0, 135: 0.25, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.25, 140: 0.0, 141: 0.25, 142: 0.25, 143: 1.0, 144: 0.0, 145: 0.5, 146: 0.75, 147: 0.25, 148: 0.5, 149: 0.25, 150: 0.0, 151: 1.0, 152: 0.0, 153: 0.25, 154: 0.25, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.25, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.25, 168: 0.0, 169: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 176: 0.0, 177: 1.0, 178: 0.0, 179: 0.0, 180: 0.0, 181: 0.0, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.25, 186: 0.0, 187: 0.0, 188: 0.0, 189: 0.0, 190: 0.0, 191: 0.0, 192: 0.5, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.5, 197: 0.0, 198: 0.0}

2024-10-10 00:59:58,503 [INFO] [3] TRAIN  loss: 4.094903108146456 acc: 0.0984708063021316
2024-10-10 00:59:58,503 [INFO] [3] TRAIN  loss dict: {'classification_loss': 4.094903108146456}
2024-10-10 00:59:58,503 [INFO] [3] VALIDATION loss: 3.696085664961073 VALIDATION  acc: 0.1590909090909091
2024-10-10 00:59:58,503 [INFO] [3] VALIDATION  loss dict: {'classification_loss': 3.696085664961073}
2024-10-10 00:59:58,503 [INFO] 
2024-10-10 01:01:21,908 [INFO] Step[50/144]: training loss : 3.4322901439666746 TRAIN  loss dict:  {'classification_loss': 3.4322901439666746}
2024-10-10 01:02:19,950 [INFO] Step[100/144]: training loss : 3.1859274768829344 TRAIN  loss dict:  {'classification_loss': 3.1859274768829344}
2024-10-10 01:04:09,263 [INFO] Label accuracies statistics:
2024-10-10 01:04:09,263 [INFO] {0: 0.0, 1: 0.3333333333333333, 2: 0.5, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.5, 10: 0.25, 11: 0.75, 12: 0.25, 13: 0.0, 14: 0.25, 15: 0.3333333333333333, 16: 0.0, 17: 0.0, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.0, 25: 0.0, 26: 0.75, 27: 0.25, 28: 0.0, 29: 0.25, 30: 0.0, 31: 0.25, 32: 0.5, 33: 0.75, 34: 0.5, 35: 0.75, 36: 0.25, 37: 0.5, 38: 0.25, 39: 1.0, 40: 0.5, 41: 0.0, 42: 0.0, 43: 0.0, 44: 0.5, 45: 0.25, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.0, 50: 0.0, 51: 0.25, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.0, 62: 0.25, 63: 0.25, 64: 0.25, 65: 0.75, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.25, 73: 0.25, 74: 0.5, 75: 0.75, 76: 0.5, 77: 0.0, 78: 1.0, 79: 0.0, 80: 0.5, 81: 0.75, 82: 0.0, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.25, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 0.25, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.0, 99: 0.4, 100: 0.0, 101: 0.0, 102: 0.25, 103: 0.0, 104: 0.0, 105: 1.0, 106: 1.0, 107: 0.0, 108: 0.5, 109: 0.0, 110: 0.75, 111: 0.25, 112: 0.25, 113: 0.5, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.25, 118: 1.0, 119: 0.25, 120: 0.0, 121: 0.25, 122: 0.5, 123: 0.0, 124: 0.5, 125: 0.25, 126: 0.0, 127: 0.5, 128: 0.75, 129: 0.5, 130: 0.0, 131: 0.0, 132: 0.75, 133: 0.25, 134: 0.25, 135: 1.0, 136: 0.25, 137: 0.0, 138: 0.0, 139: 0.75, 140: 0.5, 141: 0.0, 142: 0.25, 143: 0.0, 144: 0.0, 145: 0.5, 146: 1.0, 147: 0.25, 148: 0.5, 149: 0.25, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.0, 160: 0.0, 161: 0.0, 162: 0.0, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.75, 168: 0.0, 169: 0.0, 170: 0.25, 171: 0.25, 172: 0.0, 173: 0.5, 174: 0.5, 175: 0.5, 176: 0.25, 177: 0.25, 178: 1.0, 179: 0.0, 180: 0.0, 181: 0.25, 182: 0.0, 183: 0.0, 184: 0.0, 185: 0.75, 186: 0.0, 187: 0.5, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.0, 192: 0.75, 193: 0.25, 194: 0.5, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-10 01:04:10,041 [INFO] [4] TRAIN  loss: 3.229833874437544 acc: 0.2196478220574606
2024-10-10 01:04:10,041 [INFO] [4] TRAIN  loss dict: {'classification_loss': 3.229833874437544}
2024-10-10 01:04:10,041 [INFO] [4] VALIDATION loss: 2.9441301690207586 VALIDATION  acc: 0.27904040404040403
2024-10-10 01:04:10,041 [INFO] [4] VALIDATION  loss dict: {'classification_loss': 2.9441301690207586}
2024-10-10 01:04:10,041 [INFO] 
2024-10-10 01:05:32,801 [INFO] Step[50/144]: training loss : 2.737670319080353 TRAIN  loss dict:  {'classification_loss': 2.737670319080353}
2024-10-10 01:06:32,650 [INFO] Step[100/144]: training loss : 2.614184558391571 TRAIN  loss dict:  {'classification_loss': 2.614184558391571}
2024-10-10 01:08:24,401 [INFO] Label accuracies statistics:
2024-10-10 01:08:24,401 [INFO] {0: 0.0, 1: 0.3333333333333333, 2: 0.5, 3: 0.5, 4: 0.5, 5: 0.0, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.75, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.25, 19: 0.25, 20: 0.0, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.25, 25: 0.0, 26: 0.0, 27: 0.25, 28: 0.0, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.5, 33: 0.0, 34: 0.0, 35: 0.25, 36: 0.5, 37: 0.5, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 1.0, 43: 0.0, 44: 0.25, 45: 0.5, 46: 1.0, 47: 0.25, 48: 0.75, 49: 0.75, 50: 0.0, 51: 0.25, 52: 0.5, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.5, 57: 0.0, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.0, 62: 0.25, 63: 0.0, 64: 0.0, 65: 0.5, 66: 0.0, 67: 0.25, 68: 0.0, 69: 0.25, 70: 0.0, 71: 0.25, 72: 0.25, 73: 0.5, 74: 0.25, 75: 0.75, 76: 0.0, 77: 0.25, 78: 1.0, 79: 0.0, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.0, 84: 0.25, 85: 0.25, 86: 0.25, 87: 0.5, 88: 0.0, 89: 0.0, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.5, 96: 0.5, 97: 0.5, 98: 0.25, 99: 0.4, 100: 0.25, 101: 0.0, 102: 0.25, 103: 0.0, 104: 0.5, 105: 1.0, 106: 0.5, 107: 0.0, 108: 0.5, 109: 0.5, 110: 0.5, 111: 0.0, 112: 0.0, 113: 0.75, 114: 0.25, 115: 0.25, 116: 0.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.0, 121: 0.0, 122: 0.25, 123: 0.25, 124: 0.25, 125: 0.25, 126: 0.0, 127: 0.5, 128: 0.75, 129: 0.25, 130: 0.25, 131: 0.0, 132: 0.75, 133: 0.25, 134: 0.25, 135: 1.0, 136: 0.25, 137: 0.75, 138: 0.0, 139: 0.75, 140: 0.0, 141: 0.75, 142: 0.25, 143: 0.25, 144: 0.0, 145: 0.5, 146: 0.75, 147: 0.5, 148: 0.0, 149: 0.75, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.25, 154: 0.5, 155: 0.75, 156: 0.0, 157: 0.0, 158: 0.3333333333333333, 159: 0.25, 160: 0.0, 161: 0.75, 162: 0.75, 163: 0.0, 164: 0.0, 165: 0.5, 166: 0.0, 167: 0.25, 168: 0.0, 169: 0.5, 170: 0.5, 171: 0.0, 172: 0.25, 173: 0.5, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.0, 183: 0.25, 184: 0.25, 185: 0.5, 186: 0.25, 187: 0.75, 188: 0.0, 189: 0.25, 190: 0.0, 191: 0.25, 192: 0.75, 193: 0.0, 194: 0.0, 195: 0.0, 196: 0.25, 197: 0.0, 198: 0.0}

2024-10-10 01:08:25,218 [INFO] [5] TRAIN  loss: 2.6348601049847074 acc: 0.3211306765523633
2024-10-10 01:08:25,218 [INFO] [5] TRAIN  loss dict: {'classification_loss': 2.6348601049847074}
2024-10-10 01:08:25,218 [INFO] [5] VALIDATION loss: 2.6227220738375627 VALIDATION  acc: 0.3421717171717172
2024-10-10 01:08:25,218 [INFO] [5] VALIDATION  loss dict: {'classification_loss': 2.6227220738375627}
2024-10-10 01:08:25,218 [INFO] 
2024-10-10 01:09:49,011 [INFO] Step[50/144]: training loss : 2.16762948513031 TRAIN  loss dict:  {'classification_loss': 2.16762948513031}
2024-10-10 01:10:47,384 [INFO] Step[100/144]: training loss : 2.1577657985687257 TRAIN  loss dict:  {'classification_loss': 2.1577657985687257}
2024-10-10 01:12:36,882 [INFO] Label accuracies statistics:
2024-10-10 01:12:36,882 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.25, 3: 0.25, 4: 0.5, 5: 0.5, 6: 0.25, 7: 0.25, 8: 0.0, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.0, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.0, 18: 0.5, 19: 0.5, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 0.5, 27: 0.0, 28: 0.75, 29: 1.0, 30: 0.0, 31: 0.25, 32: 0.5, 33: 0.5, 34: 0.5, 35: 0.0, 36: 0.25, 37: 0.5, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.0, 44: 0.75, 45: 0.25, 46: 1.0, 47: 0.5, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.25, 52: 0.75, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.5, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.25, 63: 0.25, 64: 0.25, 65: 0.0, 66: 0.0, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.25, 71: 0.0, 72: 0.25, 73: 0.5, 74: 0.75, 75: 0.75, 76: 0.25, 77: 0.5, 78: 1.0, 79: 0.0, 80: 1.0, 81: 0.75, 82: 0.25, 83: 0.5, 84: 0.0, 85: 0.5, 86: 0.0, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.0, 97: 0.0, 98: 0.25, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 0.25, 105: 0.75, 106: 0.75, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.25, 112: 0.0, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.25, 122: 0.0, 123: 0.5, 124: 0.75, 125: 0.0, 126: 0.75, 127: 0.5, 128: 0.75, 129: 0.25, 130: 0.0, 131: 0.25, 132: 0.5, 133: 0.25, 134: 0.75, 135: 0.75, 136: 0.25, 137: 0.5, 138: 0.0, 139: 0.5, 140: 0.0, 141: 1.0, 142: 0.25, 143: 0.25, 144: 0.75, 145: 0.5, 146: 0.5, 147: 0.5, 148: 0.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.25, 153: 0.5, 154: 0.75, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.0, 163: 0.0, 164: 0.5, 165: 0.25, 166: 0.25, 167: 0.5, 168: 0.0, 169: 0.5, 170: 0.0, 171: 0.0, 172: 0.25, 173: 0.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.25, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.25, 194: 0.75, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.0}

2024-10-10 01:12:37,701 [INFO] [6] TRAIN  loss: 2.1429124391741223 acc: 0.448563484708063
2024-10-10 01:12:37,701 [INFO] [6] TRAIN  loss dict: {'classification_loss': 2.1429124391741223}
2024-10-10 01:12:37,702 [INFO] [6] VALIDATION loss: 2.177232477400038 VALIDATION  acc: 0.4457070707070707
2024-10-10 01:12:37,702 [INFO] [6] VALIDATION  loss dict: {'classification_loss': 2.177232477400038}
2024-10-10 01:12:37,702 [INFO] 
2024-10-10 01:14:01,429 [INFO] Step[50/144]: training loss : 1.8221059083938598 TRAIN  loss dict:  {'classification_loss': 1.8221059083938598}
2024-10-10 01:15:00,127 [INFO] Step[100/144]: training loss : 1.7499806308746337 TRAIN  loss dict:  {'classification_loss': 1.7499806308746337}
2024-10-10 01:16:49,044 [INFO] Label accuracies statistics:
2024-10-10 01:16:49,044 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.0, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.25, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.0, 32: 0.5, 33: 0.0, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.0, 39: 1.0, 40: 0.75, 41: 0.0, 42: 1.0, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.25, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.75, 62: 0.5, 63: 0.0, 64: 0.75, 65: 0.5, 66: 0.25, 67: 0.5, 68: 0.0, 69: 0.25, 70: 0.25, 71: 0.0, 72: 0.5, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.0, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 0.25, 103: 0.25, 104: 0.5, 105: 0.75, 106: 0.25, 107: 0.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.25, 113: 0.0, 114: 0.75, 115: 0.5, 116: 0.5, 117: 1.0, 118: 0.75, 119: 0.5, 120: 1.0, 121: 0.25, 122: 0.25, 123: 0.5, 124: 0.5, 125: 0.5, 126: 0.5, 127: 0.75, 128: 1.0, 129: 0.25, 130: 0.5, 131: 0.75, 132: 0.0, 133: 0.25, 134: 0.75, 135: 1.0, 136: 0.0, 137: 0.75, 138: 0.25, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.5, 143: 0.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.75, 151: 0.5, 152: 0.5, 153: 0.25, 154: 0.5, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.0, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.25, 163: 0.25, 164: 0.25, 165: 0.25, 166: 0.25, 167: 0.5, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.75, 172: 0.5, 173: 0.75, 174: 0.5, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-10 01:16:49,862 [INFO] [7] TRAIN  loss: 1.7453502921594515 acc: 0.5317423540315107
2024-10-10 01:16:49,862 [INFO] [7] TRAIN  loss dict: {'classification_loss': 1.7453502921594515}
2024-10-10 01:16:49,862 [INFO] [7] VALIDATION loss: 1.8487609404104728 VALIDATION  acc: 0.5265151515151515
2024-10-10 01:16:49,862 [INFO] [7] VALIDATION  loss dict: {'classification_loss': 1.8487609404104728}
2024-10-10 01:16:49,863 [INFO] 
2024-10-10 01:18:13,420 [INFO] Step[50/144]: training loss : 1.4376373815536498 TRAIN  loss dict:  {'classification_loss': 1.4376373815536498}
2024-10-10 01:19:11,876 [INFO] Step[100/144]: training loss : 1.4201127696037292 TRAIN  loss dict:  {'classification_loss': 1.4201127696037292}
2024-10-10 01:21:01,467 [INFO] Label accuracies statistics:
2024-10-10 01:21:01,467 [INFO] {0: 0.6666666666666666, 1: 0.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.25, 6: 0.75, 7: 0.5, 8: 0.0, 9: 0.75, 10: 0.25, 11: 0.5, 12: 0.75, 13: 0.25, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.25, 26: 0.5, 27: 0.25, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.25, 32: 0.25, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.5, 43: 0.25, 44: 0.5, 45: 0.25, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.0, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.0, 65: 0.25, 66: 0.25, 67: 0.25, 68: 0.0, 69: 0.5, 70: 0.0, 71: 0.75, 72: 0.75, 73: 0.5, 74: 0.5, 75: 0.75, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.25, 84: 0.5, 85: 0.25, 86: 0.25, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.0, 91: 0.75, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.25, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.5, 102: 1.0, 103: 0.5, 104: 0.75, 105: 1.0, 106: 0.5, 107: 1.0, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.75, 112: 0.25, 113: 0.0, 114: 0.5, 115: 0.5, 116: 0.25, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.0, 122: 0.75, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.0, 128: 1.0, 129: 0.25, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.25, 134: 0.5, 135: 1.0, 136: 0.25, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.25, 142: 0.5, 143: 0.25, 144: 0.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 0.5, 152: 0.5, 153: 0.25, 154: 1.0, 155: 0.5, 156: 0.0, 157: 1.0, 158: 0.3333333333333333, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.0, 165: 0.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.25, 171: 0.5, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 0.75, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.0, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.25, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.0, 196: 0.5, 197: 0.75, 198: 0.25}

2024-10-10 01:21:02,233 [INFO] [8] TRAIN  loss: 1.4352576844394207 acc: 0.6269694161260426
2024-10-10 01:21:02,233 [INFO] [8] TRAIN  loss dict: {'classification_loss': 1.4352576844394207}
2024-10-10 01:21:02,233 [INFO] [8] VALIDATION loss: 1.7699994687680844 VALIDATION  acc: 0.5429292929292929
2024-10-10 01:21:02,233 [INFO] [8] VALIDATION  loss dict: {'classification_loss': 1.7699994687680844}
2024-10-10 01:21:02,233 [INFO] 
2024-10-10 01:22:26,209 [INFO] Step[50/144]: training loss : 1.1501043272018432 TRAIN  loss dict:  {'classification_loss': 1.1501043272018432}
2024-10-10 01:23:24,573 [INFO] Step[100/144]: training loss : 1.191217097043991 TRAIN  loss dict:  {'classification_loss': 1.191217097043991}
2024-10-10 01:25:13,865 [INFO] Label accuracies statistics:
2024-10-10 01:25:13,865 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.25, 5: 0.0, 6: 0.75, 7: 0.0, 8: 0.0, 9: 1.0, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.75, 15: 0.0, 16: 0.5, 17: 0.0, 18: 0.5, 19: 0.25, 20: 0.25, 21: 0.0, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.25, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.25, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.25, 57: 0.5, 58: 0.0, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.0, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.25, 72: 0.5, 73: 0.5, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 0.75, 79: 0.25, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.25, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 0.75, 92: 0.5, 93: 0.75, 94: 0.25, 95: 0.5, 96: 0.5, 97: 0.25, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.25, 122: 0.75, 123: 0.75, 124: 0.75, 125: 0.75, 126: 0.5, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.5, 134: 0.0, 135: 1.0, 136: 0.25, 137: 1.0, 138: 0.0, 139: 1.0, 140: 1.0, 141: 0.5, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.25, 164: 0.0, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.25, 171: 0.25, 172: 0.5, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.0, 177: 0.75, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.25, 192: 0.75, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.25, 197: 1.0, 198: 0.25}

2024-10-10 01:25:14,640 [INFO] [9] TRAIN  loss: 1.1842797419263258 acc: 0.6807228915662651
2024-10-10 01:25:14,641 [INFO] [9] TRAIN  loss dict: {'classification_loss': 1.1842797419263258}
2024-10-10 01:25:14,641 [INFO] [9] VALIDATION loss: 1.5114606232554824 VALIDATION  acc: 0.6136363636363636
2024-10-10 01:25:14,641 [INFO] [9] VALIDATION  loss dict: {'classification_loss': 1.5114606232554824}
2024-10-10 01:25:14,641 [INFO] 
2024-10-10 01:26:38,224 [INFO] Step[50/144]: training loss : 1.015537222623825 TRAIN  loss dict:  {'classification_loss': 1.015537222623825}
2024-10-10 01:27:38,438 [INFO] Step[100/144]: training loss : 1.035300635099411 TRAIN  loss dict:  {'classification_loss': 1.035300635099411}
2024-10-10 01:29:29,028 [INFO] Label accuracies statistics:
2024-10-10 01:29:29,028 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.75, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 0.5, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.25, 55: 0.5, 56: 0.5, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.25, 64: 0.25, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.0, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.0, 84: 0.0, 85: 0.75, 86: 0.75, 87: 0.25, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.5, 99: 0.8, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.0, 115: 0.25, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.25, 122: 0.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.25, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 0.75, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.6666666666666666, 159: 0.25, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.5, 167: 0.25, 168: 0.75, 169: 0.5, 170: 0.5, 171: 0.25, 172: 0.5, 173: 0.25, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.0, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.25, 197: 0.5, 198: 0.25}

2024-10-10 01:29:29,848 [INFO] [10] TRAIN  loss: 1.0254099973373942 acc: 0.7221964782205746
2024-10-10 01:29:29,848 [INFO] [10] TRAIN  loss dict: {'classification_loss': 1.0254099973373942}
2024-10-10 01:29:29,848 [INFO] [10] VALIDATION loss: 1.447560601764255 VALIDATION  acc: 0.6224747474747475
2024-10-10 01:29:29,848 [INFO] [10] VALIDATION  loss dict: {'classification_loss': 1.447560601764255}
2024-10-10 01:29:29,848 [INFO] 
2024-10-10 01:30:54,032 [INFO] Step[50/144]: training loss : 0.7800849533081055 TRAIN  loss dict:  {'classification_loss': 0.7800849533081055}
2024-10-10 01:31:52,472 [INFO] Step[100/144]: training loss : 0.8033481645584106 TRAIN  loss dict:  {'classification_loss': 0.8033481645584106}
2024-10-10 01:33:41,570 [INFO] Label accuracies statistics:
2024-10-10 01:33:41,570 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.5, 9: 1.0, 10: 0.5, 11: 0.25, 12: 0.0, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 0.25, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.25, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.25, 85: 0.25, 86: 0.75, 87: 1.0, 88: 0.5, 89: 0.75, 90: 0.75, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 1.0, 140: 1.0, 141: 0.5, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.5, 169: 0.5, 170: 0.5, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 0.75, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 01:33:42,371 [INFO] [11] TRAIN  loss: 0.7997776785244545 acc: 0.796339202965709
2024-10-10 01:33:42,371 [INFO] [11] TRAIN  loss dict: {'classification_loss': 0.7997776785244545}
2024-10-10 01:33:42,371 [INFO] [11] VALIDATION loss: 1.2302822360286005 VALIDATION  acc: 0.6931818181818182
2024-10-10 01:33:42,371 [INFO] [11] VALIDATION  loss dict: {'classification_loss': 1.2302822360286005}
2024-10-10 01:33:42,372 [INFO] 
2024-10-10 01:35:05,558 [INFO] Step[50/144]: training loss : 0.6835882574319839 TRAIN  loss dict:  {'classification_loss': 0.6835882574319839}
2024-10-10 01:36:03,831 [INFO] Step[100/144]: training loss : 0.6850758302211761 TRAIN  loss dict:  {'classification_loss': 0.6850758302211761}
2024-10-10 01:37:52,864 [INFO] Label accuracies statistics:
2024-10-10 01:37:52,865 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.5, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.0, 22: 0.5, 23: 0.75, 24: 1.0, 25: 1.0, 26: 0.25, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.5, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.0, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.0, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.25, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.5, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.25, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.5, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.25, 144: 0.5, 145: 0.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.25, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.5, 165: 0.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 1.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.25}

2024-10-10 01:37:53,666 [INFO] [12] TRAIN  loss: 0.6947986661560006 acc: 0.819740500463392
2024-10-10 01:37:53,666 [INFO] [12] TRAIN  loss dict: {'classification_loss': 0.6947986661560006}
2024-10-10 01:37:53,667 [INFO] [12] VALIDATION loss: 1.1907111770576901 VALIDATION  acc: 0.6792929292929293
2024-10-10 01:37:53,667 [INFO] [12] VALIDATION  loss dict: {'classification_loss': 1.1907111770576901}
2024-10-10 01:37:53,667 [INFO] 
2024-10-10 01:39:16,868 [INFO] Step[50/144]: training loss : 0.5921548414230347 TRAIN  loss dict:  {'classification_loss': 0.5921548414230347}
2024-10-10 01:40:15,188 [INFO] Step[100/144]: training loss : 0.6190442430973053 TRAIN  loss dict:  {'classification_loss': 0.6190442430973053}
2024-10-10 01:42:04,705 [INFO] Label accuracies statistics:
2024-10-10 01:42:04,705 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.25, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.75, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.5, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 1.0, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.25, 99: 0.8, 100: 0.75, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.25, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.5, 112: 0.75, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 0.75, 152: 0.75, 153: 0.0, 154: 0.5, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.5, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.25, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 0.75, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.25, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 01:42:04,783 [INFO] [13] TRAIN  loss: 0.5919313547718856 acc: 0.8449953660797034
2024-10-10 01:42:04,783 [INFO] [13] TRAIN  loss dict: {'classification_loss': 0.5919313547718856}
2024-10-10 01:42:04,783 [INFO] [13] VALIDATION loss: 1.2192318627127894 VALIDATION  acc: 0.6843434343434344
2024-10-10 01:42:04,784 [INFO] [13] VALIDATION  loss dict: {'classification_loss': 1.2192318627127894}
2024-10-10 01:42:04,784 [INFO] 
2024-10-10 01:43:28,196 [INFO] Step[50/144]: training loss : 0.4969168597459793 TRAIN  loss dict:  {'classification_loss': 0.4969168597459793}
2024-10-10 01:44:26,417 [INFO] Step[100/144]: training loss : 0.5201514887809754 TRAIN  loss dict:  {'classification_loss': 0.5201514887809754}
2024-10-10 01:46:15,599 [INFO] Label accuracies statistics:
2024-10-10 01:46:15,599 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.25, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 0.5, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.5, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.25, 67: 0.75, 68: 0.0, 69: 0.25, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.5, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.25, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 01:46:19,207 [INFO] [14] TRAIN  loss: 0.5156917206736075 acc: 0.8653846153846154
2024-10-10 01:46:19,207 [INFO] [14] TRAIN  loss dict: {'classification_loss': 0.5156917206736075}
2024-10-10 01:46:19,207 [INFO] [14] VALIDATION loss: 1.158071744221228 VALIDATION  acc: 0.696969696969697
2024-10-10 01:46:19,207 [INFO] [14] VALIDATION  loss dict: {'classification_loss': 1.158071744221228}
2024-10-10 01:46:19,207 [INFO] 
2024-10-10 01:47:43,308 [INFO] Step[50/144]: training loss : 0.4489900264143944 TRAIN  loss dict:  {'classification_loss': 0.4489900264143944}
2024-10-10 01:48:42,400 [INFO] Step[100/144]: training loss : 0.43718694925308227 TRAIN  loss dict:  {'classification_loss': 0.43718694925308227}
2024-10-10 01:50:28,416 [INFO] Label accuracies statistics:
2024-10-10 01:50:28,417 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.75, 15: 0.3333333333333333, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.5, 26: 0.75, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.25, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.25, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.5, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.25, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.25, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.75, 190: 1.0, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.25}

2024-10-10 01:50:43,414 [INFO] [15] TRAIN  loss: 0.4486228617736035 acc: 0.8850787766450418
2024-10-10 01:50:43,414 [INFO] [15] TRAIN  loss dict: {'classification_loss': 0.4486228617736035}
2024-10-10 01:50:43,414 [INFO] [15] VALIDATION loss: 1.038388388024436 VALIDATION  acc: 0.7196969696969697
2024-10-10 01:50:43,414 [INFO] [15] VALIDATION  loss dict: {'classification_loss': 1.038388388024436}
2024-10-10 01:50:43,414 [INFO] 
2024-10-10 01:52:09,543 [INFO] Step[50/144]: training loss : 0.3803369614481926 TRAIN  loss dict:  {'classification_loss': 0.3803369614481926}
2024-10-10 01:53:08,599 [INFO] Step[100/144]: training loss : 0.428167881667614 TRAIN  loss dict:  {'classification_loss': 0.428167881667614}
2024-10-10 01:54:57,695 [INFO] Label accuracies statistics:
2024-10-10 01:54:57,695 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.75, 15: 0.0, 16: 0.0, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.5, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.25, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.0, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.25, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 1.0, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 01:54:57,777 [INFO] [16] TRAIN  loss: 0.4014575496936838 acc: 0.8962001853568119
2024-10-10 01:54:57,777 [INFO] [16] TRAIN  loss dict: {'classification_loss': 0.4014575496936838}
2024-10-10 01:54:57,778 [INFO] [16] VALIDATION loss: 1.1198431043713182 VALIDATION  acc: 0.7058080808080808
2024-10-10 01:54:57,778 [INFO] [16] VALIDATION  loss dict: {'classification_loss': 1.1198431043713182}
2024-10-10 01:54:57,778 [INFO] 
2024-10-10 01:56:21,722 [INFO] Step[50/144]: training loss : 0.3304508554935455 TRAIN  loss dict:  {'classification_loss': 0.3304508554935455}
2024-10-10 01:57:20,229 [INFO] Step[100/144]: training loss : 0.35157510280609133 TRAIN  loss dict:  {'classification_loss': 0.35157510280609133}
2024-10-10 01:59:09,182 [INFO] Label accuracies statistics:
2024-10-10 01:59:09,183 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.0, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.5, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.25, 48: 0.5, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.5, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-10 01:59:09,992 [INFO] [17] TRAIN  loss: 0.3514407793473866 acc: 0.9112604263206673
2024-10-10 01:59:09,992 [INFO] [17] TRAIN  loss dict: {'classification_loss': 0.3514407793473866}
2024-10-10 01:59:09,992 [INFO] [17] VALIDATION loss: 1.0234520418776407 VALIDATION  acc: 0.73989898989899
2024-10-10 01:59:09,992 [INFO] [17] VALIDATION  loss dict: {'classification_loss': 1.0234520418776407}
2024-10-10 01:59:09,992 [INFO] 
2024-10-10 02:00:33,722 [INFO] Step[50/144]: training loss : 0.26648070946335795 TRAIN  loss dict:  {'classification_loss': 0.26648070946335795}
2024-10-10 02:01:32,290 [INFO] Step[100/144]: training loss : 0.30242610529065134 TRAIN  loss dict:  {'classification_loss': 0.30242610529065134}
2024-10-10 02:03:21,108 [INFO] Label accuracies statistics:
2024-10-10 02:03:21,108 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.5, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.25, 65: 1.0, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.5, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.75, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.25, 171: 0.25, 172: 0.25, 173: 0.75, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 02:03:21,185 [INFO] [18] TRAIN  loss: 0.30017716541058487 acc: 0.9246987951807228
2024-10-10 02:03:21,185 [INFO] [18] TRAIN  loss dict: {'classification_loss': 0.30017716541058487}
2024-10-10 02:03:21,185 [INFO] [18] VALIDATION loss: 1.067517281130508 VALIDATION  acc: 0.7121212121212122
2024-10-10 02:03:21,185 [INFO] [18] VALIDATION  loss dict: {'classification_loss': 1.067517281130508}
2024-10-10 02:03:21,185 [INFO] 
2024-10-10 02:04:45,427 [INFO] Step[50/144]: training loss : 0.274259013235569 TRAIN  loss dict:  {'classification_loss': 0.274259013235569}
2024-10-10 02:05:43,836 [INFO] Step[100/144]: training loss : 0.2807443957030773 TRAIN  loss dict:  {'classification_loss': 0.2807443957030773}
2024-10-10 02:07:33,028 [INFO] Label accuracies statistics:
2024-10-10 02:07:33,028 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.0, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 0.75, 65: 0.25, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.25, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.5, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 1.0}

2024-10-10 02:07:33,112 [INFO] [19] TRAIN  loss: 0.28049347378934425 acc: 0.9325764596848934
2024-10-10 02:07:33,112 [INFO] [19] TRAIN  loss dict: {'classification_loss': 0.28049347378934425}
2024-10-10 02:07:33,112 [INFO] [19] VALIDATION loss: 1.1276418897840712 VALIDATION  acc: 0.7070707070707071
2024-10-10 02:07:33,112 [INFO] [19] VALIDATION  loss dict: {'classification_loss': 1.1276418897840712}
2024-10-10 02:07:33,112 [INFO] 
2024-10-10 02:08:57,195 [INFO] Step[50/144]: training loss : 0.24810986921191217 TRAIN  loss dict:  {'classification_loss': 0.24810986921191217}
2024-10-10 02:09:55,574 [INFO] Step[100/144]: training loss : 0.26480095282196997 TRAIN  loss dict:  {'classification_loss': 0.26480095282196997}
2024-10-10 02:11:48,686 [INFO] Label accuracies statistics:
2024-10-10 02:11:48,686 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.75, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.25, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.5, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.25, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 0.5, 112: 0.75, 113: 0.5, 114: 0.0, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 1.0, 134: 0.75, 135: 0.75, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.25, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.5, 150: 0.75, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 1.0, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 02:11:48,764 [INFO] [20] TRAIN  loss: 0.26219897443014717 acc: 0.9286376274328082
2024-10-10 02:11:48,764 [INFO] [20] TRAIN  loss dict: {'classification_loss': 0.26219897443014717}
2024-10-10 02:11:48,764 [INFO] [20] VALIDATION loss: 1.0691011583915464 VALIDATION  acc: 0.7335858585858586
2024-10-10 02:11:48,764 [INFO] [20] VALIDATION  loss dict: {'classification_loss': 1.0691011583915464}
2024-10-10 02:11:48,764 [INFO] 
2024-10-10 02:13:13,508 [INFO] Step[50/144]: training loss : 0.23106191121041775 TRAIN  loss dict:  {'classification_loss': 0.23106191121041775}
2024-10-10 02:14:11,536 [INFO] Step[100/144]: training loss : 0.22948476657271386 TRAIN  loss dict:  {'classification_loss': 0.22948476657271386}
2024-10-10 02:16:01,224 [INFO] Label accuracies statistics:
2024-10-10 02:16:01,224 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.0, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.5, 64: 0.25, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.5, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.5, 153: 0.75, 154: 0.75, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.5, 166: 0.5, 167: 0.5, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 02:16:01,295 [INFO] [21] TRAIN  loss: 0.22504676601642537 acc: 0.9413809082483782
2024-10-10 02:16:01,295 [INFO] [21] TRAIN  loss dict: {'classification_loss': 0.22504676601642537}
2024-10-10 02:16:01,295 [INFO] [21] VALIDATION loss: 1.0590791084148266 VALIDATION  acc: 0.7070707070707071
2024-10-10 02:16:01,295 [INFO] [21] VALIDATION  loss dict: {'classification_loss': 1.0590791084148266}
2024-10-10 02:16:01,295 [INFO] 
2024-10-10 02:17:25,490 [INFO] Step[50/144]: training loss : 0.16897942245006561 TRAIN  loss dict:  {'classification_loss': 0.16897942245006561}
2024-10-10 02:18:23,667 [INFO] Step[100/144]: training loss : 0.18954287946224213 TRAIN  loss dict:  {'classification_loss': 0.18954287946224213}
2024-10-10 02:20:24,511 [INFO] Label accuracies statistics:
2024-10-10 02:20:24,511 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.25, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.0, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.5, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.25, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 0.5, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.25, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 0.75, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 02:20:28,237 [INFO] [22] TRAIN  loss: 0.18579802530196807 acc: 0.956209453197405
2024-10-10 02:20:28,237 [INFO] [22] TRAIN  loss dict: {'classification_loss': 0.18579802530196807}
2024-10-10 02:20:28,237 [INFO] [22] VALIDATION loss: 0.9733223528773697 VALIDATION  acc: 0.7424242424242424
2024-10-10 02:20:28,237 [INFO] [22] VALIDATION  loss dict: {'classification_loss': 0.9733223528773697}
2024-10-10 02:20:28,237 [INFO] 
2024-10-10 02:21:53,839 [INFO] Step[50/144]: training loss : 0.18412913136184217 TRAIN  loss dict:  {'classification_loss': 0.18412913136184217}
2024-10-10 02:22:51,970 [INFO] Step[100/144]: training loss : 0.16333653561770917 TRAIN  loss dict:  {'classification_loss': 0.16333653561770917}
2024-10-10 02:24:41,527 [INFO] Label accuracies statistics:
2024-10-10 02:24:41,527 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.25, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 0.75, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 1.0, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.25, 189: 0.75, 190: 1.0, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 02:24:42,311 [INFO] [23] TRAIN  loss: 0.17870189094295105 acc: 0.9569045412418906
2024-10-10 02:24:42,311 [INFO] [23] TRAIN  loss dict: {'classification_loss': 0.17870189094295105}
2024-10-10 02:24:42,311 [INFO] [23] VALIDATION loss: 0.9718500050129714 VALIDATION  acc: 0.773989898989899
2024-10-10 02:24:42,311 [INFO] [23] VALIDATION  loss dict: {'classification_loss': 0.9718500050129714}
2024-10-10 02:24:42,311 [INFO] 
2024-10-10 02:26:07,241 [INFO] Step[50/144]: training loss : 0.14912344016134738 TRAIN  loss dict:  {'classification_loss': 0.14912344016134738}
2024-10-10 02:27:05,671 [INFO] Step[100/144]: training loss : 0.17388804197311403 TRAIN  loss dict:  {'classification_loss': 0.17388804197311403}
2024-10-10 02:28:54,988 [INFO] Label accuracies statistics:
2024-10-10 02:28:54,988 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 1.0, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.25, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.25, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 0.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.5, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.5, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 02:28:55,064 [INFO] [24] TRAIN  loss: 0.16034211109702787 acc: 0.9610750695088045
2024-10-10 02:28:55,064 [INFO] [24] TRAIN  loss dict: {'classification_loss': 0.16034211109702787}
2024-10-10 02:28:55,064 [INFO] [24] VALIDATION loss: 0.9983229159756943 VALIDATION  acc: 0.7386363636363636
2024-10-10 02:28:55,064 [INFO] [24] VALIDATION  loss dict: {'classification_loss': 0.9983229159756943}
2024-10-10 02:28:55,064 [INFO] 
2024-10-10 02:30:19,259 [INFO] Step[50/144]: training loss : 0.1658445131033659 TRAIN  loss dict:  {'classification_loss': 0.1658445131033659}
2024-10-10 02:31:18,160 [INFO] Step[100/144]: training loss : 0.13161829210817813 TRAIN  loss dict:  {'classification_loss': 0.13161829210817813}
2024-10-10 02:33:08,677 [INFO] Label accuracies statistics:
2024-10-10 02:33:08,677 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 1.0, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.0, 59: 0.25, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.25, 105: 0.75, 106: 1.0, 107: 0.75, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 0.75, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 0.5, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 02:33:09,458 [INFO] [25] TRAIN  loss: 0.1513672563402603 acc: 0.9633920296570899
2024-10-10 02:33:09,458 [INFO] [25] TRAIN  loss dict: {'classification_loss': 0.1513672563402603}
2024-10-10 02:33:09,458 [INFO] [25] VALIDATION loss: 0.9682579564827459 VALIDATION  acc: 0.7638888888888888
2024-10-10 02:33:09,458 [INFO] [25] VALIDATION  loss dict: {'classification_loss': 0.9682579564827459}
2024-10-10 02:33:09,458 [INFO] 
2024-10-10 02:34:35,414 [INFO] Step[50/144]: training loss : 0.12769209414720536 TRAIN  loss dict:  {'classification_loss': 0.12769209414720536}
2024-10-10 02:35:33,756 [INFO] Step[100/144]: training loss : 0.1466335053741932 TRAIN  loss dict:  {'classification_loss': 0.1466335053741932}
2024-10-10 02:37:23,193 [INFO] Label accuracies statistics:
2024-10-10 02:37:23,193 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.5, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.75, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.25, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.5, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 0.75, 109: 1.0, 110: 0.5, 111: 0.75, 112: 1.0, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 1.0, 123: 0.75, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.5}

2024-10-10 02:37:23,946 [INFO] [26] TRAIN  loss: 0.13783472440102035 acc: 0.9668674698795181
2024-10-10 02:37:23,946 [INFO] [26] TRAIN  loss dict: {'classification_loss': 0.13783472440102035}
2024-10-10 02:37:23,946 [INFO] [26] VALIDATION loss: 0.9677331408968678 VALIDATION  acc: 0.7702020202020202
2024-10-10 02:37:23,946 [INFO] [26] VALIDATION  loss dict: {'classification_loss': 0.9677331408968678}
2024-10-10 02:37:23,946 [INFO] 
2024-10-10 02:38:47,870 [INFO] Step[50/144]: training loss : 0.12604445658624172 TRAIN  loss dict:  {'classification_loss': 0.12604445658624172}
2024-10-10 02:39:46,955 [INFO] Step[100/144]: training loss : 0.13250003702938556 TRAIN  loss dict:  {'classification_loss': 0.13250003702938556}
2024-10-10 02:41:36,194 [INFO] Label accuracies statistics:
2024-10-10 02:41:36,194 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 1.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 02:41:36,272 [INFO] [27] TRAIN  loss: 0.13691883001269567 acc: 0.9652455977757183
2024-10-10 02:41:36,272 [INFO] [27] TRAIN  loss dict: {'classification_loss': 0.13691883001269567}
2024-10-10 02:41:36,272 [INFO] [27] VALIDATION loss: 1.003962250219451 VALIDATION  acc: 0.7575757575757576
2024-10-10 02:41:36,272 [INFO] [27] VALIDATION  loss dict: {'classification_loss': 1.003962250219451}
2024-10-10 02:41:36,273 [INFO] 
2024-10-10 02:43:00,642 [INFO] Step[50/144]: training loss : 0.11571108754724264 TRAIN  loss dict:  {'classification_loss': 0.11571108754724264}
2024-10-10 02:43:58,947 [INFO] Step[100/144]: training loss : 0.12347055681049823 TRAIN  loss dict:  {'classification_loss': 0.12347055681049823}
2024-10-10 02:45:48,273 [INFO] Label accuracies statistics:
2024-10-10 02:45:48,274 [INFO] {0: 0.6666666666666666, 1: 0.6666666666666666, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.5, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.25, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.5, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 02:45:48,346 [INFO] [28] TRAIN  loss: 0.1285538280305142 acc: 0.9675625579240037
2024-10-10 02:45:48,346 [INFO] [28] TRAIN  loss dict: {'classification_loss': 0.1285538280305142}
2024-10-10 02:45:48,346 [INFO] [28] VALIDATION loss: 1.0179289010939774 VALIDATION  acc: 0.7462121212121212
2024-10-10 02:45:48,346 [INFO] [28] VALIDATION  loss dict: {'classification_loss': 1.0179289010939774}
2024-10-10 02:45:48,346 [INFO] 
2024-10-10 02:47:12,661 [INFO] Step[50/144]: training loss : 0.1309867136925459 TRAIN  loss dict:  {'classification_loss': 0.1309867136925459}
2024-10-10 02:48:11,235 [INFO] Step[100/144]: training loss : 0.11773589689284564 TRAIN  loss dict:  {'classification_loss': 0.11773589689284564}
2024-10-10 02:50:00,600 [INFO] Label accuracies statistics:
2024-10-10 02:50:00,601 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 1.0, 88: 0.5, 89: 0.5, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.6666666666666666, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 1.0, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 02:50:00,684 [INFO] [29] TRAIN  loss: 0.12645952472101069 acc: 0.9661723818350324
2024-10-10 02:50:00,684 [INFO] [29] TRAIN  loss dict: {'classification_loss': 0.12645952472101069}
2024-10-10 02:50:00,684 [INFO] [29] VALIDATION loss: 1.0277940239067431 VALIDATION  acc: 0.7626262626262627
2024-10-10 02:50:00,684 [INFO] [29] VALIDATION  loss dict: {'classification_loss': 1.0277940239067431}
2024-10-10 02:50:00,684 [INFO] 
2024-10-10 02:51:25,930 [INFO] Step[50/144]: training loss : 0.10118956223130227 TRAIN  loss dict:  {'classification_loss': 0.10118956223130227}
2024-10-10 02:52:23,441 [INFO] Step[100/144]: training loss : 0.09497965216636657 TRAIN  loss dict:  {'classification_loss': 0.09497965216636657}
2024-10-10 02:54:16,414 [INFO] Label accuracies statistics:
2024-10-10 02:54:16,414 [INFO] {0: 0.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.5, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 1.0, 87: 1.0, 88: 0.5, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 1.0, 141: 0.5, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.5}

2024-10-10 02:54:16,502 [INFO] [30] TRAIN  loss: 0.09888778147028966 acc: 0.9798424467099166
2024-10-10 02:54:16,502 [INFO] [30] TRAIN  loss dict: {'classification_loss': 0.09888778147028966}
2024-10-10 02:54:16,502 [INFO] [30] VALIDATION loss: 1.0218196919670812 VALIDATION  acc: 0.75
2024-10-10 02:54:16,502 [INFO] [30] VALIDATION  loss dict: {'classification_loss': 1.0218196919670812}
2024-10-10 02:54:16,502 [INFO] 
2024-10-10 02:55:41,503 [INFO] Step[50/144]: training loss : 0.11273698765784503 TRAIN  loss dict:  {'classification_loss': 0.11273698765784503}
2024-10-10 02:56:39,734 [INFO] Step[100/144]: training loss : 0.11677382919937372 TRAIN  loss dict:  {'classification_loss': 0.11677382919937372}
2024-10-10 02:58:29,133 [INFO] Label accuracies statistics:
2024-10-10 02:58:29,133 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 1.0, 7: 0.5, 8: 0.5, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.0, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.5, 67: 0.5, 68: 0.25, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.25, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.5, 105: 1.0, 106: 0.75, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.25, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.25, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.5, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.5, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 0.75, 198: 0.75}

2024-10-10 02:58:29,212 [INFO] [31] TRAIN  loss: 0.1155559683425559 acc: 0.9703429101019463
2024-10-10 02:58:29,212 [INFO] [31] TRAIN  loss dict: {'classification_loss': 0.1155559683425559}
2024-10-10 02:58:29,212 [INFO] [31] VALIDATION loss: 1.073352773156431 VALIDATION  acc: 0.7512626262626263
2024-10-10 02:58:29,212 [INFO] [31] VALIDATION  loss dict: {'classification_loss': 1.073352773156431}
2024-10-10 02:58:29,212 [INFO] 
2024-10-10 02:59:53,229 [INFO] Step[50/144]: training loss : 0.08093276143074035 TRAIN  loss dict:  {'classification_loss': 0.08093276143074035}
2024-10-10 03:00:51,666 [INFO] Step[100/144]: training loss : 0.12053363293409347 TRAIN  loss dict:  {'classification_loss': 0.12053363293409347}
2024-10-10 03:02:41,258 [INFO] Label accuracies statistics:
2024-10-10 03:02:41,258 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.25, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 0.75, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.5, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.5, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 03:02:42,061 [INFO] [32] TRAIN  loss: 0.10226921131834388 acc: 0.9747451343836886
2024-10-10 03:02:42,061 [INFO] [32] TRAIN  loss dict: {'classification_loss': 0.10226921131834388}
2024-10-10 03:02:42,061 [INFO] [32] VALIDATION loss: 0.9447742330807226 VALIDATION  acc: 0.7449494949494949
2024-10-10 03:02:42,061 [INFO] [32] VALIDATION  loss dict: {'classification_loss': 0.9447742330807226}
2024-10-10 03:02:42,061 [INFO] 
2024-10-10 03:04:05,984 [INFO] Step[50/144]: training loss : 0.09221773359924555 TRAIN  loss dict:  {'classification_loss': 0.09221773359924555}
2024-10-10 03:05:04,487 [INFO] Step[100/144]: training loss : 0.09383146431297064 TRAIN  loss dict:  {'classification_loss': 0.09383146431297064}
2024-10-10 03:06:53,690 [INFO] Label accuracies statistics:
2024-10-10 03:06:53,691 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.75, 29: 0.5, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.5, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 1.0, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 0.5, 178: 0.75, 179: 0.3333333333333333, 180: 0.5, 181: 0.75, 182: 0.0, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 03:06:53,765 [INFO] [33] TRAIN  loss: 0.08718953104431017 acc: 0.9805375347544022
2024-10-10 03:06:53,765 [INFO] [33] TRAIN  loss dict: {'classification_loss': 0.08718953104431017}
2024-10-10 03:06:53,766 [INFO] [33] VALIDATION loss: 0.9696678905575363 VALIDATION  acc: 0.773989898989899
2024-10-10 03:06:53,766 [INFO] [33] VALIDATION  loss dict: {'classification_loss': 0.9696678905575363}
2024-10-10 03:06:53,766 [INFO] 
2024-10-10 03:08:17,925 [INFO] Step[50/144]: training loss : 0.0918583632260561 TRAIN  loss dict:  {'classification_loss': 0.0918583632260561}
2024-10-10 03:09:16,297 [INFO] Step[100/144]: training loss : 0.08207432128489017 TRAIN  loss dict:  {'classification_loss': 0.08207432128489017}
2024-10-10 03:11:05,610 [INFO] Label accuracies statistics:
2024-10-10 03:11:05,610 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.75, 20: 0.75, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.5, 90: 0.75, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.3333333333333333, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.75, 184: 0.25, 185: 1.0, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 1.0, 194: 0.75, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.5}

2024-10-10 03:11:05,690 [INFO] [34] TRAIN  loss: 0.08651022353054334 acc: 0.9796107506950881
2024-10-10 03:11:05,690 [INFO] [34] TRAIN  loss dict: {'classification_loss': 0.08651022353054334}
2024-10-10 03:11:05,690 [INFO] [34] VALIDATION loss: 0.960932637254397 VALIDATION  acc: 0.7525252525252525
2024-10-10 03:11:05,690 [INFO] [34] VALIDATION  loss dict: {'classification_loss': 0.960932637254397}
2024-10-10 03:11:05,690 [INFO] 
2024-10-10 03:12:29,550 [INFO] Step[50/144]: training loss : 0.07661094971001148 TRAIN  loss dict:  {'classification_loss': 0.07661094971001148}
2024-10-10 03:13:28,201 [INFO] Step[100/144]: training loss : 0.07190934404730796 TRAIN  loss dict:  {'classification_loss': 0.07190934404730796}
2024-10-10 03:15:20,403 [INFO] Label accuracies statistics:
2024-10-10 03:15:20,404 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 1.0, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 0.75, 87: 1.0, 88: 0.25, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.25}

2024-10-10 03:15:21,209 [INFO] [35] TRAIN  loss: 0.07265417708549649 acc: 0.9844763670064874
2024-10-10 03:15:21,209 [INFO] [35] TRAIN  loss dict: {'classification_loss': 0.07265417708549649}
2024-10-10 03:15:21,209 [INFO] [35] VALIDATION loss: 0.9419254572303207 VALIDATION  acc: 0.7449494949494949
2024-10-10 03:15:21,209 [INFO] [35] VALIDATION  loss dict: {'classification_loss': 0.9419254572303207}
2024-10-10 03:15:21,209 [INFO] 
2024-10-10 03:16:46,621 [INFO] Step[50/144]: training loss : 0.06304982114583253 TRAIN  loss dict:  {'classification_loss': 0.06304982114583253}
2024-10-10 03:17:45,134 [INFO] Step[100/144]: training loss : 0.06169812079519033 TRAIN  loss dict:  {'classification_loss': 0.06169812079519033}
2024-10-10 03:19:34,160 [INFO] Label accuracies statistics:
2024-10-10 03:19:34,160 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 1.0, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.0, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.25, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 1.0, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 03:19:34,237 [INFO] [36] TRAIN  loss: 0.06589179205346024 acc: 0.9870250231696015
2024-10-10 03:19:34,237 [INFO] [36] TRAIN  loss dict: {'classification_loss': 0.06589179205346024}
2024-10-10 03:19:34,238 [INFO] [36] VALIDATION loss: 0.9628097166617712 VALIDATION  acc: 0.7765151515151515
2024-10-10 03:19:34,238 [INFO] [36] VALIDATION  loss dict: {'classification_loss': 0.9628097166617712}
2024-10-10 03:19:34,238 [INFO] 
2024-10-10 03:20:59,027 [INFO] Step[50/144]: training loss : 0.06273300608620047 TRAIN  loss dict:  {'classification_loss': 0.06273300608620047}
2024-10-10 03:21:57,535 [INFO] Step[100/144]: training loss : 0.0560051129758358 TRAIN  loss dict:  {'classification_loss': 0.0560051129758358}
2024-10-10 03:23:46,974 [INFO] Label accuracies statistics:
2024-10-10 03:23:46,974 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 1.0, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.25, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.25, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.0, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.5, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 03:23:47,050 [INFO] [37] TRAIN  loss: 0.06328805071017188 acc: 0.9856348470806302
2024-10-10 03:23:47,050 [INFO] [37] TRAIN  loss dict: {'classification_loss': 0.06328805071017188}
2024-10-10 03:23:47,050 [INFO] [37] VALIDATION loss: 1.0211724288485668 VALIDATION  acc: 0.7550505050505051
2024-10-10 03:23:47,050 [INFO] [37] VALIDATION  loss dict: {'classification_loss': 1.0211724288485668}
2024-10-10 03:23:47,050 [INFO] 
2024-10-10 03:25:11,867 [INFO] Step[50/144]: training loss : 0.06088085576891899 TRAIN  loss dict:  {'classification_loss': 0.06088085576891899}
2024-10-10 03:26:10,073 [INFO] Step[100/144]: training loss : 0.055321962498128416 TRAIN  loss dict:  {'classification_loss': 0.055321962498128416}
2024-10-10 03:27:59,370 [INFO] Label accuracies statistics:
2024-10-10 03:27:59,370 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.25, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 1.0, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 0.5, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 03:28:00,141 [INFO] [38] TRAIN  loss: 0.0632929372950457 acc: 0.9844763670064874
2024-10-10 03:28:00,141 [INFO] [38] TRAIN  loss dict: {'classification_loss': 0.0632929372950457}
2024-10-10 03:28:00,142 [INFO] [38] VALIDATION loss: 0.9102569721915104 VALIDATION  acc: 0.7664141414141414
2024-10-10 03:28:00,142 [INFO] [38] VALIDATION  loss dict: {'classification_loss': 0.9102569721915104}
2024-10-10 03:28:00,142 [INFO] 
2024-10-10 03:29:24,600 [INFO] Step[50/144]: training loss : 0.04486340496689081 TRAIN  loss dict:  {'classification_loss': 0.04486340496689081}
2024-10-10 03:30:22,797 [INFO] Step[100/144]: training loss : 0.04478101901710033 TRAIN  loss dict:  {'classification_loss': 0.04478101901710033}
2024-10-10 03:32:12,116 [INFO] Label accuracies statistics:
2024-10-10 03:32:12,116 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 1.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.3333333333333333, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.5, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.75, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.5, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 03:32:12,192 [INFO] [39] TRAIN  loss: 0.049417111544042 acc: 0.9914272474513438
2024-10-10 03:32:12,192 [INFO] [39] TRAIN  loss dict: {'classification_loss': 0.049417111544042}
2024-10-10 03:32:12,192 [INFO] [39] VALIDATION loss: 0.9895207749472724 VALIDATION  acc: 0.7664141414141414
2024-10-10 03:32:12,192 [INFO] [39] VALIDATION  loss dict: {'classification_loss': 0.9895207749472724}
2024-10-10 03:32:12,193 [INFO] 
2024-10-10 03:33:36,236 [INFO] Step[50/144]: training loss : 0.05264509987086058 TRAIN  loss dict:  {'classification_loss': 0.05264509987086058}
2024-10-10 03:34:34,858 [INFO] Step[100/144]: training loss : 0.06589782632887363 TRAIN  loss dict:  {'classification_loss': 0.06589782632887363}
2024-10-10 03:36:27,278 [INFO] Label accuracies statistics:
2024-10-10 03:36:27,278 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 0.75, 163: 1.0, 164: 1.0, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 0.5, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.5, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 03:36:27,357 [INFO] [40] TRAIN  loss: 0.055808083943298295 acc: 0.9874884151992586
2024-10-10 03:36:27,357 [INFO] [40] TRAIN  loss dict: {'classification_loss': 0.055808083943298295}
2024-10-10 03:36:27,357 [INFO] [40] VALIDATION loss: 0.9798828827010261 VALIDATION  acc: 0.7537878787878788
2024-10-10 03:36:27,357 [INFO] [40] VALIDATION  loss dict: {'classification_loss': 0.9798828827010261}
2024-10-10 03:36:27,357 [INFO] 
2024-10-10 03:37:53,347 [INFO] Step[50/144]: training loss : 0.041642612013965845 TRAIN  loss dict:  {'classification_loss': 0.041642612013965845}
2024-10-10 03:38:52,136 [INFO] Step[100/144]: training loss : 0.0584553562104702 TRAIN  loss dict:  {'classification_loss': 0.0584553562104702}
2024-10-10 03:40:41,805 [INFO] Label accuracies statistics:
2024-10-10 03:40:41,806 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.25, 12: 0.25, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.0, 59: 0.5, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.25, 143: 0.25, 144: 0.5, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 03:40:41,883 [INFO] [41] TRAIN  loss: 0.051545205416106105 acc: 0.9900370713623726
2024-10-10 03:40:41,883 [INFO] [41] TRAIN  loss dict: {'classification_loss': 0.051545205416106105}
2024-10-10 03:40:41,883 [INFO] [41] VALIDATION loss: 0.9844198960948873 VALIDATION  acc: 0.7537878787878788
2024-10-10 03:40:41,883 [INFO] [41] VALIDATION  loss dict: {'classification_loss': 0.9844198960948873}
2024-10-10 03:40:41,883 [INFO] 
2024-10-10 03:42:06,223 [INFO] Step[50/144]: training loss : 0.05085277678444981 TRAIN  loss dict:  {'classification_loss': 0.05085277678444981}
2024-10-10 03:43:04,995 [INFO] Step[100/144]: training loss : 0.05147800804115832 TRAIN  loss dict:  {'classification_loss': 0.05147800804115832}
2024-10-10 03:44:54,559 [INFO] Label accuracies statistics:
2024-10-10 03:44:54,559 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.75, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.25, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 1.0, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.3333333333333333, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 03:44:54,637 [INFO] [42] TRAIN  loss: 0.05249017066671513 acc: 0.986793327154773
2024-10-10 03:44:54,638 [INFO] [42] TRAIN  loss dict: {'classification_loss': 0.05249017066671513}
2024-10-10 03:44:54,638 [INFO] [42] VALIDATION loss: 0.9345793036261091 VALIDATION  acc: 0.7866161616161617
2024-10-10 03:44:54,638 [INFO] [42] VALIDATION  loss dict: {'classification_loss': 0.9345793036261091}
2024-10-10 03:44:54,638 [INFO] 
2024-10-10 03:46:18,757 [INFO] Step[50/144]: training loss : 0.03707739114761353 TRAIN  loss dict:  {'classification_loss': 0.03707739114761353}
2024-10-10 03:47:17,215 [INFO] Step[100/144]: training loss : 0.053188728224486115 TRAIN  loss dict:  {'classification_loss': 0.053188728224486115}
2024-10-10 03:49:06,796 [INFO] Label accuracies statistics:
2024-10-10 03:49:06,796 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.0, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-10-10 03:49:06,878 [INFO] [43] TRAIN  loss: 0.04726711219862207 acc: 0.9895736793327155
2024-10-10 03:49:06,878 [INFO] [43] TRAIN  loss dict: {'classification_loss': 0.04726711219862207}
2024-10-10 03:49:06,878 [INFO] [43] VALIDATION loss: 0.9662986784069626 VALIDATION  acc: 0.7765151515151515
2024-10-10 03:49:06,878 [INFO] [43] VALIDATION  loss dict: {'classification_loss': 0.9662986784069626}
2024-10-10 03:49:06,879 [INFO] 
2024-10-10 03:50:31,440 [INFO] Step[50/144]: training loss : 0.05005593759939075 TRAIN  loss dict:  {'classification_loss': 0.05005593759939075}
2024-10-10 03:51:29,977 [INFO] Step[100/144]: training loss : 0.04388325724750757 TRAIN  loss dict:  {'classification_loss': 0.04388325724750757}
2024-10-10 03:53:19,586 [INFO] Label accuracies statistics:
2024-10-10 03:53:19,586 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 0.75, 10: 0.5, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 0.75, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.75, 61: 0.5, 62: 0.75, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 0.75, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.0, 154: 0.75, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.5, 165: 0.5, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 03:53:19,662 [INFO] [44] TRAIN  loss: 0.04605388424695573 acc: 0.9900370713623726
2024-10-10 03:53:19,662 [INFO] [44] TRAIN  loss dict: {'classification_loss': 0.04605388424695573}
2024-10-10 03:53:19,662 [INFO] [44] VALIDATION loss: 0.9646224716195354 VALIDATION  acc: 0.7613636363636364
2024-10-10 03:53:19,662 [INFO] [44] VALIDATION  loss dict: {'classification_loss': 0.9646224716195354}
2024-10-10 03:53:19,662 [INFO] 
2024-10-10 03:54:43,384 [INFO] Step[50/144]: training loss : 0.03964394454844296 TRAIN  loss dict:  {'classification_loss': 0.03964394454844296}
2024-10-10 03:55:41,680 [INFO] Step[100/144]: training loss : 0.054118174221366645 TRAIN  loss dict:  {'classification_loss': 0.054118174221366645}
2024-10-10 03:57:34,383 [INFO] Label accuracies statistics:
2024-10-10 03:57:34,383 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.75, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.25, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 1.0, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.0}

2024-10-10 03:57:34,473 [INFO] [45] TRAIN  loss: 0.04596085049949276 acc: 0.9905004633920297
2024-10-10 03:57:34,473 [INFO] [45] TRAIN  loss dict: {'classification_loss': 0.04596085049949276}
2024-10-10 03:57:34,474 [INFO] [45] VALIDATION loss: 1.011429920240685 VALIDATION  acc: 0.7702020202020202
2024-10-10 03:57:34,474 [INFO] [45] VALIDATION  loss dict: {'classification_loss': 1.011429920240685}
2024-10-10 03:57:34,474 [INFO] 
2024-10-10 03:59:00,353 [INFO] Step[50/144]: training loss : 0.03792489755898714 TRAIN  loss dict:  {'classification_loss': 0.03792489755898714}
2024-10-10 03:59:58,936 [INFO] Step[100/144]: training loss : 0.0498625965975225 TRAIN  loss dict:  {'classification_loss': 0.0498625965975225}
2024-10-10 04:01:48,058 [INFO] Label accuracies statistics:
2024-10-10 04:01:48,058 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.5, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.25, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.5, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.25, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.5, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.25, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.75, 163: 1.0, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.25, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 0.75, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-10-10 04:01:48,134 [INFO] [46] TRAIN  loss: 0.04384581349828901 acc: 0.9902687673772012
2024-10-10 04:01:48,134 [INFO] [46] TRAIN  loss dict: {'classification_loss': 0.04384581349828901}
2024-10-10 04:01:48,134 [INFO] [46] VALIDATION loss: 0.9535845678161692 VALIDATION  acc: 0.7613636363636364
2024-10-10 04:01:48,134 [INFO] [46] VALIDATION  loss dict: {'classification_loss': 0.9535845678161692}
2024-10-10 04:01:48,134 [INFO] 
2024-10-10 04:03:12,690 [INFO] Step[50/144]: training loss : 0.03622458120808005 TRAIN  loss dict:  {'classification_loss': 0.03622458120808005}
2024-10-10 04:04:11,022 [INFO] Step[100/144]: training loss : 0.04319903907366097 TRAIN  loss dict:  {'classification_loss': 0.04319903907366097}
2024-10-10 04:05:59,994 [INFO] Label accuracies statistics:
2024-10-10 04:05:59,994 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.75, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.75, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 0.75, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 04:06:00,079 [INFO] [47] TRAIN  loss: 0.04070870627765544 acc: 0.9905004633920297
2024-10-10 04:06:00,079 [INFO] [47] TRAIN  loss dict: {'classification_loss': 0.04070870627765544}
2024-10-10 04:06:00,079 [INFO] [47] VALIDATION loss: 0.9408766246504254 VALIDATION  acc: 0.7803030303030303
2024-10-10 04:06:00,079 [INFO] [47] VALIDATION  loss dict: {'classification_loss': 0.9408766246504254}
2024-10-10 04:06:00,080 [INFO] 
2024-10-10 04:07:23,783 [INFO] Step[50/144]: training loss : 0.04136421646922827 TRAIN  loss dict:  {'classification_loss': 0.04136421646922827}
2024-10-10 04:08:22,421 [INFO] Step[100/144]: training loss : 0.04363849254325032 TRAIN  loss dict:  {'classification_loss': 0.04363849254325032}
2024-10-10 04:10:17,649 [INFO] Label accuracies statistics:
2024-10-10 04:10:17,650 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.25, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 0.75, 41: 0.25, 42: 0.75, 43: 0.75, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.25, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.5, 61: 0.5, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.5, 98: 0.75, 99: 0.8, 100: 0.75, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.25, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 1.0, 160: 0.75, 161: 1.0, 162: 1.0, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.5, 176: 1.0, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 04:10:17,724 [INFO] [48] TRAIN  loss: 0.045613493408179946 acc: 0.9888785912882299
2024-10-10 04:10:17,724 [INFO] [48] TRAIN  loss dict: {'classification_loss': 0.045613493408179946}
2024-10-10 04:10:17,724 [INFO] [48] VALIDATION loss: 0.9770415005860505 VALIDATION  acc: 0.7714646464646465
2024-10-10 04:10:17,725 [INFO] [48] VALIDATION  loss dict: {'classification_loss': 0.9770415005860505}
2024-10-10 04:10:17,725 [INFO] 
2024-10-10 04:11:41,545 [INFO] Step[50/144]: training loss : 0.031735062142834065 TRAIN  loss dict:  {'classification_loss': 0.031735062142834065}
2024-10-10 04:12:39,794 [INFO] Step[100/144]: training loss : 0.03403025326319039 TRAIN  loss dict:  {'classification_loss': 0.03403025326319039}
2024-10-10 04:14:29,219 [INFO] Label accuracies statistics:
2024-10-10 04:14:29,219 [INFO] {0: 0.3333333333333333, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.5, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.0, 42: 0.75, 43: 1.0, 44: 0.75, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.5, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 0.75, 105: 0.75, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 1.0, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.25, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 1.0, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 04:14:29,298 [INFO] [49] TRAIN  loss: 0.03564361781334608 acc: 0.9921223354958295
2024-10-10 04:14:29,298 [INFO] [49] TRAIN  loss dict: {'classification_loss': 0.03564361781334608}
2024-10-10 04:14:29,298 [INFO] [49] VALIDATION loss: 1.0001123431656096 VALIDATION  acc: 0.7651515151515151
2024-10-10 04:14:29,298 [INFO] [49] VALIDATION  loss dict: {'classification_loss': 1.0001123431656096}
2024-10-10 04:14:29,298 [INFO] 
2024-10-10 04:15:53,522 [INFO] Step[50/144]: training loss : 0.031034888327121736 TRAIN  loss dict:  {'classification_loss': 0.031034888327121736}
2024-10-10 04:16:51,639 [INFO] Step[100/144]: training loss : 0.03653709561564028 TRAIN  loss dict:  {'classification_loss': 0.03653709561564028}
2024-10-10 04:18:41,667 [INFO] Label accuracies statistics:
2024-10-10 04:18:41,667 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.5, 37: 0.75, 38: 0.5, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.25, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.25, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.25, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.0, 98: 0.75, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.75, 145: 0.5, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 04:18:41,743 [INFO] [50] TRAIN  loss: 0.035316465684445575 acc: 0.9909638554216867
2024-10-10 04:18:41,743 [INFO] [50] TRAIN  loss dict: {'classification_loss': 0.035316465684445575}
2024-10-10 04:18:41,744 [INFO] [50] VALIDATION loss: 1.089348376625114 VALIDATION  acc: 0.7525252525252525
2024-10-10 04:18:41,744 [INFO] [50] VALIDATION  loss dict: {'classification_loss': 1.089348376625114}
2024-10-10 04:18:41,744 [INFO] 
2024-10-10 04:20:12,080 [INFO] Step[50/144]: training loss : 0.035746272280812265 TRAIN  loss dict:  {'classification_loss': 0.035746272280812265}
2024-10-10 04:21:10,971 [INFO] Step[100/144]: training loss : 0.026605122117325665 TRAIN  loss dict:  {'classification_loss': 0.026605122117325665}
2024-10-10 04:23:00,414 [INFO] Label accuracies statistics:
2024-10-10 04:23:00,414 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.6666666666666666, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.5, 37: 0.75, 38: 1.0, 39: 1.0, 40: 0.75, 41: 0.5, 42: 0.75, 43: 0.75, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.5, 86: 1.0, 87: 0.75, 88: 0.25, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.0, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 1.0, 164: 0.75, 165: 0.5, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 1.0, 175: 0.25, 176: 0.5, 177: 1.0, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.25, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.75}

2024-10-10 04:23:00,497 [INFO] [51] TRAIN  loss: 0.029844109198570043 acc: 0.9930491195551436
2024-10-10 04:23:00,497 [INFO] [51] TRAIN  loss dict: {'classification_loss': 0.029844109198570043}
2024-10-10 04:23:00,498 [INFO] [51] VALIDATION loss: 0.9933911194955861 VALIDATION  acc: 0.7777777777777778
2024-10-10 04:23:00,498 [INFO] [51] VALIDATION  loss dict: {'classification_loss': 0.9933911194955861}
2024-10-10 04:23:00,498 [INFO] 
2024-10-10 04:24:24,428 [INFO] Step[50/144]: training loss : 0.02634658997878432 TRAIN  loss dict:  {'classification_loss': 0.02634658997878432}
2024-10-10 04:25:22,806 [INFO] Step[100/144]: training loss : 0.03031100668013096 TRAIN  loss dict:  {'classification_loss': 0.03031100668013096}
2024-10-10 04:27:11,992 [INFO] Label accuracies statistics:
2024-10-10 04:27:11,992 [INFO] {0: 0.6666666666666666, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.5, 22: 0.75, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 0.75, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.75, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.5, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.5, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 1.0, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 0.75, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.6666666666666666, 159: 0.75, 160: 0.75, 161: 0.5, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.75, 169: 0.75, 170: 0.75, 171: 0.25, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.5, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.25, 183: 1.0, 184: 0.5, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-10-10 04:27:12,067 [INFO] [52] TRAIN  loss: 0.029146307898271415 acc: 0.9942075996292864
2024-10-10 04:27:12,067 [INFO] [52] TRAIN  loss dict: {'classification_loss': 0.029146307898271415}
2024-10-10 04:27:12,067 [INFO] [52] VALIDATION loss: 1.0431496989395883 VALIDATION  acc: 0.7689393939393939
2024-10-10 04:27:12,067 [INFO] [52] VALIDATION  loss dict: {'classification_loss': 1.0431496989395883}
2024-10-10 04:27:12,067 [INFO] 
2024-10-10 04:28:36,344 [INFO] Step[50/144]: training loss : 0.025479493401944636 TRAIN  loss dict:  {'classification_loss': 0.025479493401944636}
2024-10-10 04:29:34,590 [INFO] Step[100/144]: training loss : 0.02162222005892545 TRAIN  loss dict:  {'classification_loss': 0.02162222005892545}
2024-10-10 04:31:23,379 [INFO] Label accuracies statistics:
2024-10-10 04:31:23,379 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.25, 5: 0.5, 6: 1.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 0.25, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.3333333333333333, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.25, 21: 0.5, 22: 0.75, 23: 0.5, 24: 1.0, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.75, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.25, 42: 0.75, 43: 0.5, 44: 0.5, 45: 0.75, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 0.75, 57: 0.75, 58: 0.5, 59: 0.5, 60: 0.5, 61: 1.0, 62: 0.75, 63: 0.75, 64: 1.0, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 1.0, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 0.75, 83: 0.5, 84: 0.5, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.5, 89: 0.5, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.25, 95: 1.0, 96: 0.75, 97: 0.25, 98: 1.0, 99: 0.8, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 0.75, 105: 1.0, 106: 1.0, 107: 0.5, 108: 1.0, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.25, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.25, 146: 1.0, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 1.0, 158: 0.6666666666666666, 159: 0.5, 160: 0.75, 161: 0.5, 162: 1.0, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 1.0, 173: 1.0, 174: 1.0, 175: 0.75, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-10-10 04:31:23,453 [INFO] [53] TRAIN  loss: 0.022807801473795228 acc: 0.9962928637627433
2024-10-10 04:31:23,453 [INFO] [53] TRAIN  loss dict: {'classification_loss': 0.022807801473795228}
2024-10-10 04:31:23,453 [INFO] [53] VALIDATION loss: 1.001166262836368 VALIDATION  acc: 0.7803030303030303
2024-10-10 04:31:23,453 [INFO] [53] VALIDATION  loss dict: {'classification_loss': 1.001166262836368}
2024-10-10 04:31:23,453 [INFO] 
2024-10-10 04:31:23,454 [INFO] 

***Stop training***


2024-10-10 04:31:23,454 [INFO] 
Testing checkpointed models starting...

2024-10-10 04:32:12,507 [INFO] Label accuracies statistics:
2024-10-10 04:32:12,507 [INFO] {0: 1.0, 1: 1.0, 2: 1.0, 3: 0.75, 4: 0.0, 5: 0.75, 6: 0.5, 7: 0.5, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 0.5, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.3333333333333333, 18: 0.5, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 1.0, 24: 1.0, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.25, 31: 1.0, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 0.5, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 1.0, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 0.5, 57: 0.5, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.5, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 1.0, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 1.0, 74: 1.0, 75: 0.75, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 1.0, 81: 1.0, 82: 0.5, 83: 0.5, 84: 1.0, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.5, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 0.75, 96: 1.0, 97: 0.25, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.5, 103: 0.75, 104: 0.75, 105: 0.5, 106: 1.0, 107: 0.25, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.5, 115: 0.5, 116: 0.75, 117: 1.0, 118: 1.0, 119: 0.75, 120: 0.6666666666666666, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 1.0, 129: 0.75, 130: 0.25, 131: 1.0, 132: 0.5, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.5, 143: 0.75, 144: 0.5, 145: 1.0, 146: 1.0, 147: 0.75, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.75, 158: 0.5, 159: 0.5, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.25, 169: 0.5, 170: 1.0, 171: 0.25, 172: 1.0, 173: 1.0, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.5, 184: 0.25, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.0, 196: 1.0, 197: 0.5, 198: 0.75}

2024-10-10 04:32:12,576 [INFO] 
Testing accuracy: 0.7585335018963337
